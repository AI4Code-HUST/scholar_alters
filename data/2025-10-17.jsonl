{"title": "Optimizing Code Embeddings and ML Classifiers for Python Source Code Vulnerability Detection", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "T Farasat, J Posegga- arXiv preprint arXiv:2509.13134, 2025\nIn recent years, the growing complexity and scale of source code have rendered \nmanual software vulnerability detection increasingly impractical. To address this \nchallenge, automated approaches leveraging machine learning and code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.13134&hl=en&sa=X&d=14295113236664440900&ei=6m7waOf6IZOJ6rQPlJbh-Qc&scisig=AAZF9b8AK1x4BcUSDUudz66M56i3&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Brevity is the Soul of Wit: Condensing Code Changes to Improve Commit Message Generation", "first_label": ["Code", "Commit Message", "Code Change"], "second_label": ["Generation"], "data": "H Kuang, N Zhang, H Gao, X Zhou, WKG Assuno- arXiv preprint arXiv, 2025\nCommit messages are valuable resources for describing why code changes are \ncommitted to repositories in version control systems (eg, Git). They effectively help \ndevelopers understand code changes and better perform software maintenance", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.15567&hl=en&sa=X&d=3566966376596200560&ei=6m7waOf6IZOJ6rQPlJbh-Qc&scisig=AAZF9b-vZA0Uf808DqbPbNRX2qRx&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Balancing Validity and Vulnerability: Knowledge-Driven Seed Generation via LLMs for Deep Learning Library Fuzzing", "first_label": ["Vulnerabilities", "LLM", "Fuzzing"], "second_label": ["Generation"], "data": "R Liao, X Yan, Z Pang, K Zhu- Applied Sciences, 2025\nFuzzing deep learning (DL) libraries is essential for uncovering security \nvulnerabilities in AI systems. Existing approaches enhance large language models \n(LLMs) with external knowledge such as bug reports to improve the quality of", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2076-3417/15/19/10396&hl=en&sa=X&d=9374413942225787882&ei=6m7waOf6IZOJ6rQPlJbh-Qc&scisig=AAZF9b_coV2M25K3l6JkCX-ZdrMr&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "PIONEER: improving the robustness of student models when compressing pre-trained models of code", "first_label": ["Code"], "second_label": [], "data": "X Liu, X Liu, L Bo, X Wu, Y Yang, X Sun, F Zhou- Automated Software Engineering, 2026\nPre-trained models of code have shown significant effectiveness in a variety of \nsoftware engineering tasks, but they are difficult for local deployment due to their \nlarge size. Existing works mainly focus on compressing these large models into small", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00560-2&hl=en&sa=X&d=17836676178374949159&ei=6m7waOf6IZOJ6rQPlJbh-Qc&scisig=AAZF9b_ryg7uDpBLUFYEs8zWj5qt&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Assertion Messages with Large Language Models (LLMs) for Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "A Aljohani, AH Mollah, H Do- arXiv preprint arXiv:2509.19673, 2025\nAssertion messages significantly enhance unit tests by clearly explaining the \nreasons behind test failures, yet they are frequently omitted by developers and \nautomated test-generation tools. Despite recent advancements, Large Language", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19673&hl=en&sa=X&d=7084463702742822906&ei=6m7waOf6IZOJ6rQPlJbh-Qc&scisig=AAZF9b93i6m23y0xnjeM1zyUGkQc&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "for Learning-Based Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "RZL Foulefack, A Marchetto- Testing Software and Systems: 37th IFIP WG 6.1\nStatic code analysis conducted by means of learning-based methods is an essential \npart of Security Testing. Effective learning algo-rithms are crucial for training reliable \nmodels that can accurately detect weaknesses and vulnerabilities. During models'", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DHQuHEQAAQBAJ%26oi%3Dfnd%26pg%3DPA307%26ots%3DdVPscsSuzt%26sig%3DkHflsj_fv3tLaPJ1iQBn8xu3TgQ&hl=en&sa=X&d=879843498815082224&ei=6m7waOf6IZOJ6rQPlJbh-Qc&scisig=AAZF9b-ovLozj_0O3OrhH8tHGoVz&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Automating Code Generation for Semiconductor Equipment Control from Developer Utterances with LLMs", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Y Kim, S Park, M Kim, G Yoon, E Lee, SS Woo- arXiv preprint arXiv:2509.13055, 2025\nSemiconductors form the backbone of modern electronics, with their manufacturing \nand testing relying on highly specialized equipment and domain-specific \nprogramming languages. Equipment languages such as the Algorithmic Pattern", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.13055&hl=en&sa=X&d=8083439099579672792&ei=6m7waOf6IZOJ6rQPlJbh-Qc&scisig=AAZF9b_6B1-ggVyk13BUPke_jxTs&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "VulTriNet: A software vulnerability detection method based on tri-channel network", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "Y Yang, Y Yao, X Lv, W Chen- Information and Software Technology, 2025\nContext: Software vulnerabilities represent a critical concern in cybersecurity. As \nvulnerability patterns become increasingly complex, advanced detection methods \nare needed to fully analyze them. Recent studies have treated source codes as text", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925002320&hl=en&sa=X&d=6846078968872890597&ei=6m7waOf6IZOJ6rQPlJbh-Qc&scisig=AAZF9b9A2WNvXsJ4XtBAnM84SodY&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Beyond Syntax: Testing LLM Semantic Understanding of Code", "first_label": ["LLM", "Code", "Software Testing"], "second_label": [], "data": "A Saban, TF Bissyand- Africa Data, Artificial Intelligence and Innovations: First\nWhile Large Language Models (LLMs) have shown promise in various software \nengineering tasks, their deep understanding of code semantics remains a \nchallenging area. This paper introduces a novel methodology to probe the semantic\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DCR2LEQAAQBAJ%26oi%3Dfnd%26pg%3DPA3%26ots%3D3_pwzWwFGd%26sig%3DvFcGFyyVCtQVhJLQHrGDtJDQlro&hl=en&sa=X&d=9474776293014934540&ei=6m7waOf6IZOJ6rQPlJbh-Qc&scisig=AAZF9b_2AW_TcWrcQoUEO5DiinlJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "RelRepair: Enhancing Automated Program Repair by Retrieving Relevant Code", "first_label": ["APR", "Code"], "second_label": ["Repair"], "data": "S Liu, G Bai, M Utting, G Yang- arXiv preprint arXiv:2509.16701, 2025\nAutomated Program Repair (APR) has emerged as a promising paradigm for \nreducing debugging time and improving the overall efficiency of software \ndevelopment. Recent advances in Large Language Models (LLMs) have", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.16701&hl=en&sa=X&d=15347269361517940440&ei=6G7waMyNDJOJ6rQPlJbh-Qc&scisig=AAZF9b8vu1eZydL8Y3sfpnI8ZfQS&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Evaluating the Effectiveness of Coverage-Guided Fuzzing for Testing Deep Learning Library APIs", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "F Qin, MM Naziri, H Ai, S Dutta, M d'Amorim- arXiv preprint arXiv:2509.14626, 2025\nDeep Learning (DL) libraries such as PyTorch provide the core components to build \nmajor AI-enabled applications. Finding bugs in these libraries is important and \nchallenging. Prior approaches have tackled this by performing either API-level\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.14626&hl=en&sa=X&d=11350896954294303435&ei=6G7waMyNDJOJ6rQPlJbh-Qc&scisig=AAZF9b_GT4mzQ2w1NTOQ8RIfpK9G&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Fuzzing as editor feedback", "first_label": ["Fuzzing"], "second_label": [], "data": "M Garus, J Lincke, R Hirschfeld- Companion Proceedings of the 9th International, 2025\nLive programming requires concrete examples, but coming up with examples takes \neffort. However, there are ways to execute code without specifying examples, such \nas fuzzing. Fuzzing is a technique that synthesizes program inputs to find bugs in", "link": "https://scholar.google.com/scholar_url?url=https://drops.dagstuhl.de/storage/01oasics/oasics-vol134-programming2025/OASIcs.Programming.2025.8/OASIcs.Programming.2025.8.pdf&hl=en&sa=X&d=4846729257551256103&ei=6G7waODLOt_N6rQPqOmrqQ4&scisig=AAZF9b_a936tJ2euestamYofC9hC&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Semantic-Aware Fuzzing: An Empirical Framework for LLM-Guided, Reasoning-Driven Input Mutation", "first_label": ["LLM", "Fuzzing"], "second_label": ["Reasoning"], "data": "M Lu, S Ding, F Alaca, P Charland- arXiv preprint arXiv:2509.19533, 2025\nSecurity vulnerabilities in Internet-of-Things devices, mobile platforms, and \nautonomous systems remain critical. Traditional mutation-based fuzzers--while \neffectively explore code paths--primarily perform byte-or bit-level edits without", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19533%3F&hl=en&sa=X&d=537743905954534716&ei=6G7waODLOt_N6rQPqOmrqQ4&scisig=AAZF9b_eToZ4RmutapvruNcVtSkV&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "MALF: A Multi-Agent LLM Framework for Intelligent Fuzzing of Industrial Control Protocols", "first_label": ["LLM", "Fuzzing"], "second_label": ["Agent"], "data": "B Ning, X Zong, K He- arXiv preprint arXiv:2510.02694, 2025\nIndustrial control systems (ICS) are vital to modern infrastructure but increasingly \nvulnerable to cybersecurity threats, particularly through weaknesses in their \ncommunication protocols. This paper presents MALF (Multi-Agent LLM Fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02694&hl=en&sa=X&d=17402884467768873558&ei=6G7waODLOt_N6rQPqOmrqQ4&scisig=AAZF9b-gbdcp8la6VIQjpMAaZGFm&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "STAFF: Stateful Taint-Assisted Full-system Firmware Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A Izzillo, R Lazzeretti, E Coppa- arXiv preprint arXiv:2509.18039, 2025\nModern embedded Linux devices, such as routers, IP cameras, and IoT gateways, \nrely on complex software stacks where numerous daemons interact to provide \nservices. Testing these devices is crucial from a security perspective since vendors", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18039&hl=en&sa=X&d=14471577617811823956&ei=6G7waODLOt_N6rQPqOmrqQ4&scisig=AAZF9b8iiNsdPIPeQqPwlBXEq_w5&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Minoris: Practical Out-of-Emulator Kernel Module Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Xiang, F Wang, Y Chen, Q Liu, H Wang, J Wang- IEEE Transactions on, 2025\nVulnerabilities in the Linux kernel can be exploited to perform privilege escalation \nand take over the whole system. Fuzzing has been leveraged to detect Linux kernel \nvulnerabilities during the last decade. However, existing kernel fuzzing techniques", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11186228/&hl=en&sa=X&d=4018952161547770155&ei=6G7waODLOt_N6rQPqOmrqQ4&scisig=AAZF9b_CC9xKPQgXt0Ya_fO_Yt6g&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Extraction and Mutation at a High Level: Template-Based Fuzzing for JavaScript Engines", "first_label": ["Fuzzing"], "second_label": [], "data": "WK Wong, D Xiao, CT Lai, Y Peng, D Wu, S Wang- Proceedings of the ACM on, 2025\nJavaScript (JS) engines implement complex language semantics and optimization \nstrategies to support the dynamic nature of JS, making them difficult to test thoroughly \nand prone to subtle, security-critical bugs. Existing fuzzers often struggle to generate", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3763154&hl=en&sa=X&d=604366854830515299&ei=6G7waODLOt_N6rQPqOmrqQ4&scisig=AAZF9b-zybHDhCRxUx1hTq5-Uny_&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=6&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "R1-Fuzz: Specializing Language Models for Textual Fuzzing via Reinforcement Learning", "first_label": ["LLM", "Fuzzing"], "second_label": [], "data": "J Lin, L Su, J Li, C Qian- arXiv preprint arXiv:2509.20384, 2025\nFuzzing is effective for vulnerability discovery but struggles with complex targets such \nas compilers, interpreters, and database engines, which accept textual input that \nmust satisfy intricate syntactic and semantic constraints. Although language models", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.20384&hl=en&sa=X&d=1649136629077213896&ei=6G7waODLOt_N6rQPqOmrqQ4&scisig=AAZF9b9A_fC3MFUyhQ5sK9VXroDy&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=7&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Thanh Le-Cong - new related research"]}
{"title": "E-FuzzEdge: Optimizing Embedded Device Security with Scalable In-Place Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "D Rusconi, O Yousef, M Picca, F Toffalini, A Lanzi- arXiv preprint arXiv:2510.01393, 2025\nIn this paper we show E-FuzzEdge, a novel fuzzing architecture targeted towards \nimproving the throughput of fuzzing campaigns in contexts where scalability is \nunavailable. E-FuzzEdge addresses the inefficiencies of hardware-in-the-loop", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01393&hl=en&sa=X&d=876126288656849057&ei=6G7waODLOt_N6rQPqOmrqQ4&scisig=AAZF9b8HafEkkmQjPmdiYY4QT43e&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=8&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "TeTRIS: General-purpose Fuzzing for Translation Bugs in Source-to-Source Code Transpilers", "first_label": ["Fuzzing", "Code", "Bug"], "second_label": ["Generation"], "data": "Y Arafat, S Nagy - 2025\nAmid the rise of heterogeneous computing and concerns over systems and \napplication security, developers are increasingly embracing transpilers: a growing \nclass of tools for converting code from one programming language into another. As\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://futures.cs.utah.edu/papers/25ACSAC.pdf&hl=en&sa=X&d=7907468188891103628&ei=6G7waODLOt_N6rQPqOmrqQ4&scisig=AAZF9b_X5wz-gD-8yp4ujsLZ1oNT&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=9&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "HarmMetric Eval: Benchmarking Metrics and Judges for LLM Harmfulness Assessment", "first_label": ["LLM"], "second_label": [], "data": "L Yang, T Zheng, K Xiu, Y Chen, D Wang, P Zhao- arXiv preprint arXiv, 2025\nThe alignment of large language models (LLMs) with human values is critical for their \nsafe deployment, yet jailbreak attacks can subvert this alignment to elicit harmful \noutputs from LLMs. In recent years, a proliferation of jailbreak attacks has emerged", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24384&hl=en&sa=X&d=6954529287697046870&ei=6W7waPzNOpm96rQPkKyjqAI&scisig=AAZF9b9uM0TGT71bAeDSUUl5_-VC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration", "first_label": ["LLM"], "second_label": ["Agent"], "data": "X Chen, J Zhao, Y Yuan, T Zhang, H Zhou, Z Zhu, P Hu- arXiv preprint arXiv, 2025\nExisting safety evaluation methods for large language models (LLMs) suffer from \ninherent limitations, including evaluator bias and detection failures arising from \nmodel homogeneity, which collectively undermine the robustness of risk evaluation", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25271&hl=en&sa=X&d=9498150266007123670&ei=6W7waPzNOpm96rQPkKyjqAI&scisig=AAZF9b_UXRq4nDsuky7i5vKaVskx&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Formalization Driven LLM Prompt Jailbreaking via Reinforcement Learning", "first_label": ["LLM"], "second_label": [], "data": "Z Wang, D He, Z Zhang, X Li, L Zhu, M Li, J Liu- arXiv preprint arXiv:2509.23558, 2025\nLarge language models (LLMs) have demonstrated remarkable capabilities, yet they \nalso introduce novel security challenges. For instance, prompt jailbreaking attacks \ninvolve adversaries crafting sophisticated prompts to elicit responses from LLMs that", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23558%3F&hl=en&sa=X&d=2749826917926664463&ei=6W7waPzNOpm96rQPkKyjqAI&scisig=AAZF9b9socy1uU0idrQjXea7u6Gn&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Defeating Cerberus: Concept-Guided Privacy-Leakage Mitigation in Multimodal Language Models", "first_label": ["LLM"], "second_label": [], "data": "B Zhang, IE Akkus, R Chen, A Dethise, K Satzke- arXiv preprint arXiv, 2025\nMultimodal large language models (MLLMs) have demonstrated remarkable \ncapabilities in processing and reasoning over diverse modalities, but their advanced \nabilities also raise significant privacy concerns, particularly regarding Personally", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25525%3F&hl=en&sa=X&d=188731358198544290&ei=6W7waPzNOpm96rQPkKyjqAI&scisig=AAZF9b83Zm3Lci4vXc2-RuCtKxTZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Proactive defense against LLM Jailbreak", "first_label": ["LLM"], "second_label": [], "data": "W Zhao, J Peng, D Ben-Levi, Z Yu, J Yang- arXiv preprint arXiv:2510.05052, 2025\nThe proliferation of powerful large language models (LLMs) has necessitated robust \nsafety alignment, yet these models remain vulnerable to evolving adversarial attacks, \nincluding multi-turn jailbreaks that iteratively search for successful queries. Current", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05052&hl=en&sa=X&d=12643963361954479351&ei=6W7waPzNOpm96rQPkKyjqAI&scisig=AAZF9b8Coa_W30rxK1WFNlFrrWpl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Microsaccade-Inspired Probing: Positional Encoding Perturbations Reveal LLM Misbehaviours", "first_label": ["LLM"], "second_label": [], "data": "R Melo, R Abreu, CS Pasareanu- arXiv preprint arXiv:2510.01288, 2025\nWe draw inspiration from microsaccades, tiny involuntary eye movements that reveal \nhidden dynamics of human perception, to propose an analogous probing method for \nlarge language models (LLMs). Just as microsaccades expose subtle but informative", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01288&hl=en&sa=X&d=4079834350174690212&ei=6W7waPzNOpm96rQPkKyjqAI&scisig=AAZF9b8rbcS03ioCYUn4xb7F5XTc&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM Unlearning Under the Microscope: A Full-Stack View on Methods and Metrics", "first_label": ["LLM"], "second_label": [], "data": "C Fan, C Wang, Y Huang, S Pal, S Liu- arXiv preprint arXiv:2510.07626, 2025\nMachine unlearning for large language models (LLMs) aims to remove undesired \ndata, knowledge, and behaviors (eg, for safety, privacy, or copyright) while \npreserving useful model capabilities. Despite rapid progress over the past two years", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07626&hl=en&sa=X&d=2219175947074663426&ei=6W7waPzNOpm96rQPkKyjqAI&scisig=AAZF9b8K58fohUV3HCgE5BozXqN8&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SWE-QA: Can Language Models Answer Repository-level Code Questions?", "first_label": ["LLM", "Code", "Repository-Level"], "second_label": [], "data": "W Peng, Y Shi, Y Wang, X Zhang, B Shen, X Gu- arXiv preprint arXiv:2509.14635, 2025\nUnderstanding and reasoning about entire software repositories is an essential \ncapability for intelligent software engineering tools. While existing benchmarks such \nas CoSQA and CodeQA have advanced the field, they predominantly focus on small", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.14635&hl=en&sa=X&d=15006803551698078506&ei=6W7waPzNOpm96rQPkKyjqAI&scisig=AAZF9b-gcqnrJWuOC2cDSJR6nYNt&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "A2D: Any-Order, Any-Step Safety Alignment for Diffusion Language Models", "first_label": ["LLM"], "second_label": [], "data": "W Jeung, S Yoon, Y Cho, D Jeon, S Shin, H Hong- arXiv preprint arXiv, 2025\nDiffusion large language models (dLLMs) enable any-order generation, but this \nflexibility enlarges the attack surface: harmful spans may appear at arbitrary \npositions, and template-based prefilling attacks such as DIJA bypass response-level", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23286&hl=en&sa=X&d=16977104919503302935&ei=6W7waPzNOpm96rQPkKyjqAI&scisig=AAZF9b-9ssXxkPlc54WBS9-P-Zx-&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Demystifying the Roles of LLM Layers in Retrieval, Knowledge, and Reasoning", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "X Song, K Wang, PX Li, L Yin, S Liu- arXiv preprint arXiv:2510.02091, 2025\nRecent studies suggest that the deeper layers of Large Language Models (LLMs) \ncontribute little to representation learning and can often be removed without \nsignificant performance loss. However, such claims are typically drawn from narrow\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02091%3F&hl=en&sa=X&d=1937934351809912348&ei=6W7waPzNOpm96rQPkKyjqAI&scisig=AAZF9b_n5M9HZCtzMWvJz6YTm2TJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Vdexplainer: Sequential decision-making and probability sampling guided statement-level explanation for vulnerability detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "W Zheng, X Su, Y Jiang, H Wei, W Tao- Computers & Security, 2025\nMost existing deep learning (DL) based vulnerability detection methods, including \npre-trained models, are coarse-grained binary classification methods that lack the \ninterpretability for detection results. Although the explanation of deep learning has", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825003591&hl=en&sa=X&d=1218753570899613844&ei=527waPzOL9_N6rQPqOmrqQ4&scisig=AAZF9b-Gvd82yXjuXXps0NDpxzwO&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "MAVUL: Multi-Agent Vulnerability Detection via Contextual Reasoning and Interactive Refinement", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Agent", "Reasoning"], "data": "Y Li, K Joshi, X Wang, E Wong- arXiv preprint arXiv:2510.00317, 2025\nThe widespread adoption of open-source software (OSS) necessitates the mitigation \nof vulnerability risks. Most vulnerability detection (VD) methods are limited by \ninadequate contextual understanding, restrictive single-round interactions, and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.00317&hl=en&sa=X&d=577185325914480253&ei=527waPzOL9_N6rQPqOmrqQ4&scisig=AAZF9b9zhj17R2ND7E9Z8TAf0EMX&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "A Scalable Vulnerability Detection System with Multi-View Graph Representations", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "S Dou, H Zheng, J Shan, Y Wu, D Zou, X Huang, Y Liu- ACM Transactions on, 2025\nDeep learning (DL) has been extensively utilized in source code vulnerability \ndetection due to its robust automatic feature extraction capabilities. To achieve \nscalable vulnerability scanning, some prior studies intend to process the source code", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3770075&hl=en&sa=X&d=14953216934661661615&ei=527waPzOL9_N6rQPqOmrqQ4&scisig=AAZF9b-mdJedTULsxLZv6yXH09xW&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language", "first_label": ["LLM", "Software Testing"], "second_label": ["Agent"], "data": "S Salva, R Taguelmimt- arXiv preprint arXiv:2509.19136, 2025\nThe use of natural language (NL) test cases for validating graphical user interface \n(GUI) applications is emerging as a promising direction to manually written \nexecutable test scripts, which are costly to develop and difficult to maintain. Recent", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19136&hl=en&sa=X&d=14763218273592887225&ei=527waPzOL9_N6rQPqOmrqQ4&scisig=AAZF9b-UHW8cguy7BjMGIC6z7CK9&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework", "first_label": ["LLM"], "second_label": ["Agent"], "data": "V Tawosi, K Ramani, S Alamir, X Liu- arXiv preprint arXiv:2510.03463, 2025\nMulti-agent Large Language Model (LLM) systems have been leading the way in \napplied LLM research across a number of fields. One notable area is software \ndevelopment, where researchers have advanced the automation of code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03463&hl=en&sa=X&d=6189494284468520954&ei=527waPzOL9_N6rQPqOmrqQ4&scisig=AAZF9b8zKTPWNRtbnL5YxBMg92_V&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Towards Human-interpretable Explanation in Code Clone Detection using LLM-based Post Hoc Explainer", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "T Racharak, C Ragkhitwetsagul, C Junplong- arXiv preprint arXiv, 2025\nRecent studies highlight various machine learning (ML)-based techniques for code \nclone detection, which can be integrated into developer tools such as static code \nanalysis. With the advancements brought by ML in code understanding, ML-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22978&hl=en&sa=X&d=13116222657243354012&ei=527waPzOL9_N6rQPqOmrqQ4&scisig=AAZF9b-CrNTuw-vA-xt9R-PWj2rN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Local Agentic RAG-Based Information System Development for Intelligent Analysis of GitHub Code Repositories in Computer Science Education", "first_label": ["Code"], "second_label": ["Agent"], "data": "Z Hu, MM Paprotskyi, V Vysotska, L Chyrun, Y Ushenko\nThis study presents the development and evaluation of a local agent-based Retrieval-\nAugmented Generation (Agentic RAG) system designed for the intelligent analysis of \nGitHub repositories in computer science education and IT practice. The novelty of", "link": "https://scholar.google.com/scholar_url?url=https://www.mecs-press.org/ijmecs/ijmecs-v17-n5/IJMECS-V17-N5-7.pdf&hl=en&sa=X&d=15899062735032558573&ei=527waPzOL9_N6rQPqOmrqQ4&scisig=AAZF9b9zpITZz-kJHGT1UMgEWtn4&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "LLM Agents for Automated Dependency Upgrades", "first_label": ["LLM"], "second_label": ["Agent"], "data": "V Tawosi, S Alamir, X Liu, M Veloso- arXiv preprint arXiv:2510.03480, 2025\nAs a codebase expands over time, its library dependencies can become outdated \nand require updates to maintain innovation and security. However, updating a library \ncan introduce breaking changes in the code, necessitating significant developer time\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03480&hl=en&sa=X&d=6490656773391404708&ei=527waPzOL9_N6rQPqOmrqQ4&scisig=AAZF9b-yLSNasEq3H6Z4hOQDU0im&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Generating High-Quality Datasets for Code Editing via Open-Source Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "Z Zhang, M Liu, Z Chen, L Liang, Y Chen, G Ou- arXiv preprint arXiv, 2025\nCode editing plays a vital role in software engineering, requiring developers to adjust \nexisting code according to natural language instructions while keeping functionality \nintact and avoiding unnecessary modifications. However, commit-based datasets", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25203&hl=en&sa=X&d=16003307718581653243&ei=527waOKLFJ2k6rQP94Xs2QI&scisig=AAZF9b-WX82g5S_NgG548uiHBBUN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "What Do They Fix? LLM-Aided Categorization of Security Patches for Critical Memory Bugs", "first_label": ["LLM", "Bug"], "second_label": [], "data": "X Li, J Pu, Y Wu, X Zou, S Zhu, Q Wu, Z Zhang, J Hsu- arXiv preprint arXiv, 2025\nOpen-source software projects are foundational to modern software ecosystems, with \nthe Linux kernel standing out as a critical exemplar due to its ubiquity and \ncomplexity. Although security patches are continuously integrated into the Linux\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22796&hl=en&sa=X&d=5877456260761011502&ei=527waOKLFJ2k6rQP94Xs2QI&scisig=AAZF9b_K5bVx20Ft-L-epPjLrGqv&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning", "first_label": ["LLM", "Code"], "second_label": [], "data": "Z Chu, Y Wan, Z Zhang, D Wang, Z Yang, H Zhang- arXiv preprint arXiv, 2025\nWhile Code Language Models (CLMs) have demonstrated superior performance in \nsoftware engineering tasks such as code generation and summarization, recent \nempirical studies reveal a critical privacy vulnerability: these models exhibit", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.13755&hl=en&sa=X&d=15695711709507586926&ei=6m7waKWcEMifieoPhcWgiQc&scisig=AAZF9b-GbF4lUDy44GMQdWyqOkv7&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Integrating Large Language Models into Automated Software Testing", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "YS Iznaga, L Rato, P Salgueiro, JL Len- environments, 2025\nThis work investigates the use of LLMs to enhance automation in software testing, \nwith a particular focus on generating high-quality, context-aware test scripts from \nnatural language descriptions, while addressing both text-to-code and text+ code-to", "link": "https://scholar.google.com/scholar_url?url=https://www.preprints.org/frontend/manuscript/6dce9a44c01bba11d8679b804f89ffe3/download_pub&hl=en&sa=X&d=5631235108066530487&ei=6m7waKWcEMifieoPhcWgiQc&scisig=AAZF9b8frdiwv1HUKakv2-IdeP9i&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "CLMTracing: Black-box User-level Watermarking for Code Language Model Tracing", "first_label": ["LLM", "Code"], "second_label": [], "data": "B Zhang, P He, T Du, X Zhang, L Yun, K Chow, J Yin- arXiv preprint arXiv, 2025\nWith the widespread adoption of open-source code language models (code LMs), \nintellectual property (IP) protection has become an increasingly critical concern. \nWhile current watermarking techniques have the potential to identify the code LM to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.13982&hl=en&sa=X&d=14851863240844447268&ei=6m7waKWcEMifieoPhcWgiQc&scisig=AAZF9b9MnsfxxD6KbVrkei3eB0d6&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Investigating The Smells of LLM Generated Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "DG Paul, H Zhu, I Bayley- arXiv preprint arXiv:2510.03029, 2025\nContext: Large Language Models (LLMs) are increasingly being used to generate \nprogram code. Much research has been reported on the functional correctness of \ngenerated code, but there is far less on code quality. Objectives: In this study, we\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03029&hl=en&sa=X&d=3729774285617891173&ei=6m7waKWcEMifieoPhcWgiQc&scisig=AAZF9b9iPizFVBuT5VYe4qCl8Mca&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Software Generation With LLMs: Privacy, Utility, and Cybersecurity Tensions", "first_label": ["LLM"], "second_label": ["Generation"], "data": "W Wei, X Li, H Tanriverdi - 2025\nIn 2025, major developers of large language models (LLMs) announced that their \nsystems can automatically generate software code from natural language \ndescriptions. Yet these advances largely overlook the implications for privacy and \ncybersecurity. Drawing on machine learning theory, we propose a framework \nshowing how privacy, utility, confidentiality, integrity, and availability in LLM-\ngenerated software are shaped by inherent tensions, tradeoffs, and paradoxes. We\nCites: Exploring Parameter-Efficient Fine-Tuning Techniques for Code\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://aisel.aisnet.org/icis2025/gen_ai/gen_ai/38/&hl=en&sa=X&d=437845615390398228&ei=6W7waNqcJ5m96rQPkKyjqAI&scisig=AAZF9b9eeAWcvY96As9coEQ-9HQ5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["1 new citation to articles by Xin ZHOU"]}
