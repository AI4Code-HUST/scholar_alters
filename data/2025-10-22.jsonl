{"title": "Signature in Code Backdoor Detection, how far are we?", "first_label": ["Code"], "second_label": ["Detection"], "data": "QH Le, T Le-Cong, B Le, B Xu- arXiv preprint arXiv:2510.13992, 2025\nAs Large Language Models (LLMs) become increasingly integrated into software \ndevelopment workflows, they also become prime targets for adversarial attacks. \nAmong these, backdoor attacks are a significant threat, allowing attackers to\n\u00a0\nThis message was sent by Google Scholar because you're following new articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.13992&hl=en&sa=X&d=9067708832514091256&ei=wR_4aOupI_rUieoPvMbB8Qc&scisig=AAZF9b_JLMNW9dl9RwxW4hCMmJhW&oi=scholaralrt&hist=ylyK0_8AAAAJ:7720112214409400523:AAZF9b-xyICIzdumGrWFv_NMdYHE&html=&pos=0&folt=art", "author": ["Bach Le"], "ref": ["Bach Le - new articles", "2 new citations to articles by Thanh Le-Cong", "David Lo - new related research", "Xin ZHOU - new related research", "Thanh Le-Cong - new articles", "10 new citations to articles by Abhik Roychoudhury", "2 new citations to articles by Bach Le", "2 new citations to articles by Hong Jin Kang"]}
{"title": "A11YN: aligning LLMs for accessible web UI code generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Yoon, J Cho, J Kim, J Chung, J Jeon, Y Yu- arXiv preprint arXiv:2510.13914, 2025\nLarge language models (LLMs) have recently demonstrated strong capabilities in \ngenerating functional and aesthetic web interfaces directly from instructions. \nHowever, these models often replicate accessibility flaws from their training data, \nresulting in interfaces that exclude users with diverse needs and contexts. To \naddress this gap, we introduce A11yn, the first method that aligns code-generating \nLLMs to reliably produce accessibility-compliant web UIs. A11yn optimizes a novel\nCites: Usability and aesthetics: Better together for automated repair of", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.13914&hl=en&sa=X&d=7346817179217164407&ei=vx_4aOeJLJjO6rQPk_O3wAE&scisig=AAZF9b9DLyLFRAcw9-_z5yJXPXSZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 new citations to articles by Thanh Le-Cong", "2 new citations to articles by Bach Le"]}
{"title": "R1-Fuzz: Specializing Language Models for Textual Fuzzing via Reinforcement Learning", "first_label": ["LLM", "Fuzzing"], "second_label": [], "data": "J Lin, L Su, J Li, C Qian- arXiv preprint arXiv:2509.20384, 2025\nFuzzing is effective for vulnerability discovery but struggles with complex targets such \nas compilers, interpreters, and database engines, which accept textual input that \nmust satisfy intricate syntactic and semantic constraints. Although language models", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.20384&hl=en&sa=X&d=1649136629077213896&ei=wR_4aLPoFNWY6rQPrbXRgQY&scisig=AAZF9b9A_fC3MFUyhQ5sK9VXroDy&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "E2Edev: Benchmarking Large Language Models in End-to-End Software Development Task", "first_label": ["LLM"], "second_label": [], "data": "J Liu, C Huang, Z Guan, W Lei, Y Deng- arXiv preprint arXiv:2510.14509, 2025\nE2EDev comprises (i) a fine-grained set of user requirements,(ii){multiple BDD test \nscenarios with corresponding Python step implementations for each requirement}, \nand (iii) a fully automated testing pipeline built on the Behave framework. To ensure", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.14509&hl=en&sa=X&d=15900279319022234305&ei=wR_4aLPoFNWY6rQPrbXRgQY&scisig=AAZF9b-slRTIPFUy1BphkG4z79pS&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "A machine learning approach to vulnerability detection combining software metrics and topic modelling: Evidence from smart contracts", "first_label": ["Vulnerabilities", "Smart Contracts"], "second_label": ["Detection"], "data": "G Ibba, R Neykova, M Ortu, R Tonelli, S Counsell- Machine Learning with, 2025\nThis paper introduces a methodology for software vulnerability detection that \ncombines structural and semantic analysis through software metrics and topic \nmodelling. We evaluate the approach using smart contracts as a case study, focusing", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S2666827025001422&hl=en&sa=X&d=18134780674166341757&ei=wR_4aLPoFNWY6rQPrbXRgQY&scisig=AAZF9b-cRpRc-n1vC3Wx8S67ortE&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Quang-Cuong Bui - new related research", "Hong Jin Kang - new related research"]}
{"title": "DamFlow: Preventing a Flood of Irrelevant Data Flows in Android Apps", "first_label": ["Static Analysis"], "second_label": [], "data": "M Alecci, J Samhi, M Miltenberger, S Arzt- ACM Transactions on, 2025\nState-of-the-art tools like FlowDroid have been proposed to detect data leaks in \nAndroid apps, but two main challenges persist:  false alarms and  undetected \ndata leaks. One contributing factor to these challenges is that a tool such as", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3772002&hl=en&sa=X&d=2501993862817038890&ei=wR_4aLPoFNWY6rQPrbXRgQY&scisig=AAZF9b_gkhIWcw58mq-YwFMte_6h&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Graph neural networks for precise bug localization through structural program analysis", "first_label": ["Bug"], "second_label": ["Localization", "Graph"], "data": "L Yousofvand, S Soleimani, V Rafe, A Nikanjam- Automated Software Engineering, 2026\nBug localization (BL) is known as one of the major steps in the program repair \nprocess, which generally seeks to find a set of commands causing a program to \ncrash or fail. At the present time, locating bugs and their sources quickly seems to be\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00556-y&hl=en&sa=X&d=17248062499908466361&ei=wR_4aLPoFNWY6rQPrbXRgQY&scisig=AAZF9b9CtKOSHU4PHQ95OFzeS2YO&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "CodeDiffuSe: A masked diffusion framework for structure-aware code completion and repair", "first_label": ["Code"], "second_label": ["Repair", "Generation"], "data": "A Onan, HA Alhumyani- Journal of King Saud University Computer and, 2025\nCode completion and code repair have become fundamental tasks in software \nengineering and machine learning research. However, existing large language \nmodels (LLMs) for code generation, predominantly based on autoregressive", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00237-6&hl=en&sa=X&d=7004051865866003393&ei=wx_4aMmqBbeO6rQP6NHlsQ0&scisig=AAZF9b_qwM9Dp6AHPQxBEC9VHMMl&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "The Question Neighbourhood Approach for Systematic Evaluation of Code-Generating LLMs", "first_label": ["LLM", "Code"], "second_label": [], "data": "S Honarvar, M Rei, A Donaldson- IEEE Transactions on Software Engineering, 2025\nWe present the concept of a question neighbourhood for systematically evaluating \ninstruction-tuned large language models (LLMs) for code generation via a new \nbenchmark, Turbulence. Turbulence consists of a large set of natural language", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11175086/&hl=en&sa=X&d=12331338329639325411&ei=wx_4aMmqBbeO6rQP6NHlsQ0&scisig=AAZF9b8Ies8RuQhW4d_WHfainK40&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Enhancing LLM-based Fault Localization with a Functionality-Aware Retrieval-Augmented Generation Framework", "first_label": ["LLM", "Fault Localization"], "second_label": ["Generation", "Localization"], "data": "X Shi, Z Li, AR Chen- arXiv preprint arXiv:2509.20552, 2025\nFault localization (FL) is a critical but time-consuming task in software debugging, \naiming to identify faulty code elements. While recent advances in large language \nmodels (LLMs) have shown promise for FL, they often struggle with complex systems", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.20552&hl=en&sa=X&d=538936030362850881&ei=wx_4aMmqBbeO6rQP6NHlsQ0&scisig=AAZF9b_pS5txVadTljqov2Cyxur_&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Source Code Guardrail: AI Driven Solution to Distinguish Critical vs. Generic Code for Enterprise LLM Security", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Sharma, A Gupta- International Conference on Provable Security, 2025\nAbstract The adoption of Large Language Models (LLMs) in businesses raises the \npossibility of inadvertent intellectual property (IP) and secret data leaks to public \nartificial intelligence systems. Organizations are using security solutions, including", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1007/978-981-95-2961-2_23&hl=en&sa=X&d=5184326828152072441&ei=wx_4aMmqBbeO6rQP6NHlsQ0&scisig=AAZF9b_DHHxlXXvwx7KOr1GLjYsY&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Quang-Cuong Bui - new related research", "Bach Le - new related research"]}
{"title": "Blending Language Models and Domain-Specific Languages in Computer Science Education. A Case Study on API RESTFul", "first_label": ["LLM"], "second_label": [], "data": "F Jurado, FD Rodrguez, E Chavarriaga, L Rojas- International Journal of Interactive, 2025\nAbstract Since Computer Science students are used to applying both General \nPurpose Programming Languages (GPPLs) and Domain-Specific Languages \n(DSLs), Generative Artificial Intelligence based on Language Models (LMs) can help\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://revistas.unir.net/index.php/ijimai/article/view/890&hl=en&sa=X&d=10479196726541786525&ei=wx_4aMmqBbeO6rQP6NHlsQ0&scisig=AAZF9b9HVc-l6hnmEPdBJg3N4Vo6&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "PathFix: Automated Program Repair with Expected Path", "first_label": ["APR"], "second_label": ["Repair"], "data": "X He, S Wang, K Sun- arXiv preprint arXiv:2510.14341, 2025\nAutomated program repair (APR) techniques are effective in fixing inevitable defects \nin software, enhancing development efficiency and software robustness. However, \ndue to the difficulty of generating precise specifications, existing APR methods face", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.14341&hl=en&sa=X&d=15132899681148259377&ei=wh_4aL6pAoeVieoP9e_euQw&scisig=AAZF9b9YW4kFYhNqwb3ditygfL-4&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "Thanh Le-Cong - new related research", "Bach Le - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Cloud Security: Managing Emerging Threats", "first_label": [], "second_label": [], "data": "A Chowdhary, A Sabur - 2025\nThe book reviews the zero-trust model that deviates from the traditional definition of \ntrust boundaries and validates all interactions in a cloud environment. The incident \nresponse life cycle is used to prepare for, identify, contain, and eradicate security", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3Dj6iPEQAAQBAJ%26oi%3Dfnd%26pg%3DPT18%26ots%3DYEyqmpsFdt%26sig%3Dr6RL-6x00S9xfHZN74YQGcI-kcs&hl=en&sa=X&d=13563439903056895648&ei=wh_4aL6pAoeVieoP9e_euQw&scisig=AAZF9b91wjWScI7EHHa3MQ5_cWHG&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Vdexplainer: Sequential decision-making and probability sampling guided statement-level explanation for vulnerability detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "W Zheng, X Su, Y Jiang, H Wei, W Tao- Computers & Security, 2025\nMost existing deep learning (DL) based vulnerability detection methods, including \npre-trained models, are coarse-grained binary classification methods that lack the \ninterpretability for detection results. Although the explanation of deep learning has", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825003591&hl=en&sa=X&d=1218753570899613844&ei=wB_4aJeBI97M6rQPpPXkqAI&scisig=AAZF9b-Gvd82yXjuXXps0NDpxzwO&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "MAVUL: Multi-Agent Vulnerability Detection via Contextual Reasoning and Interactive Refinement", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Agent", "Reasoning"], "data": "Y Li, K Joshi, X Wang, E Wong- arXiv preprint arXiv:2510.00317, 2025\nThe widespread adoption of open-source software (OSS) necessitates the mitigation \nof vulnerability risks. Most vulnerability detection (VD) methods are limited by \ninadequate contextual understanding, restrictive single-round interactions, and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.00317&hl=en&sa=X&d=577185325914480253&ei=wB_4aJeBI97M6rQPpPXkqAI&scisig=AAZF9b9zhj17R2ND7E9Z8TAf0EMX&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "A Scalable Vulnerability Detection System with Multi-View Graph Representations", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "S Dou, H Zheng, J Shan, Y Wu, D Zou, X Huang, Y Liu- ACM Transactions on, 2025\nDeep learning (DL) has been extensively utilized in source code vulnerability \ndetection due to its robust automatic feature extraction capabilities. To achieve \nscalable vulnerability scanning, some prior studies intend to process the source code", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3770075&hl=en&sa=X&d=14953216934661661615&ei=wB_4aJeBI97M6rQPpPXkqAI&scisig=AAZF9b-mdJedTULsxLZv6yXH09xW&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language", "first_label": ["LLM", "Software Testing"], "second_label": ["Agent"], "data": "S Salva, R Taguelmimt- arXiv preprint arXiv:2509.19136, 2025\nThe use of natural language (NL) test cases for validating graphical user interface \n(GUI) applications is emerging as a promising direction to manually written \nexecutable test scripts, which are costly to develop and difficult to maintain. Recent", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19136&hl=en&sa=X&d=14763218273592887225&ei=wB_4aJeBI97M6rQPpPXkqAI&scisig=AAZF9b-UHW8cguy7BjMGIC6z7CK9&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Bach Le - new related research"]}
{"title": "ALMAS: an autonomous llm-based multi-agent software engineering framework", "first_label": ["LLM"], "second_label": ["Agent"], "data": "V Tawosi, K Ramani, S Alamir, X Liu- arXiv preprint arXiv:2510.03463, 2025\nMulti-agent Large Language Model (LLM) systems have been leading the way in \napplied LLM research across a number of fields. One notable area is software \ndevelopment, where researchers have advanced the automation of code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03463&hl=en&sa=X&d=6189494284468520954&ei=wB_4aJeBI97M6rQPpPXkqAI&scisig=AAZF9b8zKTPWNRtbnL5YxBMg92_V&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Towards Human-interpretable Explanation in Code Clone Detection using LLM-based Post Hoc Explainer", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "T Racharak, C Ragkhitwetsagul, C Junplong- arXiv preprint arXiv, 2025\nRecent studies highlight various machine learning (ML)-based techniques for code \nclone detection, which can be integrated into developer tools such as static code \nanalysis. With the advancements brought by ML in code understanding, ML-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22978&hl=en&sa=X&d=13116222657243354012&ei=wB_4aJeBI97M6rQPpPXkqAI&scisig=AAZF9b-CrNTuw-vA-xt9R-PWj2rN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Local Agentic RAG-Based Information System Development for Intelligent Analysis of GitHub Code Repositories in Computer Science Education", "first_label": ["Code"], "second_label": ["Agent"], "data": "Z Hu, MM Paprotskyi, V Vysotska, L Chyrun, Y Ushenko\nThis study presents the development and evaluation of a local agent-based Retrieval-\nAugmented Generation (Agentic RAG) system designed for the intelligent analysis of \nGitHub repositories in computer science education and IT practice. The novelty of", "link": "https://scholar.google.com/scholar_url?url=https://www.mecs-press.org/ijmecs/ijmecs-v17-n5/IJMECS-V17-N5-7.pdf&hl=en&sa=X&d=15899062735032558573&ei=wB_4aJeBI97M6rQPpPXkqAI&scisig=AAZF9b9zpITZz-kJHGT1UMgEWtn4&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Verification Limits Code LLM Training", "first_label": ["Verification", "LLM", "Code"], "second_label": [], "data": "S Gureja, E Tommasone, J He, S Hooker, M Gall- arXiv preprint arXiv, 2025\nLarge language models for code generation increasingly rely on synthetic data, \nwhere both problem solutions and verification tests are generated by models. While \nthis enables scalable data creation, it introduces a previously unexplored bottleneck\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.20837&hl=en&sa=X&d=4117827863762930027&ei=wB_4aJeBI97M6rQPpPXkqAI&scisig=AAZF9b_CjUHD_ysic3yg92n8IJ_N&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "PIShield: Detecting Prompt Injection Attacks via Intrinsic LLM Features", "first_label": ["LLM"], "second_label": ["Detection"], "data": "W Zou, Y Liu, Y Wang, Y Chen, N Gong, J Jia- arXiv preprint arXiv:2510.14005, 2025\nLLM-integrated applications are vulnerable to prompt injection attacks, where an \nattacker contaminates the input to inject malicious prompts, causing the LLM to follow \nthe attacker's intent instead of the original user's. Existing prompt injection detection", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.14005&hl=en&sa=X&d=13106089087168856091&ei=wh_4aPSXNom16rQPu6Ol8AM&scisig=AAZF9b_hGk51t_eyS3BpajYwvuIq&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Defender to Devil? Unintended Risk Interactions Induced by LLM Defenses", "first_label": ["LLM"], "second_label": [], "data": "X Meng, T Cong, L Wang, W Chen, Z Li, S Guo- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have shown remarkable performance across \nvarious applications, but their deployment in sensitive domains raises significant \nconcerns. To mitigate these risks, numerous defense strategies have been proposed", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07968&hl=en&sa=X&d=16628375445005170696&ei=wh_4aPSXNom16rQPu6Ol8AM&scisig=AAZF9b-769OFYdciBP8asq-WL4LX&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "HarmMetric Eval: Benchmarking Metrics and Judges for LLM Harmfulness Assessment", "first_label": ["LLM"], "second_label": [], "data": "L Yang, T Zheng, K Xiu, Y Chen, D Wang, P Zhao- arXiv preprint arXiv, 2025\nThe alignment of large language models (LLMs) with human values is critical for their \nsafe deployment, yet jailbreak attacks can subvert this alignment to elicit harmful \noutputs from LLMs. In recent years, a proliferation of jailbreak attacks has emerged", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24384%3F&hl=en&sa=X&d=6954529287697046870&ei=wh_4aPSXNom16rQPu6Ol8AM&scisig=AAZF9b9dFauzR9dpBNzzfY8bDWby&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration", "first_label": ["LLM"], "second_label": ["Agent"], "data": "X Chen, J Zhao, Y Yuan, T Zhang, H Zhou, Z Zhu, P Hu- arXiv preprint arXiv, 2025\nExisting safety evaluation methods for large language models (LLMs) suffer from \ninherent limitations, including evaluator bias and detection failures arising from \nmodel homogeneity, which collectively undermine the robustness of risk evaluation", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25271%3F&hl=en&sa=X&d=9498150266007123670&ei=wh_4aPSXNom16rQPu6Ol8AM&scisig=AAZF9b95zCxcGgN2hu1swbKS_h_V&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Formalization Driven LLM Prompt Jailbreaking via Reinforcement Learning", "first_label": ["LLM"], "second_label": [], "data": "Z Wang, D He, Z Zhang, X Li, L Zhu, M Li, J Liu- arXiv preprint arXiv:2509.23558, 2025\nLarge language models (LLMs) have demonstrated remarkable capabilities, yet they \nalso introduce novel security challenges. For instance, prompt jailbreaking attacks \ninvolve adversaries crafting sophisticated prompts to elicit responses from LLMs that", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23558%3F&hl=en&sa=X&d=2749826917926664463&ei=wh_4aPSXNom16rQPu6Ol8AM&scisig=AAZF9b9socy1uU0idrQjXea7u6Gn&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Defeating Cerberus: Concept-Guided Privacy-Leakage Mitigation in Multimodal Language Models", "first_label": ["LLM"], "second_label": [], "data": "B Zhang, IE Akkus, R Chen, A Dethise, K Satzke- arXiv preprint arXiv, 2025\nMultimodal large language models (MLLMs) have demonstrated remarkable \ncapabilities in processing and reasoning over diverse modalities, but their advanced \nabilities also raise significant privacy concerns, particularly regarding Personally", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25525%3F&hl=en&sa=X&d=188731358198544290&ei=wh_4aPSXNom16rQPu6Ol8AM&scisig=AAZF9b83Zm3Lci4vXc2-RuCtKxTZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Proactive defense against LLM Jailbreak", "first_label": ["LLM"], "second_label": [], "data": "W Zhao, J Peng, D Ben-Levi, Z Yu, J Yang- arXiv preprint arXiv:2510.05052, 2025\nThe proliferation of powerful large language models (LLMs) has necessitated robust \nsafety alignment, yet these models remain vulnerable to evolving adversarial attacks, \nincluding multi-turn jailbreaks that iteratively search for successful queries. Current", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05052&hl=en&sa=X&d=12643963361954479351&ei=wh_4aPSXNom16rQPu6Ol8AM&scisig=AAZF9b8Coa_W30rxK1WFNlFrrWpl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Microsaccade-Inspired Probing: Positional Encoding Perturbations Reveal LLM Misbehaviours", "first_label": ["LLM"], "second_label": [], "data": "R Melo, R Abreu, CS Pasareanu- arXiv preprint arXiv:2510.01288, 2025\nWe draw inspiration from microsaccades, tiny involuntary eye movements that reveal \nhidden dynamics of human perception, to propose an analogous probing method for \nlarge language models (LLMs). Just as microsaccades expose subtle but informative", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01288&hl=en&sa=X&d=4079834350174690212&ei=wh_4aPSXNom16rQPu6Ol8AM&scisig=AAZF9b8rbcS03ioCYUn4xb7F5XTc&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM Unlearning Under the Microscope: A Full-Stack View on Methods and Metrics", "first_label": ["LLM"], "second_label": [], "data": "C Fan, C Wang, Y Huang, S Pal, S Liu- arXiv preprint arXiv:2510.07626, 2025\nMachine unlearning for large language models (LLMs) aims to remove undesired \ndata, knowledge, and behaviors (eg, for safety, privacy, or copyright) while \npreserving useful model capabilities. Despite rapid progress over the past two years", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07626%3F&hl=en&sa=X&d=2219175947074663426&ei=wh_4aPSXNom16rQPu6Ol8AM&scisig=AAZF9b9WT042RKh5sfiV4352ZB2M&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A2D: Any-Order, Any-Step Safety Alignment for Diffusion Language Models", "first_label": ["LLM"], "second_label": [], "data": "W Jeung, S Yoon, Y Cho, D Jeon, S Shin, H Hong- arXiv preprint arXiv, 2025\nDiffusion large language models (dLLMs) enable any-order generation, but this \nflexibility enlarges the attack surface: harmful spans may appear at arbitrary \npositions, and template-based prefilling attacks such as DIJA bypass response-level\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23286&hl=en&sa=X&d=16977104919503302935&ei=wh_4aPSXNom16rQPu6Ol8AM&scisig=AAZF9b-9ssXxkPlc54WBS9-P-Zx-&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM Agents for Automated Web Vulnerability Reproduction: Are We There Yet?", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Agent"], "data": "B Liu, Y Zhao, G Xu, H Wang- arXiv preprint arXiv:2510.14700, 2025\nLarge language model (LLM) agents have demonstrated remarkable capabilities in \nsoftware engineering and cybersecurity tasks, including code generation, \nvulnerability discovery, and automated testing. One critical but underexplored \napplication is automated web vulnerability reproduction, which transforms \nvulnerability reports into working exploits. Although recent advances suggest \npromising potential, challenges remain in applying LLM agents to real-world web\nCites: Teams of llm agents can exploit zero-day vulnerabilities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.14700&hl=en&sa=X&d=13248429733898173552&ei=wB_4aJunEoOAieoPtpDVoA0&scisig=AAZF9b9d6aKyqbJtRpaUP3AQ9ki9&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang"]}
{"title": "Multi Language Models for On-the-Fly Syntax Highlighting", "first_label": ["LLM"], "second_label": [], "data": "ME Palma, P Rani, HC Gall- arXiv preprint arXiv:2510.04166, 2025\nSyntax highlighting is a critical feature in modern software development \nenvironments, enhancing code readability and developer productivity. However, \ndelivering accurate highlighting in real time remains challenging for online and web", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04166%3F&hl=en&sa=X&d=2254729212502568662&ei=wB_4aJWSAdyOieoP1t-zoQM&scisig=AAZF9b-GHye_T1XfPPLdXBWI9HsB&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "What Do They Fix? LLM-Aided Categorization of Security Patches for Critical Memory Bugs", "first_label": ["LLM", "Bug"], "second_label": [], "data": "X Li, J Pu, Y Wu, X Zou, S Zhu, Q Wu, Z Zhang, J Hsu- arXiv preprint arXiv, 2025\nOpen-source software projects are foundational to modern software ecosystems, with \nthe Linux kernel standing out as a critical exemplar due to its ubiquity and \ncomplexity. Although security patches are continuously integrated into the Linux", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22796&hl=en&sa=X&d=5877456260761011502&ei=wB_4aJWSAdyOieoP1t-zoQM&scisig=AAZF9b_K5bVx20Ft-L-epPjLrGqv&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Enhancing Code Quality Through Automated Refactoring Using Transformer-Based Language Models.", "first_label": ["LLM", "Code"], "second_label": [], "data": "A Lakshmi, ES Sigamany, R Traisa, R Kumar- International Journal of, 2025\nMaintaining high-quality source code is crucial for software reliability, scalability, and \nmaintainability. Traditional refactoring methods, which involve manual code \nimprovement or rule-based automation, often fall short due to their inability to \nunderstand the contextual semantics of code. These approaches are rigid, language-\nspecific, and prone to inconsistencies, especially in large and complex code bases. \nAs a result, developers spend significant time and effort identifying code smells\nCites: Automatic Programming: Large Language Models and Beyond", "link": "https://scholar.google.com/scholar_url?url=https://search.ebscohost.com/login.aspx%3Fdirect%3Dtrue%26profile%3Dehost%26scope%3Dsite%26authtype%3Dcrawler%26jrnl%3D2158107X%26AN%3D188536315%26h%3DaG%252Fldos2JqmLq9QCsaC08S%252BNMcqgYGCyl5uA%252FKcoqXuoMU9cmUSLFlkTJQueVyb8WOpgHVIk5q2f0IvlkygRBQ%253D%253D%26crl%3Dc&hl=en&sa=X&d=1898894307675892416&ei=wR_4aMzEMdrZzwKX7-SYDw&scisig=AAZF9b8imD9g68xgNm3liq5NmBg2&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Addressing Data Leakage and Imbalance for Robust Fine-Tuning of Pre-Trained Code Language Models in Program Repair and Vulnerability Detection", "first_label": ["Vulnerabilities", "APR", "LLM", "Code"], "second_label": ["Detection", "Repair"], "data": "AS Yadav - 2025\nAbstract Large Language Models (LLMs) hold significant promise for advancing \nautomated vulnerability detection and program repair, yet their effectiveness is often \nconstrained by fundamental issues in dataset construction and learning under \nsevere class imbalance. In this work, we investigate two critical and underexplored \nchallenges that limit real-world applicability.\nCites: Automated repair of programs from large language models. In", "link": "https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/7dfbd6a7d0eed2abea90a8ce491b8286/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=en&sa=X&d=2215683204885920150&ei=wR_4aMzEMdrZzwKX7-SYDw&scisig=AAZF9b-aTTP1vuyxv8xPxyubIY1W&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Specifying and Verifying Future Conditions", "first_label": [], "second_label": [], "data": "Y Song, D Foo, WN Chin- International Static Analysis Symposium, 2025\nThis paper formalizes future conditions, which complement traditional pre-and post-\nconditions to provide a more comprehensive specification of each function's \nbehaviour and expectation. Pre-conditions govern the required states before each \nfunction call, while post-conditions define the immediate outcomes (post-states) upon \ncompletion. Future conditions extend this paradigm by specifying expected temporal \nbehaviors and states that manifest after the function call has finished, potentially\nCites: ProveNFix: Temporal Property guided Program Repair", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1007/978-3-032-07106-4_5&hl=en&sa=X&d=15320364116643882547&ei=wR_4aMzEMdrZzwKX7-SYDw&scisig=AAZF9b-PUHE8sSqruZKjzNKTagsN&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Match & Mend: Minimally Invasive Local Reassembly for Patching N-day Vulnerabilities in ARM Binaries", "first_label": ["Vulnerabilities"], "second_label": [], "data": "S Jnich, M Sievers, J Kinder- arXiv preprint arXiv:2510.14384, 2025\nLow-cost Internet of Things (IoT) devices are increasingly popular but often insecure \ndue to poor update regimes. As a result, many devices run outdated and known-\nvulnerable versions of open-source software. We address this problem by proposing \nto patch IoT firmware at the binary level, without requiring vendor support. In \nparticular, we introduce minimally invasive local reassembly, a new technique for \nautomatically patching known (n-day) vulnerabilities in IoT firmware. Our approach is\nCites: Automated Patch Backporting in Linux (Experience Paper)", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.14384&hl=en&sa=X&d=10145534564009559274&ei=wR_4aMzEMdrZzwKX7-SYDw&scisig=AAZF9b9Rdosk53SryW_ToAbmNzLR&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Systematic Study of Time Limit Exceeded Errors in Online Programming Assignments", "first_label": [], "second_label": [], "data": "J Zhang, J Gu, W Zhang, JP Cambronero, J Kolesar- arXiv preprint arXiv, 2025\nOnline programming platforms such as Codeforces and LeetCode attract millions of \nusers seeking to learn to program or refine their skills for industry interviews. A major \nchallenge for these users is the Time Limit Exceeded (TLE) error, triggered when a \nprogram exceeds the execution time bound. Although designed as a performance \nsafeguard, TLE errors are difficult to resolve: error messages provide no diagnostic \ninsight, platform support is minimal, and existing debugging tools offer little help. As a\nCites: Verifix: Verified Repair of Programming Assignments", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.14339&hl=en&sa=X&d=17212581211702826722&ei=wR_4aMzEMdrZzwKX7-SYDw&scisig=AAZF9b9qmfQVMd9Tch9BlAm6eXNB&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Effective Instrumentation and Runtime Support for Enhancing Software Reliability", "first_label": [], "second_label": [], "data": "H Ling - 2025\nModern system and software development have evolved far beyond the traditional \ncode, compile, and deploy paradigm. Dynamic analysis and runtime monitoring \nhave become essential for enhancing testing, debugging, verification, and \noptimization in continuous development workflows. However, standard compilation \nprocesses and runtime environments often fail to capture the diverse data required \nfor effective dynamic analysis. Integrating additional compilation and runtime support\nCites: Efficient Greybox Fuzzing to Detect Memory Errors", "link": "https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/5eb27945c704a76635e026da1e0b1533/1%3Fpq-origsite%3Dgscholar%26cbl%3D2026366%26diss%3Dy&hl=en&sa=X&d=1957876497109822536&ei=wR_4aMzEMdrZzwKX7-SYDw&scisig=AAZF9b_Hq_iVIFdvVm3GtfIrbXmk&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "SymbFuzz: Symbolic Execution Guided Hardware Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "SS Miftah, A Srivastava, H Kim, S Wei, K Basu- Proceedings of the 58th IEEE/ACM, 2025\nModern hardware incorporates reusable designs to reduce cost and time to market, \ninadvertently increasing exposure to security vulnerabilities. While formal verification \nand simulation-based approaches have been traditionally utilized to mitigate these \nvulnerabilities, formal techniques are hindered by scalability issues, while \nconventional simulation methods frequently overlook critical edge cases. Fuzzing, as \na simulation-based strategy, has demonstrated considerable promise in enhancing\nCites: Coverage-based greybox fuzzing as markov chain", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3725843.3756131&hl=en&sa=X&d=13892451739855032330&ei=wR_4aMzEMdrZzwKX7-SYDw&scisig=AAZF9b88GEUIg1WpJJgBgKOry7E3&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Abhik Roychoudhury - new related research", "Hong Jin Kang - new related research"]}
{"title": "Detecting WebAssembly Runtime Bugs With Grammar-Guided Program Mutation", "first_label": ["Bug"], "second_label": ["Detection"], "data": "X Lu, Z Zhou, X Li, J Xuan, H Wu, H Jiang, Z Ren- IEEE Transactions on Reliability, 2025\nWebAssembly has been steadily gaining popularity in recent years, as an industry-\nwide collaborative effort to combine near-native performance with the convenience of \nhigh-level languages. It is crucial to establish effective testing methods for \nWebAssembly runtime, since all WebAssembly programs depend on the quality of \nthe runtime. Meanwhile, fuzz testing is an effective approach for detecting bugs in \ncompilers and runtimes, and has achieved promising results. However, we still face\nCites: Directed greybox fuzzing\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11205981/&hl=en&sa=X&d=2145699277606162196&ei=wR_4aMzEMdrZzwKX7-SYDw&scisig=AAZF9b-8Bfok0bfhVaiMlj-_R5-P&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=9&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Hong Jin Kang - new related research"]}
{"title": "MALF: A Multi-Agent LLM Framework for Intelligent Fuzzing of Industrial Control Protocols", "first_label": ["LLM", "Fuzzing"], "second_label": ["Agent"], "data": "B Ning, X Zong, K He- arXiv preprint arXiv:2510.02694, 2025\nIndustrial control systems (ICS) are vital to modern infrastructure but increasingly \nvulnerable to cybersecurity threats, particularly through weaknesses in their \ncommunication protocols. This paper presents MALF (Multi-Agent LLM Fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02694&hl=en&sa=X&d=17402884467768873558&ei=wh_4aKD4HLeO6rQP6NHlsQ0&scisig=AAZF9b-gbdcp8la6VIQjpMAaZGFm&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Minoris: Practical Out-of-Emulator Kernel Module Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Xiang, F Wang, Y Chen, Q Liu, H Wang, J Wang- IEEE Transactions on, 2025\nVulnerabilities in the Linux kernel can be exploited to perform privilege escalation \nand take over the whole system. Fuzzing has been leveraged to detect Linux kernel \nvulnerabilities during the last decade. However, existing kernel fuzzing techniques", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11186228/&hl=en&sa=X&d=4018952161547770155&ei=wh_4aKD4HLeO6rQP6NHlsQ0&scisig=AAZF9b_CC9xKPQgXt0Ya_fO_Yt6g&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Extraction and Mutation at a High Level: Template-Based Fuzzing for JavaScript Engines", "first_label": ["Fuzzing"], "second_label": [], "data": "WK Wong, D Xiao, CT Lai, Y Peng, D Wu, S Wang- Proceedings of the ACM on, 2025\nJavaScript (JS) engines implement complex language semantics and optimization \nstrategies to support the dynamic nature of JS, making them difficult to test thoroughly \nand prone to subtle, security-critical bugs. Existing fuzzers often struggle to generate", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3763154&hl=en&sa=X&d=604366854830515299&ei=wh_4aKD4HLeO6rQP6NHlsQ0&scisig=AAZF9b-zybHDhCRxUx1hTq5-Uny_&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Balancing Validity and Vulnerability: Knowledge-Driven Seed Generation via LLMs for Deep Learning Library Fuzzing", "first_label": ["Vulnerabilities", "LLM", "Fuzzing"], "second_label": ["Generation"], "data": "R Liao, X Yan, Z Pang, K Zhu- Applied Sciences, 2025\nFuzzing deep learning (DL) libraries is essential for uncovering security \nvulnerabilities in AI systems. Existing approaches enhance large language models \n(LLMs) with external knowledge such as bug reports to improve the quality of", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2076-3417/15/19/10396&hl=en&sa=X&d=9374413942225787882&ei=wh_4aKD4HLeO6rQP6NHlsQ0&scisig=AAZF9b_coV2M25K3l6JkCX-ZdrMr&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Hong Jin Kang - new related research"]}
{"title": "E-FuzzEdge: Optimizing Embedded Device Security with Scalable In-Place Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "D Rusconi, O Yousef, M Picca, F Toffalini, A Lanzi- arXiv preprint arXiv:2510.01393, 2025\nIn this paper we show E-FuzzEdge, a novel fuzzing architecture targeted towards \nimproving the throughput of fuzzing campaigns in contexts where scalability is \nunavailable. E-FuzzEdge addresses the inefficiencies of hardware-in-the-loop", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01393&hl=en&sa=X&d=876126288656849057&ei=wh_4aKD4HLeO6rQP6NHlsQ0&scisig=AAZF9b8HafEkkmQjPmdiYY4QT43e&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=6&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Clutch Control: An Attention-based Combinatorial Bandit for Efficient Mutation in JavaScript Engine Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "M Foley, S Maffeis, MF Rozi, T Takahashi- arXiv preprint arXiv:2510.12732, 2025\nJavaScript engines are widely used in web browsers, PDF readers, and server-side \napplications. The rise in concern over their security has led to the development of \nseveral targeted fuzzing techniques. However, existing approaches use random", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12732%3F&hl=en&sa=X&d=1368299778829400409&ei=wh_4aKD4HLeO6rQP6NHlsQ0&scisig=AAZF9b8rz6zgLGBAazZeFDCIBtfs&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=7&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "DFAFUZZ: Fuzzing for Embedded JavaScript Virtual Machines with Type-Directed DFA", "first_label": ["Fuzzing"], "second_label": [], "data": "H Lai, B Hua\nJavaScript is rapidly being deployed in securitycritical embedded domains, including \nIoT devices, edge computing, and smart automotive applications. Embedded \nJavaScript virtual machines (VMs) are critical in powering such deployments, which", "link": "https://scholar.google.com/scholar_url?url=https://csslab-ustc.github.io/publications/2025/js-vm-bugs.pdf&hl=en&sa=X&d=14086662969394613156&ei=wh_4aKD4HLeO6rQP6NHlsQ0&scisig=AAZF9b_N79M1UHX5bgLAcXN1CDD7&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=8&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "TeTRIS: General-purpose Fuzzing for Translation Bugs in Source-to-Source Code Transpilers", "first_label": ["Fuzzing", "Code", "Bug"], "second_label": ["Generation"], "data": "Y Arafat, S Nagy - 2025\nAmid the rise of heterogeneous computing and concerns over systems and \napplication security, developers are increasingly embracing transpilers: a growing \nclass of tools for converting code from one programming language into another. As\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://futures.cs.utah.edu/papers/25ACSAC.pdf&hl=en&sa=X&d=7907468188891103628&ei=wh_4aKD4HLeO6rQP6NHlsQ0&scisig=AAZF9b_X5wz-gD-8yp4ujsLZ1oNT&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=9&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Usage patterns of software product metrics in assessing developers' output: A comprehensive study", "first_label": [], "second_label": [], "data": "W Chen, H Yu, G Fan, Z Huang, Y Liang- Information and Software Technology, 2025\nContext: Accurate assessment of developers' output is crucial for both software \nengineering research and industrial practice. This assessment often relies on \nsoftware product metrics such as lines of code (LOC) and quality indicators from \nstatic analysis tools. However, existing research lacks a comprehensive \nunderstanding of the usage patterns of product metrics, and a single metric is \nincreasingly vulnerable to manipulation, particularly with the emergence of large\nCites: Detecting false alarms from automatic static analysis tools: How far\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925002745&hl=en&sa=X&d=4443828525046492267&ei=wB_4aMyNM4m16rQPu6Ol8AM&scisig=AAZF9b9CpIhaWYLtovg6iDR3kHrJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang"]}
{"title": "Detecting and Fixing API Misuses of Data Science Libraries Using Large Language Models", "first_label": ["LLM"], "second_label": ["Detection"], "data": "A Galappaththi, F Ribeiro, S Nadi- arXiv preprint arXiv:2509.25378, 2025\nData science libraries, such as scikit-learn and pandas, specialize in processing and \nmanipulating data. The data-centric nature of these libraries makes the detection of \nAPI misuse in them more challenging. This paper introduces DSCHECKER, an LLM", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25378&hl=en&sa=X&d=14058605386697265462&ei=wx_4aOefEfOx6rQP9IDG8Qs&scisig=AAZF9b9IShG12tfy_E6MI3bYz_8z&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "PIONEER: improving the robustness of student models when compressing pre-trained models of code", "first_label": ["Code"], "second_label": [], "data": "X Liu, X Liu, L Bo, X Wu, Y Yang, X Sun, F Zhou- Automated Software Engineering, 2026\nPre-trained models of code have shown significant effectiveness in a variety of \nsoftware engineering tasks, but they are difficult for local deployment due to their \nlarge size. Existing works mainly focus on compressing these large models into small", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00560-2&hl=en&sa=X&d=17836676178374949159&ei=wx_4aOefEfOx6rQP9IDG8Qs&scisig=AAZF9b_ryg7uDpBLUFYEs8zWj5qt&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Assertion Messages with Large Language Models (LLMs) for Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "A Aljohani, AH Mollah, H Do- arXiv preprint arXiv:2509.19673, 2025\nAssertion messages significantly enhance unit tests by clearly explaining the \nreasons behind test failures, yet they are frequently omitted by developers and \nautomated test-generation tools. Despite recent advancements, Large Language", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19673&hl=en&sa=X&d=7084463702742822906&ei=wx_4aOefEfOx6rQP9IDG8Qs&scisig=AAZF9b93i6m23y0xnjeM1zyUGkQc&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Detecting code paraphrased by large language models using coding style features", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "S Park, H Jin, J Cha, YS Han- Engineering Applications of Artificial Intelligence, 2025\nRecent progress in large language models (LLMs) for code generation has raised \nserious concerns about intellectual property protection. Malicious users can exploit \nLLMs to produce paraphrased versions of proprietary code that closely resemble the", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0952197625024856&hl=en&sa=X&d=5148275569496423324&ei=wx_4aOefEfOx6rQP9IDG8Qs&scisig=AAZF9b_ntG39PI9nkGiO4Gwy8bEN&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "ATGen: Adversarial Reinforcement Learning for Test Case Generation", "first_label": ["Software Testing"], "second_label": ["Generation"], "data": "Q Li, X Dai, W Liu, X Li, Y Wang, R Tang, Y Yu- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) excel at code generation, yet their outputs often \ncontain subtle bugs, for which effective test cases are a critical bottleneck. Existing \ntest generation methods, whether based on prompting or supervised fine-tuning, rely\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.14635&hl=en&sa=X&d=11721547930993359857&ei=wx_4aOefEfOx6rQP9IDG8Qs&scisig=AAZF9b9Faw97UWJFcd1PbLANiD01&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Generating High-Quality Datasets for Code Editing via Open-Source Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "Z Zhang, M Liu, Z Chen, L Liang, Y Chen, G Ou- arXiv preprint arXiv, 2025\nCode editing plays a vital role in software engineering, requiring developers to adjust \nexisting code according to natural language instructions while keeping functionality \nintact and avoiding unnecessary modifications. However, commit-based datasets", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25203&hl=en&sa=X&d=16003307718581653243&ei=4KD2aNP2K4m16rQPu6Ol8AM&scisig=AAZF9b-WX82g5S_NgG548uiHBBUN&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "SWE-QA: Can Language Models Answer Repository-level Code Questions?", "first_label": ["LLM", "Code", "Repository-Level"], "second_label": [], "data": "W Peng, Y Shi, Y Wang, X Zhang, B Shen, X Gu- arXiv preprint arXiv:2509.14635, 2025\nUnderstanding and reasoning about entire software repositories is an essential \ncapability for intelligent software engineering tools. While existing benchmarks such \nas CoSQA and CodeQA have advanced the field, they predominantly focus on small", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.14635&hl=en&sa=X&d=15006803551698078506&ei=4KD2aNP2K4m16rQPu6Ol8AM&scisig=AAZF9b-gcqnrJWuOC2cDSJR6nYNt&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Bach Le - new related research"]}
{"title": "Llama-Based Source Code Vulnerability Detection: Prompt Engineering vs Fine Tuning", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "DS Ouchebara, S Dupont- European Symposium on Research in Computer, 2025\nThe significant increase in software production, driven by the acceleration of \ndevelopment cycles over the past two decades, has led to a steady rise in software \nvulnerabilities, as shown by statistics published yearly by the CVE program. The", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-07884-1_15&hl=en&sa=X&d=16960497214690829179&ei=4KD2aNP2K4m16rQPu6Ol8AM&scisig=AAZF9b-UNFhJHUBNG5l-ec_dQkkA&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "On the Evaluation of Large Language Models in Multilingual Vulnerability Repair", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Repair"], "data": "D Wang, J Yu, H Shu, M Fu, C Tantithamthavorn- ACM Transactions on, 2025\nVarious Deep Learning-based approaches with pre-trained language models have \nbeen proposed for automatically repairing software vulnerabilities. However, these \napproaches are limited to a specific programming language (C/C++). Recent", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3771930&hl=en&sa=X&d=1573924928630608849&ei=4KD2aNP2K4m16rQPu6Ol8AM&scisig=AAZF9b__u96hBtwhKokXlEBrTBGg&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "1 new citation to articles by Quang-Cuong Bui", "8 new citations to articles by Abhik Roychoudhury", "4 new citations to articles by Xin ZHOU", "David Lo - new related research"]}
{"title": "PVDetector: Pretrained Vulnerability Detection on Vulnerability-enriched Code Semantic Graph", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection", "Graph"], "data": "J Li, L Cui, J Zhang, L Li, R Xi, H Zhu- ACM Transactions on Software Engineering, 2025\nAutomated vulnerability detection is a critical issue in software security. The advent of \ndeep learning (DL) has led to numerous studies employing DL to detect \nvulnerabilities in software source code. However, existing approaches still perform", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3768582&hl=en&sa=X&d=8582469852291084545&ei=4KD2aNP2K4m16rQPu6Ol8AM&scisig=AAZF9b-KDpNTmZzjJ738P4MlJP3u&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "Assessing the Latent Automated Program Repair Capabilities of Large Language Models using Round-Trip Translation", "first_label": ["APR", "LLM"], "second_label": ["Repair", "Generation"], "data": "F Vallecillos Ruiz, A Grishina, M Hort, L Moonen- ACM Transactions on Software, 2025\nResearch shows that errors in natural language can be corrected by translating texts \nto another language and back using language models. We explore to what extent \nthis latent correction capability extends to Automated Program Repair (APR) by", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3771922&hl=en&sa=X&d=7692600566103524135&ei=4KD2aNP2K4m16rQPu6Ol8AM&scisig=AAZF9b94X1t1g5M_Ji0DwLkthHnK&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "Thanh Le-Cong - new related research", "Abhik Roychoudhury - new related research", "Bach Le - new related research", "David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Large Language Models for Software Testing: A Research Roadmap", "first_label": ["LLM", "Software Testing"], "second_label": ["Search"], "data": "C Augusto, A Bertolino, G De Angelis, F Lonetti- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) are starting to be profiled as one of the most \nsignificant disruptions in the Software Testing field. Specifically, they have been \nsuccessfully applied in software testing tasks such as generating test code, or", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25043&hl=en&sa=X&d=1208330022631398164&ei=4KD2aNP2K4m16rQPu6Ol8AM&scisig=AAZF9b9b4upJnsQek3OFr6wbVQSd&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "The Richer Representation Fallacy: Are We Just Adding Noise to LLM-based Software Vulnerability Detectors?", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "H Hanif, S Maffeis, NB Anuar\nLarge Language Models (LLMs) have established strong baselines for software \nvulnerability detection, leading to a common assumption that their performance can \nbe enhanced by augmenting them with supplementary information such as Abstract\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.doc.ic.ac.uk/~maffeis/papers/icoco25.pdf&hl=en&sa=X&d=9374945953362351896&ei=4KD2aNP2K4m16rQPu6Ol8AM&scisig=AAZF9b8kuDDgBtCLNX4BQ9S00QXz&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "M2CVD: Enhancing Vulnerability Understanding through Multi-Model Collaboration for Code Vulnerability Detection", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "Z Wang, G Li, J Li, J Li, M Yan, Y Xiong, Z Jin- ACM Transactions on Software, 2025\nLarge Language Models (LLMs) have strong capabilities in code comprehension, \nbut fine-tuning costs and semantic alignment issues limit their project-specific \noptimization; conversely, fine-tuned models such as CodeBERT are easy to fine", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3771923&hl=en&sa=X&d=13259446402958610018&ei=36D2aMOpIdrZzwKX7-SYDw&scisig=AAZF9b8ps53CJHIdNi_Igzsg-wO_&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "Thanh Le-Cong - new related research", "Richard Fang - new related research", "Xin ZHOU - new related research"]}
{"title": "Towards Automatic Heap Exploit Generation by Using Heap Layout Constraints on Binary Programs", "first_label": [], "second_label": ["Generation", "Exploit"], "data": "J Liu, L Yao, Y Li, H Liang- IEEE Transactions on Information Forensics and, 2025\nAutomatic exploit generation (AEG) is widely recognized as one of the most effective \nmethods for assessing the risk level of vulnerabilities. To exploit heap-related \nvulnerabilities, it is necessary to precisely form a desired heap layout and construct\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11204683/&hl=en&sa=X&d=12995858747495516241&ei=36D2aMOpIdrZzwKX7-SYDw&scisig=AAZF9b96PzAh-wyH1XF8pnkUsLie&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Leveraging Intra-and Inter-References in vulnerability detection using Multi-Agent collaboration based on LLMs", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Agent"], "data": "CN Tsai, J Xie, CM Lai, CS Lin- Cluster Computing, 2025\nAs AI technology advances, early detection of code vulnerabilities becomes \nincreasingly critical for preventing exploitation, reducing remediation costs, \nenhancing user trust, and improving system performance. Recently, Large language", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10586-025-05721-2&hl=en&sa=X&d=10835680397604577360&ei=3qD2aJCpC9qI6rQP1eu4sQI&scisig=AAZF9b-8m1Pjd5UfUHC6oVBMil6f&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "2 new citations to articles by Hong Jin Kang", "4 new citations to articles by Xin ZHOU"]}
{"title": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Repair", "Reasoning"], "data": "XC Wen, Z Lin, Y Yang, C Gao, D Ye- arXiv preprint arXiv:2510.05480, 2025\nThe exponential increase in software vulnerabilities has created an urgent need for \nautomatic vulnerability repair (AVR) solutions. Recent research has formulated AVR \nas a sequence generation problem and has leveraged large language models", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05480&hl=en&sa=X&d=17087307418542281791&ei=3qD2aJCpC9qI6rQP1eu4sQI&scisig=AAZF9b9CCuNgJaX2E80axtHSP4yC&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Auto-repair without test cases: How LLMs fix compilation errors in large industrial embedded code", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Repair"], "data": "H Fu, S Eldh, K Wiklund, A Ermedahl, P Haller, C Artho- arXiv preprint arXiv, 2025\nThe co-development of hardware and software in industrial embedded systems \nfrequently leads to compilation errors during continuous integration (CI). Automated \nrepair of such failures is promising, but existing techniques rely on test cases, which", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.13575&hl=en&sa=X&d=1687674771727401275&ei=3qD2aJCpC9qI6rQP1eu4sQI&scisig=AAZF9b-7TRS9QYvOORMoj3Q9nJl9&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "8 new citations to articles by Abhik Roychoudhury", "2 new citations to articles by Bach Le"]}
{"title": "Improving the Efficiency of LLM Agent Systems through Trajectory Reduction", "first_label": ["LLM"], "second_label": ["Agent"], "data": "YA Xiao, P Gao, C Peng, Y Xiong- arXiv preprint arXiv:2509.23586, 2025\nMulti-turn agent systems based on Large Language Models (LLMs) have been \nincreasingly popular for software engineering tasks. While LLM agents show decent \neffectiveness, the high computational cost of input tokens due to the ever-growing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23586%3F&hl=en&sa=X&d=12596444921036280365&ei=3qD2aJCpC9qI6rQP1eu4sQI&scisig=AAZF9b-zx_eKF_ZSiOU7-hQKM67w&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Real-VulLLM: An LLM Based Assessment Framework in the Wild", "first_label": ["LLM"], "second_label": [], "data": "R Safdar, D Mateen, ST Ali, W Hussain- arXiv preprint arXiv:2510.04056, 2025\nArtificial Intelligence (AI) and more specifically Large Language Models (LLMs) have \ndemonstrated exceptional progress in multiple areas including software engineering, \nhowever, their capability for vulnerability detection in the wild scenario and its", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04056&hl=en&sa=X&d=7464868966945655593&ei=3qD2aJCpC9qI6rQP1eu4sQI&scisig=AAZF9b9spMVaIeR2Fu3V7bKIho7O&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "X Yin, C Ni, X Li, L Chen, G Ma, X Yang\nRecently, Large Language Models (LLMs) have gained attention for their ability to \nhandle a broad range of tasks, including unit test generation. Despite their success, \nLLMs may exhibit hallucinations when generating unit tests for focal methods or\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://vinci-grape.github.io/papers/Enhancing_LLM_s_Ability_to_Generate_More_Repository_Aware_Unit_Tests_Through_Precise_Context_Injection.pdf&hl=en&sa=X&d=3506872574868649515&ei=3qD2aJCpC9qI6rQP1eu4sQI&scisig=AAZF9b8t-WfSL2eZjQ-5h6SvSin3&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Isolating Compiler Bugs through Compilation Steps Analysis", "first_label": ["Bug"], "second_label": [], "data": "Y Liu, M Zhu, S Cheng, D Hao- arXiv preprint arXiv:2510.13128, 2025\nCompilers are essential to software systems, and their bugs can propagate to \ndependent software. Ensuring compiler correctness is critical. However, isolating \ncompiler bugs remains challenging due to the internal complexity of compiler \nexecution. Existing techniques primarily mutate compilation inputs to generate \npassing and failing tests, but often lack causal analysis of internal steps, limiting their \neffectiveness. To address this limitation, we propose CompSCAN, a novel compiler\nCites: DuoReduce: Bug Isolation for Multi-layer Extensible Compilation", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.13128&hl=en&sa=X&d=16013803281503570850&ei=3qD2aJKKGoOAieoPtpDVoA0&scisig=AAZF9b8pcJWFnqzchElg3toQfAp-&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang"]}
{"title": "International AI Safety Report 2025: First Key Update: Capabilities and Risk Implications", "first_label": [], "second_label": [], "data": "Y Bengio, S Clare, C Prunkl, S Rismani- arXiv preprint arXiv, 2025\nSince the publication of the first International AI Safety Report, AI capabilities have \ncontinued to improve across key domains. New training techniques that teach AI \nsystems to reason step-by-step and inference-time enhancements have primarily \ndriven these advances, rather than simply training larger models. As a result, general-\npurpose AI systems can solve more complex problems in a range of domains, from \nscientific research to software development. Their performance on benchmarks that\nCites: CVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.13653&hl=en&sa=X&d=6861223748622218845&ei=3aD2aOaDOc6E6rQPjY_jkQI&scisig=AAZF9b-_HUW3LSC6AwNFALOAVHZJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["3 new citations to articles by Richard Fang"]}
{"title": "Known Unknowns and Unknown Unknowns: Designing a Scalable Adverse Event Reporting System for AI", "first_label": [], "second_label": [], "data": "L Gailmard, D Spence, C Lawrence, DE Ho- of the AAAI/ACM Conference on AI, 2025\nThere continues to be substantial uncertainty surrounding the risks posed by \nadvanced general-purpose or 'frontier'AI models. Many riskslike security \nvulnerabilities, misuse, or ethical failuresare highly context-dependent and may \nonly become apparent post-deployment, limiting the feasibility of developing effective \nex ante safeguards like pre-deployment testing and capability evaluations. We argue \nthat adverse event (AE) reporting systems, long-used in sectors like healthcare and\nCites: Removing rlhf protections in gpt-4 via fine-tuning", "link": "https://scholar.google.com/scholar_url?url=https://ojs.aaai.org/index.php/AIES/article/download/36607/38745&hl=en&sa=X&d=721133511746560279&ei=3aD2aOaDOc6E6rQPjY_jkQI&scisig=AAZF9b8VzalNOZVWcfYOSosQ7iuE&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["3 new citations to articles by Richard Fang"]}
{"title": "GRIDAI: Generating and Repairing Intrusion Detection Rules via Collaboration among Multiple LLM-based Agents", "first_label": ["LLM"], "second_label": ["Detection", "Repair", "Agent"], "data": "J Li, Y Chai, L Du, C Duan, H Yan, Z Gu- arXiv preprint arXiv:2510.13257, 2025\nRule-based network intrusion detection systems play a crucial role in the real-time \ndetection of Web attacks. However, most existing works primarily focus on \nautomatically generating detection rules for new attacks, often overlooking the \nrelationships between new attacks and existing rules, which leads to significant \nredundancy within the ever-expanding ruleset. To address this issue, we propose \nGRIDAI, a novel end-to-end framework for the automated Generation and Repair of\nCites: Llm agents can autonomously exploit one-day vulnerabilities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.13257&hl=en&sa=X&d=12674899394348316534&ei=3aD2aOaDOc6E6rQPjY_jkQI&scisig=AAZF9b8bd4rCYfLiOvVnLQLvXA3K&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=2&folt=cit", "author": ["Richard Fang"], "ref": ["3 new citations to articles by Richard Fang", "8 new citations to articles by Abhik Roychoudhury"]}
{"title": "Backdoor-Powered Prompt Injection Attacks Nullify Defense Methods", "first_label": [], "second_label": [], "data": "Y Chen, H Li, Y Sui, Y Song, B Hooi- arXiv preprint arXiv:2510.03705, 2025\nWith the development of technology, large language models (LLMs) have dominated \nthe downstream natural language processing (NLP) tasks. However, because of the \nLLMs' instruction-following abilities and inability to distinguish the instructions in the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03705&hl=en&sa=X&d=9793005798347645046&ei=4KD2aPWIFYeVieoP9e_euQw&scisig=AAZF9b_HnZpDS0idSVQ9IazqK7ZK&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Q Wei, T Yang, Y Wang, X Li, L Li, Z Yin, Y Zhan, T Holz- arXiv preprint arXiv, 2025\nLarge Language Model (LLM) agents use memory to learn from past interactions, \nenabling autonomous planning and decision-making in complex environments. \nHowever, this reliance on memory introduces a critical security risk: an adversary can", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02373%3F&hl=en&sa=X&d=4598414696562770679&ei=4KD2aPWIFYeVieoP9e_euQw&scisig=AAZF9b81TzOjaUWLDsP44BPpjuXB&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Dual-Space Smoothness for Robust and Balanced LLM Unlearning", "first_label": ["LLM"], "second_label": [], "data": "H Yan, Z Liu, M Jiang- arXiv preprint arXiv:2509.23362, 2025\nWith the rapid advancement of large language models, Machine Unlearning has \nemerged to address growing concerns around user privacy, copyright infringement, \nand overall safety. Yet state-of-the-art (SOTA) unlearning methods often suffer from", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23362&hl=en&sa=X&d=1871730686130311929&ei=4KD2aPWIFYeVieoP9e_euQw&scisig=AAZF9b8As51yVW8jz__d_c1PoJ_F&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "MetaBreak: Jailbreaking Online LLM Services via Special Token Manipulation", "first_label": ["LLM"], "second_label": [], "data": "W Zhu, Z Xiang, W Niu, L Guan- arXiv preprint arXiv:2510.10271, 2025\nUnlike regular tokens derived from existing text corpora, special tokens are artificially \ncreated to annotate structured conversations during the fine-tuning process of Large \nLanguage Models (LLMs). Serving as metadata of training data, these tokens play a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10271&hl=en&sa=X&d=10904776402205985786&ei=4KD2aPWIFYeVieoP9e_euQw&scisig=AAZF9b_F0Cun6iwf_kcQRFluBJsN&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Webcloak: Characterizing and mitigating the threats of llm-driven web agents as intelligent scrapers", "first_label": ["LLM"], "second_label": ["Agent"], "data": "X Li, T Qiu, Y Jin, L Wang, H Guo, X Jia, X Wang- Proceedings of the 2026, 2026\nThe rise of web agents powered by large language models (LLMs) is reshaping the \nlandscape of human-computer interaction, enabling users to automate complex web \ntasks with natural language commands. However, this progress introduces serious", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Xinfeng-Li-7/publication/396418425_WebCloak_Characterizing_and_Mitigating_Threats_from_LLM-Driven_Web_Agents_as_Intelligent_Scrapers/links/68ea2bc4f3032e2b4be84935/WebCloak-Characterizing-and-Mitigating-Threats-from-LLM-Driven-Web-Agents-as-Intelligent-Scrapers.pdf&hl=en&sa=X&d=11222165444201781035&ei=4KD2aPWIFYeVieoP9e_euQw&scisig=AAZF9b_YUPVueXaKg_vffu8We5ja&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "C Ziakas, N Loo, N Jain, A Russo- arXiv preprint arXiv:2510.07239, 2025\nAutomated red-teaming has emerged as a scalable approach for auditing Large \nLanguage Models (LLMs) prior to deployment, yet existing approaches lack \nmechanisms to efficiently adapt to model-specific vulnerabilities at inference. We", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07239%3F&hl=en&sa=X&d=7730973334197366962&ei=4KD2aPWIFYeVieoP9e_euQw&scisig=AAZF9b_6OS1meKBJ_r2Js8UAke4U&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?", "first_label": [], "second_label": ["Agent"], "data": "X Deng, J Da, E Pan, YY He, C Ide, K Garg, N Lauffer- arXiv preprint arXiv, 2025\nWe introduce SWE-Bench Pro, a substantially more challenging benchmark that \nbuilds upon the best practices of SWE-BENCH [25], but is explicitly designed to \ncapture realistic, complex, enterprise-level problems beyond the scope of SWE", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.16941&hl=en&sa=X&d=16612405126166951427&ei=4KD2aPWIFYeVieoP9e_euQw&scisig=AAZF9b_Sny1WEMFE1cCFOEYpk5pL&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Valid Stopping for LLM Generation via Empirical Dynamic Formal Lift", "first_label": ["LLM"], "second_label": ["Generation"], "data": "S Akter, IF Shihab, A Sharma- arXiv preprint arXiv:2510.06478, 2025\nWe introduce Sequential-EDFL (Empirical Dynamic Formal Lift), applying anytime-\nvalid sequential testing to language model generation stopping. Our approach tracks \ninformation lift--the log-likelihood ratio between full models and deliberately", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.06478&hl=en&sa=X&d=14932518012707883160&ei=4KD2aPWIFYeVieoP9e_euQw&scisig=AAZF9b9Dby7z2N2n_QBkW3Cth3vw&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Certifiable Safe RLHF: Fixed-Penalty Constraint Optimization for Safer Language Models", "first_label": ["LLM"], "second_label": [], "data": "K Pandit, S Ganguly, A Banerjee, S Angizi, A Ghosh- arXiv preprint arXiv:2510.03520, 2025\nEnsuring safety is a foundational requirement for large language models (LLMs). \nAchieving an appropriate balance between enhancing the utility of model outputs \nand mitigating their potential for harm is a complex and persistent challenge\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03520&hl=en&sa=X&d=4542062984345920079&ei=4KD2aPWIFYeVieoP9e_euQw&scisig=AAZF9b_omsEoXaAlAeSrRZXeE5Ed&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Large Language Models (LLMs) in Programming Learning: The Current Research State and Agenda", "first_label": ["LLM"], "second_label": ["Search"], "data": "Q Fu, Y Zhao, Z Jia, Y Zheng- IEEE Transactions on Learning Technologies, 2025\nLarge Language Models (LLMs) show great potential in programming learning. \nHowever, existing studies mainly focus on technical implementations and lacks a \nsystematic analysis of the application of LLMs in programming learning from an \neducational perspective. This study conducts a systematic literature review and \nbibliometric analysis based on 75 high-quality papers, using a six-dimensional \nframework (roles, technology, learners, environment, effectiveness, challenges) to\nCites: Program Repair and Trusted Automatic Programming", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11204697/&hl=en&sa=X&d=1593122820067521352&ei=36D2aP29FPOx6rQP9IDG8Qs&scisig=AAZF9b9RVC4JnfUOOw_zvXURHAN2&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "Hydra-Reviewer: A holistic multi-agent system for automatic code review comment generation", "first_label": ["Code Review", "Code"], "second_label": ["Generation", "Agent"], "data": "X Ren, C Dai, Q Huang, Y Wang, C Liu, B Jiang- IEEE Transactions on Software, 2025\nReview comment generation is a crucial task in code review, and significant progress \nhas been made in automating. Previous research has generated review comments \nby fine-tuning pre-trained models or Large Language Models (LLMs). However, \nthese studies have overlooked the necessity of conducting code reviews from \nmultiple perspectives, resulting in the omission of potential issues in code changes. \nAdditionally, the complexity of review comments often hinders the accurate\nCites: AutoCodeRover: Autonomous program improvement", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11203269/&hl=en&sa=X&d=17879938940610844353&ei=36D2aP29FPOx6rQP9IDG8Qs&scisig=AAZF9b_gqkBWl0IZHAP0JgQgZLEw&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "Automated Network Protocol Testing with LLM Agents", "first_label": ["LLM", "Software Testing"], "second_label": ["Agent"], "data": "Y Wei, K Wei, S Du, J Wang, Z Liu, Y Wang, Z Li- arXiv preprint arXiv, 2025\nNetwork protocol testing is fundamental for modern network infrastructure. However, \ntraditional network protocol testing methods are labor-intensive and error-prone, \nrequiring manual interpretation of specifications, test case design, and translation \ninto executable artifacts, typically demanding one person-day of effort per test case. \nExisting model-based approaches provide partial automation but still involve \nsubstantial manual modeling and expert intervention, leading to high costs and\nCites: Large language model guided protocol fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.13248&hl=en&sa=X&d=5665301522675711612&ei=36D2aP29FPOx6rQP9IDG8Qs&scisig=AAZF9b-mKUiStmalXwVFXGH3TN8i&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Comparative Study of Android Performance Issues in Real-world Applications and Literature", "first_label": [], "second_label": [], "data": "D Liao, S Pan, S Yang, Y Zhao, Z Xing, X Sun- ACM Transactions on Software Engineering\nPerformance issues in Android applications significantly undermine users' \nexperience, engagement, and retention, which is a long-lasting research topic in \nacademia. Unlike functionality issues, performance issues are more difficult to \ndiagnose and resolve due to their complex root causes, which often emerge only \nunder specific conditions or payloads. Although many efforts have attempted to \nmitigate the impact of performance issues by developing methods to automatically\nCites: Timemachine: Time-travel testing of android apps", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3771932&hl=en&sa=X&d=7146109357952409381&ei=36D2aP29FPOx6rQP9IDG8Qs&scisig=AAZF9b-1tHNtS7TT8K5O0LqUAhlP&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "Automated Test Data and Test Oracle Generation for REST APIs", "first_label": ["Software Testing"], "second_label": ["Generation"], "data": "JCA Valenzuela - 2025\nSupport: This work has been partially supported by grants PID2021-126227NB-C22 \nand PID2021-126227NB-C21, funded by MCIN/AEI/10.13039/501100011033/\nFEDER, UE. Other contributing projects are grant TED2021-131023B-C21, funded \nby MCIN/AEI/10.13039/501100011033 and by European Union \nNextGenerationEU/PRTR; and Smart Computer systems Research and \nEngineering (SCORE), funded by the Consejera de Transformacin Econmica\nCites: Program Vulnerability Repair via Inductive Inference", "link": "https://scholar.google.com/scholar_url?url=https://idus.us.es/server/api/core/bitstreams/4bbe0929-d74c-40b1-bb0b-4f94cbf7db57/content&hl=en&sa=X&d=2454959439065122844&ei=36D2aP29FPOx6rQP9IDG8Qs&scisig=AAZF9b8wfABnstNrKEU0IYL4hOZ1&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "Analyzing Compliance with Safety Standards in C Code via Large Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "D Nueanu, A Guzu, G Nicolae- 2025 International Symposium ELMAR, 2025\nEnsuring code compliance with safety standards such as MISRA C: 2012 is essential \nfor the development of reliable and secure embedded systems in domains like \nautomotive software. Traditional compliance checks rely on rule-based static \nanalyzers, but recent advances in large language models (LLMs) suggest potential \nfor automating such tasks. This paper investigates the zero-shot capabilities of four \ngeneral-purpose LLMs, such as GPT-4o, LLaMA 3.1, O3-mini, and Mixtral, in\nCites: Large language model for vulnerability detection: Emerging results", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11194021/&hl=en&sa=X&d=3139537408139826209&ei=4KD2aJi6CYGpieoPyfaRyA4&scisig=AAZF9b80tvWYeJdsZm-nVdJ1PK9t&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "SpareCodeSearch: Searching for Code Context When You Have No Spare GPU", "first_label": ["Code"], "second_label": ["Search"], "data": "M Nguyen- arXiv preprint arXiv:2510.12948, 2025\nRetrieval-Augmented Generation (RAG) frameworks aim to enhance Code \nLanguage Models (CLMs) by including another module for retrieving relevant context \nto construct the input prompt. However, these retrieval modules commonly use \nsemantic search, requiring substantial computational resources for training and \nhosting these embedded models, making them infeasible to integrate into lightweight \napplications such as in-IDE AI-based code completion. In this solution paper, we\nCites: Assessing generalizability of codebert\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12948&hl=en&sa=X&d=10123008367277861528&ei=4KD2aJi6CYGpieoPyfaRyA4&scisig=AAZF9b9lvj2zvDb6UfpoZjeBpJD0&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=3&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "InsightQL: Advancing Human-Assisted Fuzzing with a Unified Code Database and Parameterized Query Interface", "first_label": ["Fuzzing", "Code"], "second_label": [], "data": "W Gao, R Borovica-Gajic, SK Cha, T Qiu, VT Pham- arXiv preprint arXiv:2510.04835, 2025\nFuzzing is a highly effective automated testing method for uncovering software \nvulnerabilities. Despite advances in fuzzing techniques, such as coverage-guided \ngreybox fuzzing, many fuzzers struggle with coverage plateaus caused by fuzz", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04835&hl=en&sa=X&d=7721758508651636625&ei=36D2aOv6LYeVieoP9e_euQw&scisig=AAZF9b9S6TLnsxYfSiDSKvyS6fS2&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "A Survey for MQTT Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "SY Chowdhury, R Sun, B Dudley- Proceedings of the 2025 Workshop on Re-design, 2025\nMessage Queuing Telemetry Transport (MQTT) has emerged as a promising \ncommunication protocol for Internet of Things (IoT) ecosystems, enabling lightweight, \nscalable publish-subscribe messaging across resource-constrained devices. As", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3733823.3764515&hl=en&sa=X&d=13012329971672204999&ei=36D2aOv6LYeVieoP9e_euQw&scisig=AAZF9b8vgf7FG03SkoQTaHno7c8H&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "DynamiQ: Unlocking the Potential of Dynamic Task Allocation in Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "W Yan, T Murray, B Rubinstein, VT Pham- arXiv preprint arXiv:2510.04469, 2025\nWe present DynamiQ, a full-fledged and optimized successor to AFLTeam that \nsupports dynamic and adaptive parallel fuzzing. Unlike most existing approaches \nthat treat individual seeds as tasks, DynamiQ leverages structural information from", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04469&hl=en&sa=X&d=10962816615102660239&ei=36D2aOv6LYeVieoP9e_euQw&scisig=AAZF9b_5VltWA46OsWSnq5GXtqKm&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing", "first_label": ["LLM", "Fuzzing", "Bug"], "second_label": [], "data": "S Ou, Y Li, L Yu, C Wei, T Wen, Q Chen, Y Chen- IEEE Transactions on, 2025\nDeep learning (DL) frameworks serve as the backbone for a wide range of artificial \nintelligence applications. However, bugs within DL frameworks can cascade into \ncritical issues in higher-level applications, jeopardizing reliability and security. While", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/32/4359463/11201027.pdf&hl=en&sa=X&d=1422528139240657868&ei=36D2aOv6LYeVieoP9e_euQw&scisig=AAZF9b899-spy-aa2AQhyA9vfr3w&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Function Clustering-Based Fuzzing Termination: Toward Smarter Early Stopping", "first_label": ["Fuzzing"], "second_label": [], "data": "L Ding, W Yang, Y Xue\nFuzzing is a testing technique that generates a large number of inputs to cause \nprogram crashes. As software development accelerates and projects scale, the \ndemand for fuzz testing in software assurance has increased. Performing", "link": "https://scholar.google.com/scholar_url?url=https://wzyang.cn/files/FuzzingTermination.pdf&hl=en&sa=X&d=16741608997780760317&ei=36D2aOv6LYeVieoP9e_euQw&scisig=AAZF9b8PamUxP4hadUhNaXUhRS_c&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "CG-Bench: Can Language Models Assist Call Graph Construction in the Real World?", "first_label": ["LLM", "Static Analysis"], "second_label": ["Graph"], "data": "T Yuan, W Zhang, D Chen, J Wang- Proceedings of the 1st ACM SIGPLAN, 2025\nLanguage models for coding are shifting their focus from function-level to repository-\nlevel, with complex function invocations. We introduce CG-Bench, the first manually \nconstructed benchmark that measures the ability to understand call graphs for", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3759425.3763379&hl=en&sa=X&d=11570618845570061776&ei=36D2aOv6LYeVieoP9e_euQw&scisig=AAZF9b8qflr4UNBQdgiN0mJqf1U8&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=6&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Blockchain based intelligent sensing and digital network security promote trust mechanism for rural tourism information sharing", "first_label": ["Blockchain"], "second_label": [], "data": "G Hu- International Journal of System Assurance Engineering, 2025\nIn the process of promoting the development of the rural tourism industry, the issue of \ndigital network security on the rural tourism information sharing platform has become \nincreasingly prominent, becoming a key factor affecting the stable operation of the \nplatform and user trust. A large amount of rural tourism data is stored on online \nplatforms. These data include tourists' personal information, travel preferences, etc., \nas well as the business secrets and operational data of tourism enterprises. This\nCites: Smart contract development: Challenges and opportunities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s13198-025-03014-w&hl=en&sa=X&d=3456041397637571711&ei=3qD2aJa-KO2ZieoP7ueJyQk&scisig=AAZF9b8_YAGaVQLjGhac4mcp-NZn&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le"]}
{"title": "Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "K Shehada, Y Wu, WD Feng, A Iyer, G Kumfert, Y Ding- NeurIPS 2025 Workshop on\nLarge Language Models (LLMs) have revolutionized automated program repair \n(APR) but current benchmarks like SWE-Bench predominantly focus on userspace \napplications and overlook the complexities of kernel-space debugging and repair", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DNY4wv5C39G&hl=en&sa=X&d=13284020585308537468&ei=3aD2aPWOKbeO6rQP6NHlsQ0&scisig=AAZF9b8qiQW2WOt5dhxoK0fl5lFh&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation", "first_label": ["LLM", "Fault Localization"], "second_label": ["Localization"], "data": "F Liu, T Wang, L Zhang, Z Yang, J Jiang, Z Sun- arXiv preprint arXiv:2509.25676, 2025\nProviding timely and personalized guidance for students' programming assignments, \noffers significant practical value for helping students complete assignments and \nenhance their learning. In recent years, various automated Fault Localization (FL)", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25676&hl=en&sa=X&d=16831300563596066577&ei=3aD2aPWOKbeO6rQP6NHlsQ0&scisig=AAZF9b8KiRs4870r1KbKTYTF0UyR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=3&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Automating software size measurement with language models: Insights from industrial case studies", "first_label": ["LLM"], "second_label": [], "data": "H nl, S Tenekeci, DE Kennouche, O Demirrs- Journal of Systems and Software, 2025\nObjective software size measurement is critical for accurate effort estimation, yet \nmany organizations avoid it due to high costs, required expertise, and time-\nconsuming manual effort. This often leads to vague predictions, poor planning, and\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225003073&hl=en&sa=X&d=5059883465057516935&ei=3aD2aPWOKbeO6rQP6NHlsQ0&scisig=AAZF9b_UuarYpBo8g6NwqQ3xVSkn&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=5&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "The Prevalence of Code Review Guidelines for GUI-Based Testing in Open-Source", "first_label": ["Code Review", "Code", "Software Testing"], "second_label": [], "data": "A Bauer, F Angermeir, E Algroth, S Anglert- Information and Software Technology, 2025\nObjective: This study empirically assesses the extent to which code review comments \non GUI-based tests align (explicitly or implicitly) with the concerns captured by the \nproposed guidelines, and uses the findings to refine the guideline set. Method: To", "link": "https://scholar.google.com/scholar_url?url=https://www.diva-portal.org/smash/get/diva2:2003977/FULLTEXT01.pdf&hl=en&sa=X&d=14168269758172692059&ei=36D2aMaaB86E6rQPjY_jkQI&scisig=AAZF9b-KZHkNm2VYW4N0go6nXp21&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Documenting User Stories: Does LLM Help?", "first_label": ["LLM"], "second_label": [], "data": "P Garcia, JV Depollo, L Barroso, E Figueiredo\nThe increasing capabilities of large language models (LLMs) offer a promising \navenue for enhancing human-intensive software engineering activities, such as \nrequirements elicitation. However, we lack strong empirical evidence on the impact\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://homepages.dcc.ufmg.br/~figueiredo/publications/sbqs2025preprint.pdf&hl=en&sa=X&d=12679601984378585658&ei=36D2aMaaB86E6rQPjY_jkQI&scisig=AAZF9b9_5Bc-ZscMWSo0pNibtRHc&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "OpCodeBERT: A Method for Python Code Representation Learning by BERT with Opcode", "first_label": ["Code"], "second_label": [], "data": "C Qiu, J Liu, X Xiao, Y Xiao- IEEE Transactions on Software Engineering, 2025\nProgramming language pre-training models have made significant progress in code \nrepresentation learning in recent years. Although various methods, such as data flow \nand Abstract Syntax Tree (AST), have been widely applied to enhance code", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11169752/&hl=en&sa=X&d=1825874209020573091&ei=4KD2aJvMIIOAieoPtpDVoA0&scisig=AAZF9b-cenZWTH8w2_NrvGDeuIZA&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "LLM-based Vulnerability Discovery through the Lens of Code Metrics", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": [], "data": "F Weissberg, L Pirch, E Imgrund, J Mller, T Eisenhofer- arXiv preprint arXiv, 2025\nLarge language models (LLMs) excel in many tasks of software engineering, yet \nprogress in leveraging them for vulnerability discovery has stalled in recent years. To \nunderstand this phenomenon, we investigate LLMs through the lens of classic code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19117%3F&hl=en&sa=X&d=9123199236929215814&ei=4KD2aJvMIIOAieoPtpDVoA0&scisig=AAZF9b96K8iXMK0E9g_Tx-qJET4o&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "DT4LM: Differential Testing for Reliable Language Model Updates in Classification Tasks", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "X Zuo, Y Xiao, X Cao, W Wang, JS Dong- IEEE Transactions on Software, 2025\nIn the field of Natural Language Processing (NLP), Language Models (LMs) are \nfrequently updated to enhance performance. However, these updates can introduce \nunintended regressions, cases where the updated model fails on inputs correctly", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/journal/ts/5555/01/11205851/2aRi5IeBBF6&hl=en&sa=X&d=4279235962652410820&ei=4KD2aJvMIIOAieoPtpDVoA0&scisig=AAZF9b-kVQENUhfF7IJFr7J40tEo&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "PseudoBridge: Pseudo Code as the Bridge for Better Semantic and Logic Alignment in Code Retrieval", "first_label": ["Code"], "second_label": [], "data": "Y Li, X Liu, W Yang, B Fei, S Li, M Zhou, L Ma- arXiv preprint arXiv:2509.20881, 2025\nCode search aims to precisely find relevant code snippets that match natural \nlanguage queries within massive codebases, playing a vital role in software \ndevelopment. Recent advances leverage pre-trained language models (PLMs) to\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.20881&hl=en&sa=X&d=2967728206586595706&ei=4KD2aJvMIIOAieoPtpDVoA0&scisig=AAZF9b-XdfZ8XsjnE3OySm__bMpC&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=7&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
