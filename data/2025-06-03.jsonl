{"title": "When Feelings Meet Code: How Generative AI Affects the Emotions of Developers", "first_label": ["Code"], "second_label": [], "data": "PH Jacquemin, M Gr\\xc3\\xa4f, K Bauch, A Kaur, M Mehler - 2025\nAbstract Generative Artificial Intelligence (GenAI) is transforming professional \nworkflows, particularly in programming, where tools like ChatGPT assist with code \ngeneration, debugging, and explanations. While GenAI enhances performance, \nconcerns about the implications for well-being and emotions while working with \nGenAI persist. Especially emotions in terms of positive and negative feelings play a \ncrucial role, influencing how effectively GenAI is utilized in professional settings. Our\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://aisel.aisnet.org/amcis2025/sig_cnow/sig_cnow/4/&hl=en&sa=X&d=7801860713258796150&ei=QRo9aKG-B-W16rQPsqVy&scisig=AAZF9b81za4Ew4tCXAKwNS9XMbiN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le", "2 new citations to articles by Thanh Le-Cong"]}
{"title": "Afterburner: Reinforcement Learning Facilitates Self-Improving Code Efficiency Optimization", "first_label": ["Code"], "second_label": [], "data": "M Du, LT Tuan, Y Liu, Y Qing, D Huang, X He, Q Liu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) generate functionally correct solutions but often fall \nshort in code efficiency, a critical bottleneck for real-world deployment. In this paper, \nwe introduce a novel test-time iterative optimization framework to address this, \nemploying a closed-loop system where LLMs iteratively refine code based on \nempirical performance feedback from an execution sandbox. We explore three \ntraining strategies: Supervised Fine-Tuning (SFT), Direct Preference Optimization\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaThanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23387&hl=en&sa=X&d=13812914505441854655&ei=QRo9aKG-B-W16rQPsqVy&scisig=AAZF9b9g8QfU6R_Ix12KNvgAxXM_&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le", "Hong Jin Kang - new related research", "Bach Le - new related research", "2 new citations to articles by Thanh Le-Cong", "Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "OmniGIRL: A Multilingual and Multimodal Benchmark for GitHub Issue Resolution", "first_label": ["GitHub Issue"], "second_label": [], "data": "L Guo, W Tao, R Jiang, Y Wang, J Chen, X Liu, Y Ma\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe GitHub issue resolution task aims to resolve issues reported in repositories \nautomatically. With advances in large language models (LLMs), this task has gained \nincreasing attention, and several benchmarks are proposed to evaluate the issue\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.04606&hl=en&sa=X&d=17721785651242552030&ei=QBo9aOjqPKuM6rQPsd_4QA&scisig=AAZF9b9vdcHDALBkXHSBcEUw295J&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Training Language Models to Generate Quality Code with Program Analysis Feedback", "first_label": ["LLM", "Code"], "second_label": [], "data": "F Yao, Z Wang, L Liu, J Cui, L Zhong, X Fu, H Mai\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode generation with large language models (LLMs), often termed vibe coding, is \nincreasingly adopted in production but fails to ensure code quality, particularly in \nsecurity (eg, SQL injection vulnerabilities) and maintainability (eg, missing type\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22704&hl=en&sa=X&d=13720297852295427429&ei=QBo9aOjqPKuM6rQPsd_4QA&scisig=AAZF9b9qU1hJff-ona5ynwmi0w3O&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "Bach Le - new related research", "Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "LLM Performance for Code Generation on Noisy Tasks", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "R Sendyka, C Cabrera, A Paleyes, D Robinson\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis paper investigates the ability of large language models (LLMs) to recognise and \nsolve tasks which have been obfuscated beyond recognition. Focusing on \ncompetitive programming and benchmark tasks (LeetCode and MATH), we compare\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23598&hl=en&sa=X&d=9429091642612761899&ei=QBo9aOjqPKuM6rQPsd_4QA&scisig=AAZF9b8Uzy7LaG1aYtKQ7svdsdTk&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "LLM-based Property-based Test Generation for Guardrailing Cyber-Physical Systems", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "K Etemadi, M Sirjani, MH Moghadam, P Strandberg\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCyber-physical systems (CPSs) are complex systems that integrate physical, \ncomputational, and communication subsystems. The heterogeneous nature of these \nsystems makes their safety assurance challenging. In this paper, we propose a novel\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23549&hl=en&sa=X&d=15514814573872381684&ei=QRo9aM21IObGieoP1sTUqQ8&scisig=AAZF9b9PvEQ6SOyVFPOVv07Iu9o3&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "Model Immunization from a Condition Number Perspective", "first_label": [], "second_label": [], "data": "AY Zheng, CS Bai, B Bullins, RA Yeh\\xc2\\xa0- arXiv preprint arXiv:2505.23760, 2025\nModel immunization aims to pre-train models that are difficult to fine-tune on harmful \ntasks while retaining their utility on other non-harmful tasks. Though prior work has \nshown empirical evidence for immunizing text-to-image models, the key \nunderstanding of when immunization is possible and a precise definition of an \nimmunized model remain unclear. In this work, we propose a framework, based on \nthe condition number of a Hessian matrix, to analyze model immunization for linear\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23760&hl=en&sa=X&d=12827498787661563471&ei=QBo9aOX_OdOj6rQPzMDA4AM&scisig=AAZF9b92-QyEr3RAbR40r2G0KTF4&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang"]}
{"title": "A Survey on the Impact of Pre-Trained Language Models in Sentiment Classification Task", "first_label": ["LLM"], "second_label": [], "data": "H Gautam, A Gaur, DK Yadav\\xc2\\xa0- International Journal of Data Science and Analytics, 2025\nThe evolution of pre-trained language models (PLMs) has significantly transformed \nthe landscape of sentiment analysis, particularly in handling complex, noisy, \ninformal, and short-text commonly found on social media. While numerous surveys \nhave explored PLMs and sentiment analysis separately, few provide a focused \nevaluation of large language models (LLMs) in the context of sentiment classification \nacross diverse, real-world datasets. This survey addresses that gap by systematically\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBiasfinder: Metamorphic test generation to uncover bias for\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s41060-025-00805-z&hl=en&sa=X&d=7299075348891807052&ei=QRo9aJWLBoqIieoPj_7kqQE&scisig=AAZF9b8raeFdei0FHjjeOkWKQ4PT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang"]}
{"title": "Advancements in Brain Tumor Segmentation: A Comprehensive Review of the BraTS Challenges", "first_label": [], "second_label": [], "data": "RR Kumar, S Gupta, KR Chythanya, R Singh\\xe2\\x80\\xa6\\xc2\\xa0- 2025 3rd International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBrain tumor segmentation is a critical task in medical imaging, essential for accurate \ndiagnosis, treatment planning, and monitoring of gliomas, including high-grade and \nlower-grade gliomas. The Brain Tumor Segmentation (BraTS) challenges, held \nannually from 2017 to 2022, have significantly advanced the field by providing \nstandardized datasets, evaluation frameworks, and fostering innovation in \nsegmentation methodologies. In review examines the progression of BraTS\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAndroEvolve: Automated Android API update with data flow\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11011433/&hl=en&sa=X&d=256630132479435327&ei=QRo9aJWLBoqIieoPj_7kqQE&scisig=AAZF9b-e0zYAc-ap3L4-7_LbYiqG&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang"]}
{"title": "From Knowledge to Noise: CTIM-Rover and the Pitfalls of Episodic Memory in Software Engineering Agents", "first_label": [], "second_label": ["Agent"], "data": "T Lindenbauer, G Groh, H Sch\\xc3\\xbctze\\xc2\\xa0- arXiv preprint arXiv:2505.23422, 2025\nWe introduce CTIM-Rover, an AI agent for Software Engineering (SE) built on top of \nAutoCodeRover (Zhang et al., 2024) that extends agentic reasoning frameworks with \nan episodic memory, more specifically, a general and repository-level Cross-Task-\nInstance Memory (CTIM). While existing open-source SE agents mostly rely on ReAct \n(Yao et al., 2023b), Reflexion (Shinn et al., 2023), or Code-Act (Wang et al., 2024), all \nof these reasoning and planning frameworks inefficiently discard their long-term\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23422&hl=en&sa=X&d=798671286471025813&ei=QRo9aM-PD4OuieoP-ZTn2Aw&scisig=AAZF9b9I4avC7qYzBaHdUFuv9o3o&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
{"title": "Analisis Kinerja Pengujian Black Box Terhadap Website Nestify Setelah Implementasi Equivalence Partitioning dan Boundary Value Analysis", "first_label": [], "second_label": [], "data": "AR Wicaksono\\xc2\\xa0- Jurnal Informatika dan Teknologi Pendidikan, 2025\nAplikasi Nestify merupakan aplikasi berbasis website yang dirancang untuk \nmemfasilitasi pengelolaan properti indekos, baik bagi pemilik maupun penyewa. \nUntuk memastikan aplikasi ini berjalan sesuai dengan kebutuhan fungsional yang \ndigambarkan pada use case diagram, maka dilakukan pengujian menggunakan \nmetode Black Box dengan teknik Equivalence Partitioning (EP) dan Boundary Value \nAnalysis (BVA). Kasus uji didesain dengan pendekatan berbasis use case untuk\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTest-equivalence analysis for automatic patch generation\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://jurnalitp.web.id/index.php/jitp/article/download/131/55&hl=en&sa=X&d=3769664691200650921&ei=QRo9aM-PD4OuieoP-ZTn2Aw&scisig=AAZF9b9j5Ymbdvd1EtdF5Zw192qs&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
{"title": "Targeted Fuzzing for Unsafe Rust Code: Leveraging Selective Instrumentation", "first_label": ["Fuzzing", "Code"], "second_label": [], "data": "D Paa\\xc3\\x9fen, JR Giesen, L Davi\\xc2\\xa0- arXiv preprint arXiv:2505.02464, 2025\nRust is a promising programming language that focuses on concurrency, usability, \nand security. It is used in production code by major industry players and got \nrecommended by government bodies. Rust provides strong security guarantees\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.02464&hl=en&sa=X&d=17464682910892089266&ei=QRo9aNfcELeC6rQP9sj2mQ8&scisig=AAZF9b-bvKBMc2Po_9BYZAm8NsXQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "VERINA: Benchmarking Verifiable Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "Z Ye, Z Yan, J He, T Kasriel, K Yang, D Song\\xc2\\xa0- arXiv preprint arXiv:2505.23135, 2025\nLarge language models (LLMs) are increasingly integrated in software development, \nbut ensuring correctness in LLM-generated code remains challenging and often \nrequires costly manual review. Verifiable code generation--jointly generating code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23135&hl=en&sa=X&d=17629286340878649896&ei=QRo9aNfcELeC6rQP9sj2mQ8&scisig=AAZF9b886dx7UbzS0zTtCozpRFS_&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Xin ZHOU - new related research"]}
{"title": "SWE-bench Goes Live!", "first_label": [], "second_label": [], "data": "L Zhang, S He, C Zhang, Y Kang, B Li, C Xie, J Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe issue-resolving task, where a model generates patches to fix real-world bugs, \nhas emerged as a critical benchmark for evaluating the capabilities of large \nlanguage models (LLMs). While SWE-bench and its variants have become standard\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23419&hl=en&sa=X&d=1575278786032398107&ei=QRo9aNfcELeC6rQP9sj2mQ8&scisig=AAZF9b8tq3CrWVTGRUf3cVhoSLzm&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Comprehensive Predictive Analytics for Collaborators' Answers, Code Quality, and Dropout: Stack Overflow Case Study\\xe2\\x80\\x93Replication Package", "first_label": ["Code"], "second_label": [], "data": "E Zolduoarrati, S Licorish, N Stanger - 2025\nPrevious studies that used data from Stack Overflow to develop predictive models \noften employed limited benchmarks of 3-5 models or adopted arbitrary selection \nmethods. Despite being insightful, such approaches may not provide optimal results\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ourarchive.otago.ac.nz/esploro/outputs/dataset/Comprehensive-Predictive-Analytics-for-Collaborators-Answers/9926743737901891&hl=en&sa=X&d=4622743116783783239&ei=QRo9aK2LCYCt6rQP9sPUwAg&scisig=AAZF9b9T5D8iF5mUZMDOLFoxHQ1B&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Yuan, Y Xu, J Shi, P Zhou, L Sun\\xc2\\xa0- arXiv preprint arXiv:2505.23561, 2025\nModel merging for Large Language Models (LLMs) directly fuses the parameters of \ndifferent models finetuned on various tasks, creating a unified model for multi-domain \ntasks. However, due to potential vulnerabilities in models available on open-source\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23561&hl=en&sa=X&d=6617189016454156514&ei=QRo9aLeVGcmx6rQP-rCh4AE&scisig=AAZF9b-hKaNf3ql6GqPXtJeaxsCC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "R-bench: Graduate-level multi-disciplinary benchmarks for llm & mllm complex reasoning evaluation", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "MH Guo, J Xu, Y Zhang, J Song, H Peng, YX Deng\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nReasoning stands as a cornerstone of intelligence, enabling the synthesis of existing \nknowledge to solve complex problems. Despite remarkable progress, existing \nreasoning benchmarks often fail to rigorously evaluate the nuanced reasoning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.02018%3F&hl=en&sa=X&d=8843826795691330105&ei=QRo9aLeVGcmx6rQP-rCh4AE&scisig=AAZF9b8oZTpHhJulcZKPuCXTowVa&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Superplatforms Have to Attack AI Agents", "first_label": [], "second_label": ["Agent"], "data": "J Lin, J Zhu, Z Zhou, Y Xi, W Liu, Y Yu, W Zhang\\xc2\\xa0- arXiv preprint arXiv:2505.17861, 2025\nOver the past decades, superplatforms, digital companies that integrate a vast range \nof third-party services and applications into a single, unified ecosystem, have built \ntheir fortunes on monopolizing user attention through targeted advertising and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17861%3F&hl=en&sa=X&d=3066941296948922789&ei=QRo9aLeVGcmx6rQP-rCh4AE&scisig=AAZF9b8JpE5325HDRkA5ocvOdQDq&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack", "first_label": ["LLM"], "second_label": [], "data": "S Cappelletti, T Poppi, S Poppi, ZX Yong\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly evaluated on multiple-choice \nquestion answering (MCQA) tasks using* first-token probability*(FTP), which selects \nthe answer option whose initial token has the highest likelihood. While efficient, FTP\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15323%3F&hl=en&sa=X&d=5513891085179250670&ei=QRo9aLeVGcmx6rQP-rCh4AE&scisig=AAZF9b8ts6vJnVnPKgZRZk2J59vT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Stealthy LLM-Driven Data Poisoning Attacks Against Embedding-Based Retrieval-Augmented Recommender Systems", "first_label": ["LLM"], "second_label": [], "data": "F Nazary, Y Deldjoo, T Di Noia, E Di Sciascio\\xc2\\xa0- arXiv preprint arXiv:2505.05196, 2025\nWe present a systematic study of provider-side data poisoning in retrieval-\naugmented recommender systems (RAG-based). By modifying only a small fraction \nof tokens within item descriptions--for instance, adding emotional keywords or\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.05196&hl=en&sa=X&d=7153996738322631678&ei=QRo9aLeVGcmx6rQP-rCh4AE&scisig=AAZF9b9XYvMXz8xtJ6dU7EDwB2B7&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "PS Pandey, S Simko, K Pelrine, Z Jin\\xc2\\xa0- arXiv preprint arXiv:2505.16789, 2025\nAs large language models gain popularity, their vulnerability to adversarial attacks \nremains a primary concern. While fine-tuning models on domain-specific datasets is \noften employed to improve model performance, it can introduce vulnerabilities within\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16789%3F&hl=en&sa=X&d=9827187220639785834&ei=QRo9aLeVGcmx6rQP-rCh4AE&scisig=AAZF9b-hRa3CIybDfceUhaRlecWD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution", "first_label": [], "second_label": [], "data": "J Guo, X Wen, W Jiang, C Huang, J Li, H Li\\xc2\\xa0- arXiv preprint arXiv:2505.15308, 2025\nWith the widespread application of super-resolution (SR) in various fields, \nresearchers have begun to investigate its security. Previous studies have \ndemonstrated that SR models can also be subjected to backdoor attacks through\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15308&hl=en&sa=X&d=13335437674086498390&ei=QRo9aLeVGcmx6rQP-rCh4AE&scisig=AAZF9b8WmdvUXiuzvPutlRNCBmNP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "K Zhu, J Zhang, Z Qi, N Shang, Z Liu, P Han, Y Su\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent advancements in large language model (LLM) agents have significantly \naccelerated scientific discovery automation, yet concurrently raised critical ethical \nand safety concerns. To systematically address these challenges, we introduce\\\\textbf\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23559&hl=en&sa=X&d=11195872190670696763&ei=QRo9aLeVGcmx6rQP-rCh4AE&scisig=AAZF9b-GHbm178P42FhdzzUwF79Z&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "EVOREFUSE: Evolutionary Prompt Optimization for Evaluation and Mitigation of LLM Over-Refusal to Pseudo-Malicious Instructions", "first_label": ["LLM"], "second_label": [], "data": "X Wu, X Mao, F Li, X Zhang, X Zhang, J Zhou, Y Peng\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) frequently refuse to respond to pseudo-malicious \ninstructions: semantically harmless input queries triggering unnecessary LLM \nrefusals due to conservative safety alignment, significantly impairing user\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23473&hl=en&sa=X&d=12108138930043984920&ei=QRo9aLeVGcmx6rQP-rCh4AE&scisig=AAZF9b-1Z--NymRfljISu6T1JjVD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Transferable adversarial attacks on black-box vision-language models", "first_label": ["LLM"], "second_label": [], "data": "K Hu, W Yu, L Zhang, A Robey, A Zou, C Xu, H Hu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nVision Large Language Models (VLLMs) are increasingly deployed to offer \nadvanced capabilities on inputs comprising both text and images. While prior \nresearch has shown that adversarial attacks can transfer from open-source to\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.01050&hl=en&sa=X&d=34750902821152867&ei=QRo9aLeVGcmx6rQP-rCh4AE&scisig=AAZF9b9lHgWBmRQgOUsWiSdzwfqQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Neither Stochastic Parroting nor AGI: LLMs Solve Tasks through Context-Directed Extrapolation from Training Data Priors", "first_label": ["LLM"], "second_label": [], "data": "HT Madabushi, M Torgbi, C Bonial\\xc2\\xa0- arXiv preprint arXiv:2505.23323, 2025\nIn this position paper we raise critical awareness of a realistic view of LLM \ncapabilities that eschews extreme alternative views that LLMs are either\" stochastic \nparrots\" or in possession of\" emergent\" advanced reasoning capabilities, which, due \nto their unpredictable emergence, constitute an existential threat. Our middle-ground \nview is that LLMs extrapolate from priors from their training data, and that a \nmechanism akin to in-context learning enables the targeting of the appropriate\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLessLeak-Bench: A First Investigation of Data Leakage in LLMs\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23323&hl=en&sa=X&d=12118225113071950285&ei=QRo9aPGrF8y8ieoPz-jf4A8&scisig=AAZF9b8PFXYScS5n4hctPiMxQ3wV&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "Software Vulnerability Detection: Trends, Gaps, and Future Directions in IS Research", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Search"], "data": "R Karri, P Kumar, N Islam - 2025\nWith the rise of cyber threats, Software Vulnerability Detection (SVD) plays a vital role \nin ensuring software security and reliability. The rapid growth of research in this \ndomain necessitates a comprehensive understanding of the overall research \nlandscape, trends, gaps and future directions. Existing literature studies remained \nfragmented across various subdomains. And traditional methods of analyzing vast \nbody of research manually are challenging and time consuming. To address these\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection and repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://aisel.aisnet.org/amcis2025/intelfuture/intelfuture/42/&hl=en&sa=X&d=14638189496755740306&ei=QRo9aPGrF8y8ieoPz-jf4A8&scisig=AAZF9b_BIqgK8kFFL_pGq5_iT-il&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "Improved Labeling of Security Defects in Code Review by Active Learning with LLMs", "first_label": ["LLM", "Code Review", "Code", "Software Defect"], "second_label": [], "data": "J H\\xc3\\xa4rtel\nMining high-quality datasets of security defects is important for cybersecurity. In this \npaper, we focus on mining a dataset of reviews that discuss potential security defects \nin code or other artifacts. Mining such datasets often involves labeling, and this is \nchallenging because security defects are rare. We investigate the use of active \nlearning with a fine-tuned large language model to make the mining and labeling of \nsuch datasets more effective. Our simulations demonstrate that active learning can\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaVulCurator: A Vulnerability-Fixing Commit Detector\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://johanneshaertel.github.io/Hartel25.pdf&hl=en&sa=X&d=736417192127524244&ei=rMc7aJboFcy8ieoPz-jf4A8&scisig=AAZF9b8kzE8js2vNjc88_fVs7Rh5&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 new citation to articles by Thanh Le-Cong", "1 new citation to articles by Bach Le", "Quang-Cuong Bui - new related research", "1 new citation to articles by Hong Jin Kang"]}
{"title": "SIMCOPILOT: Evaluating Large Language Models for Copilot-Style Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "M Jiang, A Jain, S Zorek, C Jermaine\\xc2\\xa0- arXiv preprint arXiv:2505.21514, 2025\nWe introduce SIMCOPILOT, a benchmark that simulates the role of large language \nmodels (LLMs) as interactive,\" copilot\"-style coding assistants. Targeting both \ncompletion (finishing incomplete methods or code blocks) and infill tasks (filling\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.21514&hl=en&sa=X&d=16513215149566256283&ei=rMc7aP6XKebGieoP1sTUqQ8&scisig=AAZF9b8QxBbiA6H8IhMpg7_Ybs-q&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "LLM Contribution Summarization in Software Projects", "first_label": ["LLM"], "second_label": [], "data": "R Corsi Ferrao, FR de Miranda, D Pavan Soler\\xc2\\xa0- arXiv e-prints, 2025\nThis full paper in innovative practice provides an automated tool to summarize \nindividual code contributions in project-based courses with external clients. Real \nindustry projects offer valuable learning opportunities by immersing students in\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ui.adsabs.harvard.edu/abs/2025arXiv250517710C/abstract&hl=en&sa=X&d=2924767007286761413&ei=rMc7aP6XKebGieoP1sTUqQ8&scisig=AAZF9b_Y1Z5q_NBLq3-QXm64AzIV&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "VulBinLLM: LLM-powered Vulnerability Detection for Stripped Binaries", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "N Hussain, H Chen, C Tran, P Huang, Z Li, P Chugh\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecognizing vulnerabilities in stripped binary files presents a significant challenge in \nsoftware security. Although some progress has been made in generating human-\nreadable information from decompiled binary files with Large Language Models\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22010&hl=en&sa=X&d=10332909566617513173&ei=rMc7aOCEHqm7ieoP1JuLsA8&scisig=AAZF9b_uFh0VfBD1MzUN8jZA2T1m&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "Richard Fang - new related research", "2 new citations to articles by Xin ZHOU", "Thanh Le-Cong - new related research"]}
{"title": "Don't Judge Code by Its Cover: Exploring Biases in LLM Judges for Code Evaluation", "first_label": ["LLM", "Code"], "second_label": [], "data": "J Moon, Y Hwang, D Lee, T Kang, Y Kim, K Jung\\xc2\\xa0- arXiv preprint arXiv:2505.16222, 2025\nWith the growing use of large language models (LLMs) as evaluators, their \napplication has expanded to code evaluation tasks, where they assess the \ncorrectness of generated code without relying on reference implementations. While\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16222&hl=en&sa=X&d=12367652824627303832&ei=rMc7aOCEHqm7ieoP1JuLsA8&scisig=AAZF9b93T306thP8hAJXMWAAP8Xs&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Generating vulnerability security fixes with Code Language Models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": [], "data": "G Bhandari, N Gavric, A Shalaginov\\xc2\\xa0- Information and Software Technology, 2025\nAbstract Existing Code Language Models (CLM) have demonstrated significant \npotential in several coding tasks, including automated code generation in software \nengineering. Similarly, Automated Program Repair (APR) has shown considerable\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925001259&hl=en&sa=X&d=3259454824039873950&ei=rMc7aOCEHqm7ieoP1JuLsA8&scisig=AAZF9b8dA_uKKprpaO6yp2cen0ap&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Bach Le - new related research", "Hong Jin Kang - new related research", "2 new citations to articles by Xin ZHOU", "6 new citations to articles by Abhik Roychoudhury", "Thanh Le-Cong - new related research", "1 new citation to articles by Quang-Cuong Bui"]}
{"title": "Variational Prefix Tuning for diverse and accurate code summarization using pre-trained language models", "first_label": ["LLM", "Code"], "second_label": [], "data": "J Zhao, Y Song, E Cohen\\xc2\\xa0- Journal of Systems and Software, 2025\nRecent advancements in source code summarization have leveraged transformer-\nbased pre-trained models, including Large Language Models of Code (LLMCs), to \nautomate and improve the generation of code summaries. However, existing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.09062&hl=en&sa=X&d=10492238756586633693&ei=rMc7aOCEHqm7ieoP1JuLsA8&scisig=AAZF9b-kVaz6dOvEUYfWxHidq5aY&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch", "first_label": ["LLM"], "second_label": [], "data": "Z Lu, Y Yang, H Ren, H Hou, H Xiao, K Wang, W Shi\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM-based agents have demonstrated great potential in generating and managing \ncode within complex codebases. In this paper, we introduce WebGen-Bench, a novel \nbenchmark designed to measure an LLM-based agent's ability to create multi-file\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.03733&hl=en&sa=X&d=18122479413935797661&ei=rMc7aOCEHqm7ieoP1JuLsA8&scisig=AAZF9b9rIxliqtwywBXTeMHJeR0E&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Rechisel: Effective automatic chisel code generation by llm with reflection", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Niu, X Liu, D Niu, X Wang, Z Jiang, N Guan\\xc2\\xa0- arXiv preprint arXiv:2505.19734, 2025\nCoding with hardware description languages (HDLs) such as Verilog is a time-\nintensive and laborious task. With the rapid advancement of large language models \n(LLMs), there is increasing interest in applying LLMs to assist with HDL coding\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19734&hl=en&sa=X&d=11721354871378454184&ei=rMc7aOCEHqm7ieoP1JuLsA8&scisig=AAZF9b9MMIAf8sNjj9lFzZ3tcSvm&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Wielding Blockchain Transactions for Capture-Replay Testing of Upgradeable Smart Contracts", "first_label": ["Smart Contracts", "Software Testing", "Blockchain"], "second_label": [], "data": "M Barboni, G De Angelis, A Morichetta, A Polini\\xc2\\xa0- ACM Transactions on Internet\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBlockchain technology is increasingly adopted in scenarios requiring trust and data \nintegrity. On the Ethereum blockchain, the proxy pattern has become increasingly \npopular because it allows smart contract code to evolve while preserving stored data\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3737699&hl=en&sa=X&d=10195425919313981683&ei=rMc7aOCEHqm7ieoP1JuLsA8&scisig=AAZF9b8zB6XdmuenNPHEmKEkoZfz&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "DISPATCH: Unraveling Security Patches from Entangled Code Changes", "first_label": ["Code", "Code Change"], "second_label": [], "data": "S Sun, Y Xing, X Wang, S Wang, Q Li, K Sun\nSecurity patches are crucial for preserving the integrity, confidentiality, and \navailability of computing resources. However, their deployment can be significantly \npostponed when intertwined with non-security patches. Existing code change\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.usenix.org/system/files/conference/usenixsecurity25/sec25cycle1-prepub-969-sun-shiyu.pdf&hl=en&sa=X&d=17658290244301718337&ei=rMc7aOCEHqm7ieoP1JuLsA8&scisig=AAZF9b_0QvAzkhbSZX-XjShHTJvs&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "From Technical Debt to Business Process Debt: A Framework for Proactive Debt Management in BPM", "first_label": [], "second_label": [], "data": "N Nousias, G Tsakalidis, G Nedos, K Vergidis\\xc2\\xa0- International Conference on Decision\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAbstract Business Process Management (BPM) is a critical methodology for \norganizations aiming to enhance operational efficiency and achieve strategic \nobjectives. While BPM's iterative lifecycle approach ensures continuous\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-90863-7_10&hl=en&sa=X&d=15686306782641778332&ei=rMc7aOCEHqm7ieoP1JuLsA8&scisig=AAZF9b8XPOLY5PQ3bTHP9YZxq7kD&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models", "first_label": ["APR"], "second_label": ["Repair"], "data": "FV Ruiz, M Hort, L Moonen\\xc2\\xa0- arXiv preprint arXiv:2505.02931, 2025\nAutomatic program repair (APR) aims to reduce the manual efforts required to \nidentify and fix errors in source code. Before the rise of LLM-based agents, a \ncommon strategy was to increase the number of generated patches, sometimes to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.02931%3F&hl=en&sa=X&d=16837479357373517474&ei=rMc7aL2lI-SN6rQPzIKygQU&scisig=AAZF9b_WjCVulOfH0bpaSqZwLopC&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "CORECRISIS: Threat-Guided and Context-Aware Iterative Learning and Fuzzing of 5G Core Networks", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Dong, T Yang, A Al Ishtiaq, SMM Rashid, A Ranjbar\\xe2\\x80\\xa6\nWe develop CORECRISIS, a stateful black-box fuzz-testing framework for 5G core \nnetwork (5GC) implementations. Unlike previous stateful security analysis efforts of \ncellular networks which rely on manually-crafted, static test inputs and are limited to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.usenix.org/system/files/conference/usenixsecurity25/sec25cycle1-prepub-1292-dong-yilu.pdf&hl=en&sa=X&d=4291979592406815479&ei=rMc7aL2lI-SN6rQPzIKygQU&scisig=AAZF9b8xMpoFy9xYsoZdVl1unvGx&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "WildSync: Automated Fuzzing Harness Synthesis via Wild API Usage Recovery", "first_label": ["Fuzzing"], "second_label": [], "data": "WEIC WU, S NAGY, C HAUSER - 2025\nAuthors' Contact Information: Wei-Cheng Wu, Dartmouth College, Hanover, USA, wei-\ncheng. wu. gr@ dartmouth. edu; Stefan Nagy, University of Utah, Salt Lake City, USA, \nstefan. nagy@ utah. edu; Christophe Hauser, Dartmouth College, Hanover, USA\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://users.cs.utah.edu/~snagy/papers/25ISSTA.pdf&hl=en&sa=X&d=3125007074729669279&ei=rMc7aL2lI-SN6rQPzIKygQU&scisig=AAZF9b8Pijs9BnZif9GfvBHcFCPy&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Fault localization of AI-enabled cyber-physical systems by exploiting temporal neuron activation", "first_label": ["Fault Localization"], "second_label": ["Exploit", "Localization"], "data": "D Lyu, Y Li, Z Zhang, P Arcaini, XY Zhang, F Ishikawa\\xe2\\x80\\xa6\\xc2\\xa0- Journal of Systems and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern cyber\\xe2\\x80\\x93physical systems (CPS) are evolving to integrate deep neural \nnetworks (DNNs) as controllers, leading to the emergence of AI-enabled CPSs. An \ninadequately trained DNN controller may produce incorrect control actions, exposing\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225001438&hl=en&sa=X&d=3286846770327067741&ei=rMc7aL2lI-SN6rQPzIKygQU&scisig=AAZF9b-jUE3fT364wIMjAbdvLNMM&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "A Comparative Study of Fuzzers and Static Analysis Tools for Finding Memory Unsafety in C and C++", "first_label": ["Fuzzing", "Static Analysis"], "second_label": [], "data": "K Hassler, P G\\xc3\\xb6rz, S Lipp, T Holz, M B\\xc3\\xb6hme\\xc2\\xa0- arXiv preprint arXiv:2505.22052, 2025\nEven today, over 70% of security vulnerabilities in critical software systems result \nfrom memory safety violations. To address this challenge, fuzzing and static analysis \nare widely used automated methods to discover such vulnerabilities. Fuzzing\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22052&hl=en&sa=X&d=14897194010795537766&ei=rMc7aMzOKqalieoP5f2nkAE&scisig=AAZF9b8hh6USg0ZVl0p7ipNqlct2&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Evaluatiing the efficacy of LLM Safety Solutions: The Palit Benchmark Dataset", "first_label": ["LLM"], "second_label": [], "data": "S Palit, D Woods\\xc2\\xa0- arXiv preprint arXiv:2505.13028, 2025\nLarge Language Models (LLMs) are increasingly integrated into critical systems in \nindustries like healthcare and finance. Users can often submit queries to LLM-\nenabled chatbots, some of which can enrich responses with information retrieved\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13028%3F&hl=en&sa=X&d=1273460049730580919&ei=rMc7aIyHJ8y8ieoPz-jf4A8&scisig=AAZF9b9ByON4eaZyjRTpM1-cA_zU&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Towards Controllable Language Models With Instruction Hierarchies", "first_label": ["LLM"], "second_label": [], "data": "J Lu, N Mu, M Lavery, DA Wagner - 2025\nInitially introduced as a sparsely documented feature in OpenAI's GPT API, the \nconcept of the system prompt or system message has grown substantially in \npopularity and utility [33]. A degree of consensus on the general purpose of system\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-130.pdf&hl=en&sa=X&d=15749312049365295239&ei=rMc7aIyHJ8y8ieoPz-jf4A8&scisig=AAZF9b_JAhlJYjQE40TyLc0HyzxL&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Wang, W Wang, S Wang, Z Li, Z Ji, Z Lyu, D Wu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Large Language Models (LLMs) has led to the \nemergence of Multi-Agent Systems (MAS) to perform complex tasks through \ncollaboration. However, the intricate nature of MAS, including their architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12442&hl=en&sa=X&d=8825331941370095164&ei=rMc7aIyHJ8y8ieoPz-jf4A8&scisig=AAZF9b_j6hKF2Zy8dNMOx-tobM6E&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AgentXploit: End-to-End Redteaming of Black-Box AI Agents", "first_label": [], "second_label": ["Agent"], "data": "Z Wang, V Siu, Z Ye, T Shi, Y Nie, X Zhao, C Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe strong planning and reasoning capabilities of Large Language Models (LLMs) \nhave fostered the development of agent-based systems capable of leveraging \nexternal tools and interacting with increasingly complex environments. However\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.05849&hl=en&sa=X&d=13145039506086791936&ei=rMc7aIyHJ8y8ieoPz-jf4A8&scisig=AAZF9b_5aWzkLQOK0HBWClMmbpt1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Ripple Effect: On Unforeseen Complications of Backdoor Attacks", "first_label": [], "second_label": [], "data": "R Zhang, Y Shen, H Li, W Jiang, H Chen, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent research highlights concerns about the trustworthiness of third-party Pre-\nTrained Language Models (PTLMs) due to potential backdoor attacks. These \nbackdoored PTLMs, however, are effective only for specific pre-defined downstream\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11586&hl=en&sa=X&d=15157304470732077928&ei=rMc7aIyHJ8y8ieoPz-jf4A8&scisig=AAZF9b997v4XRj8-KVQslhBMZvqE&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadDepth: Backdoor Attacks Against Monocular Depth Estimation in the Physical World", "first_label": [], "second_label": [], "data": "J Guo, L Zhou, Z Wang, J He, Q Song, A Chen, W Jiang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, deep learning-based Monocular Depth Estimation (MDE) models \nhave been widely applied in fields such as autonomous driving and robotics. \nHowever, their vulnerability to backdoor attacks remains unexplored. To fill the gap in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16154&hl=en&sa=X&d=5415910119131408953&ei=rMc7aIyHJ8y8ieoPz-jf4A8&scisig=AAZF9b_TN08VuFjtK_7EfYuSnDSY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Backdoor Attacks Against Patch-based Mixture of Experts", "first_label": [], "second_label": [], "data": "C Chan, J Lintelo, S Picek\\xc2\\xa0- arXiv preprint arXiv:2505.01811, 2025\nAs Deep Neural Networks (DNNs) continue to require larger amounts of data and \ncomputational power, Mixture of Experts (MoE) models have become a popular \nchoice to reduce computational complexity. This popularity increases the importance\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.01811&hl=en&sa=X&d=1629159519506462439&ei=rMc7aIyHJ8y8ieoPz-jf4A8&scisig=AAZF9b_k96jURZxN3cHIcxR5KQPQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "first_label": ["LLM"], "second_label": [], "data": "G Chen, F Song, Z Zhao, X Jia, Y Liu, Y Qiao, W Zhang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreak attacks to Large audio-language models (LALMs) are studied recently, but \nthey achieve suboptimal effectiveness, applicability, and practicability, particularly, \nassuming that the adversary can fully manipulate user prompts. In this work, we first\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14103&hl=en&sa=X&d=12355582258955555442&ei=rMc7aIyHJ8y8ieoPz-jf4A8&scisig=AAZF9b84twuHlVXU1hPFciKO3AfT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadLingual: A Novel Lingual-Backdoor Attack against Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Wang, H Li, R Zhang, W Jiang, K Chen, T Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn this paper, we present a new form of backdoor attack against Large Language \nModels (LLMs): lingual-backdoor attacks. The key novelty of lingual-backdoor attacks \nis that the language itself serves as the trigger to hijack the infected LLMs to generate\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.03501&hl=en&sa=X&d=15489349756851264058&ei=rMc7aIyHJ8y8ieoPz-jf4A8&scisig=AAZF9b_j_X5MMHAf2tokb2xerP6r&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Checking the Robustness of Code Using Mutation Testing", "first_label": ["Code", "Software Testing"], "second_label": [], "data": "R Saturi, R Kandakatla, CM Kumar, M Vinay\\xc2\\xa0- Trends in Sustainable Computing and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe foundation for facilitating the control and operation of hardware devices in \nmodern life is software in the ever-changing technological landscape. With its \npervasive influence, the quality of software directly impacts various aspects of \nsociety, including safety, efficiency, and reliability. Substandard software not only \ndisrupts daily operations but can also pose significant risks to human lives and \ncritical infrastructure [1]. Hence, ensuring the development of error-free and premium\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3D2mNgEQAAQBAJ%26oi%3Dfnd%26pg%3DPA387%26ots%3DBL_4mR4tNF%26sig%3D0tEPqiuxXIWLlzuEgpjNxsWtAP8&hl=en&sa=X&d=6068814351263886000&ei=rMc7aMHJIJ-mieoPoOrjuQU&scisig=AAZF9b8LVE_929aAVPXTjLTteKJf&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "AIPD: A Novel API Interception-Based Patch Deployment Method to Boost Software Security", "first_label": [], "second_label": [], "data": "H Li, X Kong, M Qiao, X Chen, Z Zhou, X Huang\\xc2\\xa0- 2025 2nd International Conference\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nOpen source software (OSS) vulnerabilities are crucial for ensuring the security of \nsoftware systems. Existing methods typically require application developers to patch \ntheir own operational environment clients, overlooking the security responsibilities \nthat should be assumed by the operational environment providers. This often leads \nto failed patch deployments and affects the stability of the software systems. To \naddress this issue, this paper proposes AIPD, a novel method for completing patch\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Patch Backporting in Linux (Experience Paper)\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11011229/&hl=en&sa=X&d=14377643665233014313&ei=rMc7aMHJIJ-mieoPoOrjuQU&scisig=AAZF9b-FQ6LN6Vq05kcBglt_nvEJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Improving Validity-guided Grey-box Fuzzing based on Adaptive Seed Ranking", "first_label": ["Fuzzing"], "second_label": [], "data": "J Yu, W Wu, J Zhou\\xc2\\xa0- 2025 2nd International Conference on Algorithms\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGrey-box fuzzing has emerged as the predominant automated testing technique for \nsoftware security. For target programs with complex input structures and semantic \nconstraints, the guidance of semantic validity enables efficient exploration of \nsemantic input space. However, existing validity-guided grey-box fuzzers exhibit \ninsufficient research on strategies of searching the semantic input space, particularly \nneglecting the importance of seed scheduling. This paper proposes an adaptive\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart greybox fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11011137/&hl=en&sa=X&d=6459769876622141950&ei=rMc7aMHJIJ-mieoPoOrjuQU&scisig=AAZF9b_Bs3DAg64KT6eIF4I0Lus3&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Formal Timing Analysis and Verification of the Interrupt-driven Programs for ISO26262", "first_label": ["Verification"], "second_label": [], "data": "Q She, H Huang, S Bao, X Guo\\xc2\\xa0- 2025 2nd International Conference on Algorithms\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSafety-critical systems refer to software systems whose operation can affect the \nsafety of people and facilities used in the automotive industry, aerospace, and \nhospital health care systems. The high level of safety of software in the \naforementioned fields has often drawn attention. ISO26262 has been issued for the \nautomotive industry, which defines standards and procedures, including software \nlevel, software development standards, and software validation standards to ensure\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaChronos: A timing analyzer for embedded software\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11011214/&hl=en&sa=X&d=5343779142816367503&ei=rMc7aMHJIJ-mieoPoOrjuQU&scisig=AAZF9b9W23UQIIvRmekBmfCjfYNt&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Leveraging Open-Source LLMs for Zero-Shot Vulnerability Detection: A Comparative Analysis", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "N Capuano, V Carletti, P Foggia, G Parrella, M Vento\\xc2\\xa0- International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid expansion of the Internet of Things (IoT) has brought significant security \nchallenges, primarily due to vulnerabilities in the firmware of IoT and network \ndevices, which is predominantly written in low-level programming languages such as\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-87775-9_2&hl=en&sa=X&d=8724089268434184607&ei=rMc7aPbUGOWBieoP0PLYiAU&scisig=AAZF9b-ahkowI222f9SeGE9jq2lb&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
