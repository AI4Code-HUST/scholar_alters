{"title": ":", "first_label": [], "second_label": [], "data": "- 2025\n     . \n        \n  .    \n      . \n        \n  .  \nCites: On testing embedded software\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://elar.urfu.ru/bitstream/10995/147534/1/m_th_a.r.shaikhullin_2025.pdf&hl=en&sa=X&d=2331942445289060019&ei=_pJRabrgHbux6rQPi5qW2AE&scisig=ALhkC2SzLGybV1KUFX4A2BsAmufz&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ALhkC2SLNtxsIYV7y8T6Ni2J4ruF&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["1 new citation to articles by Abhik Roychoudhury"]}
{"title": "Assessing the Software Security Comprehension of Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "ML Siddiq, N Sekerak, A Karam, M Leal- arXiv preprint arXiv, 2025\nLarge language models (LLMs) are increasingly used in software development, but \ntheir level of software security expertise remains unclear. This work systematically \nevaluates the security comprehension of five leading LLMs: GPT-4o-Mini, GPT-5\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.21238&hl=en&sa=X&d=3008638681246238265&ei=_5JRaZSPHr6Z6rQPr-v5iAc&scisig=ALhkC2TclUqSPaolcLkUxqJj4FaU&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ALhkC2Q9j5kdmlV_e8u2kLe_NWfw&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Engine Failure Prediction on Large-Scale CMAPSS Data Using Hybrid Feature Selection and Imbalance-Aware Learning", "first_label": [], "second_label": [], "data": "A Junaid, A Iqbal, A Khan, G Husnain, AR Ahmad - 2025\nMost predictive maintenance studies have emphasized accuracy but provide very \nlittle focus on Interpretability or deployment readiness. This study improves on prior \nmethods by developing a small yet robust system that can predict when turbofan \nengines will fail. It uses the NASA CMAPSS dataset, which has over 200,000 engine \ncycles from 260 engines. The process begins with systematic preprocessing, which \nincludes imputation, outlier removal, scaling, and labelling of the remaining useful\nCites: Surveying neuro-symbolic approaches for reliable artificial\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Ghassan-Husnain/publication/399027571_Engine_Failure_Prediction_on_Large-Scale_CMAPSS_Data_Using_Hybrid_Feature_Selection_and_Imbalance-Aware_Learning/links/694b6ee27e61d05b53121a72/Engine-Failure-Prediction-on-Large-Scale-CMAPSS-Data-Using-Hybrid-Feature-Selection-and-Imbalance-Aware-Learning.pdf&hl=en&sa=X&d=7575073542104611010&ei=_ZJRaaTnOZaM6rQP0-TCwQU&scisig=ALhkC2TCqYmxSSu8tUd-7gO-Dr9h&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:ALhkC2Tv0L1GNq4Kk4Fq05ZvgtDM&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["1 new citation to articles by Hong Jin Kang"]}
{"title": "Artificial or Just Artful? Do LLMs Bend the Rules in Programming?", "first_label": ["LLM"], "second_label": [], "data": "OB Sghaier, K Delcourt, H Sahraoui- arXiv preprint arXiv:2512.21028, 2025\nLarge Language Models (LLMs) are widely used for automated code generation, yet \ntheir apparent successes often mask a tension between pretraining objectives and \nalignment choices. While pretraining encourages models to exploit all available", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.21028&hl=en&sa=X&d=5351799457747135438&ei=_pJRaf6WDdKV6rQP84i9kQc&scisig=ALhkC2TW_eRyQmbbnC593J6wW6ag&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ALhkC2THo_3s8tBI3qmyNrpmj0cv&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "1 new citation to articles by Xin ZHOU"]}
{"title": "Beyond Code Pairs: Dialogue-Based Data Generation for LLM Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "L Chen, N Xu, W Chen, B Lei, PH Lin, D Zhou- arXiv preprint arXiv, 2025\nLarge language models (LLMs) have shown remarkable capabilities in code \ntranslation, yet their performance deteriorates in low-resource programming domains \nsuch as Fortran and emerging frameworks like CUDA, where high-quality parallel", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.03086&hl=en&sa=X&d=15724167796935183524&ei=_pJRaf6WDdKV6rQP84i9kQc&scisig=ALhkC2RGUOYClntRywDgzqfB8TOC&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ALhkC2THo_3s8tBI3qmyNrpmj0cv&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Automating Unit Test Generation with Large Language Models: An Integrated Empirical and Theoretical Investigation", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "JK Morales- Research Index Library of Eijmr, 2025\nBackground: The emergence of large language models (LLMs) has introduced novel \ncapabilities for program understanding and automated artifact generation, including \nunit tests. Recent empirical work suggests both promise and limitations of LLMs\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=http://eijmr.net/index.php/rileijmr/article/view/52&hl=en&sa=X&d=7912543035378311447&ei=_pJRaf6WDdKV6rQP84i9kQc&scisig=ALhkC2SUdj4xVWKzayBNSFNL5J3X&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ALhkC2THo_3s8tBI3qmyNrpmj0cv&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "VulnLLM-R: Specialized Reasoning LLM with Agent Scaffold for Vulnerability Detection", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Agent", "Reasoning"], "data": "Y Nie, H Li, C Guo, R Jiang, Z Wang, B Li, D Song- arXiv preprint arXiv, 2025\nWe propose VulnLLM-R, the~\\emph {first specialized reasoning LLM} for \nvulnerability detection. Our key insight is that LLMs can reason about program states \nand analyze the potential vulnerabilities, rather than simple pattern matching. This\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.07533&hl=en&sa=X&d=14822866035105946059&ei=_ZJRaayfFLK16rQPn86DwQ8&scisig=ALhkC2SrItwEGbUy2HNxI0DJG3ud&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ALhkC2QkVwCdvNzUylYiTyCmheSL&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Dependable Code Repair with LLMs: AI-Driven Vulnerability Detection and Automated Patching", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection", "Repair"], "data": "S Han, H Kim, H Lee, H Moon, Y Jeon, H Bae, D Yeo\nThe rapid proliferation of software vulnerabilities has created an urgent need for \nintelligent, automated methods to detect and mitigate security flaws at scale. \nTraditional vulnerability analysis depends heavily on manual inspection and domain\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://seclab.skku.edu/wp-content/uploads/2025/12/PRDC_AID_136_2025.pdf&hl=en&sa=X&d=5403717416336863891&ei=_pJRaYbkLoaw6rQPkNu46Ao&scisig=ALhkC2RDYmIkwPPsK8HJE3Ozta0n&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:ALhkC2SS1P3l44RDJXsNEdNzDLiT&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Bootstrapping Fuzzers for Compilers of Low-Resource Language Dialects Using Language Models", "first_label": ["LLM", "Fuzzing"], "second_label": [], "data": "S Vaidya, M Bhme, L D'Antoni- arXiv preprint arXiv:2512.05887, 2025\nModern extensible compiler frameworks-such as MLIR-enable rapid creation of \ndomain-specific language dialects. This flexibility, however, makes correctness \nharder to ensure as the same extensibility that accelerates development also\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.05887&hl=en&sa=X&d=4462874127133540648&ei=_ZJRafeAJ9rJieoPiYyysAk&scisig=ALhkC2QrUX2QWbZaardTdZviikC5&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ALhkC2RZmRqgZGCFQXCJyP9vthGu&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Engagement in Code Review: Emotional, Behavioral, and Cognitive Dimensions in Peer vs. LLM Interactions", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "A Alami, N Cassee, TR Silva, E Paja, NA Ernst- arXiv preprint arXiv:2512.05309, 2025\nCode review is a socio-technical practice, yet how software engineers engage in \nLarge Language Model (LLM)-assisted code reviews compared to human peer-led \nreviews is less understood. We report a two-phase qualitative study with 20 software", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.05309&hl=en&sa=X&d=473369942188785420&ei=_5JRaYqVLYaw6rQPkNu46Ao&scisig=ALhkC2SmS13J2E5MGGhr11_c3Wpo&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ALhkC2T269WwPtyd5qvti3WNZV40&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Wang, X Wang, C Gao, CY Chong, X Xia, Q Liao- arXiv preprint arXiv:2512.20159, 2025\nLarge language models (LLMs) have been increasingly deployed in real-world \nsoftware engineering, fostering the development of code evaluation metrics to study \nthe quality of LLM-generated code. Conventional rule-based metrics merely score", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20159&hl=en&sa=X&d=6711898537773507630&ei=_5JRaYqVLYaw6rQPkNu46Ao&scisig=ALhkC2S1jDXMNAnGCS6haPrkOHJI&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ALhkC2T269WwPtyd5qvti3WNZV40&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "K Wang, B Mao, S Jia, Y Ding, D Han, T Ma, B Cao- arXiv preprint arXiv:2512.17540, 2025\nAutomating code review with Large Language Models (LLMs) shows immense \npromise, yet practical adoption is hampered by their lack of reliability, context-\nawareness, and control. To address this, we propose Specification-Grounded Code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.17540&hl=en&sa=X&d=16382589271726736633&ei=_5JRaYqVLYaw6rQPkNu46Ao&scisig=ALhkC2Rx_2I5F67w4_nJO52_b37Z&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ALhkC2T269WwPtyd5qvti3WNZV40&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "BacAlarm: Mining and Simulating Composite API Traffic to Prevent Broken Access Control Violations", "first_label": [], "second_label": [], "data": "Y Yang, H Zhang, B Liu, J Xu, J Hu, L Dong, Z Mao- arXiv preprint arXiv, 2025\nBroken Access Control (BAC) violations, which consistently rank among the top five \nsecurity risks in the OWASP API Security Top 10, refer to unauthorized access \nattempts arising from BAC vulnerabilities, whose successful exploitation can impose \nsignificant risks on exposed application programming interfaces (APIs). In recent \nyears, learning-based methods have demonstrated promising prospects in detecting \nvarious types of malicious activities. However, in real-network operation and\nCites: Active learning of discriminative subgraph patterns for api misuse\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.19997&hl=en&sa=X&d=8710151879200381690&ei=Ff9PaYi9O76Z6rQPr-v5iAc&scisig=ALhkC2SL2UODLjhx8fq3xj89Z6oZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:ALhkC2Tv0L1GNq4Kk4Fq05ZvgtDM&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["1 new citation to articles by Hong Jin Kang"]}
{"title": "Well Begun is Half Done: Location-Aware and Trace-Guided Iterative Automated Vulnerability Repair", "first_label": ["Vulnerabilities"], "second_label": ["Repair"], "data": "Z Ye, X Sun, S Cao, L Bo, B Li- arXiv preprint arXiv:2512.20203, 2025\nThe advances of large language models (LLMs) have paved the way for automated \nsoftware vulnerability repair approaches, which iteratively refine the patch until it \nbecomes plausible. Nevertheless, existing LLM-based vulnerability repair\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20203&hl=en&sa=X&d=8451094022554164496&ei=F_9PaYzGN4aw6rQPkNu46Ao&scisig=ALhkC2RPF725ybz89FzNOIoqd99X&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:ALhkC2SS1P3l44RDJXsNEdNzDLiT&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "7 new citations to articles by Xin ZHOU", "Thanh Le-Cong - new related research", "David Lo - new related research", "Bach Le - new related research", "6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Emotional Strain and Frustration in LLM Interactions in Software Engineering", "first_label": ["LLM"], "second_label": [], "data": "C Martinez Montes, R Khojah- Proceedings of the 29th International Conference on, 2025\nLarge Language Models (LLMs) are increasingly integrated into various daily tasks \nin Software Engineering, such as coding and requirement elicitation. Despite their \nvarious capabilities and constant use, some interactions can lead to unexpected \nchallenges (eg hallucinations or verbose answers) and, in turn, cause emotions that \ndevelop into frustration. Frustration can negatively impact engineers' productivity and \nwell-being if it escalates into stress and burnout. In this paper, we assess the impact\nCites: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3756681.3756951&hl=en&sa=X&d=2966201137299157900&ei=FP9Pabn9GO-GieoPo9DluQE&scisig=ALhkC2TqiGNRYUO9Ab-Za6ntvuyX&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:ALhkC2SLna-N2qwXFiQXiEQOdUM_&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 new citations to articles by Thanh Le-Cong", "2 new citations to articles by Bach Le"]}
{"title": "CodeQUEST: Evaluation and Improvement of Code Quality Using LLMs", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Lius, A Frade, A Vaidya, M Labonne, M Kaiser- 2025 IEEE 36th, 2025\nThis paper presents CodeQUEST, an innovative framework leveraging Large \nLanguage Models (LLMs) to iteratively assess and enhance code quality across \nvarious dimensions, adhering to software engineering best practices. CodeQUEST \nconsists of two main components: the Evaluator, which provides quantitative scores \nand qualitative summaries to assess code quality, and the Optimizer, which refines \nthe code iteratively based on Evaluator feedback. Applying CodeQUEST to a curated\nCites: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11262341/&hl=en&sa=X&d=13371552476892238870&ei=FP9Pabn9GO-GieoPo9DluQE&scisig=ALhkC2Q1yN5Yek-t8SFmgKpWoep1&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:ALhkC2SLna-N2qwXFiQXiEQOdUM_&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 new citations to articles by Thanh Le-Cong", "2 new citations to articles by Bach Le"]}
{"title": "Toward Explaining Large Language Models in Software Engineering Tasks", "first_label": ["LLM"], "second_label": [], "data": "A Vitale, KN Nguyen, D Poshyvanyk, R Oliveto- arXiv preprint arXiv, 2025\nRecent progress in Large Language Models (LLMs) has substantially advanced the \nautomation of software engineering (SE) tasks, enabling complex activities such as \ncode generation and code summarization. However, the black-box nature of LLMs \nremains a major barrier to their adoption in high-stakes and safety-critical domains, \nwhere explainability and transparency are vital for trust, accountability, and effective \nhuman supervision. Despite increasing interest in explainable AI for software\nCites: Codeultrafeedback: An llm-as-a-judge dataset for aligning large", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20328&hl=en&sa=X&d=18107533920722513838&ei=GP9PaY_yM76Z6rQPr-v5iAc&scisig=ALhkC2RhBFqRcXhcOQIa56u5R1bE&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ALhkC2S1ZxbvKZLR2YX67Bvdxjyf&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["7 new citations to articles by Xin ZHOU", "Thanh Le-Cong - new related research", "David Lo - new related research", "Hong Jin Kang - new related research", "Bach Le - new related research", "6 new citations to articles by Abhik Roychoudhury"]}
{"title": "SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization", "first_label": ["Code"], "second_label": ["Localization"], "data": "RG Reddy, Y Liu, W Zhao, JH Doo, T Suresh, D Lee- arXiv preprint arXiv, 2025\nMaintaining large-scale, multilingual codebases hinges on accurately localizing \nissues, which requires mapping natural-language error descriptions to the relevant \nfunctions that need to be modified. However, existing ranking approaches are often \nPython-centric and perform a single-pass search over the codebase. This work \nintroduces SweRank+, a framework that couples SweRankMulti, a cross-lingual code \nranking tool, with SweRankAgent, an agentic search setup, for iterative, multi-turn\nCites: Bridging Bug Localization and Issue Fixing: A Hierarchical", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20482&hl=en&sa=X&d=1215377765737682402&ei=GP9PaY_yM76Z6rQPr-v5iAc&scisig=ALhkC2S3x3kyYbXvyp7s2_HuT_No&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ALhkC2S1ZxbvKZLR2YX67Bvdxjyf&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["7 new citations to articles by Xin ZHOU", "Abhik Roychoudhury - new related research"]}
{"title": "Grounding Generative AI in Software Engineering: Are We There Yet?", "first_label": [], "second_label": [], "data": "M Saad, JAH Lpez, B Chen, N Ernst, D Varr\nLarge Language Models (LLMs) have made significant contributions to software \nengineering, particularly in the field of code generation, demonstrating the ability to \nproduce functionally correct code snippets. The development of these models \ninvolves multiple stages, including pre-training on large amounts of source code data \nand aligning them with human preferences using various techniques. However, their \ndevelopment process often neglects foundational software engineering (SE)\nCites: Codeultrafeedback: An llm-as-a-judge dataset for aligning large", "link": "https://scholar.google.com/scholar_url?url=https://tusharma.in/preprints/SANER2026_SENAI.pdf&hl=en&sa=X&d=18351133097886877731&ei=GP9PaY_yM76Z6rQPr-v5iAc&scisig=ALhkC2Rp2lQTCiQ7koPFk37pbmco&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ALhkC2S1ZxbvKZLR2YX67Bvdxjyf&html=&pos=3&folt=cit", "author": ["Xin ZHOU"], "ref": ["7 new citations to articles by Xin ZHOU"]}
{"title": "Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models", "first_label": ["LLM", "Fuzzing"], "second_label": [], "data": "W Bin, A Yang, K Li, A Liu, H Li, G Luo, W Huang- arXiv preprint arXiv, 2025\nIn the domain of software security testing, Directed Grey-Box Fuzzing (DGF) has \ngarnered widespread attention for its efficient target localization and excellent \ndetection performance. However, existing approaches measure only the physical \ndistance between seed execution paths and target locations, overlooking logical \nrelationships among code segments. This omission can yield redundant or \nmisleading guidance in complex binaries, weakening DGF's real-world effectiveness\nCites: Large language model for vulnerability detection: Emerging results", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.19758&hl=en&sa=X&d=10404575678825130290&ei=GP9PaY_yM76Z6rQPr-v5iAc&scisig=ALhkC2S0w4_xffv2PKttMN9NnXN6&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ALhkC2S1ZxbvKZLR2YX67Bvdxjyf&html=&pos=4&folt=cit", "author": ["Xin ZHOU"], "ref": ["7 new citations to articles by Xin ZHOU", "6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Transformer-Based Memory Reverse Engineering for Malware Behavior Reconstruction", "first_label": [], "second_label": [], "data": "K Alrawashdeh- Computers, 2025\nVolatile memory provides the most direct and clear view into a system's runtime \nbehavior. Yet, traditional forensics methods are prone to errors and remain fragile \nagainst modern obfuscation and injection techniques. This paper introduces a textual-\nattention transformer framework that treats raw memory bytes as linguistic tokens, \nallowing the model to read memory as text and infer contextual relationships across \ndisjoint regions. The proposed model aligns positional encodings with memory\nCites: DexBERT: Effective, Task-Agnostic and Fine-grained", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2073-431X/15/1/8&hl=en&sa=X&d=8914754656931471012&ei=GP9PaY_yM76Z6rQPr-v5iAc&scisig=ALhkC2QA1aL000u36Bm5lkjz3UmT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ALhkC2S1ZxbvKZLR2YX67Bvdxjyf&html=&pos=5&folt=cit", "author": ["Xin ZHOU"], "ref": ["7 new citations to articles by Xin ZHOU"]}
{"title": "Energy-Efficient Multi-LLM Reasoning for Binary-Free Zero-Day Detection in IoT Firmware", "first_label": ["LLM"], "second_label": ["Detection", "Reasoning"], "data": "S Jamshidi, O Abdul-Wahab, M Bellache, F Khomh- arXiv preprint arXiv:2512.19945, 2025\nSecuring Internet of Things (IoT) firmware remains difficult due to proprietary \nbinaries, stripped symbols, heterogeneous architectures, and limited access to \nexecutable code. Existing analysis methods, such as static analysis, symbolic \nexecution, and fuzzing, depend on binary visibility and functional emulation, making \nthem unreliable when firmware is encrypted or inaccessible. To address this \nlimitation, we propose a binary-free, architecture-agnostic solution that estimates the\nCites: Large language model for vulnerability detection: Emerging results\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.19945&hl=en&sa=X&d=4375246272036169078&ei=GP9PaY_yM76Z6rQPr-v5iAc&scisig=ALhkC2TvQkUF78241vk-lXd8rmsz&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ALhkC2S1ZxbvKZLR2YX67Bvdxjyf&html=&pos=6&folt=cit", "author": ["Xin ZHOU"], "ref": ["7 new citations to articles by Xin ZHOU"]}
{"title": "BGF-DR: Bidirectional Greybox Fuzzing for DNS Resolver Vulnerability Discovery", "first_label": ["Vulnerabilities", "Fuzzing"], "second_label": [], "data": "J Ying, J Li, R Chen, H Su, T Zhu- Computers & Security, 2025\nAbstract The Domain Name System (DNS) represents a vital infrastructure \ncomponent of the Internet, within which DNS resolvers constitute the core element of \nthis system. Specifically, DNS resolvers mediate between DNS clients and DNS", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825004985&hl=en&sa=X&d=10939999995567921851&ei=GP9Pad-vDsW4ieoP4szBiAE&scisig=ALhkC2T4XvBETGS9yQs4kRf9dS8A&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ALhkC2Tff526TIEbfh2mbT-kfB65&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Methodology for Analyzing Dockerfile Using AI for Vulnerabilities", "first_label": ["Vulnerabilities"], "second_label": [], "data": "P Sharikov, A Chechulin- Proceedings of the Ninth International Scientific, 2025\nThis paper presents a methodology that utilizes artificial intelligence tools to analyze \nDockerfiles and identify security vulnerabilities. The authors propose an approach \nthat automates the labor-intensive manual processes of Dockerfile creation and \nsubsequent verification. The primary focus is on detecting potentially dangerous \nconfigurations, sub-optimal practices, and latent security risks at the Dockerfile level \nbefore the image is built. Implementing this methodology enhances the security of\nCites: Dockercleaner: Automatic repair of security smells in dockerfiles\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Pavel-Sharikov/publication/398872251_Methodology_for_Analyzing_Dockerfile_Using_AI_for_Vulnerabilities/links/6949787c9aa6b4649dc339e2/Methodology-for-Analyzing-Dockerfile-Using-AI-for-Vulnerabilities.pdf&hl=en&sa=X&d=18394493293571089090&ei=Fv9PafuJMoaw6rQPkNu46Ao&scisig=ALhkC2SUX1ngp6QOYavxRWch9Zhb&oi=scholaralrt&hist=ylyK0_8AAAAJ:5615766320347152220:ALhkC2SDGf2CXtZzq0zyAUcOBMgu&html=&pos=0&folt=cit", "author": ["Quang-Cuong Bui"], "ref": ["1 new citation to articles by Quang-Cuong Bui"]}
{"title": "VDMPAGR: A vulnerability detection model based on pointer analysis and graph representation", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "Y Dong, S Liu, X Liu, M Chen, S Wang, Y Feng- Information and Software, 2025\nContext: Software vulnerabilities pose a major threat to software security. Deep \nlearning-based vulnerability detection models have demonstrated notable \nadvantages, particularly in terms of automation and accuracy. Among these, graph", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925003210&hl=en&sa=X&d=558143430722896337&ei=Ff9PadPEHrux6rQPi5qW2AE&scisig=ALhkC2Q-zlQbenNHcC1nYe1IeGcP&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ALhkC2RZmRqgZGCFQXCJyP9vthGu&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Tuning LLM in secure code generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "DS Shaikhelislamov, MS Varetsa, AS Syomkin-  , 2025\nThe popularity of using LLM for code generation makes it mandatory to \ncomprehensively verify the security and reliability of the generated code. To verify the \ngenerated code, it is suggested to use the static analyzer Svace, which checks the\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.mathnet.ru/rus/tisp1045&hl=en&sa=X&d=5765086413756448946&ei=Ff9PadPEHrux6rQPi5qW2AE&scisig=ALhkC2RNVNU28flijldY4h73JER0&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ALhkC2RZmRqgZGCFQXCJyP9vthGu&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "A Comprehensive Study of Bugs in Modern Distributed Deep Learning Systems", "first_label": ["Bug"], "second_label": [], "data": "X Ma, W Zhan, J Chen, Y Li, J Keung, F Sarro- arXiv preprint arXiv:2512.20345, 2025\nIn today's data-driven era, deep learning is vital for processing massive datasets, yet \nsingle-device training is constrained by computational and memory limits. Distributed \ndeep learning overcomes these challenges by leveraging multiple GPUs or\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20345&hl=en&sa=X&d=7317740715534641535&ei=F_9PaaKsDK-nieoPz8HDqAc&scisig=ALhkC2T3gbh4iaLIXo7VSTFODlaJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ALhkC2THo_3s8tBI3qmyNrpmj0cv&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Catching common vulnerabilities with code language models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "S Al Atiiq, C Gehrmann, K Khalil, K Dahln- 2025 IEEE Secure Development, 2025\nCode Language Model (code-LM)-based vulnerability detection for C/C++ faces a \nsubstantial challenge. Previous research has shown that even though it is better than \nany prior machine learning approach, it still struggles to generalize well, as shown by\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://lup.lub.lu.se/record/4a13fc00-b39b-4ac7-8940-4fa571d55e8d&hl=en&sa=X&d=189082203538347483&ei=Gf9Pace2CNKV6rQP84i9kQc&scisig=ALhkC2SU0YaKyLoFQquj7BYIIm-s&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ALhkC2Q9j5kdmlV_e8u2kLe_NWfw&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "CoSrch: Syntactic and Semantic Structure-Aware Code Representation for Effective Code Search", "first_label": ["Code"], "second_label": ["Search"], "data": "J Xu, Y He, H Liu, P Lv, T Zhang, Z Tian- ACM Transactions on Software Engineering, 2025\nCode search, which retrieves relevant code snippets from a large codebase based \non natural language queries, significantly enhances software development efficiency \nand quality, with effective code representation being crucial for its success. While\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3785469&hl=en&sa=X&d=12641140021273245868&ei=Gf9PacGyGYKUieoP5cGFWQ&scisig=ALhkC2SrAVHj95Y4BwzdU6-Gx6eP&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ALhkC2T269WwPtyd5qvti3WNZV40&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Exploring the Potential and Limitations of Large Language Models for Novice Program Fault Localization", "first_label": ["LLM", "Fault Localization"], "second_label": ["Localization"], "data": "H Xu, H Liu, Y Wu, X Kang, X Chen, Y Liu- Journal of Systems and Software, 2025\nNovice programmers often face challenges in fault localization due to their limited \nexperience and understanding of programming syntax and logic. Traditional \nmethods like Spectrum-Based Fault Localization (SBFL) and Mutation-Based Fault\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.03421&hl=en&sa=X&d=14474168845101817028&ei=FP9PafqAPNKV6rQP84i9kQc&scisig=ALhkC2Sh55MR8Jvam3drU0L05GmR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ALhkC2QkVwCdvNzUylYiTyCmheSL&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Crowdsourcing Framework for Security Testing and Verification of Industrial Cyber-Physical Systems", "first_label": ["Verification", "Software Testing"], "second_label": [], "data": "Z Li, Y Ding, R Zhao, S Wang, J Li- Sensors, 2025\nWith the widespread deployment of Industrial Cyber-Physical Systems (ICPS), their \ninherent vulnerabilities have increasingly exposed them to sophisticated \ncybersecurity threats. Although existing protective mechanisms can block attacks at \nruntime, the risk of defense failure remains. To proactively evaluate and harden ICPS \nsecurity, we design a distributed crowdsourced testing platform tailored to the four-\nlayer cloud ICPS architecturespanning the workshop, factory, enterprise, and\nCites: Selectively Uniform Concurrency Testing", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/1424-8220/26/1/79&hl=en&sa=X&d=4899713721774725616&ei=F_9PaYy7It_OieoPg6WE2QY&scisig=ALhkC2R0vSLeu7E6UorK9Nv1O1Rj&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ALhkC2SLNtxsIYV7y8T6Ni2J4ruF&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models", "first_label": ["APR"], "second_label": ["Repair"], "data": "F Vallecillos Ruiz, M Hort, L Moonen- of the 29th International Conference on, 2025\nAutomatic program repair (APR) aims at reducing the manual efforts required to \nidentify and fix errors in source code. Before the rise of Large Language Model (LLM)-\nbased agents, a common strategy was simply to increase the number of generated \npatches, sometimes to the thousands, which usually yielded better repair results on \nbenchmarks. More recently, self-iterative capabilities enabled LLMs to refine patches \nover multiple rounds guided by feedback. However, literature often focuses on many\nCites: Trust Enhancement Issues in Program Repair", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3756681.3756966&hl=en&sa=X&d=17470407147567288266&ei=F_9PaYy7It_OieoPg6WE2QY&scisig=ALhkC2SRP6HPpHGLzhnyHAckmgvK&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ALhkC2SLNtxsIYV7y8T6Ni2J4ruF&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
