{"title": "MGC: A modal mapping coupling and gate-driven contrastive learning approach for multimodal intent recognition", "first_label": [], "second_label": [], "data": "M Wang, L Xie, C Li, X Wang, M Sun, Z Liu\\xc2\\xa0- Expert Systems with Applications, 2025\nMultimodal intent recognition seeks to comprehensively analyze and interpret a \nspeaker's viewpoint, attitude, and emotional inclination by integrating information \nfrom diverse modalities. However, conventional methods often fail to adequately \naddress the issue of modality frequency inconsistency arising from data \ndesynchronization during the feature fusion process, which subsequently hampers \nthe accuracy of the recognition task. To mitigate this challenge, the present study\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSurveying neuro-symbolic approaches for reliable artificial\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0957417425012539&hl=en&sa=X&d=5116476463814215910&ei=sFYCaLLTIIio6rQP9feogAU&scisig=AFWwaeZmw5MjVFiX_HqSDM8FiAsT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AFWwaeZ0cPfysy_B7V1I3HcGE9Io&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang"]}
{"title": "MigGPT: Harnessing Large Language Models for Automated Migration of Out-of-Tree Linux Kernel Patches Across Versions", "first_label": ["LLM"], "second_label": [], "data": "P Dang, D Huang, D Li, K Chen, Y Wen, Q Guo, X Hu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nOut-of-tree kernel patches are essential for adapting the Linux kernel to new \nhardware or enabling specific functionalities. Maintaining and updating these \npatches across different kernel versions demands significant effort from experienced \nengineers. Large language models (LLMs) have shown remarkable progress across \nvarious domains, suggesting their potential for automating out-of-tree kernel patch \nmigration. However, our findings reveal that LLMs, while promising, struggle with\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomatic Android deprecated-API usage update by learning from\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.09474&hl=en&sa=X&d=1960075332266941840&ei=sFYCaLLTIIio6rQP9feogAU&scisig=AFWwaeaDdG69Y1WbgolcX9e3sh7U&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AFWwaeZ0cPfysy_B7V1I3HcGE9Io&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang", "Xin ZHOU - new related research"]}
{"title": "GitBugs: Bug Reports for Duplicate Detection, Retrieval Augmented Generation, Triage, and More", "first_label": ["Bug"], "second_label": ["Detection", "Generation"], "data": "A Patil\\xc2\\xa0- arXiv preprint arXiv:2504.09651, 2025\nBug reports provide critical insights into software quality, yet existing datasets often \nsuffer from limited scope, outdated content, or insufficient metadata for machine \nlearning. To address these limitations, we present GitBugs-a comprehen-sive and up-\nto-date dataset comprising over 150,000 bug reports from nine actively maintained \nopen-source projects, including Firefox, Cassandra, and VS Code. GitBugs \naggregates data from Github, Bugzilla and Jira issue trackers, offering standardized\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCc2vec: Distributed representations of code changes\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.09651&hl=en&sa=X&d=8871451496193637128&ei=sFYCaLLTIIio6rQP9feogAU&scisig=AFWwaebBtv0WvIm-C4TBUnSN4tMQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AFWwaeZ0cPfysy_B7V1I3HcGE9Io&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang"]}
{"title": "Reasoning with LLMs for Zero-Shot Vulnerability Detection", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Reasoning"], "data": "A Zibaeirad, M Vieira\\xc2\\xa0- arXiv preprint arXiv:2503.17885, 2025\nAutomating software vulnerability detection (SVD) remains a critical challenge in an \nera of increasingly complex and interdependent software systems. Despite \nsignificant advances in Large Language Models (LLMs) for code analysis, prevailing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.17885&hl=en&sa=X&d=16151102993317123730&ei=sFYCaNSRH5Gu6rQPhJLo-Qk&scisig=AFWwaeaU1duZG60YHiU0D1fyotku&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AFWwaeYwgMeQSPpxCfDXmGy5aE3n&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis", "first_label": ["LLM", "Code"], "second_label": ["Agent", "Reasoning"], "data": "A Wei, T Suresh, J Cao, N Kannan, Y Wu, K Yan\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInductive program synthesis, or programming by example, requires synthesizing \nfunctions from input-output examples that generalize to unseen inputs. While large \nlanguage model agents have shown promise in programming tasks guided by\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.23145&hl=en&sa=X&d=7322261732284042571&ei=sFYCaNSRH5Gu6rQPhJLo-Qk&scisig=AFWwaeaAH4_AfF9MmAImwDIX-Jtw&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AFWwaeYwgMeQSPpxCfDXmGy5aE3n&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "White-box structure analysis of pre-trained language models of code for effective attacking", "first_label": ["Code"], "second_label": [], "data": "C Liu, X Ren, Y Xue\\xc2\\xa0- Information and Software Technology, 2025\nContext: Pre-trained language models of code (PLMs-C for short) have dramatically \nimproved the state-of-the-art on various programming language processing tasks. \nObjective: Due to these well-performed models being easily disturbed by slight\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925000692&hl=en&sa=X&d=10831422306869385650&ei=sFYCaJ2mKpGu6rQPhJLo-Qk&scisig=AFWwaeaYut7czcHGT0TluKBywRaC&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Large Language Models (LLMs) for Source Code Analysis: applications, models and datasets", "first_label": ["LLM", "Code"], "second_label": [], "data": "H Jelodar, M Meymani, R Razavi-Far\\xc2\\xa0- arXiv preprint arXiv:2503.17502, 2025\nLarge language models (LLMs) and transformer-based architectures are \nincreasingly utilized for source code analysis. As software systems grow in \ncomplexity, integrating LLMs into code analysis workflows becomes essential for\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.17502&hl=en&sa=X&d=13932223716190867094&ei=sFYCaJ2mKpGu6rQPhJLo-Qk&scisig=AFWwaeb1dh07lugR2sszh6eusTe5&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Evaluating API-Level Deep Learning Fuzzers: A Comprehensive Benchmarking Study", "first_label": ["Fuzzing"], "second_label": [], "data": "N Shiri Harzevili, M Wei, MM Mohajer, VH Pham\\xe2\\x80\\xa6\\xc2\\xa0- ACM Transactions on Software\\xc2\\xa0\\xe2\\x80\\xa6\nIn recent years, the practice of fuzzing Deep Learning (DL) APIs has received \nsignificant attention in the software engineering community. Many API-level DL \nfuzzers have been proposed to test individual DL APIs by generating malformed\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3729533&hl=en&sa=X&d=7084698531104603808&ei=sFYCaJ2mKpGu6rQPhJLo-Qk&scisig=AFWwaebLI62cHENmKJRJFgzoOWtS&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Cryptoscope: Analyzing cryptographic usages in modern software", "first_label": [], "second_label": [], "data": "M Moffie, O Boehm, A Koyfman, E Bin, E Sztokman\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe advent of quantum computing poses a significant challenge as it has the \npotential to break certain cryptographic algorithms, necessitating a proactive \napproach to identify and modernize cryptographic code. Identifying these\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.19531&hl=en&sa=X&d=6686443909091919827&ei=sFYCaJ2mKpGu6rQPhJLo-Qk&scisig=AFWwaea67RT8XqRdcr5ZIgfReDEG&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "DALO-APR: LLM-based automatic program repair with data augmentation and loss function optimization", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "S Wang, L Lu, S Qiu, Q Tian, H Lin\\xc2\\xa0- The Journal of Supercomputing, 2025\nAutomatic program repair (APR) has made significant strides with the advent of large \nlanguage models (LLMs) such as T5 and CodeT5. However, LLM-based APR \nmodels may rely on repetitive repair patterns due to limited training data diversity\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11227-025-07102-3&hl=en&sa=X&d=10480458481806281342&ei=sFYCaJ2mKpGu6rQPhJLo-Qk&scisig=AFWwaeZgISIeIz-af4x6cYmuf3Oy&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "FANDANGO: Evolving Language-Based Testing", "first_label": ["Software Testing"], "second_label": [], "data": "JA Amaya Zamudio, M Smytzek, A Zeller - 2025\nLanguage-based fuzzers leverage formal input specifications (languages) to \ngenerate arbitrarily large and diverse sets of valid inputs for a program under test. \nModern language-based test generators combine grammars and constraints to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://publications.cispa.de/articles/conference_contribution/FANDANGO_Evolving_Language-Based_Testing/28769753/1/files/53582009.pdf&hl=en&sa=X&d=9799348799216676838&ei=sFYCaJ2mKpGu6rQPhJLo-Qk&scisig=AFWwaeYGxcve-C-cod8MrX3cSZKA&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "RAG-Based Fuzzing of Cross-Architecture Compilers", "first_label": ["Fuzzing"], "second_label": [], "data": "R Elnaggar, B Delgado, JM Fung\\xc2\\xa0- arXiv preprint arXiv:2504.08967, 2025\nOneAPI is an open standard that supports cross-architecture software development \nwith minimal effort from developers. It brings DPC++ and C++ compilers which need \nto be thoroughly tested to verify their correctness, reliability, and security. Compilers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.08967&hl=en&sa=X&d=18234725876643657828&ei=sFYCaJ2mKpGu6rQPhJLo-Qk&scisig=AFWwaeYdv3A16hwtKYPOY2o9MT03&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Automatic High-Level Test Case Generation using Large Language Models", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "NB Hasan, MA Islam, JY Khan, S Senjik, A Iqbal\\xc2\\xa0- arXiv preprint arXiv:2503.17998, 2025\nWe explored the challenges practitioners face in software testing and proposed \nautomated solutions to address these obstacles. We began with a survey of local \nsoftware companies and 26 practitioners, revealing that the primary challenge is not\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.17998&hl=en&sa=X&d=2435370287861060433&ei=sFYCaJ2mKpGu6rQPhJLo-Qk&scisig=AFWwaeb0yzfBEwJ9p6RT6YLxQ0vY&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "CodeReviewQA: The Code Review Comprehension Assessment for Large Language Models", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "HY Lin, C Liu, H Gao, P Thongtanunam, C Treude\\xc2\\xa0- arXiv preprint arXiv:2503.16167, 2025\nState-of-the-art large language models (LLMs) have demonstrated impressive code \ngeneration capabilities but struggle with real-world software engineering tasks, such \nas revising source code to address code reviews, hindering their practical use. Code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.16167&hl=en&sa=X&d=13987149689206803549&ei=sFYCaJ2mKpGu6rQPhJLo-Qk&scisig=AFWwaeZRD8EhNW4NSPG4ypaH_WWQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Enhancing LLM-based Code Translation in Repository Context via Triple Knowledge-Augmented", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "G Ou, M Liu, Y Chen, X Du, S Wang, Z Zhang, X Peng\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have behaved well in function-level code translation \nwithout repository-level context. However, the performance of LLMs in repository-\nlevel context code translation remains suboptimal due to complex dependencies and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.18305&hl=en&sa=X&d=1496301354611823227&ei=sFYCaJ2mKpGu6rQPhJLo-Qk&scisig=AFWwaebZgjNWSGlwwMWRyrQ2cYwe&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "StruPhantom: Evolutionary Injection Attacks on Black-Box Tabular Agents Powered by Large Language Models", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Y Feng, X Pan\\xc2\\xa0- arXiv preprint arXiv:2504.09841, 2025\nThe proliferation of autonomous agents powered by large language models (LLMs) \nhas revolutionized popular business applications dealing with tabular data, ie, \ntabular agents. Although LLMs are observed to be vulnerable against prompt\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.09841&hl=en&sa=X&d=8898975456969396814&ei=sFYCaKusJua16rQPr6HEKA&scisig=AFWwaeZrl_2--SQtyJrIKCVWjzmL&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AdaSteer: Your Aligned LLM is Inherently an Adaptive Jailbreak Defender", "first_label": ["LLM"], "second_label": [], "data": "W Zhao, J Guo, Y Hu, Y Deng, A Zhang, X Sui, X Han\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite extensive efforts in safety alignment, large language models (LLMs) remain \nvulnerable to jailbreak attacks. Activation steering offers a training-free defense \nmethod but relies on fixed steering coefficients, resulting in suboptimal protection\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.09466&hl=en&sa=X&d=2341918032029788356&ei=sFYCaKusJua16rQPr6HEKA&scisig=AFWwaebrgnVogbG4VPSgee9degAs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "ControlNET: A Firewall for RAG-based LLM System", "first_label": ["LLM"], "second_label": [], "data": "H Yao, H Shi, Y Chen, Y Jiang, C Wang, Z Qin, K Ren\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRetrieval-Augmented Generation (RAG) has significantly enhanced the factual \naccuracy and domain adaptability of Large Language Models (LLMs). This \nadvancement has enabled their widespread deployment across sensitive domains\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.09593&hl=en&sa=X&d=17184153539705524448&ei=sFYCaKusJua16rQPr6HEKA&scisig=AFWwaeYqxdktorXrqpRSjr3bDLUg&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SaRO: Enhancing LLM Safety through Reasoning-based Alignment", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "Y Mou, Y Luo, S Zhang, W Ye\\xc2\\xa0- arXiv preprint arXiv:2504.09420, 2025\nCurrent safety alignment techniques for large language models (LLMs) face two key \nchallenges:(1) under-generalization, which leaves models vulnerable to novel \njailbreak attacks, and (2) over-alignment, which leads to the excessive refusal of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.09420&hl=en&sa=X&d=5520993791348679153&ei=sFYCaKusJua16rQPr6HEKA&scisig=AFWwaeaN4AT63fhFbjcsMxrzqv3X&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Guiding Reasoning in Small Language Models with LLM Assistance", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "Y Kim, E Yi, M Kim, SY Yun, T Kim\\xc2\\xa0- arXiv preprint arXiv:2504.09923, 2025\nThe limited reasoning capabilities of small language models (SLMs) cast doubt on \ntheir suitability for tasks demanding deep, multi-step logical deduction. This paper \nintroduces a framework called Small Reasons, Large Hints (SMART), which\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.09923&hl=en&sa=X&d=14164917725099182845&ei=sFYCaKusJua16rQPr6HEKA&scisig=AFWwaeaZyKC2MhX_kv3y_wekoi1s&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "XSShield: Defending Against Stored XSS Attacks Using LLM-Based Semantic Understanding", "first_label": ["LLM"], "second_label": [], "data": "Y Zhou, E Wang, W Yang, W Ge, S Yang, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- Applied Sciences, 2025\nCross-site scripting attacks represent one of the major security threats facing web \napplications, with Stored XSS attacks becoming the predominant form. Compared to \nreflected XSS, stored XSS attack payloads exhibit temporal and spatial asynchrony\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2076-3417/15/6/3348&hl=en&sa=X&d=11849643047241211005&ei=sFYCaKusJua16rQPr6HEKA&scisig=AFWwaeZJp-xCesiNk9t9IXhXxSLJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Dapo: An open-source llm reinforcement learning system at scale", "first_label": ["LLM"], "second_label": [], "data": "Q Yu, Z Zhang, R Zhu, Y Yuan, X Zuo, Y Yue, T Fan\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInference scaling empowers LLMs with unprecedented reasoning ability, with \nreinforcement learning as the core technique to elicit complex reasoning. However, \nkey technical details of state-of-the-art reasoning LLMs are concealed (such as in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.14476&hl=en&sa=X&d=1968980266662184520&ei=sFYCaKusJua16rQPr6HEKA&scisig=AFWwaebXNS6d8Y_C8FG4sfvmXe0u&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM Social Simulations Are a Promising Research Method", "first_label": ["LLM"], "second_label": ["Search"], "data": "JR Anthis, R Liu, SM Richardson, AC Kozlowski\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAccurate and verifiable large language model (LLM) simulations of human research \nsubjects promise an accessible data source for understanding human behavior and \ntraining new AI systems. However, results to date have been limited, and few social\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.02234&hl=en&sa=X&d=16711303184695482252&ei=sFYCaKusJua16rQPr6HEKA&scisig=AFWwaeYGBtI8NvC7VEpsMD3Vz-UB&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Test-Time Backdoor Detection for Object Detection Models", "first_label": ["Software Testing"], "second_label": ["Detection"], "data": "H Zhang, Y Wang, S Yan, C Zhu, Z Zhou, L Hou, S Hu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nObject detection models are vulnerable to backdoor attacks, where attackers poison \na small subset of training samples by embedding a predefined trigger to manipulate \nprediction. Detecting poisoned samples (ie, those containing triggers) at test time can\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.15293%3F&hl=en&sa=X&d=6052108469819470987&ei=sFYCaKusJua16rQPr6HEKA&scisig=AFWwaeZFwCtybcnsCXtBxoexifa2&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Aligning Multimodal LLM with Human Preference: A Survey", "first_label": ["LLM"], "second_label": [], "data": "T Yu, C Fu, J Wu, J Lu, K Wang, X Lu, Y Shen, G Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) can handle a wide variety of general tasks with \nsimple prompts, without the need for task-specific training. Multimodal Large \nLanguage Models (MLLMs), built upon LLMs, have demonstrated impressive\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.14504&hl=en&sa=X&d=1315835665997175613&ei=sFYCaKusJua16rQPr6HEKA&scisig=AFWwaeaYxO6Scdjrz2Sdyj1j9_2t&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "A Happe, J Cito\\xc2\\xa0- arXiv preprint arXiv:2504.10112, 2025\nLarge Language Models (LLMs) have emerged as a powerful approach for driving \noffensive penetration-testing tooling. This paper analyzes the methodology and \nbenchmarking practices used for evaluating Large Language Model (LLM)-driven \nattacks, focusing on offensive uses of LLMs in cybersecurity. We review 16 research \npapers detailing 15 prototypes and their respective testbeds. We detail our findings \nand provide actionable recommendations for future research, emphasizing the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLLM agents can autonomously exploit one-day vulnerabilities (2024)\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.10112&hl=en&sa=X&d=1049283443257479609&ei=sFYCaL7OHeTO6rQPlsna-Qw&scisig=AFWwaeYqMZ5AEX91gvMlww9VDgQQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AFWwaebib5Pw9QKWi9BJ6ThKDwc5&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang"]}
{"title": "A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems", "first_label": ["LLM"], "second_label": ["Agent", "Reasoning"], "data": "Z Ke, F Jiao, Y Ming, XP Nguyen, A Xu, DX Long, M Li\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nReasoning is a fundamental cognitive process that enables logical inference, \nproblem-solving, and decision-making. With the rapid advancement of large \nlanguage models (LLMs), reasoning has emerged as a key capability that \ndistinguishes advanced AI systems from conventional models that empower \nchatbots. In this survey, we categorize existing methods along two orthogonal \ndimensions:(1) Regimes, which define the stage at which reasoning is achieved\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCodeultrafeedback: An llm-as-a-judge dataset for aligning large\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.09037&hl=en&sa=X&d=12535639908536195100&ei=sFYCaPfrJPOy6rQP0re88AY&scisig=AFWwaebmqOv4WIr3NLEXLWnfHh9g&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AFWwaeZamHljvPChNBtOABcetGTp&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["1 new citation to articles by Xin ZHOU"]}
{"title": "MSCoT: Structured Chain-of-Thought Generation for Multiple Programming Languages", "first_label": [], "second_label": ["Generation"], "data": "N Jin, Z Li, T Zhang, Q Zeng\\xc2\\xa0- arXiv preprint arXiv:2504.10178, 2025\nWith the rapid development of code intelligence, the application of multiple \nprogramming languages is becoming increasingly widespread. However, most \nexisting code generation models mainly focus on a single or a few programming\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.10178&hl=en&sa=X&d=3821996461058345675&ei=sFYCaOWsKMeUywTJ0bLoBg&scisig=AFWwaeZoe1lxEPIV49Clg6MndGF0&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AFWwaeZADCuvrSiGaZ1pge7b9bMB&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "Code-Craft: Hierarchical Graph-Based Code Summarization for Enhanced Context Retrieval", "first_label": ["Code"], "second_label": [], "data": "D Sounthiraraj, J Hancock, Y Kortam, A Javvaji\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nUnderstanding and navigating large-scale codebases remains a significant \nchallenge in software engineering. Existing methods often treat code as flat text or \nfocus primarily on local structural relationships, limiting their ability to provide holistic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.08975&hl=en&sa=X&d=13012966678791827914&ei=sFYCaOWsKMeUywTJ0bLoBg&scisig=AFWwaeaOv07lhVW3UYMZqvuTZhS_&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AFWwaeZADCuvrSiGaZ1pge7b9bMB&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Uncertainty-Guided Chain-of-Thought for Code Generation with LLMs", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Y Zhu, G Li, X Jiang, J Li, H Mei, Z Jin, Y Dong\\xc2\\xa0- arXiv preprint arXiv:2503.15341, 2025\nChain-of-Thought (CoT) reasoning has been demonstrated as an effective technique \nfor improving the problem-solving capabilities of large language models (LLMs) in \nthe context of code generation. However, existing CoT methods often exhibit a\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.15341&hl=en&sa=X&d=15218041727249303368&ei=sFYCaOWsKMeUywTJ0bLoBg&scisig=AFWwaeabwVl7WI6ZmTuhEFUfvVBc&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AFWwaeZADCuvrSiGaZ1pge7b9bMB&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "Evaluating Spectrum-based Fault Localization on Deep Learning Libraries", "first_label": ["Fault Localization"], "second_label": ["Localization"], "data": "M Yan, J Chen, T Jiang, J Jiang, Z Wang\\xc2\\xa0- IEEE Transactions on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeep learning (DL) libraries have become increasingly popular and their quality \nassurance is also gaining significant attention. Although many fault detection \ntechniques have been proposed, effective fault localization techniques tailored to DL\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10930847/&hl=en&sa=X&d=13097586511829065482&ei=sFYCaPyiIpm7ieoPjfnLuQk&scisig=AFWwaeZIPeEWx0xchtsAVxGkT88r&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "LLM-based Unit Test Generation for Dynamically-Typed Programs", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "R Liu, Z Zhang, Y Hu, Y Lin, X Gao, H Sun\\xc2\\xa0- arXiv preprint arXiv:2503.14000, 2025\nAutomated unit test generation has been widely studied, but generating effective \ntests for dynamically typed programs remains a significant challenge. Existing \napproaches, including search-based software testing (SBST) and recent LLM-based\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.14000&hl=en&sa=X&d=7430576131620821752&ei=sFYCaPyiIpm7ieoPjfnLuQk&scisig=AFWwaeY9lDQzBc37lJzEKJmFY6Qx&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "CodeRAG: Supportive Code Retrieval on Bigraph for Real-World Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "J Li, X Shi, K Zhang, L Li, G Li, Z Tao, F Liu, C Tao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have shown promising performance in automated \ncode generation, especially excelling in simple tasks such as generating standalone \ncodes. Different from simple tasks, real-world code generation usually depends on\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.10046&hl=en&sa=X&d=14720281153510071392&ei=sFYCaPyiIpm7ieoPjfnLuQk&scisig=AFWwaeZLUxRan7HesVUXuzhTEec3&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "An Empirical Study of the Comparison of Task Recommendation Techniques and Similar Source Code in Open Source Software Projects", "first_label": ["Code"], "second_label": [], "data": "GC Regis, I Wiese, I Polato, MAG Silva, R R\\xc3\\xa9\\xe2\\x80\\xa6 - 2025\nContext: Managing issues in open-source software projects is challenging and \ncostly, as many developers are casual and/or newcomers. On the one hand, \nmaintainers must ensure the quality of issue descriptions and their labels and create\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.researchsquare.com/article/rs-6322361/latest&hl=en&sa=X&d=7136585553535855548&ei=sFYCaPyiIpm7ieoPjfnLuQk&scisig=AFWwaeZumoxlBxq_sg9en-vbYhdw&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
