{"title": "DocAgent: A Multi-Agent System for Automated Code Documentation Generation", "first_label": ["Code"], "second_label": ["Generation", "Agent"], "data": "D Yang, A Simoulin, X Qian, X Liu, Y Cao, Z Teng\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nHigh-quality code documentation is crucial for software development especially in \nthe era of AI. However, generating it automatically using Large Language Models \n(LLMs) remains challenging, as existing approaches often produce incomplete, \nunhelpful, or factually incorrect outputs. We introduce DocAgent, a novel multi-agent \ncollaborative system using topological code processing for incremental context \nbuilding. Specialized agents (Reader, Searcher, Writer, Verifier, Orchestrator) then\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLess is More: DocString Compression in Code Generation\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.08725&hl=en&sa=X&d=17391487040813928421&ei=OKwAaKHqNeTO6rQPlsna-Qw&scisig=AFWwaea2ejBoJN0a6J_zGnAekPXP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AFWwaeZamHljvPChNBtOABcetGTp&html=&pos=0&folt=cit", "ref": ["1 new citation to articles by Xin ZHOU"]}
{"title": "SelfCodeAlign: Self-Alignment for Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "YWF Cassano, JLYDN Jain, Z Mueller, HVL von Werra\\xe2\\x80\\xa6\nInstruction tuning is a supervised fine-tuning approach that significantly improves the \nability of large language models (LLMs) to follow human instructions. For \nprogramming tasks, most models are finetuned with costly human-annotated\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://lingming.cs.illinois.edu/publications/neurips2024a.pdf&hl=en&sa=X&d=13342178319076674588&ei=OKwAaKmZM4SlieoPktaN-QY&scisig=AFWwaeY3aA9S3s56bUtMzibeyxLc&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=0&folt=rel", "ref": ["David Lo - new related research", "Bach Le - new related research"]}
{"title": "Metamorphic Testing for Fairness Evaluation in Large Language Models: Identifying Intersectional Bias in LLaMA and GPT", "first_label": ["LLM", "Software Testing"], "second_label": ["Detection"], "data": "H Reddy, M Srinivasan, U Kanewala\\xc2\\xa0- arXiv preprint arXiv:2504.07982, 2025\nLarge Language Models (LLMs) have made significant strides in Natural Language \nProcessing but remain vulnerable to fairness-related issues, often reflecting biases \ninherent in their training data. These biases pose risks, particularly when LLMs are\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.07982&hl=en&sa=X&d=8291365832876885813&ei=OKwAaKmZM4SlieoPktaN-QY&scisig=AFWwaeZyi3Jp-3LFv6s7E9lgYh2C&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=1&folt=rel", "ref": ["David Lo - new related research"]}
{"title": "Quality evaluation of Tabby coding assistant using real source code snippets", "first_label": ["Code"], "second_label": [], "data": "M Borek, R Nowak\\xc2\\xa0- arXiv preprint arXiv:2504.08650, 2025\nLarge language models have become a popular tool in software development, \nproviding coding assistance. The proper measurement of the accuracy and reliability \nof the code produced by such tools is a challenge due to natural language prompts\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.08650&hl=en&sa=X&d=15609747677451661680&ei=OKwAaKmZM4SlieoPktaN-QY&scisig=AFWwaeaWG1SBB5A6wNSBTGDE_bar&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=2&folt=rel", "ref": ["David Lo - new related research"]}
{"title": "Test Amplification for REST APIs via Single and Multi-Agent LLM Systems", "first_label": ["LLM", "Software Testing"], "second_label": ["Agent"], "data": "R Nooyens, T Bardakci, M Beyazit, S Demeyer\\xc2\\xa0- arXiv preprint arXiv:2504.08113, 2025\nREST APIs (Representational State Transfer Application Programming Interfaces) \nare essential to modern cloud-native applications. Strong and automated test cases \nare crucial to expose lurking bugs in the API. However, creating automated tests for\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.08113&hl=en&sa=X&d=12090231993758040543&ei=OKwAaKmZM4SlieoPktaN-QY&scisig=AFWwaeYG4H3F9NsolySjg13ZaZ15&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=3&folt=rel", "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Rethinking Trust in AI Assistants for Software Development: A Critical Review", "first_label": [], "second_label": [], "data": "S Baltes, T Speith, B Chiteri, S Mohsenimofidi\\xe2\\x80\\xa6\nTrust is a fundamental concept in human decisionmaking and collaboration that has \nlong been studied in philosophy and psychology. However, software engineering \n(SE) articles often use the term 'trust'informally\\xe2\\x80\\x94providing an explicit definition or \nembedding results in established trust models is rare. In SE research on AI \nassistants, this practice culminates in equating trust with the likelihood of accepting \ngenerated content, which does not capture the full complexity of the trust concept\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://assets.empirical-software.engineering/pdf/tse25-trust-ai-code.pdf&hl=en&sa=X&d=941957821090728764&ei=OKwAaNfbK7GyieoPnei3oQ4&scisig=AFWwaeYRfOQ9-hiKmqHTb0830v39&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AFWwaeagPGjpoAfsUTlpD2ZsD6em&html=&pos=0&folt=cit", "ref": ["1 new citation to articles by Thanh Le-Cong", "1 new citation to articles by Bach Le"]}
{"title": "A comprehensive survey on integrating large language models with knowledge-based methods", "first_label": ["LLM"], "second_label": [], "data": "W Yang, L Some, M Bain, B Kang\\xc2\\xa0- Knowledge-Based Systems, 2025\nThe rapid development of artificial intelligence has led to marked progress in the \nfield. One interesting direction for research is whether Large Language Models \n(LLMs) can be integrated with structured knowledge-based systems. This approach \naims to combine the generative language understanding of LLMs and the precise \nknowledge representation systems by which they are integrated. This article surveys \nthe relationship between LLMs and knowledge bases, looks at how they can be\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950705125005490&hl=en&sa=X&d=14645346362399576310&ei=OKwAaOHiLvmJ6rQPs4n98A8&scisig=AFWwaebb5VLCuEjXxDH42bc8yd2z&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AFWwaebib5Pw9QKWi9BJ6ThKDwc5&html=&pos=0&folt=cit", "ref": ["1 new citation to articles by Richard Fang"]}
{"title": "Compromising LLM Driven Embodied Agents with Contextual Backdoor Attacks", "first_label": ["LLM"], "second_label": ["Agent"], "data": "A Liu, Y Zhou, X Liu, T Zhang, S Liang, J Wang, Y Pu\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have transformed the development of embodied \nintelligence. By providing a few contextual demonstrations (such as rationales and \nsolution examples) developers can utilize the extensive internal knowledge of LLMs\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10943262/&hl=en&sa=X&d=12719951651069852610&ei=OKwAaMi4N5Gu6rQPhJLo-Qk&scisig=AFWwaeZpVIpHx7agj5Gt0-h7Qtt8&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=0&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "aiXcoder-7B-v2: Training LLMs to Fully Utilize the Long Context in Repository-level Code Completion", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Li, H Zhu, H Liu, X Shi, H Zong, Y Dong, K Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRepository-level code completion aims to complete code based on the long contexts \nof the repository. Existing studies extract long contexts from the repository as inputs \nand leverage Large Language Models (LLMs) to generate code. However, we reveal\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.15301&hl=en&sa=X&d=15788931866516891147&ei=OKwAaMi4N5Gu6rQPhJLo-Qk&scisig=AFWwaeYi_7K3zAnZWQ5kRBngFmjW&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=1&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "L4: Diagnosing large-scale llm training failures via automated log analysis", "first_label": ["LLM"], "second_label": [], "data": "Z Jiang, J Huang, Z Chen, Y Li, G Yu, C Feng, Y Yang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs Large Language Models (LLMs) show their capabilities across various \napplications, training customized LLMs has become essential for modern \nenterprises. However, due to the complexity of LLM training, which requires massive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.20263&hl=en&sa=X&d=14583207368034027437&ei=OKwAaMi4N5Gu6rQPhJLo-Qk&scisig=AFWwaebRe6Hz8JgakljjX6ZP8ib_&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=2&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Does context matter? contextualjudgebench for evaluating llm-based judges in contextual settings", "first_label": ["LLM"], "second_label": [], "data": "A Xu, S Bansal, Y Ming, S Yavuz, S Joty\\xc2\\xa0- arXiv preprint arXiv:2503.15620, 2025\nThe large language model (LLM)-as-judge paradigm has been used to meet the \ndemand for a cheap, reliable, and fast evaluation of model outputs during AI system \ndevelopment and post-deployment monitoring. While judge models--LLMs finetuned\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.15620&hl=en&sa=X&d=4694277635380098830&ei=OKwAaMi4N5Gu6rQPhJLo-Qk&scisig=AFWwaeZWWBCgHzhwdV7rV4U7IIiY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=3&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Trajectory Balance with Asynchrony: Decoupling Exploration and Learning for Fast, Scalable LLM Post-Training", "first_label": ["LLM"], "second_label": [], "data": "BR Bartoldson, S Venkatraman, J Diffenderfer, M Jain\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nReinforcement learning (RL) is a critical component of large language model (LLM) \npost-training. However, existing on-policy algorithms used for post-training are \ninherently incompatible with the use of experience replay buffers, which can be\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.18929&hl=en&sa=X&d=9558060532125767644&ei=OKwAaMi4N5Gu6rQPhJLo-Qk&scisig=AFWwaeYoVzcxOA7NOnZtm52EYzED&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=4&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Jenga: Effective Memory Management for Serving LLM with Heterogeneity", "first_label": ["LLM"], "second_label": [], "data": "C Zhang, K Du, S Liu, W Kwon, X Mo, Y Wang, X Liu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are widely used but expensive to run, especially as \ninference workloads grow. To lower costs, maximizing the request batch size by \nmanaging GPU memory efficiently is crucial. While PagedAttention has recently been\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.18292&hl=en&sa=X&d=7739656753816907647&ei=OKwAaMi4N5Gu6rQPhJLo-Qk&scisig=AFWwaebgcPGXUDU8gTuYj4zLJnGn&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=5&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Enhancing LLM Reasoning with Iterative DPO: A Comprehensive Empirical Investigation", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "S Tu, J Lin, X Tian, Q Zhang, L Li, Y Fu, N Xu, W He\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent advancements in post-training methodologies for large language models \n(LLMs) have highlighted reinforcement learning (RL) as a critical component for \nenhancing reasoning. However, the substantial computational costs associated with\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.12854%3F&hl=en&sa=X&d=6242916882998245282&ei=OKwAaMi4N5Gu6rQPhJLo-Qk&scisig=AFWwaeas1YS6MF9XYtnthgs4xm8W&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=6&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Navigating Rifts in Human-LLM Grounding: Study and Benchmark", "first_label": ["LLM"], "second_label": [], "data": "O Shaikh, H Mozannar, G Bansal, A Fourney, E Horvitz\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models excel at following instructions but often struggle with the \ncollaborative aspects of conversation that humans naturally employ. This limitation in \ngrounding--the process by which conversation participants establish mutual\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.13975&hl=en&sa=X&d=6056628797355529511&ei=OKwAaMi4N5Gu6rQPhJLo-Qk&scisig=AFWwaeYuzwNKVc6ZCL0NUy7wCU7P&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=7&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Parameters vs. Context: Fine-Grained Control of Knowledge Reliance in Language Models", "first_label": [], "second_label": [], "data": "B Bi, S Liu, Y Wang, Y Xu, J Fang, L Mei, X Cheng\\xc2\\xa0- arXiv preprint arXiv:2503.15888, 2025\nRetrieval-Augmented Generation (RAG) mitigates hallucinations in Large Language \nModels (LLMs) by integrating external knowledge. However, conflicts between \nparametric knowledge and retrieved context pose challenges, particularly when\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.15888&hl=en&sa=X&d=8358907449720691769&ei=OKwAaMi4N5Gu6rQPhJLo-Qk&scisig=AFWwaeZPIqjVcxmMuI4nDW3DhW3i&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=8&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Superbpe: Space travel for language models", "first_label": [], "second_label": [], "data": "A Liu, J Hayase, V Hofmann, S Oh, NA Smith, Y Choi\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe assumption across nearly all language model (LM) tokenization schemes is that \ntokens should be subwords, ie, contained within word boundaries. While providing a \nseemingly reasonable inductive bias, is this common practice limiting the potential of\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.13423&hl=en&sa=X&d=8253915600160210066&ei=OKwAaMi4N5Gu6rQPhJLo-Qk&scisig=AFWwaeYtH_P2lSDfkM9dWgyLRFRC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=9&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "RustEvo^ 2: An Evolving Benchmark for API Evolution in LLM-based Rust Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "L Liang, J Gong, M Liu, C Wang, G Ou, Y Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have become pivotal tools for automating code \ngeneration in software development. However, these models face significant \nchallenges in producing version-aware code for rapidly evolving languages like\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.16922%3F&hl=en&sa=X&d=16675224894932160996&ei=OKwAaJieMJuw6rQP7-68qA0&scisig=AFWwaea4g_0zH5bNDjn1WSqwrFGh&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AFWwaeYwgMeQSPpxCfDXmGy5aE3n&html=&pos=0&folt=rel", "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Smart Contract Vulnerability Detection Using Large Language Models and Graph Structural Analysis", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection"], "data": "RY Choi, Y Song, M Jang, T Kim, J Ahn, DH Im\\xc2\\xa0- Computers, Materials and Continua, 2025\nSmart contracts are self-executing programs on blockchains that manage complex \nbusiness logic with transparency and integrity. However, their immutability after \ndeployment makes programming errors particularly critical, as such errors can be\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/org/science/article/pii/S1546221825002504&hl=en&sa=X&d=4504820058459498391&ei=OKwAaJieMJuw6rQP7-68qA0&scisig=AFWwaeZMeaniylWwEGOyOdrF9Ulz&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AFWwaeYwgMeQSPpxCfDXmGy5aE3n&html=&pos=1&folt=rel", "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "Reasoning with LLMs for Zero-Shot Vulnerability Detection", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Reasoning"], "data": "A Zibaeirad, M Vieira\\xc2\\xa0- arXiv preprint arXiv:2503.17885, 2025\nAutomating software vulnerability detection (SVD) remains a critical challenge in an \nera of increasingly complex and interdependent software systems. Despite \nsignificant advances in Large Language Models (LLMs) for code analysis, prevailing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.17885&hl=en&sa=X&d=16151102993317123730&ei=OKwAaIuDOcmpieoPnPbKsA4&scisig=AFWwaeaU1duZG60YHiU0D1fyotku&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=0&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Enhancing llm code generation with ensembles: A similarity-based selection approach", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "T Mahmud, B Duan, C Pasareanu, G Yang\\xc2\\xa0- arXiv preprint arXiv:2503.15838, 2025\nEnsemble learning has been widely used in machine learning to improve model \nrobustness, accuracy, and generalization, but has not yet been applied to code \ngeneration tasks with large language models (LLMs). We propose an ensemble\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.15838&hl=en&sa=X&d=6315180162277152648&ei=OKwAaIuDOcmpieoPnPbKsA4&scisig=AFWwaeYw_s8WAmNdUs0l_UHZtKix&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=1&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Intelligent Test Case Generation Method for Fuzzing IoT Protocols Based on LLM", "first_label": ["LLM", "Fuzzing", "Software Testing"], "second_label": ["Generation"], "data": "M Zhong, Z Zeng, Y Guo, D Zhao, B Zhang, S Li\\xe2\\x80\\xa6 - 2025\nAbstract The Internet of Things (IoT) protocols are a core element of IoT systems, \nproviding the fundamental support for communication and data exchange between \ndevices. These protocols enable various devices to connect and work together\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.researchsquare.com/article/rs-6331846/latest&hl=en&sa=X&d=7977717061909231178&ei=OKwAaIuDOcmpieoPnPbKsA4&scisig=AFWwaeapZ-qmTHpSU3vKd7fjLdqF&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=3&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "BESA: Extending Bugs Triggered by Runtime Testing via Static Analysis", "first_label": ["Bug", "Software Testing", "Static Analysis"], "second_label": [], "data": "JJ Bai\\xc2\\xa0- Proceedings of the Twentieth European Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDue to limited test cases and execution scenarios, runtime testing often has \ninsufficient code coverage and thus misses many real bugs. To tackle this problem, \nwe propose a novel idea that static analysis of the triggered bug in runtime testing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3689031.3696089&hl=en&sa=X&d=11971501184870035235&ei=OKwAaIuDOcmpieoPnPbKsA4&scisig=AFWwaebDNiyhkoXdOVlEYm5l6Q09&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=4&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Every Sample Matters: Leveraging Mixture-of-Experts and High-Quality Data for Efficient and Accurate Code LLM", "first_label": ["LLM", "Code"], "second_label": [], "data": "L Team, W Cai, Y Cao, C Chen, C Chen, S Chen, Q Cui\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent advancements in code large language models (LLMs) have demonstrated \nremarkable capabilities in code generation and understanding. It is still challenging \nto build a code LLM with comprehensive performance yet ultimate efficiency. Many\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.17793&hl=en&sa=X&d=6822469255660902021&ei=OKwAaIuDOcmpieoPnPbKsA4&scisig=AFWwaeZ8vcQc_PT5mFMW0Uih-mYZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=5&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "A Comprehensive Study of LLM Secure Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "SC Dai, J Xu, G Tao\\xc2\\xa0- arXiv preprint arXiv:2503.15554, 2025\nLLMs are widely used in software development. However, the code generated by \nLLMs often contains vulnerabilities. Several secure code generation methods have \nbeen proposed to address this issue, but their current evaluation schemes leave\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.15554%3F&hl=en&sa=X&d=1363137439941333778&ei=OKwAaIuDOcmpieoPnPbKsA4&scisig=AFWwaea70lzbx-2dnx-SlddbyIDc&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=6&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Automated Harmfulness Testing for Code Large Language Models", "first_label": ["LLM", "Code", "Software Testing"], "second_label": [], "data": "H Tan, H Wang, D Pressato, Y Xu, SH Tan\\xc2\\xa0- arXiv preprint arXiv:2503.16740, 2025\nGenerative AI systems powered by Large Language Models (LLMs) usually use \ncontent moderation to prevent harmful content spread. To evaluate the robustness of \ncontent moderation, several metamorphic testing techniques have been proposed to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.16740&hl=en&sa=X&d=9984898886618882508&ei=OKwAaIuDOcmpieoPnPbKsA4&scisig=AFWwaeY9TKp5hroYtjAXp0K1dUfY&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=7&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "LSPAI: An IDE Plugin for LLM-Powered Multi-Language Unit Test Generation with Language Server Protocol", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "G Go, C Zhou, Q Zhang, Y Jiang, Z Wei - 2025\nUnit testing is crucial for ensuring code validity, and extensive research has been \nconducted to advance this domain. However, existing studies fail to address critical \nindustry requirements, particularly support for multi-language static analysis and real\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://gwihwan-go.github.io/files/papers/fse-industry-LSPAI-v1.pdf&hl=en&sa=X&d=11950018507395283255&ei=OKwAaIuDOcmpieoPnPbKsA4&scisig=AFWwaea7SQm3uWdWdA_CN8rRFfhT&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=9&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
