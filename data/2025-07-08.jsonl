{"title": "Analyzing the dependability of Large Language Models for code clone generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "A Eagal, KT Stolee, JP Ore\\xc2\\xa0- Journal of Systems and Software, 2025\nThe ability to generate multiple equivalent versions of the same code segment \nacross different programming languages and within the same language is valuable \nfor code translation, language migration, and code comprehension in education\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225002171&hl=en&sa=X&d=8172210399981332567&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b8neGEDrN-Ld8JkOzvj3eeF&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "KBL: a golden keywords-based query reformulation approach for bug localization", "first_label": ["Bug"], "second_label": ["Localization"], "data": "B Cai, W Zou, Q Meng, H Xu, J Zhang\\xc2\\xa0- Empirical Software Engineering, 2025\nReformulating initial bug reports to obtain better queries for buggy code retrieval is \nan important research direction in the bug localization area. Existing query \nreformulation strategies of bug reports are generally unsupervised and may lack\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10694-2&hl=en&sa=X&d=8373958395174059718&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b8k5U65jZhLvSn4GsfMGhBx&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Retrieval-Augmented Code Review Comment Generation", "first_label": ["Code Review", "Code"], "second_label": ["Generation"], "data": "H Hong, J Baik\\xc2\\xa0- arXiv preprint arXiv:2506.11591, 2025\nAutomated code review comment generation (RCG) aims to assist developers by \nautomatically producing natural language feedback for code changes. Existing \napproaches are primarily either generation-based, using pretrained language\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11591&hl=en&sa=X&d=15885059784306332833&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b-1WT7RGxAC1bABTNtyDxhD&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "HPCTransCompile: An AI Compiler Generated Dataset for High-Performance CUDA Transpilation and LLM Preliminary Exploration", "first_label": ["LLM"], "second_label": [], "data": "J Lv, X He, Y Liu, X Dai, Y Hu, S Yin\\xc2\\xa0- arXiv preprint arXiv:2506.10401, 2025\nThe rapid growth of deep learning has driven exponential increases in model \nparameters and computational demands. NVIDIA GPUs and their CUDA-based \nsoftware ecosystem provide robust support for parallel computing, significantly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10401&hl=en&sa=X&d=14309937792901999617&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b_LyVd5W0C0U28-mRiJrH9j&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Reductive Analysis with Compiler-Guided Large Language Models for Input-Centric Code Optimizations", "first_label": ["LLM", "Code"], "second_label": [], "data": "X Wang, X Hui, C Liao, X Shen\\xc2\\xa0- Proceedings of the ACM on Programming\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInput-centric program optimization aims to optimize code by considering the relations \nbetween program inputs and program behaviors. Despite its promise, a long-\nstanding barrier for its adoption is the difficulty of automatically identifying critical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729282&hl=en&sa=X&d=4066048552262082451&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b_cHHDNeP008iH4qW9Tn7JR&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A First Look at Bugs in LLM Inference Engines", "first_label": ["LLM", "Bug"], "second_label": [], "data": "M Liu, S Zhong, W Bi, Y Zhang, Z Chen, Z Chen, X Liu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language model-specific inference engines (in short as\\\\emph {LLM inference \nengines}) have become a fundamental component of modern AI infrastructure, \nenabling the deployment of LLM-powered applications (LLM apps) across cloud and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09713&hl=en&sa=X&d=1829118811417287869&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b9PFvonW4DF-GngDik42RDE&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Bach Le - new related research", "Thanh Le-Cong - new related research"]}
{"title": "SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications", "first_label": ["LLM"], "second_label": [], "data": "J Li, X Li, G Qu, P Jacobsson, B Qin, B Hui, S Si, N Huo\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nResolution of complex SQL issues persists as a significant bottleneck in real-world \ndatabase applications. Current Large Language Models (LLMs), while adept at text-\nto-SQL translation, have not been rigorously evaluated on the more challenging task\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18951&hl=en&sa=X&d=15016797413837099283&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b8EvGjCaMjnyqMJC8gRoyX7&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A Framework for Creating Non-Regressive Test Cases via Branch Consistency Analysis Driven by Descriptions", "first_label": ["Software Testing"], "second_label": [], "data": "Y Zhang, P Xue, Z Yang, X Ren, X Li, L Wu, J Zhao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomated test-generation research overwhelmingly assumes the correctness of \nfocal methods, yet practitioners routinely face non-regression scenarios where the \nfocal method may be defective. A baseline evaluation of EvoSuite and two leading\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07486&hl=en&sa=X&d=12300473129148860276&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b8EYaZUm5p8en4HDg1pCFjV&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "On the Effectiveness of LLM-as-a-judge for Code Generation and Summarization", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "G Crupi, R Tufano, A Velasco, A Mastropaolo\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAbstract Large Language Models (LLMs) have been recently exploited as judges for \ncomplex natural language processing tasks, such as Q&A (Question & Answer). The \nbasic idea is to delegate to an LLM the assessment of the \\xe2\\x80\\x9cquality\\xe2\\x80\\x9d of the output\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/journal/ts/5555/01/11071936/2851vlBjr9e&hl=en&sa=X&d=3855054686599960749&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b_3TIYnXdiW1O8VBlraopqf&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "AdaDec: Uncertainty-Guided Adaptive Decoding for LLM-based Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "K He, M Liu, C Wang, Z Li, Y Wang, X Peng, Z Zheng\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode generation with large language models (LLMs) is highly sensitive to token \nselection during decoding, particularly at uncertain decision points that influence \nprogram logic. While standard strategies like greedy and beam search treat all\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/abs/2506.08980&hl=en&sa=X&d=13258586616362940623&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b8MEr3Z8_Z7RsEYbOc3Nj4V&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "ZTaint-Havoc: From Havoc Mode to Zero-Execution Fuzzing-Driven Taint Inference", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Xie, W Zhang, D She\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nFuzzing is a popular software testing technique for discovering vulnerabilities. A \ncentral problem in fuzzing is identifying hot bytes that can influence program \nbehavior. Taint analysis can track the data flow of hot bytes in a white-box fashion\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728916&hl=en&sa=X&d=11807420278266769302&ei=iUxsaO7wJM2l6rQPh4i_0AE&scisig=AAZF9b8qJKOy3h08rQgyQ5y4FnqB&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "FuzzCode: Code Large Language Model-Based Fuzz Testing for Industrial IoT Programs", "first_label": ["LLM", "Fuzzing", "Code", "Software Testing"], "second_label": [], "data": "L Yang, C Wei, J Yang, W Xia, Y Yang, Y Luo, D Niyato\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Internet of Things\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFuzz testing is an dynamic program analysis technique designed for discovering \nvulnerabilities in IoT systems. The core goal is to deliberately feed maliciously crafted \ninputs into an IoT device or service, triggering vulnerabilities such as system crashes\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11028927/&hl=en&sa=X&d=8104462651931100859&ei=iUxsaO7wJM2l6rQPh4i_0AE&scisig=AAZF9b8NEppCb0nwiT9UFTmtv4yr&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Adversarial Attack Classification and Robustness Testing for Large Language Models for Code", "first_label": ["LLM", "Code", "Software Testing"], "second_label": [], "data": "Y Liu, A Foundjem, F Khomh, H Li\\xc2\\xa0- arXiv preprint arXiv:2506.07942, 2025\nLarge Language Models (LLMs) have become vital tools in software development \ntasks such as code generation, completion, and analysis. As their integration into \nworkflows deepens, ensuring robustness against vulnerabilities especially those\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07942&hl=en&sa=X&d=10411796502631711196&ei=iUxsaO7wJM2l6rQPh4i_0AE&scisig=AAZF9b-eMQpfZUdxJwBqS5XD673H&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Reasoning"], "data": "XC Wen, Y Yang, C Gao, Y Xiao, D Ye\\xc2\\xa0- arXiv preprint arXiv:2506.07390, 2025\nLarge language models (LLMs) demonstrate considerable proficiency in numerous \ncoding-related tasks; however, their capabilities in detecting software vulnerabilities \nremain limited. This limitation primarily stems from two factors:(1) the absence of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07390%3F&hl=en&sa=X&d=10299031030894150274&ei=iUxsaO7wJM2l6rQPh4i_0AE&scisig=AAZF9b_gI2XqGy6iUeaE4tdr-c1h&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "AdaptiveLLM: A Framework for Selecting Optimal Cost-Efficient LLM for Code-Generation Based on CoT Length", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Cheng, F Liu, C Wu, L Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.10525, 2025\nWhile Large Language Models (LLMs) have significantly advanced code generation \nefficiency, they face inherent challenges in balancing performance and inference \ncosts across diverse programming tasks. Dynamically selecting the optimal LLM\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10525&hl=en&sa=X&d=12946040656504681529&ei=iUxsaO7wJM2l6rQPh4i_0AE&scisig=AAZF9b8m2TloB0C3Hd11YMxRGFIR&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "Program Generation Methods: Types and Instances", "first_label": [], "second_label": ["Generation"], "data": "D Borodin, A Prutzkow\\xc2\\xa0- International Journal of Open Information Technologies, 2025\nThe study systematizes existing approaches by chronological principle and \ncategories. The strategy of searching for sources consists of using modern library \nplatforms and keywords on the topic of program generation. We classified program\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=http://injoit.org/index.php/j1/article/download/2161/1937&hl=en&sa=X&d=8796434817097384330&ei=iUxsaO7wJM2l6rQPh4i_0AE&scisig=AAZF9b-idOfsqT7sK1pekHEp51Od&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "PyXray: Practical Cross-Language Call Graph Construction through Object Layout Analysis", "first_label": ["Static Analysis"], "second_label": ["Graph"], "data": "G Alexopoulos, T Sotiropoulos, G Gousios, Z Su\\xe2\\x80\\xa6\nA great number of software packages combine code in high-level languages, such \nas Python, with binary extensions compiled from low-level languages such as C, C++ \nor Rust to either boost efficiency or enable specific functionalities. In this context, high\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://grgalex.gr/assets/pdf/pyxray_icse26.pdf&hl=en&sa=X&d=15584438577859100231&ei=iUxsaO7wJM2l6rQPh4i_0AE&scisig=AAZF9b9eMKy4n1itl9D4CR9WopG3&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "FuncVul: An Effective Function Level Vulnerability Detection Model using LLM and Code Chunk", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "S Halder, ME Ahmed, S Camtepe\\xc2\\xa0- arXiv preprint arXiv:2506.19453, 2025\nSoftware supply chain vulnerabilities arise when attackers exploit weaknesses by \ninjecting vulnerable code into widely used packages or libraries within software \nrepositories. While most existing approaches focus on identifying vulnerable\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.19453&hl=en&sa=X&d=2355126994281101941&ei=iUxsaMT3E82l6rQPh4i_0AE&scisig=AAZF9b8nV7dMzuUWlB0QlvHRGoC6&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "To Model, to Prompt, or to Code? The Choice Is Yours: A Multi-Paradigmatic Approach to Software Development", "first_label": ["Code"], "second_label": [], "data": "T Buchmann, F Schw\\xc3\\xa4gerl, R Peinl - 2025\nThis paper considers three fundamental approaches to software development, \nnamely manual coding, modeldriven software engineering, and code generation by \nlarge language models. All of these approaches have their individual pros and cons, \nmotivating the desire for an integrated approach. We present MoProCo, a technical \nsolution to integrate the three approaches into a single tool chain, allowing the \ndeveloper to split a software engineering task into modeling, prompting or coding\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomatic Programming: Large Language Models and Beyond\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.scitepress.org/Papers/2025/135571/135571.pdf&hl=en&sa=X&d=11698545604526486650&ei=iUxsaJyWG7vM6rQP-5ru-QU&scisig=AAZF9b_Yc2npUX2Rjr_kPnbBx0Y0&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Exploring Zero-Shot Prompting for Generating Data Format Descriptions", "first_label": [], "second_label": [], "data": "P Anantharaman, V Varadharaju\\xc2\\xa0- 2025 IEEE Security and Privacy Workshops (SPW), 2025\nParsers validate and process untrusted user input and transform it into data \nstructures that provide easier access. Software engineers either build these parsers \nfor data formats from scratch or leverage libraries targeting specific formats. The \nrecent surge in data description languages (DDLs) and parser combinator libraries \nfor parsing data formats has aided developers in producing parsers using \nstandardized tools. However, producing a parser for an unfamiliar data format in an\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11050832/&hl=en&sa=X&d=2153662549751710342&ei=iUxsaJyWG7vM6rQP-5ru-QU&scisig=AAZF9b_UqdNXSkM6j71YOe3hos5y&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "TransferFuzz-Pro: Large Language Model Driven Code Debugging Technology for Verifying Propagated Vulnerability", "first_label": ["Vulnerabilities", "LLM", "Fuzzing", "Code", "Bug"], "second_label": [], "data": "S Li, K Xie, Y Li, H Li, Y Ren, L Sun, H Zhu\\xc2\\xa0- IEEE Transactions on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode reuse in software development frequently facilitates the spread of \nvulnerabilities, leading to imprecise scopes of affected software in CVE reports. \nTraditional methods focus primarily on detecting reused vulnerability code in target \nsoftware but lack the ability to confirm whether these vulnerabilities can be triggered \nin new software contexts. In previous work, we introduced the TransferFuzz \nframework to address this gap by using historical trace-based fuzzing. However, its\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11066171/&hl=en&sa=X&d=4037450502686363181&ei=iUxsaJyWG7vM6rQP-5ru-QU&scisig=AAZF9b_wsst2tlkLPk6iCbi8LdVm&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "LLM-Driven Code Refactoring: Opportunities and Limitations", "first_label": ["LLM", "Code"], "second_label": [], "data": "J Cordeiro, S Noei, Y Zou\\xc2\\xa0- 2025 IEEE/ACM Second IDE Workshop (IDE), 2025\nRefactoring is a systematic process of improving code quality while preserving the \nfunctional behavior of the software. In recent years, integrated development \nenvironments (IDEs) have added or improved automatic refactoring in their features, \nto enhance developers' productivity and reduce the likelihood of human errors. With \nthe advancement and increasing popularity of large language models (LLMs), \ncoding automation using them has gained enormous attention and has shown to be\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAngelix: Scalable multiline program patch synthesis via symbolic\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/ide/2025/018800a032/27ZLzLyi5ZS&hl=en&sa=X&d=12236558554458443249&ei=iUxsaJyWG7vM6rQP-5ru-QU&scisig=AAZF9b9cjO-riikBduPhXcgXPwAV&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Designing With AI: A Study of Non-Developer Software Creation Using ChatGPT", "first_label": ["LLM"], "second_label": [], "data": "MK Taspunar - 2025\nThis thesis investigates the potential of enabling non-developers to create functional \nsoftware applications comparable to those built by experienced developers through \nthe use of AI-assisted coding tools, specifically focusing on ChatGPT. The study \nexplores whether AI-powered code generation can effectively bridge the gap \nbetween users with no programming background and professional developers, thus \ndemocratizing software development. A mixed-methods approach was employed\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.diva-portal.org/smash/get/diva2:1975899/FULLTEXT01.pdf&hl=en&sa=X&d=4213015147011324533&ei=iUxsaJKmGK6l6rQP7MCumQ8&scisig=AAZF9b9mpknJwkOIq3p9_XsB_zJi&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le", "1 new citation to articles by Thanh Le-Cong"]}
{"title": "BCAAS: A Blockchain-Based Certificateless Anonymous Aggregate Signcryption Scheme Using Edge Computing", "first_label": ["Blockchain"], "second_label": [], "data": "X Chen, Q Cheng, X Luo\\xc2\\xa0- IEEE Transactions on Vehicular Technology, 2025\nWith the advancement of intelligent transportation systems, advanced traffic \ninformation service systems have emerged as critical infrastructure that integrates \nmulti-source data to offer real-time traffic condition services. Current systems mainly \nrely on cloud computing for centralized data storage and flexible resource \nscheduling. However, this architecture is vulnerable to service disruptions from \nsingle-point failures. The centrally stored sensitive data raises privacy breach risks\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11063329/&hl=en&sa=X&d=16402366462725922424&ei=iUxsaJKmGK6l6rQP7MCumQ8&scisig=AAZF9b8FAtu9SKVYMZdHs_HmfpGf&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "Time and Cost Savings Associated With the Use of Smart Contracts on the Swedish Real Estate Market", "first_label": ["Smart Contracts"], "second_label": [], "data": "H G\\xc3\\xb6ranson - 2025\nThe Swedish real estate sector, while efficient compared to global standards, \nremains characterized by manual, paper-heavy processes that introduce \nadministrative delays and transaction costs. This thesis explores the potential of \nsmart contracts, self-executing agreements based on blockchain technology, to \nreduce time and cost inefficiencies in residential property transactions on the \nSwedish real estate market. Using a mixed-methods approach that includes semi\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.diva-portal.org/smash/get/diva2:1979253/FULLTEXT01.pdf&hl=en&sa=X&d=14630972224412669177&ei=iUxsaJKmGK6l6rQP7MCumQ8&scisig=AAZF9b-oJ-TzPHlrHAL8BupcVNMP&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "Learning never stops: Improving software vulnerability type identification via incremental learning", "first_label": ["Vulnerabilities"], "second_label": [], "data": "J Xue, X Chen, Z Cui, Y Liu\\xc2\\xa0- Journal of Systems and Software, 2025\nAs new vulnerabilities are continuously discovered, software vulnerability type \nidentification (SVTI) data is dynamic. Moreover, SVTI data often exhibits a long-tailed \ndistribution, where some vulnerability types (ie, head classes) have numerous\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225002134&hl=en&sa=X&d=8336644414088433817&ei=iUxsaKS9HLWP6rQP2NG60As&scisig=AAZF9b_2IKzcE3nveqhF8ZQiR11H&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "1 new citation to articles by Xin ZHOU"]}
{"title": "From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Y Mao, T Cui, P Liu, D You, H Zhu\\xc2\\xa0- arXiv preprint arXiv:2506.15170, 2025\nLarge language models (LLMs) are rapidly evolving from single-modal systems to \nmultimodal LLMs and intelligent agents, significantly expanding their capabilities \nwhile introducing increasingly severe security risks. This paper presents a systematic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15170&hl=en&sa=X&d=16427093263132639213&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b-zqUEdPZ8IyWJxfUDycl5Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Emoji attack: Enhancing jailbreak attacks against judge llm detection", "first_label": ["LLM"], "second_label": ["Detection"], "data": "Z Wei, Y Liu, NB Erichson\\xc2\\xa0- Forty-second International Conference on Machine\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreaking techniques trick Large Language Models (LLMs) into producing \nrestricted output, posing a potential threat. One line of defense is to use another LLM \nas a Judge to evaluate the harmfulness of generated text. However, we reveal that\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DQ0rKYiVEZq&hl=en&sa=X&d=17491126507172914063&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b_yTB1R20z-t6ApkecZnFST&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems", "first_label": ["LLM"], "second_label": ["Agent", "Search"], "data": "X Li, J Chen, X Fang, S Ding, H Duan, Q Liu, K Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown remarkable capabilities in solving \ndiverse tasks. However, their proficiency in iteratively optimizing complex solutions \nthrough learning from previous feedback remains insufficiently explored. To bridge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10764&hl=en&sa=X&d=1134890120116902745&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b8s_mGNSGwzfKFs6o2hgsbd&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "L Jiang, Z Zhang, Z Wang, X Sun, Z Li, L Zhen, X Xu\\xc2\\xa0- arXiv preprint arXiv:2506.16760, 2025\nLarge Vision-Language Models (LVLMs) demonstrate exceptional performance \nacross multimodal tasks, yet remain vulnerable to jailbreak attacks that bypass built-\nin safety mechanisms to elicit restricted content generation. Existing black-box\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16760&hl=en&sa=X&d=12136733750645262486&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b8NosIP6RI9jYFVbBgmH01C&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring", "first_label": ["LLM"], "second_label": [], "data": "Y Li, Q Sheng, Y Yang, X Zhang, J Cao\\xc2\\xa0- arXiv preprint arXiv:2506.09996, 2025\nThough safety alignment has been applied to most large language models (LLMs), \nLLM service providers generally deploy a subsequent moderation as the external \nsafety guardrail in real-world products. Existing moderators mainly practice a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09996&hl=en&sa=X&d=8967671192696781749&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b-I099JquXawda445fWweEs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM Jailbreak Oracle", "first_label": ["LLM"], "second_label": [], "data": "S Lin, A Suri, A Oprea, C Tan\\xc2\\xa0- arXiv preprint arXiv:2506.17299, 2025\nAs large language models (LLMs) become increasingly deployed in safety-critical \napplications, the lack of systematic methods to assess their vulnerability to jailbreak \nattacks presents a critical security gap. We introduce the jailbreak oracle problem\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17299&hl=en&sa=X&d=13276394224623482198&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b9_2v0eFVwHwueuxrSl-vyP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Use Property-Based Testing to Bridge LLM Code Generation and Validation", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation"], "data": "L He, Z Chen, Z Zhang, J Shao, X Gao, L Sheng\\xc2\\xa0- arXiv preprint arXiv:2506.18315, 2025\nLarge Language Models (LLMs) excel at code generation, but ensuring their outputs \nto be functionally correct, especially in complex programming tasks, is a persistent \nchallenge. While traditional Test-Driven Development (TDD) offers a path for code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18315&hl=en&sa=X&d=3101719763251668573&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b8VwRdS0BYT5dVQlhiDylYe&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning", "first_label": ["LLM"], "second_label": [], "data": "GJ Perin, R Chen, X Chen, NST Hirata, Z Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have become indispensable in real-world \napplications. However, their widespread adoption raises significant safety concerns, \nparticularly in responding to socially harmful questions. Despite substantial efforts to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15606&hl=en&sa=X&d=5494164285246185827&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b83jkzg6GWJfE0yBor7b9qA&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Context manipulation attacks: Web agents are susceptible to corrupted memory", "first_label": [], "second_label": ["Agent"], "data": "AS Patlan, A Hebbar, P Viswanath, P Mittal\\xc2\\xa0- arXiv preprint arXiv:2506.17318, 2025\nAutonomous web navigation agents, which translate natural language instructions \ninto sequences of browser actions, are increasingly deployed for complex tasks \nacross e-commerce, information retrieval, and content discovery. Due to the stateless\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17318&hl=en&sa=X&d=5832395619822196251&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b9s0vj_fsKQ_zB6ujfs5QJc&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "When Style Breaks Safety: Defending Language Models Against Superficial Style Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Xiao, S Tonekaboni, W Gerych, V Suriyakumar\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) can be prompted with specific styles (eg, formatting \nresponses as lists), including in jailbreak queries. Although these style patterns are \nsemantically unrelated to the malicious intents behind jailbreak queries, their safety\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07452&hl=en&sa=X&d=14291869118481763294&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b-0bTujJ8d_dpW8Eytxq3G4&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Leveraging activation and optimisation layers as dynamic strategies in the multi-task fuzzing scheme", "first_label": ["Fuzzing"], "second_label": [], "data": "S Bamohabbat Chafjiri, P Legg, MA Tsompanas\\xe2\\x80\\xa6 - 2025\nFuzzing is a common technique for identifying vulnerabilities in software. Recent \napproaches, like She et al.'s Multi-Task Fuzzing (MTFuzz), use neural networks to \nimprove fuzzing efficiency. However, key elements like network architecture and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1016/j.csi.2025.104011&hl=en&sa=X&d=18210490462320417689&ei=iUxsaPn6Hde5ieoPgIGkkA0&scisig=AAZF9b-SniAFgKPoPY_eeSgA0SFX&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Reassessing Code Authorship Attribution in the Era of Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "AK Dipongkor, Z Yao, K Moran\\xc2\\xa0- arXiv preprint arXiv:2506.17120, 2025\nThe study of Code Stylometry, and in particular Code Authorship Attribution (CAA), \naims to analyze coding styles to identify the authors of code samples. CAA is crucial \nin cybersecurity and software forensics for addressing, detecting plagiarism, and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17120&hl=en&sa=X&d=12069506939304281396&ei=iUxsaLTNFpPN6rQPhMr3yAg&scisig=AAZF9b9OxubQtYi2lTNPr1YQmcjb&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Bach Le - new related research"]}
{"title": "ConTested: Consistency-Aided Tested Code Generation with LLM", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation"], "data": "J Dong, J Sun, W Zhang, JS Dong, D Hao\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent advancements in large language models (LLMs) have significantly improved \ncode generation, which generates code snippets automatically based on natural \nlanguage requirements. Despite achieving state-of-the-art performance, LLMs often\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728902&hl=en&sa=X&d=551936643568606765&ei=iUxsaLTNFpPN6rQPhMr3yAg&scisig=AAZF9b_BffNT3Tq28AAfyZzriimH&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "TypyBench: Evaluating LLM Type Inference for Untyped Python Repositories", "first_label": ["LLM"], "second_label": [], "data": "H Dong, J Yang, X Deng, Y Jiang, G Pekhimenko\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nType inference for dynamic languages like Python is a persistent challenge in \nsoftware engineering. While large language models (LLMs) have shown promise in \ncode understanding, their type inference capabilities remain underexplored. We\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dxl9sv9vEDy&hl=en&sa=X&d=5590401666570182726&ei=iUxsaLTNFpPN6rQPhMr3yAg&scisig=AAZF9b_1v2ZiYt35IkKDr0FkrnZ_&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Nemotron-CORTEXA: Enhancing LLM Agents for Software Engineering Tasks via Improved Localization and Solution Diversity", "first_label": ["LLM"], "second_label": ["Agent", "Localization"], "data": "A Sohrabizadeh, J Song, M Liu, R Roy, C Lee\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nLarge Language Models (LLMs) have demonstrated significant potential in code \ngeneration by following natural language instructions. Unfortunately, crucial real-\nworld software engineering tasks, such as debugging or repository-level feature\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dk6p8UKRdH7&hl=en&sa=X&d=951048739864022913&ei=iUxsaLTNFpPN6rQPhMr3yAg&scisig=AAZF9b-H11fzuFCoL6Gk97_KnR7i&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Precisely Detecting Python Type Errors via LLM-based Unit Test Generation", "first_label": ["LLM", "Software Testing"], "second_label": ["Detection", "Generation"], "data": "C Yang, Z Wang, Y Jiang, L Yang, Y Zheng, J Zhou\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nType errors in Python often lead to runtime failures, posing significant challenges to \nsoftware reliability and developer productivity. Existing static analysis tools aim to \ndetect such errors without execution but frequently suffer from high false positive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2507.02318&hl=en&sa=X&d=10550404789210041321&ei=iUxsaLTNFpPN6rQPhMr3yAg&scisig=AAZF9b_WrA-mJ_gHGIH5oUCaTKbi&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "4 new citations to articles by Hong Jin Kang"]}
{"title": "Mapping NVD Records to Their VFCs: How Hard is it?", "first_label": [], "second_label": [], "data": "HH Nguyen, DM Tran, Y Cheng, T Le-Cong, HJ Kang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMapping National Vulnerability Database (NVD) records to vulnerability-fixing \ncommits (VFCs) is crucial for vulnerability analysis but challenging due to sparse \nexplicit links in NVD references. This study explores this mapping's feasibility through\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09702&hl=en&sa=X&d=17350753801902205444&ei=iUxsaLywI8zM6rQP_8mNwQs&scisig=AAZF9b9GdE1B-xLLhUOLme72JT4D&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Today's Cat Is Tomorrow's Dog: Accounting for Time-Based Changes in the Labels of ML Vulnerability Detection Approaches", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "R Paramitha, Y Feng, F Massacci\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nVulnerability datasets used for ML testing implicitly contain retrospective information. \nWhen tested on the field, one can only use the labels available at the time of training \nand testing (eg seen and assumed negatives). As vulnerabilities are discovered\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715731&hl=en&sa=X&d=7396654833478791244&ei=iUxsaLywI8zM6rQP_8mNwQs&scisig=AAZF9b8Le9KZc3LupQcs5YssN_DQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "VulStamp: Vulnerability Assessment using Large Language Model", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "M Hu, X Xie, J Li, M Chen\\xc2\\xa0- arXiv preprint arXiv:2506.11484, 2025\nAlthough modern vulnerability detection tools enable developers to efficiently identify \nnumerous security flaws, indiscriminate remediation efforts often lead to superfluous \ndevelopment expenses. This is particularly true given that a substantial portion of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11484&hl=en&sa=X&d=10210371631874132603&ei=iUxsaLywI8zM6rQP_8mNwQs&scisig=AAZF9b8D5-GPG5LVOP0Ejn5MaoBB&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "PREFACE-A Reinforcement Learning Framework for Code Verification via LLM Prompt Repair", "first_label": ["Verification", "LLM", "Code"], "second_label": ["Repair"], "data": "M Jha, J Wan, H Zhang, D Chen\\xc2\\xa0- Proceedings of the Great Lakes Symposium on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have emerged as powerful tools for code \ngeneration. Yet, they often struggle to produce code that is both syntactically and \nsemantically correct, particularly when correctness must be formally verified\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3716368.3735300&hl=en&sa=X&d=13382965706076482844&ei=iUxsaLywI8zM6rQP_8mNwQs&scisig=AAZF9b-4t4cRZQ4ZX29y9rKLFJ1R&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "AST2CVCode: A New Benchmark Dataset for Source Code Generation on Computer Vision Applications", "first_label": ["Code"], "second_label": ["Generation"], "data": "WS Alshehri, SK Jarraya, AA Allinjawi\\xc2\\xa0- International Conference on Advanced\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBenchmark datasets are important in evaluating various methods for source code \ngeneration tasks. In this paper, we present AST2CVCode, a new benchmark dataset \nto enhance deep learning models for source code generation. AST2CVCode is\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-91337-2_46&hl=en&sa=X&d=15545214955806460595&ei=iUxsaLywI8zM6rQP_8mNwQs&scisig=AAZF9b-xEY_Bo700rs_NZO5gdshG&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=8&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "On Predicting Vulnerability Severity Using In-Context Learning: An Industrial Case Study", "first_label": ["Vulnerabilities"], "second_label": [], "data": "D Rodriguez-Cardenas, DN Palacio, A Schmedding\\xe2\\x80\\xa6 - 2025\nModern software systems demand earlier vulnerability severity detection to protect \nsystems from critical issues such as data leaking or attacker access. Security \nanalysts are in charge of triaging the vulnerability severity by computing a score\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.authorea.com/doi/pdf/10.22541/au.175033470.05916058&hl=en&sa=X&d=13350311129524430544&ei=iUxsaLywI8zM6rQP_8mNwQs&scisig=AAZF9b9J_sXjT3UaQPWnFl14GrrB&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=9&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Artificial intelligence security and privacy: a survey", "first_label": [], "second_label": [], "data": "X He, G Xu, X Han, Q Wang, L Zhao, C Shen, C Lin\\xe2\\x80\\xa6\\xc2\\xa0- Science China Information\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nArtificial intelligence (AI) is revolutionizing both industries and reshaping the global \neconomy. However, the rapid advancement of AI technologies brings significant \nsecurity and privacy challenges. Recent incidents highlight vulnerabilities in AI \nsystems, such as data leakage and malicious code injection, leading to severe \nfinancial losses and privacy breaches. Although existing studies have discussed \nspecific security threats, they often lack detailed granularity and cover a limited\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11432-025-4388-5&hl=en&sa=X&d=4615437522668012197&ei=iUxsaIa0FdSWieoP7_C3mAw&scisig=AAZF9b9vHhHMA0n1vnCfMlLnzwX_&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "What LLM Knows About Cybersecurity", "first_label": ["LLM"], "second_label": [], "data": "D Namiot\\xc2\\xa0- International Journal of Open Information Technologies, 2025\nThe article is devoted to testing large language models (LLM). Cybersecurity \nknowledge is chosen as the subject of testing. The work provides an overview of test \ndatasets (benchmarks) that can be used to test LLM knowledge in the field of \ncybersecurity. Technically, these are tens of thousands of questions covering a wide \nvariety of areas: monitoring computer networks and planning their topology, \nconducting network analysis, creating reports and quickly finding and eliminating\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=http://www.injoit.ru/index.php/j1/article/viewFile/2214/1931&hl=en&sa=X&d=6406596895346885781&ei=iUxsaIa0FdSWieoP7_C3mAw&scisig=AAZF9b9l6Lo6UXsheQzG6rBuJ0Yb&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Vulnerability-Triggering Test Case Generation from Third-Party Libraries", "first_label": ["Vulnerabilities", "Software Testing"], "second_label": ["Generation"], "data": "Y Gao, X Hu, Z Chen, T Xu, X Yang\\xc2\\xa0- \\xe2\\x80\\xa6\\xc2\\xa0IEEE/ACM Second International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nOpen-source third-party libraries are widely used in software development. These \nlibraries offer substantial advantages in terms of time and resource savings. \nHowever, a significant concern arises due to the publicly disclosed vulnerabilities \nwithin these libraries. Existing automated vulnerability detection tools often suffer \nfrom false positives and fail to accurately assess the propagation of inputs capable of \ntriggering vulnerabilities from client projects to vulnerable code in libraries. In this\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaChronos: Time-aware zero-shot identification of libraries from\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11052811/&hl=en&sa=X&d=16271702545102533147&ei=mOlqaPC9DrvM6rQP-5ru-QU&scisig=AAZF9b_XCrL7raXC8SlNxY_p1LEC&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["4 new citations to articles by Hong Jin Kang", "2 new citations to articles by Thanh Le-Cong", "1 new citation to articles by Bach Le"]}
{"title": "Meta-Fair: AI-Assisted Fairness Testing of Large Language Models", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "M Romero-Arjona, JA Parejo, JC Alonso, AB S\\xc3\\xa1nchez\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFairness--the absence of unjustified bias--is a core principle in the development of \nArtificial Intelligence (AI) systems, yet it remains difficult to assess and enforce. \nCurrent approaches to fairness testing in large language models (LLMs) often rely on \nmanual evaluation, fixed templates, deterministic heuristics, and curated datasets, \nmaking them resource-intensive and difficult to scale. This work aims to lay the \ngroundwork for a novel, automated method for testing fairness in LLMs, reducing the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBiasfinder: Metamorphic test generation to uncover bias for\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2507.02533&hl=en&sa=X&d=6485868157592794721&ei=mOlqaPC9DrvM6rQP-5ru-QU&scisig=AAZF9b89Cf68ISHWPfb-FcZ3CFU-&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["4 new citations to articles by Hong Jin Kang", "David Lo - new related research"]}
{"title": "Testing Android Third Party Libraries with LLMs to Detect Incompatible APIs", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "T Mahmud, B Duan, M Che, A Ngu, G Yang\\xc2\\xa0- \\xe2\\x80\\xa6\\xc2\\xa0on AI Foundation Models and Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThird-party libraries (TPLs) are an integral part of Android app development, offering \napp developers essential tools for enhancing app functionality, design, and \nintegration capabilities. However, the fast-paced evolution of Android APIs \nintroduces compatibility issues not only in Android apps but also in TPLs as they rely \nheavily on these Android APIs too. These challenges necessitate continuous \nupdates and compatibility checks to maintain apps as well as TPL's compatibility\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAndroevolve: Automated update for android deprecated-api usages\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11052795/&hl=en&sa=X&d=1835022594226939509&ei=mOlqaPC9DrvM6rQP-5ru-QU&scisig=AAZF9b9sUjJleOzemQebOH0GKcHV&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["4 new citations to articles by Hong Jin Kang"]}
{"title": "deepSURF: Detecting Memory Safety Vulnerabilities in Rust Through Fuzzing LLM-Augmented Harnesses", "first_label": ["Vulnerabilities", "LLM", "Fuzzing"], "second_label": ["Detection"], "data": "G Androutsopoulos, A Bianchi\\xc2\\xa0- arXiv preprint arXiv:2506.15648, 2025\nAlthough Rust ensures memory safety by default, it also permits the use of unsafe \ncode, which can introduce memory safety vulnerabilities if misused. Unfortunately, \nexisting tools for detecting memory bugs in Rust typically exhibit limited detection\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15648&hl=en&sa=X&d=5470473754710042022&ei=mOlqaKf3E9e5ieoPgIGkkA0&scisig=AAZF9b-QLCAPbmOGA94zxamaJ1DB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Directed Testing in MLIR: Unleashing Its Potential by Overcoming the Limitations of Random Fuzzing", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "W Tong, Z Wang, Z Tang, J Fang, Y Zhang, G Ye\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMLIR is a new way of creating compiler infrastructures that can be easily reused and \nextended. Current MLIR fuzzing methods focus primarily on test case generation or \nmutation using randomly selected passes. However, they often overlook the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729372&hl=en&sa=X&d=10225165863736020095&ei=mOlqaKf3E9e5ieoPgIGkkA0&scisig=AAZF9b9XDaU-7-dG1ms-uNWhw7no&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "David Lo - new related research"]}
{"title": "Malo in the Code Jungle: Explainable Fault Localization for Decentralized Applications", "first_label": ["Fault Localization", "Code"], "second_label": ["Localization"], "data": "H Zhang, J Wu, Z Wu, Z Chen, D Lin, J Chen, Y Zhou\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDecentralized applications (DApps) have long been sitting ducks for hackers due to \ntheir valuable cryptocurrency assets, exposing them to various security risks. When a \nDApp is attacked, promptly identifying faults is crucial to minimizing financial losses\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11034691/&hl=en&sa=X&d=7651709202352945146&ei=mOlqaKf3E9e5ieoPgIGkkA0&scisig=AAZF9b8cw1Hmz_K4wN9ajW1PUmQk&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "HornBro: Homotopy-Like Method for Automated Quantum Program Repair", "first_label": ["APR"], "second_label": ["Repair"], "data": "S Tan, L Lu, D Xiang, T Chu, C Lang, J Chen, X Hu\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nQuantum programs provide exponential speedups compared to classical programs \nin certain areas, but they also inevitably encounter logical faults. Automatically \nrepairing quantum programs is much more challenging than repairing classical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715751&hl=en&sa=X&d=13228585835236654799&ei=mOlqaJfpCK6l6rQP7MCumQ8&scisig=AAZF9b-8_CqaMqv576h_a4v0IZHT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "An Adaptive Language-Agnostic Pruning Method for Greener Language Models for Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "M Saad, JAH L\\xc3\\xb3pez, B Chen, D Varr\\xc3\\xb3, T Sharma\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models of code have demonstrated remarkable performance across \nvarious software engineering and source code analysis tasks. However, their \ndemanding computational resource requirements and consequential environmental\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715773&hl=en&sa=X&d=7944316343425442468&ei=mOlqaJfpCK6l6rQP7MCumQ8&scisig=AAZF9b_df9m6q87B5fG6FvHqqLve&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "UCP: a unified framework for code generation with pseudocode-based multi-task learning and reinforcement alignment: Y. Wen et al.", "first_label": ["Code"], "second_label": ["Generation"], "data": "Y Wen, Z Cui, Y Liu, Z Zhang, J Zhou, L Tang\\xc2\\xa0- The Journal of Supercomputing, 2025\nPre-trained large language models (LLMs) have been widely applied to natural \nlanguage-based code generation. However, because code generation tasks are \nhighly sensitive to structured information and exhibit diverse logical forms, directly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11227-025-07487-1&hl=en&sa=X&d=1292157430609543902&ei=mOlqaJfpCK6l6rQP7MCumQ8&scisig=AAZF9b8HnhQLRB1NFzaWU0iyGBfI&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=3&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Li, J Ding, C Peng, B Zhao, X Gao, H Gao, X Gu\\xc2\\xa0- arXiv preprint arXiv:2506.05692, 2025\nThe code generation capabilities of large language models (LLMs) have emerged as \na critical dimension in evaluating their overall performance. However, prior research \nhas largely overlooked the security risks inherent in the generated code. In this work\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05692%3F&hl=en&sa=X&d=5492650506064335063&ei=mOlqaJfpCK6l6rQP7MCumQ8&scisig=AAZF9b_uwkPsOhWMHWjfdGwYFezG&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=4&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "The Foundation Cracks: A Comprehensive Study on Bugs and Testing Practices in LLM Libraries", "first_label": ["LLM", "Bug", "Software Testing"], "second_label": [], "data": "W Jiang, X Zhang, X Xie, J Yu, Y Zhi, S Ma, C Shen\\xc2\\xa0- arXiv preprint arXiv:2506.12320, 2025\nLarge Language Model (LLM) libraries have emerged as the foundational \ninfrastructure powering today's AI revolution, serving as the backbone for LLM \ndeployment, inference optimization, fine-tuning, and production serving across\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12320&hl=en&sa=X&d=16202500750200898582&ei=mOlqaJfpCK6l6rQP7MCumQ8&scisig=AAZF9b--UIAtYzwloYca2LhAL11r&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=5&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Thanh Le-Cong - new related research"]}
{"title": "SemAgent: A Semantics Aware Program Repair Agent", "first_label": ["APR"], "second_label": ["Repair", "Agent"], "data": "A Pabba, A Mathai, A Chakraborty, B Ray\\xc2\\xa0- arXiv preprint arXiv:2506.16650, 2025\nLarge Language Models (LLMs) have shown impressive capabilities in downstream \nsoftware engineering tasks such as Automated Program Repair (APR). In particular, \nthere has been a lot of research on repository-level issue-resolution benchmarks\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16650&hl=en&sa=X&d=9444763424952485232&ei=mOlqaLLjC4OuieoPwo7EuAE&scisig=AAZF9b8bAFz9tFwM1PpRte-a75b9&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Optimization of Bayesian Neural Networks using hybrid PSO and fuzzy logic approach for time series forecasting", "first_label": ["Fuzzing"], "second_label": [], "data": "F Sobhanifard\\xc2\\xa0- Discover Artificial Intelligence, 2025\nBayesian network is a form of graphical model for identification and calculation \nbased on a group of influential variables, related to a probability distribution to deal \nwith the complexity of the model. Providing flexible frameworks for the Neural \nNetwork training algorithm is one of the topics that has focused on many issues of the \nreal world. On the other hand, Particle Swarm Optimization is a computational \napproach, an intelligent optimization, and the most popular algorithm that has been\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaA multifactorial optimization paradigm for linkage tree genetic\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44163-025-00322-9&hl=en&sa=X&d=3655405521694506770&ei=mOlqaK-SB_uvieoPzc2EkQE&scisig=AAZF9b8Vx4XefrdLhyh7c-BXmUrq&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 new citations to articles by Thanh Le-Cong"]}
{"title": "Not One to Rule Them All: Mining Meaningful Code Review Orders From GitHub", "first_label": ["Code Review", "Code"], "second_label": [], "data": "A Bouraffa, C Brandt, A Zaidmann, W Maalej\\xc2\\xa0- arXiv preprint arXiv:2506.10654, 2025\nDevelopers use tools such as GitHub pull requests to review code, discuss proposed \nchanges, and request modifications. While changed files are commonly presented in \nalphabetical order, this does not necessarily coincide with the reviewer's preferred\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10654&hl=en&sa=X&d=3992668249292818405&ei=mOlqaLG0GvuvieoPzc2EkQE&scisig=AAZF9b9_WwY7lVF-4S1NfuqiNPEi&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Improving Compiler Bug Isolation by Leveraging Large Language Models", "first_label": ["LLM", "Bug"], "second_label": [], "data": "Y Qi, J Jiang, F Li, B Chen, H Zhang, J Chen\\xc2\\xa0- arXiv preprint arXiv:2506.17647, 2025\nCompilers play a foundational role in building reliable software systems, and bugs \nwithin them can lead to catastrophic consequences. The compilation process \ntypically involves hundreds of files, making traditional automated bug isolation\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17647&hl=en&sa=X&d=15966502884654963985&ei=mOlqaLG0GvuvieoPzc2EkQE&scisig=AAZF9b8HVK2FSOPtCH0zqcVktTCo&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "ClassEval-T: Evaluating Large Language Models in Class-Level Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "P Xue, L Wu, Z Yang, C Wang, X Li, Y Zhang, J Li, R Jin\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, Large Language Models (LLMs) have dramatically advanced the \nperformance of automated code translation, making their computational accuracy \nscore reach up to over 80% on many previous benchmarks. However, most code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728940&hl=en&sa=X&d=992730946725353213&ei=mOlqaLG0GvuvieoPzc2EkQE&scisig=AAZF9b81lPsuDwbRQxK8NE-6-iQ6&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "SyzSpec: Specification Generation for Linux Kernel Fuzzing via Under-Constrained Symbolic Execution", "first_label": ["Fuzzing"], "second_label": ["Generation"], "data": "Y Hao, J Pu, X Li, Z Qian, AA Sani - 2025\nFuzzing has become one of the most effective and widely used techniques for \nidentifying bugs and vulnerabilities in software, particularly due to its practicality and \nsuccess in real-world applications. For example, in the domain of large-scale and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.cs.ucr.edu/~zhiyunq/pub/ccs25_syzspec.pdf&hl=en&sa=X&d=10333609124370710558&ei=mOlqaLG0GvuvieoPzc2EkQE&scisig=AAZF9b9o_LPMWtlFoeqJjbrHs0K7&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "EXPEREPAIR: Dual-Memory Enhanced LLM-based Repository-Level Program Repair", "first_label": ["APR", "LLM", "Repository-Level"], "second_label": ["Repair"], "data": "F Mu, J Wang, L Shi, S Wang, S Li, Q Wang\\xc2\\xa0- arXiv preprint arXiv:2506.10484, 2025\nAutomatically repairing software issues remains a fundamental challenge at the \nintersection of software engineering and AI. Although recent advancements in Large \nLanguage Models (LLMs) have demonstrated potential for repository-level repair\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10484&hl=en&sa=X&d=8896195699042165095&ei=mOlqaLG0GvuvieoPzc2EkQE&scisig=AAZF9b-QM99LNcUecB-Nh5bI2Tl5&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Establishing Best Practices for Building Rigorous Agentic Benchmarks", "first_label": [], "second_label": ["Agent"], "data": "Y Zhu, T Jin, Y Pruksachatkun, A Zhang, S Liu, S Cui\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBenchmarks are essential for quantitatively tracking progress in AI. As AI agents \nbecome increasingly capable, researchers and practitioners have introduced agentic \nbenchmarks to evaluate agents on complex, real-world tasks. These benchmarks \ntypically measure agent capabilities by evaluating task outcomes via specific reward \ndesigns. However, we show that many agentic benchmarks have issues task setup \nor reward design. For example, SWE-bench Verified uses insufficient test cases\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2507.02825&hl=en&sa=X&d=4596808475042611624&ei=mOlqaKCeCvfWieoPlcTkiAc&scisig=AAZF9b_ibZQMgAHS4oXc8HQsCc4B&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang"]}
{"title": "LLM-Guided Scenario-based GUI Testing", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "S Yu, Y Ling, C Fang, Q Zhou, C Chen, S Zhu, Z Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe assurance of mobile app GUI is more and more significant. Automated GUI \ntesting approaches of different strategies have been developed, while there are still \nhuge gaps between the approaches and the app business logic, not taking the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05079&hl=en&sa=X&d=10587655884573272012&ei=mOlqaIigEbWP6rQP2NG60As&scisig=AAZF9b_9oZAteogzTFVCpm4ZVNB0&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Understanding practitioners' reasoning and requirements for efficient tool support in technical debt management", "first_label": [], "second_label": ["Reasoning"], "data": "JP Biazotto, D Feitosa, P Avgeriou, EY Nakagawa\\xc2\\xa0- Empirical Software Engineering, 2025\nContext Maintaining software projects over the long term requires controlling the \naccumulation of technical debt (TD). However, the time and cost associated with \ntechnical debt management (TDM) are often high, hindering practitioners from\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10691-5&hl=en&sa=X&d=2717520013810446763&ei=mOlqaIigEbWP6rQP2NG60As&scisig=AAZF9b_gULF4VmvHkIukA2H5YMiS&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Metric-based defect prediction from class diagram", "first_label": ["Software Defect"], "second_label": [], "data": "B Battulga, L Tsoodol, E Dovdon, N Bold, OE Namsrai\\xc2\\xa0- Array, 2025\nA software defect refers to a fault, failure, or error in software. With the rapid \ndevelopment and increasing reliance on software products, it is essential to identify \nthese defects as early and easily as possible, given the efforts and budget invested\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S2590005625000657&hl=en&sa=X&d=261383994743102888&ei=mOlqaIigEbWP6rQP2NG60As&scisig=AAZF9b--GCZ1PyzLR4zvswO7UZgj&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Towards Trustworthy Sentiment Analysis in Software Engineering: Dataset Characteristics and Tool Selection", "first_label": [], "second_label": [], "data": "M Obaidi, M Herrmann, J Kl\\xc3\\xbcnder, K Schneider\\xc2\\xa0- arXiv preprint arXiv:2507.02137, 2025\nSoftware development relies heavily on text-based communication, making \nsentiment analysis a valuable tool for understanding team dynamics and supporting \ntrustworthy AI-driven analytics in requirements engineering. However, existing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2507.02137&hl=en&sa=X&d=16609657528017131642&ei=mOlqaIigEbWP6rQP2NG60As&scisig=AAZF9b9rZGT3Pa_pjzZi4yFKohDg&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "An LLM-assisted approach to designing software architectures using ADD", "first_label": ["LLM"], "second_label": [], "data": "H Cervantes, R Kazman, Y Cai\\xc2\\xa0- arXiv preprint arXiv:2506.22688, 2025\nDesigning effective software architectures is a complex, iterative process that \ntraditionally relies on expert judgment. This paper proposes an approach for Large \nLanguage Model (LLM)-assisted software architecture design using the Attribute\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.22688&hl=en&sa=X&d=1118086390082491302&ei=mOlqaIigEbWP6rQP2NG60As&scisig=AAZF9b_YEZ2BZ_OIJzFpd_p-bR8v&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "LibAFLstar: Fast and State-Aware Protocol Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "M Maugeri\nFuzzing is arguably one of the most effective software vulnerability discovery \ntechniques. However, despite recent advances, fuzzing stateful software suffers from \nsevere inefficiencies and scalability limitations. This hinders automated testing for \nsoftware that relies on state models, such as protocol implementations. Unlike \nstateless approaches, efficient stateful fuzzers need to i) explore the state model of \nthe target system, ii) focus on the most interesting states, iii) track which messages\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=http://www.cs.ru.nl/E.Poll/publications/LibAFLstar.pdf&hl=en&sa=X&d=3054526607721912088&ei=mOlqaP7SEtSWieoP7_C3mAw&scisig=AAZF9b-lsaRs1Wx-qvblFiN3SFK6&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Automated Codebase Reconciliation using Large Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "A Gandhi, S De, M Chechik, V Pandit, M Kiehn\\xe2\\x80\\xa6\\xc2\\xa0- 2025 IEEE/ACM Second\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge-scale software projects frequently encounter the challenge of manually \npropagating code changes across branches\\xe2\\x80\\x94a process that is error-prone due to \ncode divergence, conflicting dependencies, and branch-specific modifications. \nAutomating code porting can streamline development workflows, accelerate \ndevelopment cycles, and improve team collaboration. However, achieving this \nautomation presents significant hurdles, particularly in maintaining consistency and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Patch Backporting in Linux (Experience Paper)\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11052825/&hl=en&sa=X&d=12890063858203717122&ei=mOlqaP7SEtSWieoP7_C3mAw&scisig=AAZF9b_WKu5aK7QCqaqw5RLXQ5XP&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Spectre Attack Detection with Formal Method on RISC-V Processor at RTL Design Level", "first_label": [], "second_label": ["Detection"], "data": "CC Ting, YT Huang, YT Chen, YR Chen, EH Lin\\xc2\\xa0- 2025 International VLSI Symposium\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSpeculative execution, widely used in modern processors, improves performance but \nis vulnerable to Spectre attacks. By mistraining the branch predictor, attackers \nexecute transient instructions to access confidential data and leave traces in the \ncache, exposing sensitive information despite squashed instructions. Many detection \nmethods have been proposed, but currently, none of them can be directly applied to \nprocessor design register transfer level (RTL) without any manual efforts to provide a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaoo7: Low-overhead defense against spectre attacks via program\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11046778/&hl=en&sa=X&d=3593067293732385955&ei=mOlqaP7SEtSWieoP7_C3mAw&scisig=AAZF9b9dD4sLSGrv4rrHnZBt4yj5&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Empirical Evaluation of Large Language Models in Automated Program Repair", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "J Sun, F Li, X Qi, H Zhang, J Jiang\\xc2\\xa0- arXiv preprint arXiv:2506.13186, 2025\nThe increasing prevalence of software bugs has made automated program repair \n(APR) a key research focus. Large language models (LLMs) offer new opportunities \nfor APR, but existing studies mostly rely on smaller, earlier-generation models and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13186&hl=en&sa=X&d=14847840234469800688&ei=mOlqaMrEGMmQ6rQPzMjc4AI&scisig=AAZF9b_y41VlOZ86kZEkYfQJ-XbI&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "FuseApplyBench: Multilingual Benchmark for Trustworthy Code Edit Applying Task", "first_label": ["Code"], "second_label": [], "data": "M Liang, Q Zhang, Z Zuo, S Zheng, D Chen, W Jiang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 34th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the rise of Language Models (LMs) and Large Language Models (LLMs), their \npotential for code editing (CE) has gained attention. An approach is to have LLMs \ngenerate draft code modifications, which are then refined by smaller LMs in further\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3732929&hl=en&sa=X&d=7791836070318800823&ei=mOlqaMrEGMmQ6rQPzMjc4AI&scisig=AAZF9b_-xxPAC4O-ILuaMHDNHkH0&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "End-User Customization of Trigger-Action Rules Through Fine-Tuned LLMs", "first_label": ["LLM"], "second_label": [], "data": "G Cimino, V Deufemia\\xc2\\xa0- International Symposium on End User Development, 2025\nAbstract While Trigger-Action Platforms (TAPs) provide an effective solution for end-\nusers to automate interactions between smart devices and online services through \ncustomizable rules, their flexibility is often limited by restricted access to source code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-95452-8_2&hl=en&sa=X&d=2148692169908663268&ei=mOlqaMrEGMmQ6rQPzMjc4AI&scisig=AAZF9b_Mv7kTvNKKktKs_aihUb5T&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "FrontendBench: A Benchmark for Evaluating LLMs on Front-End Development via Automatic Evaluation", "first_label": ["LLM"], "second_label": [], "data": "H Zhu, Y Zhang, B Zhao, J Ding, S Liu, T Liu, D Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have made significant strides in front-end code \ngeneration. However, existing benchmarks exhibit several critical limitations: many \ntasks are overly simplistic, test cases often lack rigor, and end-to-end validation is\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13832&hl=en&sa=X&d=2112639698671840186&ei=mOlqaMrEGMmQ6rQPzMjc4AI&scisig=AAZF9b8od9psvT-Kt0tqTsCNZNad&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Structural Code Search using Natural Language Queries", "first_label": ["Code"], "second_label": ["Search"], "data": "B Limpanukorn, Y Wang, Z Patterson, P Garg\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSearching code is a common task that developers perform to understand APIs, learn \ncommon code patterns, and navigate code. Currently, developers most commonly \nsearch using keywords and regular expressions that are easy to use and widely\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2507.02107&hl=en&sa=X&d=6852625154069875151&ei=mOlqaMrEGMmQ6rQPzMjc4AI&scisig=AAZF9b-rNXgV-vwCEw6Y3O5qyFmW&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Multi-Dataset Evaluation of Models for Automated Vulnerability Repair", "first_label": ["Vulnerabilities"], "second_label": ["Repair"], "data": "ZA Khan, A Garg, Q Tang\\xc2\\xa0- arXiv preprint arXiv:2506.04987, 2025\nSoftware vulnerabilities pose significant security threats, requiring effective \nmitigation. While Automated Program Repair (APR) has advanced in fixing general \nbugs, vulnerability patching, a security-critical aspect of APR remains underexplored\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04987&hl=en&sa=X&d=8355847986163965479&ei=mOlqaMrEGMmQ6rQPzMjc4AI&scisig=AAZF9b9iPSTGWnyCaOCv5RKilXRE&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=7&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Knowledge Enhanced Large Language Model for Bug Localization", "first_label": ["LLM", "Bug"], "second_label": ["Localization"], "data": "Y Li, B Liu, T Zhang, Z Wang, D Lo, L Yang, J Lyu\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nA significant number of bug reports are generated every day as software systems \ncontinue to develop. Large Language Models (LLMs) have been used to correlate \nbug reports with source code to locate bugs automatically. The existing research has\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729356&hl=en&sa=X&d=16532092839572238040&ei=mOlqaMrEGMmQ6rQPzMjc4AI&scisig=AAZF9b-PmFlcmxHgFCjDtRfes5nX&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=8&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Andromeda: Debugging Database Performance Issues with Retrieval-Augmented Large Language Models", "first_label": ["LLM", "Bug"], "second_label": [], "data": "P Wang, S Chen, J Fan, B Wu, N Tang, J Tan\\xc2\\xa0- Companion of the 2025 International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDebugging performance issues in a database management system (DBMS) is \ntedious and challenging, even for experienced database administrators (DBAs). \nThus, with the rapid advancement of large language models (LLMs), developing an\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3722212.3725080&hl=en&sa=X&d=11546786090620021914&ei=mOlqaMrEGMmQ6rQPzMjc4AI&scisig=AAZF9b9ePwZ-JpKhnVkDq6wmWEpg&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=9&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Your Agent Can Defend Itself against Backdoor Attacks", "first_label": [], "second_label": ["Agent"], "data": "L Changjiang, L Jiacheng, C Bochuan, C Jinghui\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite their growing adoption across domains, large language model (LLM)-\npowered agents face significant security risks from backdoor attacks during training \nand fine-tuning. These compromised agents can subsequently be manipulated to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08336%3F&hl=en&sa=X&d=9281612337423238890&ei=mOlqaKPmFu2rieoP-PKl6QY&scisig=AAZF9b_8MLxfIxWhYE6GVNyu9rSa&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks", "first_label": ["LLM"], "second_label": [], "data": "S Chen, A Zharmagambetov, D Wagner, C Guo\\xc2\\xa0- arXiv preprint arXiv:2507.02735, 2025\nPrompt injection attacks pose a significant security threat to LLM-integrated \napplications. Model-level defenses have shown strong effectiveness, but are \ncurrently deployed into commercial-grade models in a closed-source manner. We\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2507.02735&hl=en&sa=X&d=14694239694720190383&ei=mOlqaKPmFu2rieoP-PKl6QY&scisig=AAZF9b8rTMKEjTVjPHsbYsIOgTis&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SecurityLingua: Efficient Defense of LLM Jailbreak Attacks via Security-Aware Prompt Compression", "first_label": ["LLM"], "second_label": [], "data": "Y Li, S Ahn, H Jiang, AH Abdi, Y Yang, L Qiu\\xc2\\xa0- arXiv preprint arXiv:2506.12707, 2025\nLarge language models (LLMs) have achieved widespread adoption across \nnumerous applications. However, many LLMs are vulnerable to malicious attacks \neven after safety alignment. These attacks typically bypass LLMs' safety guardrails by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12707&hl=en&sa=X&d=8418273368991399970&ei=mOlqaKPmFu2rieoP-PKl6QY&scisig=AAZF9b8AOJ5PQ2S2DYr5nVOYpqTl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Syntactic paraphrase-based synthetic data generation for backdoor attacks against Chinese language models", "first_label": ["LLM"], "second_label": ["Generation"], "data": "M Hu, Y Yang, D Pan, Z Guo, L Xiao, D Lin, S Zhao\\xc2\\xa0- Information Fusion, 2025\nAbstract Language Models (LMs) have shown significant advancements in various \nNatural Language Processing (NLP) tasks. However, recent studies indicate that \nLMs are particularly susceptible to malicious backdoor attacks, where attackers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S156625352500449X&hl=en&sa=X&d=11939540759867308872&ei=mOlqaKPmFu2rieoP-PKl6QY&scisig=AAZF9b_omHEFDqgnSwVne_pfKwnY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas", "first_label": ["LLM"], "second_label": ["Search"], "data": "C Si, T Hashimoto, D Yang\\xc2\\xa0- arXiv preprint arXiv:2506.20803, 2025\nLarge Language Models (LLMs) have shown promise in accelerating the scientific \nresearch pipeline. A key capability for this process is the ability to generate novel \nresearch ideas, and prior studies have found settings in which LLM-generated\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.20803&hl=en&sa=X&d=12936314858694523072&ei=mOlqaKPmFu2rieoP-PKl6QY&scisig=AAZF9b9OO1DSvhRdAUtwVxkfCQ2j&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge", "first_label": ["LLM"], "second_label": [], "data": "S Li, C Xu, J Wang, X Gong, C Chen, J Zhang, J Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable intelligence across \nvarious tasks, which has inspired the development and widespread adoption of LLM-\nas-a-Judge systems for automated model testing, such as red teaming and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09443&hl=en&sa=X&d=2052322274134661445&ei=mOlqaKPmFu2rieoP-PKl6QY&scisig=AAZF9b9u9cyhYi06xXXt37CLZpdh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Advancing Jailbreak Strategies: A Hybrid Approach to Exploiting LLM Vulnerabilities and Bypassing Modern Defenses", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Exploit"], "data": "M Ahmed, M Abdelmouty, M Kim, G Kandula, A Park\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe advancement of Pre-Trained Language Models (PTLMs) and Large Language \nModels (LLMs) has led to their widespread adoption across diverse applications. \nDespite their success, these models remain vulnerable to attacks that exploit their\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.21972&hl=en&sa=X&d=675653787277926698&ei=mOlqaKPmFu2rieoP-PKl6QY&scisig=AAZF9b91mMHa8_Zo3bUEFFi7T1Lf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Kill Two Birds with One Stone! Trajectory enabled Unified Online Detection of Adversarial Examples and Backdoor Attacks", "first_label": [], "second_label": ["Detection"], "data": "A Fu, F Meng, H Peng, H Ma, Z Zhang, Y Zheng\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe proposed UniGuard is the first unified online detection framework capable of \nsimultaneously addressing adversarial examples and backdoor attacks. UniGuard \nbuilds upon two key insights: first, both AE and backdoor attacks have to compromise\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.22722&hl=en&sa=X&d=13093507617708419502&ei=mOlqaKPmFu2rieoP-PKl6QY&scisig=AAZF9b8n_qu391txTcOD2oGBZnJs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AsFT: Anchoring Safety During LLM Fine-Tuning Within Narrow Safety Basin", "first_label": ["LLM"], "second_label": [], "data": "S Yang, Q Zhang, Y Liu, Y Huang, X Jia, K Ning, J Yao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are vulnerable to safety risks during fine-tuning, \nwhere small amounts of malicious or harmless data can compromise safeguards. In \nthis paper, building on the concept of alignment direction--defined by the weight\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08473%3F&hl=en&sa=X&d=15059004078714992755&ei=mOlqaKPmFu2rieoP-PKl6QY&scisig=AAZF9b-cmQJQ2nP1jAOJlM9iLuaf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Arms Race in Deep Learning: A Survey of Backdoor Defenses and Adaptive Attacks", "first_label": [], "second_label": [], "data": "X Mo, N Sun, LY Zhang, W Luo, S Gao, Y Xiang\\xc2\\xa0- Pacific-Asia Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeep neural networks (DNNs) face a growing threat from backdoor attacks, which \nembed hidden malicious functionalities triggered by specific inputs. This survey \nexamines the escalating arms race between backdoor defenses and increasingly\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-96-8183-9_24&hl=en&sa=X&d=4258756518287065675&ei=mOlqaKPmFu2rieoP-PKl6QY&scisig=AAZF9b80XRQuOtBuq86IspbsVv3h&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
