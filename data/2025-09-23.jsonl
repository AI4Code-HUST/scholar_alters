{"title": "On-the-fly Generation-Quality Enhancement of Deep Code Models via Model Collaboration", "first_label": ["Code"], "second_label": ["Generation"], "data": "W Sun, N Huang, M Yan, Z Liu, H Li, Y Lei, D Lo- ACM Transactions on Software, 2025\nThe growing prominence of deep code models in automating software engineering \ntasks is undeniable. However, their deployment encounters significant challenges in \non-the-fly performance enhancement, which refers to dynamically improving the", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3765752&hl=en&sa=X&d=8461622238338289043&ei=QaG-aIazK8yjieoPqvzj-QU&scisig=AAZF9b8XRChF1VQRgFEY-oK3km8Q&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research", "6 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research", "Thanh Le-Cong - new related research"]}
{"title": "VULSOVER: Vulnerability Detection via LLM-Driven Constraint Solving", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "X Li, Y Su, J Liu, Z Lin, Y Hou, P Gao, Y Zhang- arXiv preprint arXiv:2509.00882, 2025\nTraditional vulnerability detection methods rely heavily on predefined rule matching, \nwhich often fails to capture vulnerabilities accurately. With the rise of large language \nmodels (LLMs), leveraging their ability to understand code semantics has emerged", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.00882&hl=en&sa=X&d=16404367334041769832&ei=QaG-aIazK8yjieoPqvzj-QU&scisig=AAZF9b-z-8SpaZd54VNxydRHWVN0&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models", "first_label": ["LLM", "Bug", "Repository-Level"], "second_label": [], "data": "J Liu, Z Liu, Z Cheng, M He, X Shi, Y Guo, X Zhu, Y Guo- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have exhibited significant proficiency in code \ndebugging, especially in automatic program repair, which may substantially reduce \nthe time consumption of developers and enhance their efficiency. Significant", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04078&hl=en&sa=X&d=12419661760319839544&ei=QaG-aIazK8yjieoPqvzj-QU&scisig=AAZF9b_gGl-IbKvqw4yNAGQhtCLB&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "6 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research"]}
{"title": "Syntactic multilingual probing of pre-trained language models of code", "first_label": ["LLM", "Code"], "second_label": [], "data": "JAH Lpez, M Weyssow, JS Cuadrado, H Sahraoui- Journal of Systems and, 2026\nPre-trained language models (PLMs) have demonstrated remarkable abilities in \ncoding tasks, establishing themselves as a state-of-the-art technique in machine \nlearning for code. However, due to their deep neural network-based structure, PLMs", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225002730&hl=en&sa=X&d=912414639058686127&ei=QaG-aIazK8yjieoPqvzj-QU&scisig=AAZF9b_JpbZnEYTzTsY6dFTnCppp&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research", "David Lo - new related research", "Abhik Roychoudhury - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Energy-Aware Code Generation with LLMs: Benchmarking Small vs. Large Language Models for Sustainable AI Programming", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "H Ashraf, SM Danish, A Leivadeas, Y Otoum, Z Sattar- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) are widely used for code generation. However, \ncommercial models like ChatGPT require significant computing power, which leads \nto high energy use and carbon emissions. This has raised concerns about their\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.08332&hl=en&sa=X&d=11279727966461860434&ei=QaG-aIazK8yjieoPqvzj-QU&scisig=AAZF9b-7e3D89arfkJWv8yFOEorb&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Vulnerability-Affected Versions Identification: How Far Are We?", "first_label": ["Vulnerabilities"], "second_label": [], "data": "X Chen, C Liu, J Cao, Y Xiao, X Cai, Y Li, J Shi, T Sun- arXiv preprint arXiv, 2025\nIdentifying which software versions are affected by a vulnerability is critical for \npatching, risk mitigation. Despite a growing body of tools, their real-world \neffectiveness remains unclear due to narrow evaluation scopes often limited to early \nSZZ variants, outdated techniques, and small or coarse-graineddatasets. In this \npaper, we present the first comprehensive empirical study of vulnerability affected \nversions identification. We curate a high quality benchmark of 1,128 real-world\nCites: Evaluating SZZ implementations: An empirical study on the linux", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.03876&hl=en&sa=X&d=13995589590814654976&ei=P6G-aImLDOHO6rQP6evakQg&scisig=AAZF9b-slAfnQVJg-TJvM2cA22C-&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["9 new citations to articles by Hong Jin Kang", "6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Benchmarking Static Analysis for PHP Applications Security", "first_label": ["Static Analysis"], "second_label": [], "data": "J Zhao, K Zhu, C Lu, J Zhao, Y Lu- Entropy, 2025\nPHP is the most widely used server-side programming language, but it remains \nhighly susceptible to diverse classes of vulnerabilities. Static Application Security \nTesting (SAST) tools are commonly adopted for vulnerability detection; however, \ntheir evaluation lacks systematic criteria capable of quantifying information loss and \nuncertainty in analysis. Existing approaches, often based on small real-world case \nsets or heuristic sampling, fail to control experimental entropy within test cases. This\nCites: Detecting false alarms from automatic static analysis tools: How far", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/1099-4300/27/9/926&hl=en&sa=X&d=3642674625913140847&ei=P6G-aImLDOHO6rQP6evakQg&scisig=AAZF9b_xAzGp68bmi_Xdev-hKzqM&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["9 new citations to articles by Hong Jin Kang"]}
{"title": "VulnRepairEval: An Exploit-Based Evaluation Framework for Assessing Large Language Model Vulnerability Repair Capabilities", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Repair", "Exploit"], "data": "W Wang, W Ma, Q Hu, Y Zhang, J Sun, B Wu, Y Liu- arXiv preprint arXiv, 2025\nThe adoption of Large Language Models (LLMs) for automated software vulnerability \npatching has shown promising outcomes on carefully curated evaluation sets. \nNevertheless, existing datasets predominantly rely on superficial validation methods \nrather than exploit-based verification, leading to overestimated performance in \nsecurity-sensitive applications. This paper introduces VulnRepairEval, an evaluation \nframework anchored in functional Proof-of-Concept (PoC) exploits. Our framework\nCites: Bugsinpy: a database of existing bugs in python programs to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.03331&hl=en&sa=X&d=8967275014658144841&ei=P6G-aImLDOHO6rQP6evakQg&scisig=AAZF9b_jjnkUUQ9qmV8lwtwRGnmU&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["9 new citations to articles by Hong Jin Kang", "Abhik Roychoudhury - new related research", "1 new citation to articles by Quang-Cuong Bui"]}
{"title": ":", "first_label": [], "second_label": [], "data": ",  -  . :   , 2025\n       \n       \n .      \n ,    ,      \n .     ,  \n  .     \nCites: Biasfinder: Metamorphic test generation to uncover bias for", "link": "https://scholar.google.com/scholar_url?url=https://journals.vsu.ru/sait/article/view/13193/13250&hl=en&sa=X&d=14327240359416002116&ei=P6G-aImLDOHO6rQP6evakQg&scisig=AAZF9b-HZai9mnXg_x3BhLRRre3A&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=3&folt=cit", "author": ["Hong Jin Kang"], "ref": ["9 new citations to articles by Hong Jin Kang"]}
{"title": "Neurosymbolic Programming in Scallop: Design, Implementation, and Applications", "first_label": [], "second_label": [], "data": "Z Li - 2025\nNeurosymbolic programming combines the otherwise complementary worlds of deep \nlearning and symbolic reasoning. It thereby enables more accurate, interpretable, \nand domain-aware AI solutions that surpass purely neural or symbolic approaches. \nWhile significant advances have been made in domain-specific neurosymbolic \nmethods, the field lacks a unified programming system for general neurosymbolic \napplications. This dissertation proposes Scallop, a language for neurosymbolic\nCites: Detecting false alarms from automatic static analysis tools: How far", "link": "https://scholar.google.com/scholar_url?url=https://repository.upenn.edu/bitstreams/f0c0b264-3884-4892-9f24-6c761f2116c1/download&hl=en&sa=X&d=104279435660605634&ei=P6G-aImLDOHO6rQP6evakQg&scisig=AAZF9b-GJo1u04hzGT_mZSqcgO_2&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=4&folt=cit", "author": ["Hong Jin Kang"], "ref": ["9 new citations to articles by Hong Jin Kang"]}
{"title": "Detecting Exception-Related Behavioural Breaking Changes with UnCheckGuard", "first_label": [], "second_label": ["Detection"], "data": "V Sharma, P Lam\nThe ubiquitous use of third-party libraries in software development has enabled \ndevelopers to quickly add new functionality to their client software. Unfortunately, \nlibrary usage also carries a cost in terms of software maintenance: library upgrades \nmay include breaking changes, in which client expectations about library behaviour \nare no longer met in new library versions. Behavioural breaking changes can be \nparticularly insidious, and in their full generality, could require sophisticated program\nCites: Automated identification of libraries from vulnerability data: Can we", "link": "https://scholar.google.com/scholar_url?url=https://patricklam.ca/papers/25.scam.breaking-exceptions.pdf&hl=en&sa=X&d=8638375304603820365&ei=P6G-aImLDOHO6rQP6evakQg&scisig=AAZF9b_BN0gETiFihqNMavGPLp4R&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=5&folt=cit", "author": ["Hong Jin Kang"], "ref": ["9 new citations to articles by Hong Jin Kang"]}
{"title": "Detecting Unchecked Exception-Related Behavioural Breaking Changes with UnCheckGuard", "first_label": [], "second_label": ["Detection"], "data": "V Sharma - 2025\nThe ubiquitous use of third-party libraries in software development has enabled \ndevelopers to quickly add new functionality to their client software. Unfortunately, \nlibrary usage also carries a cost in terms of software maintenance: library upgrades \nmay include breaking changes, in which client expectations about library behaviour \nare no longer met in new library versions. Behavioural breaking changes can be \nparticularly insidious, and in their full generality, could require sophisticated program\nCites: Automated identification of libraries from vulnerability data: Can we", "link": "https://scholar.google.com/scholar_url?url=https://uwspace.uwaterloo.ca/bitstreams/16cf055d-22fc-4e04-b147-40e4d0d355e7/download&hl=en&sa=X&d=1823104780300073596&ei=P6G-aImLDOHO6rQP6evakQg&scisig=AAZF9b9ynhhyiwbSHR0zKVT2D7Ft&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=6&folt=cit", "author": ["Hong Jin Kang"], "ref": ["9 new citations to articles by Hong Jin Kang"]}
{"title": "Meta-Fair: Metamorphic Testing of Fairness in Large Language Models", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "M Romero-Arjona, JA Parejo, JC Alonso, AB Snchez- Jornadas de Ingeniera del, 2025\nLarge Language Models (LLMs) have significantly advanced natural language \nprocessing but remain susceptible to biases that can reinforce discrimination and \nundermine equitable outcomes. As AI-driven applications become increasingly \nembedded in critical decision-making processes, mitigating these biases has \nbecome an ethical and regulatory necessity. This paper presents Meta-Fair, a tool \nsuite designed for evaluating fairness in LLMs. Meta-Fair comprises three integrated\nCites: Biasfinder: Metamorphic test generation to uncover bias for", "link": "https://scholar.google.com/scholar_url?url=https://trust4ai.github.io/trust4ai/publication/2025_trust4ai2025jisbd/romero25-mcps.pdf&hl=en&sa=X&d=17615910458456533745&ei=P6G-aImLDOHO6rQP6evakQg&scisig=AAZF9b9hXwa5CrZDgZ3yM0f3fI3t&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=7&folt=cit", "author": ["Hong Jin Kang"], "ref": ["9 new citations to articles by Hong Jin Kang", "Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Enhancing Security Patch Documentation Through Generative AI", "first_label": [], "second_label": [], "data": "I Majeri - 2025\nSecurity patch documentation is a critical yet time-consuming aspect of secure \nsoftware development. This thesis investigates the use of generative AI models to \nautomate the generation of SECOM-compliant commit messages directly from code \ndiffs. Two prompting strategies are evaluated: a zero-shot baseline, where messages \nare generated from raw Git diffs without examples, and a few-shot approach, where \nstructured exemplars guide the model via in-context learning. In a large-scale\nCites: Cc2vec: Distributed representations of code changes\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://repositorio-aberto.up.pt/bitstream/10216/169063/2/737035.pdf&hl=en&sa=X&d=8971919107096250728&ei=P6G-aImLDOHO6rQP6evakQg&scisig=AAZF9b-3jLdLgSQnPnDUAYkGB8Tz&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=8&folt=cit", "author": ["Hong Jin Kang"], "ref": ["9 new citations to articles by Hong Jin Kang"]}
{"title": "GTVD: a multi-level aggregation vulnerability detection method based on full-dependency program graph", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "H He, S Li, Y Li, Y Li- Cluster Computing, 2025\nIn modern software development life cycles, proactive vulnerability discovery and \nremediation play crucial roles in ensuring application security. However, current \ndeep learning-based vulnerability detection methods frequently face limitations due", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10586-025-05506-7&hl=en&sa=X&d=9365356712912853263&ei=QaG-aPypOOHO6rQP6evakQg&scisig=AAZF9b_DdZ4fyL1mLj90wo4wpBRq&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research", "4 new citations to articles by Xin ZHOU", "Thanh Le-Cong - new related research"]}
{"title": "TypeNFuzz: Dynamic Type-aware Object Dependence Graph Guided Fuzzing for JavaScript Library Bug Discovery", "first_label": ["Fuzzing", "Bug"], "second_label": ["Graph"], "data": "Y Zeng, Y Wu, C Zhang- ACM Transactions on Software Engineering and\nNode. js owes much of its popularity to an enormous library ecosystem. While this \nabundance speeds development, widely varying code quality complicates efforts to \nassure robustness. Effective library testing is hard for two reasons:(1) dynamic typing", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3765760&hl=en&sa=X&d=5116157467151094045&ei=QaG-aPypOOHO6rQP6evakQg&scisig=AAZF9b_fURRjvwZAmKpjZeYsQVaO&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Assessing the Impact of Tuning Parameter in Instance Selection based Bug Resolution Classification", "first_label": ["Bug"], "second_label": [], "data": "C Miloudi, L Cheikhi, A Idri, A Abran- Information and Software Technology, 2025\nContext Software maintenance is time-consuming and requires significant effort for \nbug resolution and various types of software enhancement. Estimating software \nmaintenance effort is challenging for open source software (OSS) without historical", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925002137&hl=en&sa=X&d=12306640846877965626&ei=QaG-aPypOOHO6rQP6evakQg&scisig=AAZF9b_8g4BurvlpnjBWWamE01nP&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Policy-driven Software Bill of Materials on GitHub: An Empirical Study", "first_label": [], "second_label": [], "data": "O Novikov, D Fucci, O Adamov, D Mendez- arXiv preprint arXiv:2509.01255, 2025\nBackground. The Software Bill of Materials (SBOM) is a machine-readable list of all \nthe software dependencies included in a software. SBOM emerged as way to assist \nsecuring the software supply chain. However, despite mandates from governments to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01255&hl=en&sa=X&d=209382978198355243&ei=QaG-aPypOOHO6rQP6evakQg&scisig=AAZF9b88Wz5QaFfXK0_CPqyTQksD&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "An Empirical Study of Vulnerabilities in Python Packages and Their Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "H Quan, J Wang, X Li, TY Zhuo, X Chen, X Du- arXiv preprint arXiv:2509.04260, 2025\nIn the rapidly evolving software development landscape, Python stands out for its \nsimplicity, versatility, and extensive ecosystem. Python packages, as units of \norganization, reusability, and distribution, have become a pressing concern", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04260&hl=en&sa=X&d=7788001607781427801&ei=QKG-aOCvAvfP6rQP2-GA-Qo&scisig=AAZF9b_GfUu7uYi9lp8bNNE9eVv5&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Quang-Cuong Bui - new related research", "4 new citations to articles by Xin ZHOU"]}
{"title": "From Cryptic to Clear-Training on LLM Explanations to Detect Smart Contract Vulnerabilities", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": [], "data": "Y Chen, Z Sun, G Wang, Q Liang, X Yu, D Hao- ACM Transactions on Software, 2025\nSmart contracts have revolutionized the way transactions are executed, offering \ndecentralized and immutable frameworks. The immutability of smart contracts poses \nsignificant risks when vulnerabilities exist in their code, leading to financial losses", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3765753&hl=en&sa=X&d=10696251976758637118&ei=QKG-aOCvAvfP6rQP2-GA-Qo&scisig=AAZF9b9ZBf4NQYTpgMU9yATSPdqf&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research"]}
{"title": "EVuLLM: Ethereum Smart Contract Vulnerability Detection Using Large Language Models", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM", "Ethereum"], "second_label": ["Detection"], "data": "E Mandana, G Vlahavas, A Vakali- Electronics, 2025\nSmart contracts have become integral to decentralized applications, yet their \nprogrammability introduces critical security risks, exemplified by high-profile exploits \nsuch as the DAO and Parity Wallet incidents. Existing vulnerability detection", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2079-9292/14/16/3226&hl=en&sa=X&d=5671146682972568211&ei=QKG-aOCvAvfP6rQP2-GA-Qo&scisig=AAZF9b_QN_iE24E2yiouSjQbgpvu&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Gradient Surgery for Safe LLM Fine-Tuning", "first_label": ["LLM"], "second_label": [], "data": "B Yi, J Li, B Zhang, L Nie, T Li, T Huang, Z Liu- arXiv preprint arXiv:2508.07172, 2025\nFine-tuning-as-a-Service introduces a critical vulnerability where a few malicious \nexamples mixed into the user's fine-tuning dataset can compromise the safety \nalignment of Large Language Models (LLMs). While a recognized paradigm frames", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.07172&hl=en&sa=X&d=10352052812613128560&ei=QaG-aJP_HfmI6rQP1e7wmQQ&scisig=AAZF9b_-UmhxxnT9CjoTuoEHfdfM&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Jailbreak Attack with Multimodal Virtual Scenario Hypnosis for Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "X Shi, S Chen, G Zhang, W Wei, Y Li, Z Fan, J Liu- Pattern Recognition, 2025\nDue to the inherent vulnerabilities of large Vision-Language Models (VLMs), security \ngovernance has emerged as a critical concern, particularly given the risks posed by \nnoisy and biased training data as well as adversarial attacks, including data", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0031320325010520&hl=en&sa=X&d=18404876866865125967&ei=QaG-aJP_HfmI6rQP1e7wmQQ&scisig=AAZF9b9xJx3YOX0I9CBN24pCw_YG&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Rethinking Safety in LLM Fine-tuning: An Optimization Perspective", "first_label": ["LLM"], "second_label": [], "data": "M Kim, JM Kwak, L Alssum, B Ghanem, P Torr- arXiv preprint arXiv, 2025\nFine-tuning language models is commonly believed to inevitably harm their safety, \nie, refusing to respond to harmful user requests, even when using harmless datasets, \nthus requiring additional safety measures. We challenge this belief through", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.12531&hl=en&sa=X&d=5765344796588629336&ei=QaG-aJP_HfmI6rQP1e7wmQQ&scisig=AAZF9b824RRmgPcbwax6O3_MzYe2&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SafeConstellations: Steering LLM Safety to Reduce Over-Refusals Through Task-Specific Trajectory", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, S Yadav, M Dras, U Naseem- arXiv preprint arXiv:2508.11290, 2025\nLLMs increasingly exhibit over-refusal behavior, where safety mechanisms cause \nmodels to reject benign instructions that superficially resemble harmful content. This \nphenomena diminishes utility in production applications that repeatedly rely on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.11290&hl=en&sa=X&d=4418065858919549735&ei=QaG-aJP_HfmI6rQP1e7wmQQ&scisig=AAZF9b_590TBu9nutdVdOeEXPNS5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "M Phute, R Balakrishnan- arXiv preprint arXiv:2508.08521, 2025\nVision Language Models (VLMs) are increasingly being used in a broad range of \napplications, bringing their security and behavioral control to the forefront. While \nexisting approaches for behavioral control or output redirection, like system", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.08521%3F&hl=en&sa=X&d=3389705349380814363&ei=QaG-aJP_HfmI6rQP1e7wmQQ&scisig=AAZF9b_q3Y2_Sm63cdpM1VXa1B78&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents", "first_label": ["LLM"], "second_label": ["Agent", "Graph"], "data": "H An, J Zhang, T Du, C Zhou, Q Li, T Lin, S Ji- arXiv preprint arXiv:2508.15310, 2025\nLarge language model (LLM) agents are widely deployed in real-world applications, \nwhere they leverage tools to retrieve and manipulate external data for complex tasks. \nHowever, when interacting with untrusted data sources (eg, fetching information from", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.15310%3F&hl=en&sa=X&d=10016631352339170343&ei=QaG-aJP_HfmI6rQP1e7wmQQ&scisig=AAZF9b_6vPzQ2dLdwqnzliHL703r&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A Survey on the Feedback Mechanism of LLM-based AI Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Z Liu, X Bai, K Chen, X Chen, X Li, Y Xiang, J Liu\nLarge language models (LLMs) are increasingly being adopted to develop general-\npurpose AI agents. However, it remains challenging for these LLM-based AI agents \nto efficiently learn from feedback and iteratively optimize their strategies. To address", "link": "https://scholar.google.com/scholar_url?url=https://ijcai-preprints.s3.us-west-1.amazonaws.com/2025/8835.pdf&hl=en&sa=X&d=14511738061688557547&ei=QaG-aJP_HfmI6rQP1e7wmQQ&scisig=AAZF9b-4ZyHqXzP38qhsex58ULA6&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Membership and Memorization in LLM Knowledge Distillation", "first_label": ["LLM"], "second_label": [], "data": "Z Zhang, AS Shamsabadi, H Lu, Y Cai, H Haddadi- arXiv preprint arXiv:2508.07054, 2025\nRecent advances in Knowledge Distillation (KD) aim to mitigate the high \ncomputational demands of Large Language Models (LLMs) by transferring \nknowledge from a large''teacher''to a smaller''student''model. However, students may", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.07054%3F&hl=en&sa=X&d=15568245874926800615&ei=QaG-aJP_HfmI6rQP1e7wmQQ&scisig=AAZF9b9B1fRaZ0fcyasatykoQEOB&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A Real-Time, Self-Tuning Moderator Framework for Adversarial Prompt Detection", "first_label": [], "second_label": ["Detection"], "data": "I Zhang- arXiv preprint arXiv:2508.07139, 2025\nEnsuring LLM alignment is critical to information security as AI models become \nincreasingly widespread and integrated in society. Unfortunately, many defenses \nagainst adversarial attacks and jailbreaking on LLMs cannot adapt quickly to new", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.07139%3F&hl=en&sa=X&d=16044253908885372456&ei=QaG-aJP_HfmI6rQP1e7wmQQ&scisig=AAZF9b93YxGfEQp3lERsZvriTNh4&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Cut Costs, Not Accuracy: LLM-Powered Data Processing with Guarantees", "first_label": ["LLM"], "second_label": [], "data": "S Zeighami, S Shankar, A Parameswaran- arXiv preprint arXiv:2509.02896, 2025\nLarge Language Models (LLMs) are being increasingly used as a building block in \ndata systems to process large text datasets. To do so, LLM model providers offer \nmultiple LLMs with different sizes, spanning various cost-quality trade-offs when\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.02896&hl=en&sa=X&d=17574372354989562785&ei=QaG-aJP_HfmI6rQP1e7wmQQ&scisig=AAZF9b8158xbAAVHG1BtXxJ1Uztw&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Exploring the Design Space of Fair Tree Learning Algorithms", "first_label": [], "second_label": [], "data": "K Stempel, M Cerrato, S Kramer- arXiv preprint arXiv:2509.03204, 2025\nDecision trees have been studied extensively in the context of fairness, aiming to \nmaximize prediction performance while ensuring non-discrimination against different \ngroups. Techniques in this space usually focus on imposing constraints at training \ntime, constraining the search space so that solutions which display unacceptable \nvalues of relevant metrics are not considered, discarded, or discouraged. If we \nassume one target variable y and one sensitive attribute s, the design space of tree\nCites: Fair decision making via automated repair of decision trees", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.03204&hl=en&sa=X&d=10689722562965220132&ei=QKG-aJepErWR6rQPyczN4AQ&scisig=AAZF9b8AfZ3ZL8nnpGOoOr6L25NG&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "app. build: A Production Framework for Scaling Agentic Prompt-to-App Generation with Environment Scaffolding", "first_label": [], "second_label": ["Generation", "Agent"], "data": "E Kniazev, A Kravchenko, I Rekun, J Broadhead- arXiv preprint arXiv, 2025\nWe present app. build (https://github. com/appdotbuild/agent/), an open-source \nframework that improves LLM-based application generation through systematic \nvalidation and structured environments. Our approach combines multi-layered \nvalidation pipelines, stack-specific orchestration, and model-agnostic architecture, \nimplemented across three reference stacks. Through evaluation on 30 generation \ntasks, we demonstrate that comprehensive validation achieves 73.3% viability rate\nCites: Autocoderover: Autonomous program improvement, 2024", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.03310&hl=en&sa=X&d=4718396752738015023&ei=QKG-aJepErWR6rQPyczN4AQ&scisig=AAZF9b_gTE2KpKgbDOsq2O4_r0f6&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "D4: Debugging Databases During Development", "first_label": ["Bug"], "second_label": [], "data": "A Keles, E Chou, H Goldstein, L Lampropoulos - 2025\nDatabase management systems (DBMSs) are notoriously complex, making them \ndifficult to test effectively, especially during early development when many features \nare incomplete. Traditional testing tools like SQLancer and SQLSmith are highly \neffective for mature databases, but they struggle with high false positive rates and \nlow actionability when applied to evolving systems. We present D4, a paradigm \ndesigned specifically for debugging databases during development, which integrates\nCites: Coverage-based greybox fuzzing as markov chain\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://alperenkeles.com/documents/d4.pdf&hl=en&sa=X&d=18405272025730104109&ei=QKG-aJepErWR6rQPyczN4AQ&scisig=AAZF9b8mbvI53Mfsl_WVQn8qw4YC&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM Evaluators", "first_label": ["LLM"], "second_label": [], "data": "D Roytburg, M Bozoukov, M Nguyen, J Barzdukas- arXiv preprint arXiv, 2025\nLarge language models (LLMs) increasingly serve as automated evaluators, yet they \nsuffer from\" self-preference bias\": a tendency to favor their own outputs over those of \nother models. This bias undermines fairness and reliability in evaluation pipelines, \nparticularly for tasks like preference tuning and model routing. We investigate \nwhether lightweight steering vectors can mitigate this problem at inference time \nwithout retraining. We introduce a curated dataset that distinguishes self-preference\nCites: Codeultrafeedback: An llm-as-a-judge dataset for aligning large", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.03647&hl=en&sa=X&d=13923089661984229423&ei=QaG-aJ-bEPfP6rQP2-GA-Qo&scisig=AAZF9b90K_u5blPq6XXTANVg22sG&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "Development of a virtual reality application and general methodological considerations for seeking code for a possible continuation", "first_label": ["Code"], "second_label": [], "data": "BK Szab - 2025\nVirtual reality (VR) is gaining increasing importance, not only in entertainment and \ngames, but also in education, training and research. One such field of application is \nthe simulation of the operation of nuclear power plants. Experimenting on a virtual \nmodel of a nuclear power plant is risk-free: a situation which would be dangerous to \ntry out in real life (such as serious malfunctions jeopardizing nuclear safety) can be \ntried out without real risk. Physical replica simulators (where a computer simulates\nCites: Big Code Search: a Bibliography\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://dea.lib.unideb.hu/bitstreams/d24ca3bc-b100-4203-93a7-3322844cbf4d/download&hl=en&sa=X&d=6714136785030516704&ei=QaG-aJ-bEPfP6rQP2-GA-Qo&scisig=AAZF9b979LVKqo_LXYqN1StlkZcJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=3&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "Ascertaining Susceptibilities in Smart Contracts: A Quantum Machine Learning Approach", "first_label": ["Smart Contracts"], "second_label": [], "data": "A Sridhar, K Nagaraj, S Bangalore Ravi, S Kurup- Entropy, 2025\nThe current research aims to discover applications of QML approaches in realizing \nliabilities within smart contracts. These contracts are essential commodities of the \nblockchain interface and are also decisive in developing decentralized products. But \nliabilities in smart contracts could result in unfamiliar system failures. Presently, static \ndetection tools are utilized to discover accountabilities. However, they could result in \ninstances of false narratives due to their dependency on predefined rules. In\nCites: Smart contract development: Challenges and opportunities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/1099-4300/27/9/933&hl=en&sa=X&d=10695310403205703053&ei=P6G-aJDqHZ6s6rQP_Izu4Q0&scisig=AAZF9b8mOmj7TP2d8lJeT-fzefoE&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["1 new citation to articles by Bach Le"]}
{"title": "Aligning Requirement for Large Language Model's Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Z Tian, J Chen- arXiv preprint arXiv:2509.01313, 2025\nCode generation refers to the automatic generation of source code based on a given \nprogramming specification, which has garnered significant attention particularly with \nthe advancement of large language models (LLMs). However, due to the inherent", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01313&hl=en&sa=X&d=13370697676538068499&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b9B7L937IdcMo1J6Zsy7VAv&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Automated Repair of C Programs Using Large Language Models", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "M Farzandway, F Ghassemi- arXiv preprint arXiv:2509.01947, 2025\nThis study explores the potential of Large Language Models (LLMs) in automating \nthe repair of C programs. We present a framework that integrates spectrum-based \nfault localization (SBFL), runtime feedback, and Chain-of-Thought-structured", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01947&hl=en&sa=X&d=1317846922093490120&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b9xJ1n4DpSkY2MDDEUWo_Wk&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "10 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research"]}
{"title": "ChopChop: a Programmable Framework for Semantically Constraining the Output of Language Models", "first_label": ["LLM"], "second_label": [], "data": "S Nagy, T Zhou, N Polikarpova, L D'Antoni- arXiv preprint arXiv:2509.00360, 2025\nLanguage models (LMs) can generate code, but cannot guarantee its correctness--\nproducing outputs that often violate type safety, program invariants, or semantic \nequivalence. Constrained decoding offers a solution by restricting generation to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.00360&hl=en&sa=X&d=15761961036894749958&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b9gFg_U0FktMXuQ5DX2sTxT&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "Bach Le - new related research"]}
{"title": "Detecting Stealthy Data Poisoning Attacks in AI Code Generators", "first_label": ["Code"], "second_label": ["Detection"], "data": "C Improta- arXiv preprint arXiv:2508.21636, 2025\nDeep learning (DL) models for natural language-to-code generation have become \nintegral to modern software development pipelines. However, their heavy reliance on \nlarge amounts of data, often collected from unsanitized online sources, exposes", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21636&hl=en&sa=X&d=1475469146271069602&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b__JixuCYDK6mHiazPm85iV&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "4 new citations to articles by Hong Jin Kang"]}
{"title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "first_label": ["LLM"], "second_label": ["Agent"], "data": "T Lindenbauer, I Slinko, L Felder, E Bogomolov- arXiv preprint arXiv, 2025\nLarge Language Model (LLM)-based agents solve complex tasks through iterative \nreasoning, exploration, and tool-use, a process that can result in long, expensive \ncontext histories. While state-of-the-art Software Engineering (SE) agents like", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21433&hl=en&sa=X&d=3778813371369713554&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b8vjKgLLO8JtQg2HjxwaIIj&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Richard Fang - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Exploiting Contexts of LLM-based Code-Completion", "first_label": ["LLM", "Code"], "second_label": ["Generation", "Exploit"], "data": "M Noppel, K Rubel, C Wressnegger- German Conference on Artificial Intelligence, 2025\nCode assistants based on Large language models (LLMs) are built on massive \ndatasets, often sourced from untrusted GitHub repositories. Adversaries can poison \nthese sources so that the resulting models suggest insecure code. The", "link": "https://scholar.google.com/scholar_url?url=https://intellisec.org/pubs/2025a-ki.pdf&hl=en&sa=X&d=11435910170571140017&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b9NKcJ1sJL5SUxGI6_c6C_d&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Defect Prediction Guided Greybox Fuzz Testing", "first_label": ["Fuzzing", "Software Testing", "Software Defect"], "second_label": [], "data": "H Jin, Z Cui, R Zhang, X Chen, R Wang, X Liu- Journal of Systems and Software, 2025\nFuzz testing is an established automated technique for detecting defects in software \nby generating test cases randomly or semi-randomly. The escalating complexity of \nsoftware functionalities makes comprehensive testing more arduous. Research", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S016412122500278X&hl=en&sa=X&d=5767936158160667382&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b8Dto_RV5XzXWrnnCmGynLS&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "PATTERNS AND BEST PRACTICES OF KNOWLEDGE SHARING AMONG PROGRAMMERS ON STACK OVERFLOW: A QUALITATIVE STUDY", "first_label": [], "second_label": [], "data": "C WIRABUANA, MM RIDHO, DI SENSUSE, I EITIVENI- : Faculty of, 2025\nThis research explores knowledge-sharing patterns and best practices among \nprogrammers on the Stack Overflow platform. Using a qualitative approach, the study \nanalyzes interviews with seven programmers to identify user behavior and", "link": "https://scholar.google.com/scholar_url?url=https://elibrary.ru/item.asp%3Fid%3D82030709&hl=en&sa=X&d=15767019009267805002&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b85rkfchdG0s1hOqrm8mFGA&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution (arXiv version)", "first_label": ["LLM"], "second_label": [], "data": "K Even-Mendoza, A Brownlee, A Geiger, C Hanna - 2025\nGenetic Improvement (GI) of software automatically creates alternative software \nversions that are improved according to certain properties of interests (eg, running-\ntime). Search-based GI excels at navigating large program spaces, but operates\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://kclpure.kcl.ac.uk/portal/en/publications/llm-guided-genetic-improvement-envisioning-semantic-aware-automat&hl=en&sa=X&d=17522263310458421835&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b9Mrgn6Wd2hitLrRWwo4Pj-&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "An Empirical Study of Vulnerable Package Dependencies in LLM Repositories", "first_label": ["LLM"], "second_label": [], "data": "S Liu, X Hu, X Xia, D Lo, X Yang- arXiv preprint arXiv:2508.21417, 2025\nLarge language models (LLMs) have developed rapidly in recent years, \nrevolutionizing various fields. Despite their widespread success, LLMs heavily rely \non external code dependencies from package management systems, creating a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21417&hl=en&sa=X&d=14553577615445056080&ei=xv68aNvfF_fP6rQP2-GA-Qo&scisig=AAZF9b9j862ZVwGt7jgVb2PyU_Ih&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Benchmarking and Studying the LLM-based Code Review", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "Z Zeng, R Shi, K Han, Y Li, K Sun, Y Wang, Z Yu, R Xie- arXiv preprint arXiv, 2025\nAutomated Code Review (ACR) is crucial for software quality, yet existing \nbenchmarks often fail to reflect real-world complexities, hindering the evaluation of \nmodern Large Language Models (LLMs). Current benchmarks frequently focus on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01494&hl=en&sa=X&d=9924101107475937857&ei=xv68aNvfF_fP6rQP2-GA-Qo&scisig=AAZF9b9CW-Ez1-ukRHGu-p7F6_IT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "LLM-Based Program Generation for Triggering Numerical Inconsistencies Across Compilers", "first_label": ["LLM"], "second_label": ["Generation"], "data": "Y Wang, C Rubio-Gonzlez- arXiv preprint arXiv:2509.00256, 2025\nFloating-point inconsistencies across compilers can undermine the reliability of \nnumerical software. We present LLM4FP, the first framework that uses Large \nLanguage Models (LLMs) to generate floating-point programs specifically designed", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.00256&hl=en&sa=X&d=6362971429469914313&ei=xv68aNvfF_fP6rQP2-GA-Qo&scisig=AAZF9b_4FT9ZnZeCMwHPUqYhSw9g&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Token Sugar: Making Source Code Sweeter for LLMs through Token-Efficient Shorthand", "first_label": ["LLM", "Code"], "second_label": [], "data": "Z Sun, C Yang, X Du, Z Yang, L Li, D Lo\nLarge language models (LLMs) have shown exceptional performance in code \ngeneration and understanding tasks, yet their high computational costs hinder \nbroader adoption. One important factor is the inherent verbosity of programming\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://v587su.github.io/papers/SugarPaper.pdf&hl=en&sa=X&d=10071555566761971863&ei=xv68aNvfF_fP6rQP2-GA-Qo&scisig=AAZF9b_FQtP2qw0czwy-pXoKQTUa&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Human-Written vs. AI-Generated Code: A Large-Scale Study of Defects, Vulnerabilities, and Complexity", "first_label": ["Vulnerabilities", "Code", "Software Defect"], "second_label": [], "data": "D Cotroneo, C Improta, P Liguori- arXiv preprint arXiv:2508.21634, 2025\nAs AI code assistants become increasingly integrated into software development \nworkflows, understanding how their code compares to human-written programs is \ncritical for ensuring reliability, maintainability, and security. In this paper, we present \na large-scale comparison of code authored by human developers and three state-of-\nthe-art LLMs, ie, ChatGPT, DeepSeek-Coder, and Qwen-Coder, on multiple \ndimensions of software quality: code defects, security vulnerabilities, and structural\nCites: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21634&hl=en&sa=X&d=8477581447837533475&ei=xv68aNvhNfvoieoPtJ70sAg&scisig=AAZF9b-M9zrl_2Ouj3ipW3Ds0IQb&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le", "2 new citations to articles by Thanh Le-Cong", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Avaliao comparativa do desempenho de inteligncias artificiais generativas e ferramentas tradicionais na anlise de cdigo-fonte JavaScript", "first_label": [], "second_label": [], "data": "R Pimentel, CB Progetti- Simpsio Brasileiro de Segurana da Informao e de, 2025\nEstudo comparativo entre ferramentas SAST (Semgrep/SonarQube) e modelos LLM \n(DeepSeek/CodeLlama) na deteco de vulnerabilidades em JavaScript (OWASP \nJuice Shop). Resultados revelam complementaridade: SASTs alcanam 100% de \npreciso para vulnerabilidades padro (XSS/SQLi), enquanto LLMs oferecem maior \nrecall (70% no DeepSeek) para ameaas contextuais (NoSQLi/Broken Access \nControl). A taxa de 22-45% de falsos positivos em LLMs demanda estratgias de\nCites: Comparison of static application security testing tools and large", "link": "https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/sbseg_estendido/article/download/36756/36542/&hl=en&sa=X&d=11971438696651862258&ei=xv68aNvhNfvoieoPtJ70sAg&scisig=AAZF9b8NSgOQNe0ibg7Gi2jABLp4&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le", "2 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Xin ZHOU"]}
{"title": "AI-Driven Smart Contract Vulnerability Detection: A Systematic Review of Methods, Challenges, and Future Prospects", "first_label": ["Vulnerabilities", "Smart Contracts"], "second_label": ["Detection"], "data": "SAL Azzam, RAL Kolandaisamy, GAL Dharhani- Mesopotamian Journal of Big Data, 2025\nSmart contracts (SCs) have become an essential component in the world of \ndecentralized applications, automating transactions across blockchain networks \nwithout the need for intermediaries, and with this rise in adoption, the technology has \nalso brought forth growing concern due to security vulnerabilities, which have led to \nserious financial damage, and the problem is far from being solved. Traditional \nauditing methods often struggle to capture the more intricate vulnerabilities hidden\nCites: Smart contract development: Challenges and opportunities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://mesopotamian.press/journals/index.php/bigdata/article/download/893/851&hl=en&sa=X&d=12330023021292636129&ei=xv68aNvhNfvoieoPtJ70sAg&scisig=AAZF9b_7P-iu93c_o28izZTxCF_Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "Strata-Sword: A Hierarchical Safety Evaluation towards LLMs based on Reasoning Complexity of Jailbreak Instructions", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "S Zhao, R Duan, J Liu, X Jia, F Wang, C Wei, R Cheng- arXiv preprint arXiv, 2025\nLarge language models (LLMs) have gained widespread recognition for their \nsuperior comprehension and have been deployed across numerous domains. \nBuilding on Chain-of-Thought (CoT) ideology, Large Reasoning models (LRMs)", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01444&hl=en&sa=X&d=896578385661372830&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b8I5vGKeuVxp-aOZiMcDRaL&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "CCFC: Core & Core-Full-Core Dual-Track Defense for LLM Jailbreak Protection", "first_label": ["LLM"], "second_label": [], "data": "J Hu, H Wang, D Mukherjee, IC Paschalidis- arXiv preprint arXiv:2508.14128, 2025\nJailbreak attacks pose a serious challenge to the safe deployment of large language \nmodels (LLMs). We introduce CCFC (Core & Core-Full-Core), a dual-track, prompt-\nlevel defense framework designed to mitigate LLMs' vulnerabilities from prompt", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.14128%3F&hl=en&sa=X&d=11599114206454984055&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b9Gdzj9YdOMEQ2S0fYXS8oj&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks", "first_label": ["LLM"], "second_label": [], "data": "B Han, F Zhao, D Zhao, G Shen, P Wu, Y Shi, Y Zeng- arXiv preprint arXiv, 2025\nFine-tuning as service injects domain-specific knowledge into large language \nmodels (LLMs), while challenging the original alignment mechanisms and \nintroducing safety risks. A series of defense strategies have been proposed for the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.09190%3F&hl=en&sa=X&d=4598373852349660026&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b-FE-O4pS9mJhwptehdW8I-&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Automatic LLM Red Teaming", "first_label": ["LLM"], "second_label": [], "data": "R Belaire, A Sinha, P Varakantham- arXiv preprint arXiv:2508.04451, 2025\nRed teaming is critical for identifying vulnerabilities and building trust in current \nLLMs. However, current automated methods for Large Language Models (LLMs) rely \non brittle prompt templates or single-turn attacks, failing to capture the complex", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.04451%3F&hl=en&sa=X&d=2257827261327917536&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b_g0uCpzSGEd0WDaskjDUbX&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "When AIOps Become\" AI Oops\": Subverting LLM-driven IT Operations via Telemetry Manipulation", "first_label": ["LLM"], "second_label": [], "data": "D Pasquini, EM Kornaropoulos, G Ateniese, O Akgul- arXiv preprint arXiv, 2025\nAI for IT Operations (AIOps) is transforming how organizations manage complex \nsoftware systems by automating anomaly detection, incident diagnosis, and \nremediation. Modern AIOps solutions increasingly rely on autonomous LLM-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.06394&hl=en&sa=X&d=3305610682736444973&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b9VIvh1YIWaVZu12q2YDMRD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "In-Training Defenses against Emergent Misalignment in Language Models", "first_label": ["LLM"], "second_label": [], "data": "D Kaczr, M Jrgenvg, C Vetter, L Flek, F Mai- arXiv preprint arXiv:2508.06249, 2025\nFine-tuning lets practitioners repurpose aligned large language models (LLMs) for \nnew domains, yet recent work reveals emergent misalignment (EMA): Even a small, \ndomain-specific fine-tune can induce harmful behaviors far outside the target", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.06249%3F&hl=en&sa=X&d=2848574234538730362&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b_Lcm2qHmGdjcK978cplr7k&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Oyster-I: Beyond Refusal--Constructive Safety Alignment for Responsible Language Models", "first_label": ["LLM"], "second_label": [], "data": "R Duan, J Liu, X Jia, S Zhao, R Cheng, F Wang, C Wei- arXiv preprint arXiv, 2025\nLarge language models (LLMs) typically deploy safety mechanisms to prevent \nharmful content generation. Most current approaches focus narrowly on risks posed \nby malicious actors, often framing risks as adversarial events and relying on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01909&hl=en&sa=X&d=6590160868100905669&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b_ezPamqt6bxzEfPBipWSm1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards", "first_label": ["LLM"], "second_label": ["Agent"], "data": "X Wei, B Lu, X Zhang, Z Zhao, D Shen, L Xia, D Yin- arXiv preprint arXiv:2508.21476, 2025\nLarge Language Models (LLMs) have demonstrated remarkable creative writing \ncapabilities, yet their substantial computational demands hinder widespread use. \nEnhancing Small Language Models (SLMs) offers a promising alternative, but", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21476&hl=en&sa=X&d=16045680670429217257&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b8TCftu59j3-3zvJyKGC7dF&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Attacks and Defenses Against LLM Fingerprinting", "first_label": ["LLM"], "second_label": [], "data": "K Kurian, E Holland, S Oesch- arXiv preprint arXiv:2508.09021, 2025\nAs large language models are increasingly deployed in sensitive environments, \nfingerprinting attacks pose significant privacy and security risks. We present a study \nof LLM fingerprinting from both offensive and defensive perspectives. Our attack\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.09021%3F&hl=en&sa=X&d=11346875403769852401&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b80TL_tYih6TYkyzlWZHNot&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "WFC/WFD: Web Fuzzing Commons, Dataset and Guidelines to Support Experimentation in REST API Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "O Sahin, M Zhang, A Arcuri- arXiv preprint arXiv:2509.01612, 2025\nFuzzing REST APIs is an important research problem, with practical applications and \nimpact in industry. As such, a lot of research work has been carried out on this topic \nin the last few years. However, there are three major issues that hinder further", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01612&hl=en&sa=X&d=15816350851778106621&ei=yP68aLnjL-KIieoPnLqQyAQ&scisig=AAZF9b-S2JCSg3XJhjkuUNrlz4x7&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "10 new citations to articles by Abhik Roychoudhury", "Abhik Roychoudhury - new related research"]}
{"title": "Automated Bug Triaging using Instruction-Tuned Large Language Models", "first_label": ["LLM", "Bug"], "second_label": [], "data": "K Kiashemshaki, A Khosravani, A Hosseinpour- arXiv preprint arXiv, 2025\nBug triaging, the task of assigning new issues to developers, is often slow and \ninconsistent in large projects. We present a lightweight framework that instruction-\ntuned large language model (LLM) with LoRA adapters and uses candidate", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21156&hl=en&sa=X&d=2172606231080988528&ei=yP68aLnjL-KIieoPnLqQyAQ&scisig=AAZF9b_ky7wXlxHsyUsXzgeZukqK&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Wit-HW: Bug Localization in Hardware Design Code via Witness Test Case Generation", "first_label": ["Code", "Bug", "Software Testing"], "second_label": ["Generation", "Localization"], "data": "R Ma, D Kuang, Z Liu, J Zhang, P Fan, G Luo- arXiv preprint arXiv:2508.14414, 2025\nDebugging hardware designs requires significant manual effort during hardware \ndevelopment. After engineers identify a bug-triggering test case in simulation-based \nhardware verification, they usually spend considerable time analyzing the execution", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.14414&hl=en&sa=X&d=16419987568237253552&ei=yP68aLnjL-KIieoPnLqQyAQ&scisig=AAZF9b9FQ07vmTOCd9OcmFcv6_Gi&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Locus: Agentic Predicate Synthesis for Directed Fuzzing", "first_label": ["Fuzzing"], "second_label": ["Agent"], "data": "J Zhu, C Shen, Z Li, J Yu, Y Chen, K Pei- arXiv preprint arXiv:2508.21302, 2025\nDirected fuzzing aims to find program inputs that lead to specified target program \nstates. It has broad applications, such as debugging system crashes, confirming \nreported bugs, and generating exploits for potential vulnerabilities. This task is", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21302&hl=en&sa=X&d=2138932734315377454&ei=yP68aLnjL-KIieoPnLqQyAQ&scisig=AAZF9b9iXz21pxlN8QAQ_QbeooKc&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Shaking Up Quantum Simulators with Fuzzing and Rigour", "first_label": ["Fuzzing"], "second_label": [], "data": "V Klimis- Proceedings of the Conference on Object-Oriented, 2025\nQuantum computing platforms rely on simulators for modelling circuit behaviour prior \nto hardware execution, where inconsistencies can lead to costly errors. While \nexisting formal validation methods typically target specific compiler components to\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/110396/Klimis%2520Shaking%2520Up%2520Quantum%2520Simulators%2520with%2520Fuzzing%2520and%2520Rigour%25202025%2520Accepted.pdf%3Fsequence%3D2&hl=en&sa=X&d=5527035386124790821&ei=yP68aLnjL-KIieoPnLqQyAQ&scisig=AAZF9b80cRKCwibL_hONzlSQKdaw&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Advanced Smart Contract Vulnerability Detection via LLM-Powered Multi-Agent Systems", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection", "Agent"], "data": "Z Wei, J Sun, Y Sun, Y Liu, D Wu, Z Zhang, X Zhang- IEEE Transactions on, 2025\nBlockchain's inherent immutability, while transformative, creates critical security risks \nin smart contracts, where undetected vulnerabilities can result in irreversible financial \nlosses. Current auditing tools and approaches often address specific vulnerability", "link": "https://scholar.google.com/scholar_url?url=http://daoyuan14.github.io/papers/TSE25_LLM-SmartAudit.pdf&hl=en&sa=X&d=8638183047541502664&ei=yP68aOGTJPfP6rQP2-GA-Qo&scisig=AAZF9b8v_J-cP7-n2rnam8LynLRR&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "CoreThink: A Symbolic Reasoning Layer to reason over Long Horizon Tasks with LLMs", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "J Vaghasiya, O Ghugarkar, V Bhat, V Dholaria- arXiv preprint arXiv, 2025\nWe introduce CoreThink, a state-of-the-art Reasoning Layer built upon a novel \nreasoning method called General Symbolics. This approach diverges from reasoning \nparadigms such as test-time scaling, Supervised Fine-Tuning (SFT), and \nReinforcement Learning with Verifiable Rewards (RLVR). CoreThink General \nSymbolic Reasoner (GSR) is specifically structured around three key use cases: tool-\ncalling, code generation, and planning, demonstrating exemplary performance\nCites: Surveying neuro-symbolic approaches for reliable artificial", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.00971&hl=en&sa=X&d=253240008306322840&ei=xv68aPv7Jp6s6rQP_Izu4Q0&scisig=AAZF9b8YC0I5jUP3UwA8gr77yxL0&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["4 new citations to articles by Hong Jin Kang"]}
{"title": "Neuro-Symbolic Methods for Times Series Analysis for Edge Computing", "first_label": [], "second_label": [], "data": "A Pacheco, M Rivera, E Flores, R Torres, R Chacon - 2025\nThis chapter explores methodologies for time series analysis based on the Neuro-\nsymbolic Artificial Intelligence paradigm, combining pattern recognition, knowledge \nrepresentation, and logical reasoning abilities to improve the effectiveness and \nverification of AI applications. Despite its promise, Neuro-symbolic AI is still in its \nearly stages and lacks widespread adoption. Taxonomies play a critical role in \norganizing this field, providing conceptual frameworks that help researchers\nCites: Surveying neuro-symbolic approaches for reliable artificial", "link": "https://scholar.google.com/scholar_url?url=https://www.intechopen.com/online-first/1225695&hl=en&sa=X&d=10619964232039270385&ei=xv68aPv7Jp6s6rQP_Izu4Q0&scisig=AAZF9b-GKpDssgkNyEC-AU5I18xM&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["4 new citations to articles by Hong Jin Kang"]}
{"title": "Towards Responsible AI through NeuroSymbolic Integration: A Survey", "first_label": [], "second_label": [], "data": "AI Weinberg, K Cohen - 2025\nThis paper explores how NeuroSymbolic (NeSy) approacheshybrid systems that \ncombine neural networks with symbolic reasoningcan enhance key dimensions of \nResponsible Artificial Intelligence (RAI), including transparency, fairness, robustness, \nand human-centered design. While deep learning models often lack interpretability \nand ethical alignment, NeSy systems offer structured reasoning, explainable \ndecision-making, and verifiable constraint enforcement. Uniquely, this paper\nCites: Surveying neuro-symbolic approaches for reliable artificial\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Abraham-Weinberg/publication/395129655_Towards_Responsible_AI_through_NeuroSymbolic_Integration_A_Survey/links/68b55e69360112563e0f9fdd/Towards-Responsible-AI-through-NeuroSymbolic-Integration-A-Survey.pdf&hl=en&sa=X&d=875708866933953987&ei=xv68aPv7Jp6s6rQP_Izu4Q0&scisig=AAZF9b8u9toDKn-oCJJlGpzea4iw&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=3&folt=cit", "author": ["Hong Jin Kang"], "ref": ["4 new citations to articles by Hong Jin Kang"]}
{"title": "Scalable Thread-Safety Analysis of Java Classes with CodeQL", "first_label": ["Code"], "second_label": [], "data": "BH Jtten, SB Jrgensen, R Petersen, R Pardo- arXiv preprint arXiv:2509.02022, 2025\nIn object-oriented languages software developers rely on thread-safe classes to \nimplement concurrent applications. However, determining whether a class is thread-\nsafe is a challenging task. This paper presents a highly scalable method to analyze \nthread-safety in Java classes. We provide a definition of thread-safety for Java \nclasses founded on the correctness principle of the Java memory model, data race \nfreedom. We devise a set of properties for Java classes that are proven to ensure\nCites: Selectively Uniform Concurrency Testing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.02022&hl=en&sa=X&d=13350781536613733323&ei=x_68aPztFLWR6rQPyczN4AQ&scisig=AAZF9b99OYKD6ckdbzQbLp49qaI_&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Automated Generation of Issue-Reproducing Tests by Combining LLMs and Search-Based Testing", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation", "Search"], "data": "K Kitsios, M Castelluccio, A Bacchelli- arXiv preprint arXiv:2509.01616, 2025\nIssue-reproducing tests fail on buggy code and pass once a patch is applied, thus \nincreasing developers' confidence that the issue has been resolved and will not be \nre-introduced. However, past research has shown that developers often commit \npatches without such tests, making the automated generation of issue-reproducing \ntests an area of interest. We propose BLAST, a tool for automatically generating \nissue-reproducing tests from issue-patch pairs by combining LLMs and search\nCites: AutoCodeRover: Autonomous program improvement", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01616&hl=en&sa=X&d=7662112283941476702&ei=x_68aPztFLWR6rQPyczN4AQ&scisig=AAZF9b-fTfxp7oa_qkRHNK5lFZpA&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Quang-Cuong Bui - new related research"]}
{"title": "A Contemporary Survey of Large Language Model Assisted Program Analysis", "first_label": ["LLM"], "second_label": [], "data": "J Wang, T Ni, WB Lee, Q Zhao- Transactions on Artificial Intelligence, 2025\nThe increasing complexity of software systems has driven significant advancements \nin program analysis, as traditional methods are unable to meet the demands of \nmodern software development. To address these limitations, deep learning \ntechniques, particularly Large Language Models (LLMs), have gained attention due \nto their context-aware capabilities in code comprehension. Recognizing the potential \nof LLMs, researchers have extensively explored their application in program analysis\nCites: Large language model guided protocol fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://www.sciltp.com/journals/tai/articles/2505000685&hl=en&sa=X&d=9976958458677084056&ei=x_68aPztFLWR6rQPyczN4AQ&scisig=AAZF9b-2X6b0-ttOl4JtqeNz6pii&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Automobile Intelligent Controls: A Comprehensive Review", "first_label": [], "second_label": [], "data": "Z Weiya, GZ Kai- 2025 IEEE Symposium on Industrial Electronics &, 2025\nThe rapid development of embedded systems has significantly transformed the \nautomotive industry. With the rise of wireless communication, smart sensors, and AI, \nembedded systems are crucial for enhancing vehicle performance and safety. This \npaper provides a thorough investigation into the current advancements in automobile-\nembedded controls and identifies challenges faced in the field. Some of the most \nsignificant advancements are ARM7-based airbag systems for low-cost accident\nCites: On testing embedded software", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11138426/&hl=en&sa=X&d=1672811103612883876&ei=x_68aPztFLWR6rQPyczN4AQ&scisig=AAZF9b_VvOVF0VaLCMY-4YBO0ASt&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Advancement of HTTP and Security Issues Over It", "first_label": [], "second_label": [], "data": "NN Dwivedi, D Singh\nNow days so many organizations are focusing that how to improve http and security \nrelated problem over it. The new protocol, HTTP/2, has most popular in the web \nindustry as its typical information was confirmed and accepted earlier few years. \nMany of its technical structures are derived from the Google application-based \nprotocol, HTTP/2 solves many bugs and variations of HTTP/1.1, improving web \nperformance during page loading times. Expected. HTTP/2 introduces topic\nCites: Detecting energy bugs and hotspots in mobile apps\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.tejasjournals.com/Papers/2025/03/TJTHS-0403-002.pdf&hl=en&sa=X&d=9002435591097519327&ei=x_68aPztFLWR6rQPyczN4AQ&scisig=AAZF9b9b4jVN_5sHbG-qTMv90w1s&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=9&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "GRAM-R $^ 2$: Self-Training Generative Foundation Reward Models for Reward Reasoning", "first_label": [], "second_label": ["Reasoning"], "data": "C Wang, Y Mu, H Zhou, Y Huo, Z Zhu, J Zeng, M Yang- arXiv preprint arXiv, 2025\nSignificant progress in reward modeling over recent years has been driven by a \nparadigm shift from task-specific designs towards generalist reward models. Despite \nthis trend, developing effective reward models remains a fundamental challenge: the \nheavy reliance on large-scale labeled preference data. Pre-training on abundant \nunlabeled data offers a promising direction, but existing approaches fall short of \ninstilling explicit reasoning into reward models. To bridge this gap, we propose a self\nCites: Codeultrafeedback: An llm-as-a-judge dataset for aligning large", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.02492&hl=en&sa=X&d=2685845414329502017&ei=yP68aLD5C4XR6rQPlLfCsQ8&scisig=AAZF9b-mrIGUqIlnQaB3qv3qMf3_&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks", "first_label": ["LLM"], "second_label": ["Search"], "data": "H Wan, C Yang, J Yu, M Tu, J Lu, D Yu, J Cao, B Gao- arXiv preprint arXiv, 2025\nDeep research agents have attracted growing attention for their potential to \norchestrate multi-stage research workflows, spanning literature synthesis, \nmethodological design, and empirical verification. Despite these strides, evaluating \ntheir research capability faithfully is rather challenging due to the difficulty of \ncollecting frontier research questions that genuinely capture researchers' attention \nand intellectual curiosity. To address this gap, we introduce DeepResearch Arena, a\nCites: LessLeak-Bench: A First Investigation of Data Leakage in LLMs", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01396&hl=en&sa=X&d=15455967310149889969&ei=yP68aLD5C4XR6rQPlLfCsQ8&scisig=AAZF9b9Cen7EYpR12FOXThd6aoud&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "MDPMORPH: An MDP-Based Metamorphic Testing Framework for Deep Reinforcement Learning Agents", "first_label": ["Software Testing"], "second_label": ["Agent"], "data": "J Li, Z Zheng, Y Xing, D Ren, S Cho, V Terragni\nDeep Reinforcement Learning (DRL) systems are widely used across various \ndomains. However, testing these systems presents significant challenges. The DRL \nagent, which serves as the core decision-maker, generates continuous value \nestimates rather than discrete labels and operates under nonstationary policies \nwithin complex and stochastic environments. Consequently, there is no definitive \ncorrect answer for each state-action pair, complicating automated test generation\nCites: Curiosity-driven testing for sequential decision-making process", "link": "https://scholar.google.com/scholar_url?url=https://valerio-terragni.github.io/assets/pdf/li-issre-2025.pdf&hl=en&sa=X&d=11908862816750347491&ei=yP68aLD5C4XR6rQPlLfCsQ8&scisig=AAZF9b8FHOsMn8c4xLUnrQKTZ7Mx&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "Private, Verifiable, and Auditable AI Systems", "first_label": [], "second_label": [], "data": "T South- arXiv preprint arXiv:2509.00085, 2025\nThe growing societal reliance on artificial intelligence necessitates robust \nframeworks for ensuring its security, accountability, and trustworthiness. This thesis \naddresses the complex interplay between privacy, verifiability, and auditability in \nmodern AI, particularly in foundation models. It argues that technical solutions that \nintegrate these elements are critical for responsible AI innovation. Drawing from \ninternational policy contributions and technical research to identify key risks in the AI\nCites: Llm agents can autonomously hack websites, 2024", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.00085&hl=en&sa=X&d=14343213836759072369&ei=xv68aJGHCPmI6rQP1e7wmQQ&scisig=AAZF9b-JMx3l6Rx1JgATaoEwRCOG&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "A Whole New World: Creating a Parallel-Poisoned Web Only AI-Agents Can See", "first_label": [], "second_label": ["Agent"], "data": "S Zychlinski- arXiv preprint arXiv:2509.00124, 2025\nThis paper introduces a novel attack vector that leverages website cloaking \ntechniques to compromise autonomous web-browsing agents powered by Large \nLanguage Models (LLMs). As these agents become more prevalent, their unique and \noften homogenous digital fingerprints-comprising browser attributes, automation \nframework signatures, and network characteristics-create a new, distinguishable \nclass of web traffic. The attack exploits this fingerprintability. A malicious website can\nCites: Llm agents can autonomously hack websites, 2024\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.00124&hl=en&sa=X&d=12002829683849877755&ei=xv68aJGHCPmI6rQP1e7wmQQ&scisig=AAZF9b9fZTLcHqX5d7AaOCr2Ebbp&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Software Engineering in the Era of Intelligence, Security, and Automation", "first_label": [], "second_label": [], "data": "S Aftab - 2025\nSoftware Engineering (JSE) as an academic platform dedicated to advancing \nresearch and innovation across the full spectrum of software engineering. The \njournal aims to create an inclusive and high-quality space for contributions that span", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Shabib-Aftab-2/publication/395107678_Software_Engineering_in_the_Era_of_Intelligence_Security_and_Automation/links/68b37e563391fb1a7a4c6087/Software-Engineering-in-the-Era-of-Intelligence-Security-and-Automation.pdf&hl=en&sa=X&d=5156508072237023278&ei=x_68aPa7L4zSieoP3YSb4Q4&scisig=AAZF9b_snamPPxcBt904-5TN2Pcl&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Leveraging SystemC-TLM-based Virtual Prototypes for Embedded Software Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "C Ghinami, J Winzer, N Bosbach, LM Reimann- arXiv preprint arXiv, 2025\nSystemC-based virtual prototypes have emerged as widely adopted tools to test \nsoftware ahead of hardware availability, reducing the time-to-market and improving \nsoftware reliability. Recently, fuzzing has become a popular method for automated", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01318&hl=en&sa=X&d=1341175212014518141&ei=x_68aPa7L4zSieoP3YSb4Q4&scisig=AAZF9b9xqbJnzFJ8oCl2uemQ46wF&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
