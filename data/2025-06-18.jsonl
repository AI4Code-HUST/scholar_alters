{"title": "Visualization Task Taxonomy to Understand the Fuzzing Internals", "first_label": ["Fuzzing"], "second_label": [], "data": "S Kummita, M Miao, E Bodden, S Wei\\xc2\\xa0- ACM Transactions on Software Engineering\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGreybox fuzzing is used extensively in research and practice. There are umpteen \npublications that improve greybox fuzzing. However, to what extent do these \nimprovements affect the internal components or internals of a given fuzzer is not yet\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3718346&hl=en&sa=X&d=6310038100822609560&ei=cttQaLfLJte5ieoP1rfqmQU&scisig=AAZF9b_Ue_jmzHRI425oDGHolQub&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "KRAKEN: Program-Adaptive Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A ZHOU, H HUANG, C ZHANG - 2025\nDespite numerous advances, most existing fuzzers still require more than 24 hours to \nthoroughly test the target programs to achieve satisfactory code coverage or bug \ndetection results [7, 32, 42, 64]. Recently, as cloud-based computing and multicore\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://seviezhou.github.io/files/kraken.pdf&hl=en&sa=X&d=6944396394299119143&ei=cttQaLfLJte5ieoP1rfqmQU&scisig=AAZF9b9QILhkfV1b1x87AW8NkoEo&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Fuzzing Graph Database Applications with Graph Transformations", "first_label": ["Fuzzing"], "second_label": ["Graph"], "data": "S Dumbrava, MWM Oudemans, B Kulahcioglu Ozkan\\xc2\\xa0- International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGraph databases have surged in popularity, and applications increasingly employ \nthem to store and retrieve interconnected data. However, testing graph database-\nbacked applications has distinctive challenges. Due to the sheer dimension of the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-94706-3_7&hl=en&sa=X&d=17411223200189550748&ei=cttQaLfLJte5ieoP1rfqmQU&scisig=AAZF9b9hC_iu-fBtu3ntJrcVfGlm&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Leveraging activation and optimisation layers as dynamic strategies in the multi-task fuzzing scheme", "first_label": ["Fuzzing"], "second_label": [], "data": "S Bamohabbat Chafjiri, P Legg, MA Tsompanas\\xe2\\x80\\xa6 - 2025\nFuzzing is a common technique for identifying vulnerabilities in software. Recent \napproaches, like She et al.'s Multi-Task Fuzzing (MTFuzz), use neural networks to \nimprove fuzzing efficiency. However, key elements like network architecture and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1016/j.csi.2025.104011&hl=en&sa=X&d=18210490462320417689&ei=cttQaLfLJte5ieoP1rfqmQU&scisig=AAZF9b-SniAFgKPoPY_eeSgA0SFX&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift", "first_label": ["LLM"], "second_label": [], "data": "S Liang, J Liang, T Pang, C Du, A Liu, M Zhu, X Cao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInstruction tuning enhances large vision-language models (LVLMs) but increases \ntheir vulnerability to backdoor attacks due to their open design. Unlike prior studies in \nstatic settings, this paper explores backdoor attacks in LVLM instruction tuning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.pdf&hl=en&sa=X&d=5142527777954789704&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b_Zz7b9xsyiBVRqo7nDX3YO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, M Dras, U Naseem\\xc2\\xa0- arXiv preprint arXiv:2506.02442, 2025\nThis paper presents a systematic evaluation of Large Language Models'(LLMs) \nbehavior on long-tail distributed (encrypted) texts and their safety implications. We \nintroduce a two-dimensional framework for assessing LLM safety:(1) instruction\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02442&hl=en&sa=X&d=15102350404536711280&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b_4gGVOvmiHUrKGvn2E4Vhh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Evaluatiing the efficacy of LLM Safety Solutions: The Palit Benchmark Dataset", "first_label": ["LLM"], "second_label": [], "data": "S Palit, D Woods\\xc2\\xa0- arXiv preprint arXiv:2505.13028, 2025\nLarge Language Models (LLMs) are increasingly integrated into critical systems in \nindustries like healthcare and finance. Users can often submit queries to LLM-\nenabled chatbots, some of which can enrich responses with information retrieved\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13028%3F&hl=en&sa=X&d=1273460049730580919&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b9ByON4eaZyjRTpM1-cA_zU&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents", "first_label": ["LLM", "Code"], "second_label": ["Agent", "Reasoning"], "data": "K Hariharan, U Girit, A Wang, J Andreas\\xc2\\xa0- arXiv preprint arXiv:2506.00172, 2025\nBenchmarks for large language models (LLMs) have predominantly assessed short-\nhorizon, localized reasoning. Existing long-horizon suites (eg SWE-bench) rely on \nmanually curated issues, so expanding or tuning difficulty demands expensive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00172&hl=en&sa=X&d=7723120566071680437&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b-MEatAoZUO5Dw1f9NQmtaH&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Ip leakage attacks targeting llm-based multi-agent systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Wang, W Wang, S Wang, Z Li, Z Ji, Z Lyu, D Wu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Large Language Models (LLMs) has led to the \nemergence of Multi-Agent Systems (MAS) to perform complex tasks through \ncollaboration. However, the intricate nature of MAS, including their architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12442&hl=en&sa=X&d=8825331941370095164&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b_j6hKF2Zy8dNMOx-tobM6E&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "first_label": ["LLM"], "second_label": [], "data": "G Chen, F Song, Z Zhao, X Jia, Y Liu, Y Qiao, W Zhang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreak attacks to Large audio-language models (LALMs) are studied recently, but \nthey achieve suboptimal effectiveness, applicability, and practicability, particularly, \nassuming that the adversary can fully manipulate user prompts. In this work, we first\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14103&hl=en&sa=X&d=12355582258955555442&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b84twuHlVXU1hPFciKO3AfT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Securing AI Agents with Information-Flow Control", "first_label": [], "second_label": ["Agent"], "data": "M Costa, B K\\xc3\\xb6pf, A Kolluri, A Paverd, M Russinovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI agents become increasingly autonomous and capable, ensuring their security \nagainst vulnerabilities such as prompt injection becomes critical. This paper explores \nthe use of information-flow control (IFC) to provide security guarantees for AI agents\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23643%3F&hl=en&sa=X&d=4534448032257376326&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b-ruPZ7fbYUs0K6HirRZr2z&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Words reveal wants: How well can simple LLM-based AI agents replicate people's choices based on their social media posts", "first_label": ["LLM"], "second_label": ["Agent"], "data": "S Goethals, J Luther, S Matz\\xc2\\xa0- Adjunct Proceedings of the 33rd ACM Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs artificial intelligence systems take on increasingly agentic roles, they begin \nmaking decisions on behalf of users rather than merely supporting them. \nConsequently, it becomes crucial to understand how closely these systems can\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3708319.3733689&hl=en&sa=X&d=2217390685673034747&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b9SWHaYFGLzkiYnbHT29Ug6&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Shots to Stories: LLM-Assisted Video Editing with Unified Language Representations", "first_label": ["LLM"], "second_label": [], "data": "Y Li, H Xu, F Tian\\xc2\\xa0- arXiv preprint arXiv:2505.12237, 2025\nLarge Language Models (LLMs) and Vision-Language Models (VLMs) have \ndemonstrated remarkable reasoning and generalization capabilities in video \nunderstanding; however, their application in video editing remains largely\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12237&hl=en&sa=X&d=10505763597250854428&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b90gQPI6R4RwX9k19MeWwCR&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents", "first_label": [], "second_label": ["Agent", "Reasoning"], "data": "X Yu, B Peng, R Xu, M Galley, H Cheng, S Nath, J Gao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent progress in reasoning with large language models (LLMs), such as \nDeepSeek-R1, demonstrates impressive capabilities in domains like mathematics \nand coding, by exhibiting complex cognitive behaviors such as verification, goal\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00320&hl=en&sa=X&d=5278749394870424961&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b9b-0jt4alWRaYfXuIUsA9R&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Multi-source cross-domain vulnerability detection based on code pre-trained model", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "Y Cao, Y Dong\\xc2\\xa0- Information and Software Technology, 2025\nContext: In recent years, deep learning-based vulnerability detection methods have \nachieved significant success. These methods predict vulnerabilities by automatically \nlearning patterns from code annotated with vulnerability information. However\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S095058492500103X&hl=en&sa=X&d=15955544814733929240&ei=cttQaPLeH9SWieoP89D1uAI&scisig=AAZF9b81Qmv0jwO9frlyKQ4ruxkr&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Zheng, X Qian, H Zhou, S Yang, Y He, S Jana\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models (LMs) show promise for vulnerability detection but struggle with \nlong, real-world code due to sparse and uncertain vulnerability locations. These \nissues, exacerbated by token limits, often cause models to miss vulnerability-related\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17460&hl=en&sa=X&d=9334848497739178959&ei=cttQaJ-yHs6r6rQP0M7u0Ao&scisig=AAZF9b_EDz61GJXVBfE-c2mGro5g&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Debugging and Help-Seeking With Chatbots in CS1", "first_label": ["Bug"], "second_label": [], "data": "S Yang - 2025\nFor many beginner programmers, encountering errors in code can be frustrating and \ndisheartening\\xe2\\x80\\x94leading some to questions their belonging in computer science (CS). \nIn these moments, timely debugging help is essential to sustain motivation and foster \nlearning. While students have traditionally turned to peers or teaching assistants for \nguidance, many now seek debugging support from conversational Large Language \nModels (LLMs). These chatbots offer promise in providing immediate help, but their\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/44ea4f2adeb64e8bf54209dfbae38a5c/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=en&sa=X&d=17651482257810592070&ei=cttQaK2hJau26rQPmILk4AI&scisig=AAZF9b8bwrhTgzrfX4-sFKJVqHC1&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": "GAL-KARS: Exploiting LLMs for Graph Augmentation in Knowledge-Aware Recommender Systems", "first_label": ["LLM"], "second_label": ["Exploit", "Graph"], "data": "G Spillo, C Musto, M Mannavola, M de Gemmis, P Lops\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 33rd\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn this paper, we propose a recommendation model that exploits a graph \naugmentation technique based on Large Language Models (LLMs) to enrich the \ninformation encoded in its underlying Knowledge Graph (KG). Our work relies on the \nassumption that the triples encoded in a KG can often be noisy or incomplete, and \nthis may lead to sub-optimal modeling of both the characteristics of items and the \nusers' preferences. In this setting, graph augmentation can be a suitable solution to\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLessLeak-Bench: A First Investigation of Data Leakage in LLMs\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3699682.3728342&hl=en&sa=X&d=1949338591660211917&ei=cttQaKS7LO2rieoPnJq6oQ8&scisig=AAZF9b_8SRhBfjt4RVj4nSQqrZnI&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "From Theory to Practice: Code Generation Using LLMs for CAPEC and CWE Frameworks", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "M Shahzad, J Wilson, I Al Azher, H Alhoori, M Rahimi\\xc2\\xa0- 2025 IEEE/ACM International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe increasing complexity and volume of software systems have heightened the \nimportance of identifying and mitigating security vulnerabilities. The existing software \nvulnerability datasets frequently fall short in providing comprehensive, detailed code \nsnippets explicitly linked to specific vulnerability descriptions, reducing their utility for \nadvanced research and hindering efforts to develop a deeper understanding of \nsecurity vulnerabilities. To address this challenge, we present a novel dataset that\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection and repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/llm4code/2025/261500a137/27uerFwNhrq&hl=en&sa=X&d=13790469415771046125&ei=cttQaKS7LO2rieoPnJq6oQ8&scisig=AAZF9b-PmjBmccmRY4bcIsgYoBhC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "An LLM Agent for Functional Bug Detection in Network Protocols", "first_label": ["LLM", "Bug"], "second_label": ["Detection", "Agent"], "data": "M Zheng, C Wang, X Liu, J Guo, S Feng, X Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.00714, 2025\nFunctional correctness is critical for ensuring the reliability and security of network \nprotocol implementations. Functional bugs, instances where implementations \ndiverge from behaviors specified in RFC documents, can lead to severe\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00714&hl=en&sa=X&d=14025741833580725532&ei=cttQaIa6L_uvieoPlKmY8Ag&scisig=AAZF9b8vkBixnPr2fRq2ZYFDK47O&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Leveraging LLM Enhanced Commit Messages to Improve Machine Learning Based Test Case Prioritization", "first_label": ["LLM", "Commit Message", "Software Testing"], "second_label": [], "data": "Y Mahmoud, A Azim, R Liscano, K Smith, YK Chang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 21st\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn the rapidly evolving landscape of software development, software testing is critical \nfor maintaining code quality and reducing defects. Effective test case prioritization \nemploys techniques to identify defects early and ensure software quality. New\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3727582.3728681&hl=en&sa=X&d=2338002588478877175&ei=cttQaIa6L_uvieoPlKmY8Ag&scisig=AAZF9b9ZZdQSJWoVODzmMybSzj_D&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "End-User Customization of Trigger-Action Rules Through Fine-Tuned LLMs", "first_label": ["LLM"], "second_label": [], "data": "G Cimino, V Deufemia\\xc2\\xa0- International Symposium on End User Development, 2025\nAbstract While Trigger-Action Platforms (TAPs) provide an effective solution for end-\nusers to automate interactions between smart devices and online services through \ncustomizable rules, their flexibility is often limited by restricted access to source code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-95452-8_2&hl=en&sa=X&d=2148692169908663268&ei=cttQaMGjIqalieoPsZriwAs&scisig=AAZF9b_Mv7kTvNKKktKs_aihUb5T&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "SURVIVING GENERATIVE AI: TEMPORAL TRAJECTORY OF RESILIENCE IN STACK OVERFLOW AND GITHUB", "first_label": [], "second_label": [], "data": "D Scholtz, A Griva, K Conboy\\xc2\\xa0- LMDE 2025 CONFERENCE\nPlatforms such as Stack Overflow and GitHub serve as the lifeblood for global \nknowledge exchange for software development, yet they face profound challenges \nfrom emerging technologies like Generative AI (GAI) that accelerate knowledge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://lmde.net/images/BoA_LMDE_2025.pdf%23page%3D311&hl=en&sa=X&d=10770644147813442473&ei=cttQaMGjIqalieoPsZriwAs&scisig=AAZF9b_lXpdds-L9OhASwo3GMSLr&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Access Control Modeling and Validation for Ethereum Smart Contracts", "first_label": ["Smart Contracts", "Ethereum"], "second_label": [], "data": "I Achour, H Idoudi, S Ayed\\xc2\\xa0- Concurrency and Computation: Practice and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSmart contracts are self\\xe2\\x80\\x90executing programs that operate on a blockchain network. \nThey are designed to automate transaction execution without the need for \nintermediaries. Once deployed in the blockchain network, smart contracts cannot be\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.70108&hl=en&sa=X&d=6638502576514252848&ei=cttQaMGjIqalieoPsZriwAs&scisig=AAZF9b9ZwDFro6wpA1J_m2o9u6lg&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A Neuro-Symbolic Artificial Intelligence and Zero-Knowledge Blockchain Framework for a Patient-Owned Digital-Twin Marketplace in US Value-Based Care.", "first_label": ["Blockchain"], "second_label": [], "data": "YT Adeshina\nAs the US healthcare system shifts toward value-based care, there is a growing need \nfor patient-centered technologies that ensure data ownership, interoperability, and \ntrust. This paper proposes a novel framework integrating neuro-symbolic artificial \nintelligence (AI) and zero-knowledge (ZK) blockchain to enable a secure, scalable, \nand ethically grounded digital-twin marketplace for patient data. The goal is to \nempower individuals to own and control their health digital twins\\xe2\\x80\\x94comprehensive\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSurveying neuro-symbolic approaches for reliable artificial\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Taofeek-Yusuff/publication/392626529_A_Neuro-Symbolic_Artificial_Intelligence_and_Zero-Knowledge_Blockchain_Framework_for_a_Patient-Owned_Digital-Twin_Marketplace_in_US_Value-Based_Care/links/684b1bc4bc28f5215e941f0f/A-Neuro-Symbolic-Artificial-Intelligence-and-Zero-Knowledge-Blockchain-Framework-for-a-Patient-Owned-Digital-Twin-Marketplace-in-US-Value-Based-Care.pdf&hl=en&sa=X&d=4356628560497418595&ei=cttQaNH-IKKr6rQPx5XhkQQ&scisig=AAZF9b9LRdSlHcVvibowhC6tkQpU&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["1 new citation to articles by Hong Jin Kang"]}
{"title": "Generative AI for Industry Transformation: A Systematic Review of ChatGPT's Capabilities and Integration Challenges", "first_label": ["LLM"], "second_label": [], "data": "S Salih, O Husain, EAM Abdalla, AO Ibrahim\\xe2\\x80\\xa6\\xc2\\xa0- International Journal of\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Generative Artificial Intelligence (GAI), particularly \nOpenAI's ChatGPT, has significantly transformed various industries by enhancing \nefficiency, reducing operational costs, and fostering innovation. This systematic \nreview explores the applications and integration challenges of ChatGPT across six \nkey sectors: tourism and travel, banking and finance, construction, software solutions, \nsupply chain and transportation, and digital marketing and social media. The findings\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://koreascience.kr/article/JAKO202516439602807.pdf&hl=en&sa=X&d=7842693449860769807&ei=jH1PaLCsHeWs6rQPhLia-QI&scisig=AAZF9b8r8FyRKkBEcWv2hZcwt4z0&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 new citations to articles by Thanh Le-Cong", "5 new citations to articles by Bach Le"]}
{"title": "Mapping NVD Records to Their VFCs: How Hard is it?", "first_label": [], "second_label": [], "data": "HH Nguyen, DM Tran, Y Cheng, T Le-Cong, HJ Kang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMapping National Vulnerability Database (NVD) records to vulnerability-fixing \ncommits (VFCs) is crucial for vulnerability analysis but challenging due to sparse \nexplicit links in NVD references. This study explores this mapping's feasibility through \nan empirical approach. Manual analysis of NVD references showed Git references \nenable over 86% success, while non-Git references achieve under 14%. Using these \nfindings, we built an automated pipeline extracting 31,942 VFCs from 20,360 NVD\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaThanh Le-Cong, Hong Jin Kang, Ratnadira Widyasari, Chengran\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09702&hl=en&sa=X&d=17350753801902205444&ei=jH1PaLCsHeWs6rQPhLia-QI&scisig=AAZF9b9GdE1B-xLLhUOLme72JT4D&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 new citations to articles by Thanh Le-Cong", "Xin ZHOU - new related research", "5 new citations to articles by Bach Le", "Quang-Cuong Bui - new related research", "2 new citations to articles by Hong Jin Kang", "Hong Jin Kang - new articles", "Thanh Le-Cong - new articles"]}
{"title": "Augmenting Large Language Models with Static Code Analysis for Automated Code Quality Improvements", "first_label": ["LLM", "Code"], "second_label": [], "data": "SM Abtahi, A Azim\\xc2\\xa0- arXiv preprint arXiv:2506.10330, 2025\nThis study examined code issue detection and revision automation by integrating \nLarge Language Models (LLMs) such as OpenAI's GPT-3.5 Turbo and GPT-4o into \nsoftware development workflows. A static code analysis framework detects issues \nsuch as bugs, vulnerabilities, and code smells within a large-scale software project. \nDetailed information on each issue was extracted and organized to facilitate \nautomated code revision using LLMs. An iterative prompt engineering process is\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10330&hl=en&sa=X&d=14953940439194560444&ei=jH1PaPLAIs6r6rQP0M7u0Ao&scisig=AAZF9b9THE90CyjHtq9AalX7uLgr&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["3 new citations to articles by Richard Fang"]}
{"title": "AI Goes Off the Grid: The Rise of Local AI Demands Rethinking AI Governance", "first_label": [], "second_label": [], "data": "BA Sokhansanj - 2025\nThe centralized AI governance paradigm is breaking down. While policymakers \nfocus on regulating cloud-based systems that run on massive, power-hungry data \ncenters operated by big companies like Google and OpenAI, a revolution in the AI \necosystem unfolds. Open-source AI models can now run on personal computers and \ndevices, invisible to regulators and stripped of safety constraints. Recent software \nand hardware advances mean that the capabilities of local-scale AI models now lag\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.preprints.org/frontend/manuscript/69ddd3bad35442c7882a4ed2297a7056/download_pub&hl=en&sa=X&d=271532393346224400&ei=jH1PaPLAIs6r6rQP0M7u0Ao&scisig=AAZF9b9njrFQRg5YhQ9I8zobIdtG&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["3 new citations to articles by Richard Fang"]}
{"title": "Quantifying Return on Controls in LLM Cybersecurity", "first_label": ["LLM"], "second_label": [], "data": "RH Moulton - 2025\nAs large language models are increasingly deployed in real world systems, concerns \nabout their security have grown. While these models demonstrate impressive fluency \nand utility, they are also susceptible to a variety of attacks, including prompt injection, \ndata leakage, and adversarial manipulation. These vulnerabilities pose serious risks \nin high stakes environments where privacy, reliability, and trust are essential. Despite \nemerging efforts to document and mitigate such issues, a gap remains in the ability to\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://scholar.dsu.edu/cgi/viewcontent.cgi%3Farticle%3D1480%26context%3Dtheses&hl=en&sa=X&d=6633521575266018192&ei=jH1PaPLAIs6r6rQP0M7u0Ao&scisig=AAZF9b9w-AQ7X9PFaodvjCKZwHgg&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=2&folt=cit", "author": ["Richard Fang"], "ref": ["3 new citations to articles by Richard Fang", "3 new citations to articles by Xin ZHOU"]}
{"title": "EXPEREPAIR: Dual-Memory Enhanced LLM-based Repository-Level Program Repair", "first_label": ["APR", "LLM", "Repository-Level"], "second_label": ["Repair"], "data": "F Mu, J Wang, L Shi, S Wang, S Li, Q Wang\\xc2\\xa0- arXiv preprint arXiv:2506.10484, 2025\nAutomatically repairing software issues remains a fundamental challenge at the \nintersection of software engineering and AI. Although recent advancements in Large \nLanguage Models (LLMs) have demonstrated potential for repository-level repair\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10484&hl=en&sa=X&d=8896195699042165095&ei=jH1PaKuwJKKr6rQPx5XhkQQ&scisig=AAZF9b-QM99LNcUecB-Nh5bI2Tl5&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "7 new citations to articles by Abhik Roychoudhury", "3 new citations to articles by Xin ZHOU", "Bach Le - new related research"]}
{"title": "AdaptiveLLM: A Framework for Selecting Optimal Cost-Efficient LLM for Code-Generation Based on CoT Length", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Cheng, F Liu, C Wu, L Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.10525, 2025\nWhile Large Language Models (LLMs) have significantly advanced code generation \nefficiency, they face inherent challenges in balancing performance and inference \ncosts across diverse programming tasks. Dynamically selecting the optimal LLM\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10525&hl=en&sa=X&d=12946040656504681529&ei=jH1PaKuwJKKr6rQPx5XhkQQ&scisig=AAZF9b8m2TloB0C3Hd11YMxRGFIR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research", "Bach Le - new related research"]}
{"title": "Not One to Rule Them All: Mining Meaningful Code Review Orders From GitHub", "first_label": ["Code Review", "Code"], "second_label": [], "data": "A Bouraffa, C Brandt, A Zaidmann, W Maalej\\xc2\\xa0- arXiv preprint arXiv:2506.10654, 2025\nDevelopers use tools such as GitHub pull requests to review code, discuss proposed \nchanges, and request modifications. While changed files are commonly presented in \nalphabetical order, this does not necessarily coincide with the reviewer's preferred\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10654&hl=en&sa=X&d=3992668249292818405&ei=jH1PaKuwJKKr6rQPx5XhkQQ&scisig=AAZF9b9_WwY7lVF-4S1NfuqiNPEi&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "A First Look at Bugs in LLM Inference Engines", "first_label": ["LLM", "Bug"], "second_label": [], "data": "M Liu, S Zhong, W Bi, Y Zhang, Z Chen, Z Chen, X Liu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language model-specific inference engines (in short as\\\\emph {LLM inference \nengines}) have become a fundamental component of modern AI infrastructure, \nenabling the deployment of LLM-powered applications (LLM apps) across cloud and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09713&hl=en&sa=X&d=1829118811417287869&ei=jH1PaKuwJKKr6rQPx5XhkQQ&scisig=AAZF9b9PFvonW4DF-GngDik42RDE&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "Prompt Variability Effects On LLM Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "A Paleyes, R Sendyka, D Robinson, C Cabrera\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode generation is one of the most active areas of application of Large Language \nModels (LLMs). While LLMs lower barriers to writing code and accelerate \ndevelopment process, the overall quality of generated programs depends on the\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10204&hl=en&sa=X&d=8221586340604733001&ei=jH1PaKuwJKKr6rQPx5XhkQQ&scisig=AAZF9b9gCI1DDrluK2nwtgWAyhR5&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "HPCTransCompile: An AI Compiler Generated Dataset for High-Performance CUDA Transpilation and LLM Preliminary Exploration", "first_label": ["LLM"], "second_label": [], "data": "J Lv, X He, Y Liu, X Dai, Y Hu, S Yin\\xc2\\xa0- arXiv preprint arXiv:2506.10401, 2025\nThe rapid growth of deep learning has driven exponential increases in model \nparameters and computational demands. NVIDIA GPUs and their CUDA-based \nsoftware ecosystem provide robust support for parallel computing, significantly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10401&hl=en&sa=X&d=14309937792901999617&ei=jH1PaNClKdGM6rQP7_O2WA&scisig=AAZF9b_LyVd5W0C0U28-mRiJrH9j&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Evaluating Large Language Models on Non-Code Software Engineering Tasks", "first_label": ["LLM", "Code"], "second_label": [], "data": "FC Pe\\xc3\\xb1a, S Herbold\\xc2\\xa0- arXiv preprint arXiv:2506.10833, 2025\nLarge Language Models (LLMs) have demonstrated remarkable capabilities in code \nunderstanding and generation; however, their effectiveness on non-code Software \nEngineering (SE) tasks remains underexplored. We present the first comprehensive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10833&hl=en&sa=X&d=11330207664789335570&ei=jH1PaNClKdGM6rQP7_O2WA&scisig=AAZF9b-o1DrbJ7pUNkr3zs_CtfAF&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Execution Guided Line-by-Line Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "B Lavon, S Katz, L Wolf\\xc2\\xa0- arXiv preprint arXiv:2506.10948, 2025\nWe present a novel approach to neural code generation that incorporates real-time \nexecution signals into the language model generation process. While large \nlanguage models (LLMs) have demonstrated impressive code generation\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10948&hl=en&sa=X&d=17842318467524186504&ei=jH1PaNClKdGM6rQP7_O2WA&scisig=AAZF9b-oYv4dwNheMuXcCd49tRRg&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Towards Understanding Bugs in Distributed Training and Inference Frameworks for Large Language Models", "first_label": ["LLM", "Bug"], "second_label": [], "data": "X Yu, H Chen, F Niu, X Hu, JW Keung, X Xia\\xc2\\xa0- arXiv preprint arXiv:2506.10426, 2025\nWith the rapid development of large language models (LLMs), distributed training \nand inference frameworks like DeepSpeed have become essential for scaling model \ntraining and inference across multiple GPUs or nodes. However, the increasing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10426&hl=en&sa=X&d=10709409943946815133&ei=jH1PaNClKdGM6rQP7_O2WA&scisig=AAZF9b-__b2AwgjohzjD2dWHKe4l&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "An Accurate and Efficient Vulnerability Propagation Analysis Framework", "first_label": ["Vulnerabilities"], "second_label": [], "data": "B Ruan, Z Lin, J Liu, C Zhang, K Ji, Z Liang\\xc2\\xa0- arXiv preprint arXiv:2506.01342, 2025\nIdentifying the impact scope and scale is critical for software supply chain \nvulnerability assessment. However, existing studies face substantial limitations. First, \nprior studies either work at coarse package-level granularity, producing many false\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.01342&hl=en&sa=X&d=9255320428769668635&ei=jH1PaNClKdGM6rQP7_O2WA&scisig=AAZF9b8hfSB2IBLj53xaiPgSfPtf&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Python's evolution on Stack Overflow: An empirical analysis of topic trends", "first_label": [], "second_label": [], "data": "F Hu, W Xue, S Zhou, Y Wang, B Jiang, Q Huang\\xe2\\x80\\xa6\\xc2\\xa0- Journal of Computer\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the rapid development of information technology and changing programming \npractices, the demand for programming discussions on online Q&A platforms is \ngrowing. This study analyzes over two million Python-related posts on Stack\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S2590118425000267&hl=en&sa=X&d=13849246130136905655&ei=jH1PaNClKdGM6rQP7_O2WA&scisig=AAZF9b9N_7lpzWF1h2BttBvz3C-F&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "VADER: A Human-Evaluated Benchmark for Vulnerability Assessment, Detection, Explanation, and Remediation", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "ETS Liu, A Wang, S Mateega, C Georgescu, D Tang\\xc2\\xa0- arXiv preprint arXiv:2505.19395, 2025\nEnsuring that large language models (LLMs) can effectively assess, detect, explain, \nand remediate software vulnerabilities is critical for building robust and secure \nsoftware systems. We introduce VADER, a human-evaluated benchmark designed\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19395%3F&hl=en&sa=X&d=9714217024162720024&ei=jH1PaNClKdGM6rQP7_O2WA&scisig=AAZF9b_-FsHIQqysH23COzO04ZAM&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Minimizing False Positives in Static Bug Detection via LLM-Enhanced Path Feasibility Analysis", "first_label": ["LLM", "Bug"], "second_label": ["Detection"], "data": "X Du, K Yu, C Wang, Y Zou, W Deng, Z Ou, X Peng\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nStatic bug analyzers play a crucial role in ensuring software quality. However, \nexisting analyzers for bug detection in large codebases often suffer from high false \npositive rates. This is primarily due to the limited capabilities of analyzers in path\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10322&hl=en&sa=X&d=3716496945675701158&ei=jH1PaK2aONGM6rQP7_O2WA&scisig=AAZF9b9tlzM6L6pCsrobgQHDcd_w&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Code Execution as Grounded Supervision for LLM Reasoning", "first_label": ["LLM", "Code"], "second_label": ["Reasoning"], "data": "D Jung, W Zhou, M Chen\\xc2\\xa0- arXiv preprint arXiv:2506.10343, 2025\nTraining large language models (LLMs) with chain-of-thought (CoT) supervision has \nproven effective for enhancing their reasoning abilities. However, obtaining reliable \nand accurate reasoning supervision remains a significant challenge. We propose a\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10343&hl=en&sa=X&d=17674122244614595470&ei=jH1PaK2aONGM6rQP7_O2WA&scisig=AAZF9b9FVx8sOStQ10lLNlQUVvgU&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=7&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Intelligent Design 4.0: Paradigm Evolution Toward the Agentic AI Era", "first_label": [], "second_label": ["Agent"], "data": "S Jiang, M Xie, FY Chen, J Ma, J Luo\\xc2\\xa0- arXiv preprint arXiv:2506.09755, 2025\nResearch and practice in Intelligent Design (ID) have significantly enhanced \nengineering innovation, efficiency, quality, and productivity over recent decades, \nfundamentally reshaping how engineering designers think, behave, and interact with \ndesign processes. The recent emergence of Foundation Models (FMs), particularly \nLarge Language Models (LLMs), has demonstrated general knowledge-based \nreasoning capabilities, and open new paths and avenues for further transformation in\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge Language Models for Computer-Aided Design: A Survey\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09755&hl=en&sa=X&d=16722619763704977554&ei=jH1PaKXlJ8Or6rQPmID_oA8&scisig=AAZF9b_IFlBw4nRAIel8SelWZuD5&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le"]}
{"title": "Assessing the Effectiveness of ChatGPT in Secure Code Development: A Systematic Literature Review", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Bouzid, R Khoury\\xc2\\xa0- ACM Computing Surveys, 2025\nChatGPT, a Large Language Model (LLM) maintained by OpenAI, has demonstrated \na remarkable ability to seemingly comprehend and contextually generate text. \nAmong its myriad applications, its capability to autonomously generate and analyze \ncomputer code stands out as particularly promising. This functionality has piqued \nsubstantial interest due to its potential to streamline the software development \nprocess. However, this technological advancement also brings to the forefront\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTest mimicry to assess the exploitability of library vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3744553&hl=en&sa=X&d=15707337781146378531&ei=jH1PaKXlJ8Or6rQPmID_oA8&scisig=AAZF9b9wa9SZBSY4ovy8NIneyP_7&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le", "2 new citations to articles by Hong Jin Kang"]}
{"title": "Leveraging Blockchain for Confidentiality in Cloud-Hosted Smart Health Platforms", "first_label": ["Blockchain"], "second_label": [], "data": "R Padmavathy\nIn order to address the significant issues of secure data sharing, access control, and \nconfidentiality, this study proposes a blockchain-supported paradigm for privacy \nguarantee in intelligent healthcare cloud platforms. Medical imaging, wearable IoT \nsensors, and electronic health records are just a few of the several sources of \nhealthcare data that the system unifies into a cohesive, privacy-preserving \nframework. To make sure the data is compatible with the encryption procedures, it is\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Padmavathy-Ramamurthy/publication/392621209_Leveraging_Blockchain_for_Confidentiality_in_Cloud-Hosted_Smart_Health_Platforms/links/684abd76e7be56124ab5d04a/Leveraging-Blockchain-for-Confidentiality-in-Cloud-Hosted-Smart-Health-Platforms.pdf&hl=en&sa=X&d=6838355421113122484&ei=jH1PaKXlJ8Or6rQPmID_oA8&scisig=AAZF9b8Zkm9J07T70_HYpaBZTGd9&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=4&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le"]}
{"title": "AI-Based Software Vulnerability Detection: A Systematic Literature Review", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "S Shimmi, H Okhravi, M Rahimi\\xc2\\xa0- arXiv preprint arXiv:2506.10280, 2025\nSoftware vulnerabilities in source code pose serious cybersecurity risks, prompting a \nshift from traditional detection methods (eg, static analysis, rule-based matching) to \nAI-driven approaches. This study presents a systematic review of software\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10280&hl=en&sa=X&d=15991194206893667408&ei=jH1PaNmqLKy16rQP8djq6A8&scisig=AAZF9b_FgRTOeTMea6FrGh_mlzZy&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=1&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Evaluating the predictive power of software metrics for fault localization", "first_label": ["Fault Localization"], "second_label": ["Localization"], "data": "I Arab, K Magel, M Akour\\xc2\\xa0- Computers, 2025\nFault localization remains a critical challenge in software engineering, directly \nimpacting debugging efficiency and software quality. This study investigates the \npredictive power of various software metrics for fault localization by framing the task\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://repository.uantwerpen.be/docstore/d:irua:29201&hl=en&sa=X&d=6977454171370856630&ei=jH1PaNmqLKy16rQP8djq6A8&scisig=AAZF9b_jUwm7zJUovu4NBhDE1xh1&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=3&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks", "first_label": [], "second_label": [], "data": "L Guo, Y Wang, C Li, P Yang, J Chen, W Tao, Y Zou\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nConstructing large-scale datasets for the GitHub issue resolution task is crucial for \nboth training and evaluating the software engineering capabilities of Large \nLanguage Models (LLMs). However, the traditional process for creating such \nbenchmarks is notoriously challenging and labor-intensive, particularly in the stages \nof setting up evaluation environments, grading test outcomes, and validating task \ninstances. In this paper, we propose SWE-Factory, an automated pipeline designed\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10954&hl=en&sa=X&d=12192749699931707766&ei=jH1PaJLhKtSWieoP89D1uAI&scisig=AAZF9b879LSN6xsky7b-aaSU70MH&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research"]}
{"title": "UTBoost: Rigorous Evaluation of Coding Agents on SWE-Bench", "first_label": [], "second_label": ["Agent"], "data": "B Yu, Y Zhu, P He, D Kang\\xc2\\xa0- arXiv preprint arXiv:2506.09289, 2025\nThe advent of Large Language Models (LLMs) has spurred the development of \ncoding agents for real-world code generation. As a widely used benchmark for \nevaluating the code generation capabilities of these agents, SWE-Bench uses real-\nworld problems based on GitHub issues and their corresponding pull requests. \nHowever, the manually written test cases included in these pull requests are often \ninsufficient, allowing generated patches to pass the tests without resolving the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09289&hl=en&sa=X&d=11182501873954298604&ei=jH1PaJLhKtSWieoP89D1uAI&scisig=AAZF9b_2PIQ56ufLjIxE0_sQz9BZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research"]}
{"title": "Reasoning as a Resource: Optimizing Fast and Slow Thinking in Code Generation Models", "first_label": ["Code"], "second_label": ["Generation", "Reasoning"], "data": "Z Li, S Wang\\xc2\\xa0- arXiv preprint arXiv:2506.09396, 2025\nThis position paper proposes a fundamental shift in designing code generation \nmodels: treating reasoning depth as a controllable resource. Rather than being an \nincidental byproduct of prompting, we argue that the trade-off between rapid, direct \nanswers (\" fast thinking\") and elaborate, chain-of-thought deliberation (\" slow \nthinking\") must be explicitly managed. We contend that optimizing reasoning budgets \nacross the entire model lifecycle-from synthetic data creation and benchmarking to\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaOracle-guided Program Selection from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09396&hl=en&sa=X&d=316315899628158003&ei=jH1PaJLhKtSWieoP89D1uAI&scisig=AAZF9b808IwFCkNLr2rEc14pEVP6&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "Exploiting Control-flow Enforcement Technology for Sound and Precise Static Binary Disassembly", "first_label": [], "second_label": ["Exploit"], "data": "B Zhao, Y Yang, Y Zheng, A Quinn\\xc2\\xa0- arXiv preprint arXiv:2506.09426, 2025\nRewriting x86_64 binaries-whether for security hardening, dynamic instrumentation, \nor performance profiling is notoriously difficult due to variable-length instructions, \ninterleaved code and data, and indirect jumps to arbitrary byte offsets. Existing \nsolutions (eg,\" superset disassembly\") ensure soundness but incur significant \noverhead and produce large rewritten binaries, especially for on-the-fly \ninstrumentation. This paper addresses these challenges by introducing the Time\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBinary Rewriting without Control Flow Recovery\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09426&hl=en&sa=X&d=16181490165003004320&ei=jH1PaJLhKtSWieoP89D1uAI&scisig=AAZF9b_VYxxnDbtKHVt_Dv0SQF90&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "Enhancing software testing automation through large language models", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "YS Iznaga - 2025\nThis dissertation explores the application of advanced language models for \nautomated software testing, focusing on generating high quality, context aware test \nscripts. It leverages the Codestral Mamba model using Low-Rank Adaptation \ntechnique to enhance test case generation. The model was fine-tuned on both the \nTest-Case2Code dataset and CONCODE/CodeXGLUE to evaluate its capability to \nproduce syntactically and semantically accurate automated code testing cases from\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTime-travel Testing of Android Apps\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dspace.uevora.pt/rdpc/bitstream/10174/38507/1/Mestrado-Inteligencia_Artificial_e_Ciencia_de_Dados-Yanet_Saez_Iznaga.pdf&hl=en&sa=X&d=13502173359317452277&ei=jH1PaJLhKtSWieoP89D1uAI&scisig=AAZF9b9LJJjk4WtC876UXxhz17GD&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "CGFuzzerArt: A Directed Graybox Fuzzer for Vulnerability Discovery", "first_label": ["Vulnerabilities", "Fuzzing"], "second_label": [], "data": "Z Merza - 2025\nFuzzing is an effective approach to mitigating vulnerabilities in software applications. \nIt encompasses various types of fuzzing, including black-box, white-box, and gray-\nbox, each with advantages and limitations. This research presents a novel method to \nimprove the efficiency of coverage-guided directed gray-box fuzzers by improving the \nunderstanding of indirect function calls in the call graph and leveraging ThinLTO \nwhen generating an instrumented binary. A more comprehensive call graph enables\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://scholar.dsu.edu/cgi/viewcontent.cgi%3Farticle%3D1492%26context%3Dtheses&hl=en&sa=X&d=5207521501416889944&ei=jH1PaJLhKtSWieoP89D1uAI&scisig=AAZF9b886vaAI5I68tZkUDIv78Hv&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "Expert-in-the-Loop Systems with Cross-Domain and In-Domain Few-Shot Learning for Software Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "D Farr, K Talty, A Farr, J Stockdale, I Cruickshank\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs cyber threats become more sophisticated, rapid and accurate vulnerability \ndetection is essential for maintaining secure systems. This study explores the use of \nLarge Language Models (LLMs) in software vulnerability assessment by simulating \nthe identification of Python code with known Common Weakness Enumerations \n(CWEs), comparing zero-shot, few-shot cross-domain, and few-shot in-domain \nprompting strategies. Our results indicate that while zero-shot prompting performs\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection and repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10104&hl=en&sa=X&d=5206393032883760630&ei=jH1PaMiCM6Kr6rQPx5XhkQQ&scisig=AAZF9b9Q0mrO6AUW2cOIV_YCpwTT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["3 new citations to articles by Xin ZHOU"]}
{"title": "Training Language Models to Generate Quality Code with Program Analysis Feedback", "first_label": ["LLM", "Code"], "second_label": [], "data": "F Yao, Z Wang, L Liu, J Cui, L Zhong, X Fu, H Mai\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode generation with large language models (LLMs), often termed vibe coding, is \nincreasingly adopted in production but fails to ensure code quality, particularly in \nsecurity (eg, SQL injection vulnerabilities) and maintainability (eg, missing type\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22704&hl=en&sa=X&d=13720297852295427429&ei=jH1PaNjPIMy8ieoP6KaDYQ&scisig=AAZF9b9qU1hJff-ona5ynwmi0w3O&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=4&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "RIMFuzz: real-time impact-aware mutation for library API fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "X Wang, L Zhao\\xc2\\xa0- Journal of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs libraries merely expose APIs to developers rather than directly handling user \ninput, applying fuzzing to libraries requires fuzz drivers to help process fuzzer-\nprovided input and invoke APIs. To reduce manual effort and avoid reliance on\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00050-1&hl=en&sa=X&d=11566396351270247841&ei=jH1PaK_dL-Ws6rQPhLia-QI&scisig=AAZF9b9NzGapAGT-Gt26V3wejXNn&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Yuan, Y Xu, J Shi, P Zhou, L Sun\\xc2\\xa0- arXiv preprint arXiv:2505.23561, 2025\nModel merging for Large Language Models (LLMs) directly fuses the parameters of \ndifferent models finetuned on various tasks, creating a unified model for multi-domain \ntasks. However, due to potential vulnerabilities in models available on open-source\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23561&hl=en&sa=X&d=6617189016454156514&ei=jH1PaOXYNqalieoPsZriwAs&scisig=AAZF9b-hKaNf3ql6GqPXtJeaxsCC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "PandaGuard: Systematic Evaluation of LLM Safety in the Era of Jailbreaking Attacks", "first_label": ["LLM"], "second_label": [], "data": "G Shen, D Zhao, L Feng, X He, J Wang, S Shen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have achieved remarkable capabilities but remain \nvulnerable to adversarial prompts known as jailbreaks, which can bypass safety \nalignment and elicit harmful outputs. Despite growing efforts in LLM safety research\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13862&hl=en&sa=X&d=7957433049052051517&ei=jH1PaOXYNqalieoPsZriwAs&scisig=AAZF9b8uuohndjng7lcz2CFokw4p&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based Backdoor Attacks for Jailbreaking Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "J Kong, H Fang, X Yang, K Gao, B Chen, ST Xia\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSupervised fine-tuning (SFT) aligns large language models (LLMs) with human \nintent by training them on labeled task-specific data. Recent studies have shown that \nmalicious attackers can inject backdoors into these models by embedding triggers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17601%3F&hl=en&sa=X&d=14932585774719166007&ei=jH1PaOXYNqalieoPsZriwAs&scisig=AAZF9b-bRcbQ7r2VSTXuEVUTZE69&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge", "first_label": ["LLM"], "second_label": [], "data": "S Li, C Xu, J Wang, X Gong, C Chen, J Zhang, J Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable intelligence across \nvarious tasks, which has inspired the development and widespread adoption of LLM-\nas-a-Judge systems for automated model testing, such as red teaming and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09443&hl=en&sa=X&d=2052322274134661445&ei=jH1PaOXYNqalieoPsZriwAs&scisig=AAZF9b9u9cyhYi06xXXt37CLZpdh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Syntactic paraphrase-based synthetic data generation for backdoor attacks against Chinese language models", "first_label": ["LLM"], "second_label": ["Generation"], "data": "M Hu, Y Yang, D Pan, Z Guo, L Xiao, D Lin, S Zhao\\xc2\\xa0- Information Fusion, 2025\nAbstract Language Models (LMs) have shown significant advancements in various \nNatural Language Processing (NLP) tasks. However, recent studies indicate that \nLMs are particularly susceptible to malicious backdoor attacks, where attackers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S156625352500449X&hl=en&sa=X&d=11939540759867308872&ei=jH1PaOXYNqalieoPsZriwAs&scisig=AAZF9b_omHEFDqgnSwVne_pfKwnY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack", "first_label": ["LLM"], "second_label": [], "data": "S Cappelletti, T Poppi, S Poppi, ZX Yong\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly evaluated on multiple-choice \nquestion answering (MCQA) tasks using* first-token probability*(FTP), which selects \nthe answer option whose initial token has the highest likelihood. While efficient, FTP\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15323%3F&hl=en&sa=X&d=5513891085179250670&ei=jH1PaOXYNqalieoPsZriwAs&scisig=AAZF9b8ts6vJnVnPKgZRZk2J59vT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems", "first_label": ["LLM"], "second_label": ["Agent", "Search"], "data": "X Li, J Chen, X Fang, S Ding, H Duan, Q Liu, K Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown remarkable capabilities in solving \ndiverse tasks. However, their proficiency in iteratively optimizing complex solutions \nthrough learning from previous feedback remains insufficiently explored. To bridge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10764&hl=en&sa=X&d=1134890120116902745&ei=jH1PaOXYNqalieoPsZriwAs&scisig=AAZF9b8s_mGNSGwzfKFs6o2hgsbd&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Lifelong Safety Alignment for Language Models", "first_label": ["LLM"], "second_label": [], "data": "H Wang, Z Qin, Y Zhao, C Du, M Lin, X Wang, T Pang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLMs have made impressive progress, but their growing capabilities also expose \nthem to highly flexible jailbreaking attacks designed to bypass safety alignment. \nWhile many existing defenses focus on known types of attacks, it is more critical to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20259%3F&hl=en&sa=X&d=16834372085988299596&ei=jH1PaOXYNqalieoPsZriwAs&scisig=AAZF9b9d_59vHSVRWjToyCIlG2f5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "PS Pandey, S Simko, K Pelrine, Z Jin\\xc2\\xa0- arXiv preprint arXiv:2505.16789, 2025\nAs large language models gain popularity, their vulnerability to adversarial attacks \nremains a primary concern. While fine-tuning models on domain-specific datasets is \noften employed to improve model performance, it can introduce vulnerabilities within\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16789%3F&hl=en&sa=X&d=9827187220639785834&ei=jH1PaOXYNqalieoPsZriwAs&scisig=AAZF9b-hRa3CIybDfceUhaRlecWD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution", "first_label": [], "second_label": [], "data": "J Guo, X Wen, W Jiang, C Huang, J Li, H Li\\xc2\\xa0- arXiv preprint arXiv:2505.15308, 2025\nWith the widespread application of super-resolution (SR) in various fields, \nresearchers have begun to investigate its security. Previous studies have \ndemonstrated that SR models can also be subjected to backdoor attacks through\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15308&hl=en&sa=X&d=13335437674086498390&ei=jH1PaOXYNqalieoPsZriwAs&scisig=AAZF9b8WmdvUXiuzvPutlRNCBmNP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
