{"title": "MGS3: A Multi-Granularity Self-Supervised Code Search Framework", "first_label": ["Code"], "second_label": ["Search"], "data": "R Li, J Kang, Q Liu, L He, Z Zhang, Y Sha, L Zhu\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 31st\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn the pursuit of enhancing software reusability and developer productivity, code \nsearch has emerged as a key area, aimed at retrieving code snippets relevant to \nfunctionalities based on natural language queries. Despite significant progress in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3690624.3709263&hl=en&sa=X&d=1009890518697704121&ei=FX75Z5i1FrGyieoPw4eO4A4&scisig=AFWwaebymtIN-0ZFuPvqxNkkLlXu&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AFWwaeZADCuvrSiGaZ1pge7b9bMB&html=&pos=0&folt=rel", "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Evaluating the Generalization Capabilities of Large Language Models on Code Reasoning", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Yang, J Dai, N Vasilakis, M Rinard\\xc2\\xa0- arXiv preprint arXiv:2504.05518, 2025\nWe assess how the code reasoning abilities of large language models (LLMs) \ngeneralize to different kinds of programs. We present techniques for obtaining in-and \nout-of-distribution programs with different characteristics: code sampled from a\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.05518&hl=en&sa=X&d=805905684378306330&ei=FX75Z5i1FrGyieoPw4eO4A4&scisig=AFWwaeZ9BtEhgM_L83-1uaig0DXh&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AFWwaeZADCuvrSiGaZ1pge7b9bMB&html=&pos=1&folt=rel", "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Reasoning with LLMs for Zero-Shot Vulnerability Detection", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "A Zibaeirad, M Vieira\\xc2\\xa0- arXiv preprint arXiv:2503.17885, 2025\nAutomating software vulnerability detection (SVD) remains a critical challenge in an \nera of increasingly complex and interdependent software systems. Despite \nsignificant advances in Large Language Models (LLMs) for code analysis, prevailing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.17885&hl=en&sa=X&d=16151102993317123730&ei=FX75Z_e_DsmpieoPv7aWiQ4&scisig=AFWwaeaU1duZG60YHiU0D1fyotku&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AFWwaeYwgMeQSPpxCfDXmGy5aE3n&html=&pos=0&folt=rel", "ref": ["Thanh Le-Cong - new related research"]}
{"title": "A Comprehensive Study of LLM Secure Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "SC Dai, J Xu, G Tao\\xc2\\xa0- arXiv preprint arXiv:2503.15554, 2025\nLLMs are widely used in software development. However, the code generated by \nLLMs often contains vulnerabilities. Several secure code generation methods have \nbeen proposed to address this issue, but their current evaluation schemes leave\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.15554%3F&hl=en&sa=X&d=1363137439941333778&ei=FX75Z_e_DsmpieoPv7aWiQ4&scisig=AFWwaea70lzbx-2dnx-SlddbyIDc&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AFWwaeYwgMeQSPpxCfDXmGy5aE3n&html=&pos=1&folt=rel", "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Retrieval-Augmented Fine-Tuning for Improving Retrieve-and-Edit Based Assertion Generation", "first_label": [], "second_label": ["Generation"], "data": "H Li, W Sun, M Yan, L Xu, Q Li, X Zhang, H Zhang\\xc2\\xa0- IEEE Transactions on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nUnit Testing is crucial in software development and maintenance, aiming to verify \nthat the implemented functionality is consistent with the expected functionality. A unit \ntest is composed of two parts: a test prefix, which drives the unit under test to a \nparticular state, and a test assertion, which determines what the expected behavior is \nunder that state. To reduce the effort of conducting unit tests manually, Yu et al. \nproposed an integrated approach (integration for short), combining information\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCCBERT: Self-Supervised Code Change Representation Learning\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10949862/&hl=en&sa=X&d=1832626827113407670&ei=FX75Z5P9EsCSieoPgfq5yAo&scisig=AFWwaeYd1ZjQg27v5i1h4-T0_o0S&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AFWwaeZamHljvPChNBtOABcetGTp&html=&pos=0&folt=cit", "ref": ["2 new citations to articles by Xin ZHOU", "David Lo - new related research"]}
{"title": "SoK: Frontier AI's Impact on the Cybersecurity Landscape", "first_label": [], "second_label": [], "data": "W Guo, Y Potter, T Shi, Z Wang, A Zhang, D Song\\xc2\\xa0- arXiv preprint arXiv:2504.05408, 2025\nAs frontier AI advances rapidly, understanding its impact on cybersecurity and \ninherent risks is essential to ensuring safe AI evolution (eg, guiding risk mitigation \nand informing policymakers). While some studies review AI applications in \ncybersecurity, none of them comprehensively discuss AI's future impacts or provide \nconcrete recommendations for navigating its safe and secure usage. This paper \npresents an in-depth analysis of frontier AI's impact on cybersecurity and establishes\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection and repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.05408&hl=en&sa=X&d=8797189251482550811&ei=FX75Z5P9EsCSieoPgfq5yAo&scisig=AFWwaeaiUdJD8sWdAsXbQZqsuu0D&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AFWwaeZamHljvPChNBtOABcetGTp&html=&pos=1&folt=cit", "ref": ["2 new citations to articles by Xin ZHOU", "2 new citations to articles by Richard Fang"]}
{"title": "Enhancing High-Quality Code Generation in Large Language Models with Comparative Prefix-Tuning", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Y Jiang, Y Zhang, L Lu, C Treude, X Su, S Huang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have been widely adopted in commercial code \ncompletion engines, significantly enhancing coding efficiency and productivity. \nHowever, LLMs may generate code with quality issues that violate coding standards\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.09020&hl=en&sa=X&d=274986171076802173&ei=FX75Z5vwF8uZieoPg4fsmAg&scisig=AFWwaea-q7yfbqCfb2mRj_yZrJ7q&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=1&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Fixing Large Language Models' Specification Misunderstanding for Better Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Z Tian, J Chen, X Zhang\\xc2\\xa0- 2025 IEEE/ACM 47th International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode generation is to automatically generate source code conforming to a given \nprogramming specification, which has received extensive attention especially with \nthe development of large language models (LLMs). Due to the inherent difficulty of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://drive.google.com/file/d/1eiTmCxYs6FgdxCZNOdS9egz6U1Jf4wOL/view&hl=en&sa=X&d=6513233471596826292&ei=FX75Z5vwF8uZieoPg4fsmAg&scisig=AFWwaeZjNzZZqbOuWO8MZmi5NgiS&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=2&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Exploring the Lifecycle and Maintenance Practices of Pre-Trained Models in Open-Source Software Repositories", "first_label": [], "second_label": [], "data": "M Koohjani, DE Costa\\xc2\\xa0- arXiv preprint arXiv:2504.06040, 2025\nPre-trained models (PTMs) are becoming a common component in open-source \nsoftware (OSS) development, yet their roles, maintenance practices, and lifecycle \nchallenges remain underexplored. This report presents a plan for an exploratory\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.06040&hl=en&sa=X&d=5791951061414034500&ei=FX75Z5vwF8uZieoPg4fsmAg&scisig=AFWwaearbzhUesD4E-PQqPp1R7rY&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=3&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "HALURust: Exploiting Hallucinations of Large Language Models to Detect Vulnerabilities in Rust", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Exploit"], "data": "Y Luo, H Zhou, M Zhang, D De La Rosa, H Ahmed\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs an emerging programming language, Rust has rapidly gained popularity and \nrecognition among developers due to its strong emphasis on safety. It employs a \nunique ownership system and safe concurrency practices to ensure robust safety\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.10793&hl=en&sa=X&d=5829414047755650757&ei=FX75Z5vwF8uZieoPg4fsmAg&scisig=AFWwaeY9qSDL2ktzIVFeZhrU-G2d&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=4&folt=rel", "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "KotSuite: Unit Test Generation for Kotlin Programs in Android Applications", "first_label": ["Software Testing"], "second_label": ["Generation"], "data": "F Yang, Q Xin, Z Ren, J Xuan\nUnit testing plays a pivotal role in safeguarding functional requirements and \nsupporting the maintainence during the development of Android applications. The \nKotlin programming language emerges in developing Android applications since\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://qixin5.github.io/files/pdf/research/icpc25kotsuite.pdf&hl=en&sa=X&d=4160603672644182246&ei=FX75Z5vwF8uZieoPg4fsmAg&scisig=AFWwaebk9skrRKkb80KaNdrfD3RV&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=5&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Fuzzing: On Benchmarking Outcome as a Function of Benchmark Properties", "first_label": ["Fuzzing"], "second_label": [], "data": "D WOLFF, A ROYCHOUDHURY - 2025\nAuthors' addresses: Dylan Wolff, wolffd@ comp. nus. edu. sg, National University of \nSingapore, Singapore; Marcel B\\xc3\\xb6hme, marcel. boehme@ mpi-sp. org, Max Planck \nInstitute for Security and Privacy, Germany; Abhik Roychoudhury, abhik@ comp. nus\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dylanjwolff.com/assets/eval.pdf&hl=en&sa=X&d=3899393433676860100&ei=FX75Z5vwF8uZieoPg4fsmAg&scisig=AFWwaeZCpAIF5IaVvnEXyVRhuvNd&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=6&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Evaluating Biased Synthetic Data Effects on Large Language Model-Based Software Vulnerability Detection", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "LB Germano, LQ Vieira, RR Goldschmidt, JC Duarte\\xe2\\x80\\xa6\nSoftware security ensures data privacy and system reliability. Vulnerabilities in the \ndevelopment cycle can lead to privilege escalation, causing data exfiltration or denial \nof service attacks. Static code analyzers, based on predefined rules, often fail to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.scitepress.org/Papers/2025/131568/131568.pdf&hl=en&sa=X&d=2607917738470903508&ei=FX75Z5vwF8uZieoPg4fsmAg&scisig=AFWwaeZ0Q2EahjIXC8AC_4u3u9GS&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=8&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Dataset collection for automatic generation of commit messages", "first_label": ["Commit Message"], "second_label": ["Generation"], "data": "IA Kosyanenko, RG Bolbakov\\xc2\\xa0- RUSSIAN, 2025\nObjectives. In contemporary software development practice, version control systems \nare often used to manage the development process. Such systems allow developers \nto track changes in the codebase and convey the context of these changes through\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.rtj-mirea.ru/jour/issue/download/57/76%23page%3D8&hl=en&sa=X&d=11738522829282307678&ei=FX75Z5vwF8uZieoPg4fsmAg&scisig=AFWwaeZ3_DGZkQ2HI7j6l3KtFhuh&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=9&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Modularization is Better: Effective Code Generation with Modular Prompting", "first_label": ["Code"], "second_label": ["Generation"], "data": "R Pan, H Zhang\\xc2\\xa0- arXiv preprint arXiv:2503.12483, 2025\nLarge Language Models are transforming software development by automatically \ngenerating code. Current prompting techniques such as Chain-of-Thought (CoT) \nsuggest tasks step by step and the reasoning process follows a linear structure\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.12483&hl=en&sa=X&d=14254932694001679206&ei=FX75Z9mTEJm7ieoP3oH9uAU&scisig=AFWwaebJFNOBSO1Oa5RjObIyQw5e&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=3&folt=rel", "ref": ["David Lo - new related research"]}
{"title": "How Do Solidity Versions Affect Vulnerability Detection Tools? An Empirical Study", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "G Iuliano, D Corradini, M Pasqua, M Ceccato\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nContext: Smart contract vulnerabilities pose significant security risks for the Ethereum \necosystem, driving the development of automated tools for detection and mitigation. \nSmart contracts are written in Solidity, a programming language that is rapidly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.05515&hl=en&sa=X&d=10406177812794992313&ei=FX75Z9mTEJm7ieoP3oH9uAU&scisig=AFWwaeYkpOtMh71pWOgA4odw8ZlC&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=5&folt=rel", "ref": ["David Lo - new related research"]}
{"title": "LLM-assisted Mutation for Whitebox API Testing", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "J Li, J Shen, Y Su, MR Lyu\\xc2\\xa0- arXiv preprint arXiv:2504.05738, 2025\nCloud applications heavily rely on APIs to communicate with each other and \nexchange data. To ensure the reliability of cloud applications, cloud providers widely \nadopt API testing techniques. Unfortunately, existing API testing approaches are\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.05738&hl=en&sa=X&d=7557048715145801310&ei=FX75Z9mTEJm7ieoP3oH9uAU&scisig=AFWwaeZ-CTfa-2rzX0xbP2wE_SKz&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=6&folt=rel", "ref": ["David Lo - new related research"]}
{"title": "CBPF: A Novel Method For Filtering Poisoned Data Based on Composite Backdoor Attacks", "first_label": [], "second_label": [], "data": "H Xia, H Hong, R Wang, Y Sun, H Ding\\xc2\\xa0- IEEE Internet of Things Journal, 2025\nBackdoor attacks involve the injection of a limited quantity of poisoned samples \ncontaining triggers into the training dataset. During the inference stage, backdoor \nattacks can uphold a high level of accuracy for normal examples, yet when presented\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10954977/&hl=en&sa=X&d=14956579577820071145&ei=FX75Z8jEFNSyieoP2ane-QQ&scisig=AFWwaeYcJx9MusTKHvt-hle13r9Q&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=0&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Defending Deep Neural Networks against Backdoor Attacks via Module Switching", "first_label": [], "second_label": [], "data": "W Li, A Arora, X He, M Dras, Q Xu\\xc2\\xa0- arXiv preprint arXiv:2504.05902, 2025\nThe exponential increase in the parameters of Deep Neural Networks (DNNs) has \nsignificantly raised the cost of independent training, particularly for resource-\nconstrained entities. As a result, there is a growing reliance on open-source models\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.05902&hl=en&sa=X&d=8952997710940951785&ei=FX75Z8jEFNSyieoP2ane-QQ&scisig=AFWwaebMnBVDpo1_qCHfNg_gyeFe&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=1&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "LLMs Meet Library Evolution: Evaluating Deprecated API Usage in LLM-based Code Completion", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "C Wang, K Huang, J Zhang, Y Feng, L Zhang, Y Liu\\xe2\\x80\\xa6\\xc2\\xa0- 2025 IEEE/ACM 47th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs), pre-trained or fine-tuned on large code corpora, \nhave shown effectiveness in generating code completions. However, in LLM-based \ncode completion, LLMs may struggle to use correct and up-to-date Application\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a781/251mHK5tjdC&hl=en&sa=X&d=4291983748355056793&ei=FX75Z8jEFNSyieoP2ane-QQ&scisig=AFWwaebbFgNB42GTnyK8DsY5wt9u&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=2&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Bridging Industrial Expertise and XR with LLM-Powered Conversational Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "D Tomkou, G Fatouros, A Andreou, G Makridis\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis paper introduces a novel integration of Retrieval-Augmented Generation (RAG) \nenhanced Large Language Models (LLMs) with Extended Reality (XR) technologies \nto address knowledge transfer challenges in industrial environments. The proposed\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.05527&hl=en&sa=X&d=665950199627025975&ei=FX75Z8jEFNSyieoP2ane-QQ&scisig=AFWwaebU2ZAPYX5DEiQ9lYaxtIxy&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=3&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Evolution-based Region Adversarial Prompt Learning for Robustness Enhancement in Vision-Language Models", "first_label": [], "second_label": [], "data": "X Jia, S Gao, S Qin, K Ma, X Li, Y Huang, W Dong\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge pre-trained vision-language models (VLMs), such as CLIP, demonstrate \nimpressive generalization but remain highly vulnerable to adversarial examples \n(AEs). Previous work has explored robust text prompts through adversarial training\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.12874&hl=en&sa=X&d=4288320110718600484&ei=FX75Z8jEFNSyieoP2ane-QQ&scisig=AFWwaebZ47dtXpHPS7gkzptvLmTz&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=4&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "XSShield: Defending Against Stored XSS Attacks Using LLM-Based Semantic Understanding", "first_label": ["LLM"], "second_label": [], "data": "Y Zhou, E Wang, W Yang, W Ge, S Yang, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- Applied Sciences, 2025\nCross-site scripting attacks represent one of the major security threats facing web \napplications, with Stored XSS attacks becoming the predominant form. Compared to \nreflected XSS, stored XSS attack payloads exhibit temporal and spatial asynchrony\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2076-3417/15/6/3348&hl=en&sa=X&d=11849643047241211005&ei=FX75Z8jEFNSyieoP2ane-QQ&scisig=AFWwaeZJp-xCesiNk9t9IXhXxSLJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=5&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Vulnerability Detection: From Formal Verification to Large Language Models and Hybrid Approaches: A Comprehensive Overview", "first_label": ["Vulnerabilities", "Verification", "LLM"], "second_label": ["Detection"], "data": "N Tihanyi, T Bisztray, MA Ferrag, B Cherif\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware testing and verification are critical for ensuring the reliability and security of \nmodern software systems. Traditionally, formal verification techniques, such as \nmodel checking and theorem proving, have provided rigorous frameworks for\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.10784&hl=en&sa=X&d=12911561823202945144&ei=FX75Z8jEFNSyieoP2ane-QQ&scisig=AFWwaeYhatByJp-efqzH8QuYSI72&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=6&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "AgentDAM: Privacy Leakage Evaluation for Autonomous Web Agents", "first_label": [], "second_label": ["Agent"], "data": "A Zharmagambetov, C Guo, I Evtimov, M Pavlova\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM-powered AI agents are an emerging frontier with tremendous potential to \nincrease human productivity. However, empowering AI agents to take action on their \nuser's behalf in day-to-day tasks involves giving them access to potentially sensitive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.09780%3F&hl=en&sa=X&d=12860650719968363446&ei=FX75Z8jEFNSyieoP2ane-QQ&scisig=AFWwaeaZP1nOXGDyZqifdZ_WOtaf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=7&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Dapo: An open-source llm reinforcement learning system at scale", "first_label": ["LLM"], "second_label": [], "data": "Q Yu, Z Zhang, R Zhu, Y Yuan, X Zuo, Y Yue, T Fan\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInference scaling empowers LLMs with unprecedented reasoning ability, with \nreinforcement learning as the core technique to elicit complex reasoning. However, \nkey technical details of state-of-the-art reasoning LLMs are concealed (such as in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.14476&hl=en&sa=X&d=1968980266662184520&ei=FX75Z8jEFNSyieoP2ane-QQ&scisig=AFWwaebXNS6d8Y_C8FG4sfvmXe0u&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=8&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking", "first_label": ["LLM"], "second_label": ["Generation"], "data": "YH Wu, YJ Xiong\\xc2\\xa0- arXiv preprint arXiv:2504.05652, 2025\nLarge Language Models (LLMs) have become increasingly integral to a wide range \nof applications. However, they still remain the threat of jailbreak attacks, where \nattackers manipulate designed prompts to make the models elicit malicious outputs\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.05652&hl=en&sa=X&d=9735385300123201340&ei=FX75Z8jEFNSyieoP2ane-QQ&scisig=AFWwaeYrOPjdrzg0rfaML-0wq6dO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=9&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "CAI: An Open, Bug Bounty-Ready Cybersecurity AI", "first_label": ["Bug"], "second_label": [], "data": "V Mayoral-Vilches, LJ Navarrete-Lozano\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBy 2028 most cybersecurity actions will be autonomous, with humans teleoperating. \nWe present the first classification of autonomy levels in cybersecurity and introduce \nCybersecurity AI (CAI), an open-source framework that democratizes advanced \nsecurity testing through specialized AI agents. Through rigorous empirical \nevaluation, we demonstrate that CAI consistently outperforms state-of-the-art results \nin CTF benchmarks, solving challenges across diverse categories with significantly\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.06017&hl=en&sa=X&d=17999546665399519711&ei=FX75Z_eLDYSlieoPpZSOmAc&scisig=AFWwaeYPU6hfAgxSLSQhxSdg3yiu&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AFWwaebib5Pw9QKWi9BJ6ThKDwc5&html=&pos=1&folt=cit", "ref": ["2 new citations to articles by Richard Fang"]}
