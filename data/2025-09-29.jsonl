{"title": "Vdexplainer: Sequential decision-making and probability sampling guided statement-level explanation for vulnerability detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "W Zheng, X Su, Y Jiang, H Wei, W Tao- Computers & Security, 2025\nMost existing deep learning (DL) based vulnerability detection methods, including \npre-trained models, are coarse-grained binary classification methods that lack the \ninterpretability for detection results. Although the explanation of deep learning has", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825003591&hl=en&sa=X&d=1218753570899613844&ei=Hv_YaLCfApXP6rQPo4LniQU&scisig=AAZF9b-Gvd82yXjuXXps0NDpxzwO&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "1 new citation to articles by Xin ZHOU", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Assertion Messages with Large Language Models (LLMs) for Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "A Aljohani, AH Mollah, H Do- arXiv preprint arXiv:2509.19673, 2025\nAssertion messages significantly enhance unit tests by clearly explaining the \nreasons behind test failures, yet they are frequently omitted by developers and \nautomated test-generation tools. Despite recent advancements, Large Language", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19673&hl=en&sa=X&d=7084463702742822906&ei=Hv_YaLCfApXP6rQPo4LniQU&scisig=AAZF9b93i6m23y0xnjeM1zyUGkQc&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Beyond Language Barriers: Multi-Agent Coordination for Multi-Language Code Generation", "first_label": ["Code"], "second_label": ["Generation", "Agent"], "data": "MB Moumoula, SL Nikiema, AE Djire, AK Kabore- arXiv preprint arXiv, 2025\nProducing high-quality code across multiple programming languages is increasingly \nimportant as today's software systems are built on heterogeneous stacks. Large \nlanguage models (LLMs) have advanced the state of automated programming, yet", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19918&hl=en&sa=X&d=14811258885698436173&ei=Hv_YaLCfApXP6rQPo4LniQU&scisig=AAZF9b8x1dDUh0eB-LPirrM3oNjg&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "3 new citations to articles by Bach Le", "Xin ZHOU - new related research"]}
{"title": "Semantic-Aware Fuzzing: An Empirical Framework for LLM-Guided, Reasoning-Driven Input Mutation", "first_label": ["LLM", "Fuzzing"], "second_label": ["Reasoning"], "data": "M Lu, S Ding, F Alaca, P Charland- arXiv preprint arXiv:2509.19533, 2025\nSecurity vulnerabilities in Internet-of-Things devices, mobile platforms, and \nautonomous systems remain critical. Traditional mutation-based fuzzers--while \neffectively explore code paths--primarily perform byte-or bit-level edits without", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19533&hl=en&sa=X&d=537743905954534716&ei=Hv_YaLCfApXP6rQPo4LniQU&scisig=AAZF9b8SCOpQdg1OxBk00igQIrJA&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research", "6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Reverse Engineering User Stories from Code using Large Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "M Ouf, H Li, M Zhang, M Guizani- arXiv preprint arXiv:2509.19587, 2025\nUser stories are essential in agile development, yet often missing or outdated in \nlegacy and poorly documented systems. We investigate whether large language \nmodels (LLMs) can automatically recover user stories directly from source code and\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19587&hl=en&sa=X&d=4022008907747344847&ei=Hv_YaLCfApXP6rQPo4LniQU&scisig=AAZF9b-HkVlKR0YrBD-Eded7EAOJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Balancing Validity and Vulnerability: Knowledge-Driven Seed Generation via LLMs for Deep Learning Library Fuzzing", "first_label": ["Vulnerabilities", "LLM", "Fuzzing"], "second_label": ["Generation"], "data": "R Liao, X Yan, Z Pang, K Zhu- Applied Sciences, 2025\nFuzzing deep learning (DL) libraries is essential for uncovering security \nvulnerabilities in AI systems. Existing approaches enhance large language models \n(LLMs) with external knowledge such as bug reports to improve the quality of", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2076-3417/15/19/10396&hl=en&sa=X&d=9374413942225787882&ei=H__YaOS4MpXP6rQPo4LniQU&scisig=AAZF9b_coV2M25K3l6JkCX-ZdrMr&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "LLM-Guided Differential Fuzzing for Detecting Platform-Specific Bugs in Scientific Applications", "first_label": ["LLM", "Fuzzing", "Bug"], "second_label": ["Detection"], "data": "M Motwani, A Kulkarni, Y Qiao, M Davis, Z Chen\nModern scientific and AI-based applications run complex workloads across \nheterogeneous platforms, such as CPUs and accelerators (eg, GPUs). These \napplications often use platform-specific libraries to move data between compute", "link": "https://scholar.google.com/scholar_url?url=https://mmotwani.com/publications/publication_sources/Motwani25aixse.pdf&hl=en&sa=X&d=5122384816117524811&ei=H__YaOS4MpXP6rQPo4LniQU&scisig=AAZF9b__jhfqqmr0CI2oW8ETr47G&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Demystifying the Evolution of Neural Networks with BOM Analysis: Insights from a Large-Scale Study of 55,997 GitHub Repositories", "first_label": [], "second_label": [], "data": "X Ren, Y Ye, X Wu, Y Wu, Y Xue- arXiv preprint arXiv:2509.20010, 2025\nNeural networks have become integral to many fields due to their exceptional \nperformance. The open-source community has witnessed a rapid influx of neural \nnetwork (NN) repositories with fast-paced iterations, making it crucial for practitioners", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.20010&hl=en&sa=X&d=7068609705453111894&ei=H__YaOS4MpXP6rQPo4LniQU&scisig=AAZF9b-xjTuce_u6MpnTv1bMQQDb&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "The Ground Truth Effect: Investigating SZZ Variants in Just-in-Time Vulnerability Prediction", "first_label": ["Vulnerabilities"], "second_label": [], "data": "A Cannavale, E Iannone, G Di Lillo, F Palomba- Euromicro Conference on, 2025\nAbstract Just-in-Time (JIT) vulnerability prediction is critical for proactively securing \nsoftware, yet its effectiveness heavily relies on the quality of the ground truth used for \ntraining models. This ground truth is commonly established using variants of the SZZ", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1007/978-3-032-04207-1_21&hl=en&sa=X&d=7079951351329674156&ei=H__YaOS4MpXP6rQPo4LniQU&scisig=AAZF9b8nsQWVZ7KNLp4p8ZePB-Wu&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Performance and interpretability analysis of code generation large language models", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "VS Pendyala, NB Thakur- Neurocomputing, 2025\nAbstract As Large Language Models (LLMs) are increasingly getting integrated into \nsoftware development workflows, understanding their reliability, error patterns and \ninterpretability in real-world development scenarios is crucial for establishing their", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0925231225021332&hl=en&sa=X&d=12519052331836719178&ei=H__YaOS4MpXP6rQPo4LniQU&scisig=AAZF9b_3S5NkeiHUCnc01CtGOqCD&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "sBugChecker: A Systematic Framework for Detecting Solidity Compiler-Introduced Bugs", "first_label": ["Bug"], "second_label": ["Detection"], "data": "F Tong, Z Li, G Cheng, Y Zhang, H Li- IEEE Transactions on Information Forensics, 2025\nA compiler converts smart contract source code into bytecode, ensuring behavior \nconsistency between them. However, as compiler is also a program, it may contain \nbugs that disrupt this consistency, known as Compiler-Introduced Bugs (CIBs). Of the", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11159069/&hl=en&sa=X&d=973917564340753579&ei=H__YaOS4MpXP6rQPo4LniQU&scisig=AAZF9b9U6EYUWy1dQpWLOy1eKf7T&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Self-Debugging AI: A Comprehensive Analysis of Claude 4.1 Sonnet's Code Generation and Error Resolution Capabilities", "first_label": ["Code", "Bug"], "second_label": ["Generation"], "data": "H Vaddiparthy - 2025\nThis paper presents a novel meta-experimental approach to analyzing the \ndebugging capabilities of large language models (LLMs), specifically Claude 3 \nOpus. Through a carefully designed experiment where the AI system first generates\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.researchsquare.com/article/rs-7467553/latest&hl=en&sa=X&d=12063740762042943711&ei=H__YaOS4MpXP6rQPo4LniQU&scisig=AAZF9b-UwAsu44FCSeQ8iOS9N4-Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Unraveling LLM Jailbreaks Through Safety Knowledge Neurons", "first_label": ["LLM"], "second_label": [], "data": "C Zhao, K Huang- arXiv preprint arXiv:2509.01631, 2025\nLarge Language Models (LLMs) are increasingly attracting attention in various \napplications. Nonetheless, there is a growing concern as some users attempt to \nexploit these models for malicious purposes, including the synthesis of controlled", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01631&hl=en&sa=X&d=1514740733256060014&ei=H__YaNGrGcasieoPpPjngQI&scisig=AAZF9b9hCs1ysD6JyG0WYWiQsfvZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "first_label": ["LLM"], "second_label": ["Agent"], "data": "T Lindenbauer, I Slinko, L Felder, E Bogomolov- arXiv preprint arXiv, 2025\nLarge Language Model (LLM)-based agents solve complex tasks through iterative \nreasoning, exploration, and tool-use, a process that can result in long, expensive \ncontext histories. While state-of-the-art Software Engineering (SE) agents like", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21433&hl=en&sa=X&d=3778813371369713554&ei=H__YaNGrGcasieoPpPjngQI&scisig=AAZF9b8vjKgLLO8JtQg2HjxwaIIj&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "When Your Reviewer is an LLM: Biases, Divergence, and Prompt Injection Risks in Peer Review", "first_label": ["LLM"], "second_label": [], "data": "C Zhu, J Xiong, R Ma, Z Lu, Y Liu, L Li- arXiv preprint arXiv:2509.09912, 2025\nPeer review is the cornerstone of academic publishing, yet the process is \nincreasingly strained by rising submission volumes, reviewer overload, and expertise \nmismatches. Large language models (LLMs) are now being used as\" reviewer aids,\"", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.09912&hl=en&sa=X&d=559709989728729115&ei=H__YaNGrGcasieoPpPjngQI&scisig=AAZF9b_J-eLdccTA9UluyGqY5GIL&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Instruction Boundary: Quantifying Biases in LLM Reasoning under Various Coverage", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "Z Ling, Y Tang, C Huang, S Liu, G Jiang, S Fu, J Yang- arXiv preprint arXiv, 2025\nLarge-language-model (LLM) reasoning has long been regarded as a powerful tool \nfor problem solving across domains, providing non-experts with valuable advice. \nHowever, their limitations-especially those stemming from prompt design-remain", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.20278&hl=en&sa=X&d=9832136441215644139&ei=H__YaNGrGcasieoPpPjngQI&scisig=AAZF9b8lFOORKHONdnfwrZ1NWcns&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Beyond Sharp Minima: Robust LLM Unlearning via Feedback-Guided Multi-Point Optimization", "first_label": ["LLM"], "second_label": [], "data": "W Wu, Z Liu, C Gao, R Wang, K Ding- arXiv preprint arXiv:2509.20230, 2025\nCurrent LLM unlearning methods face a critical security vulnerability that undermines \ntheir fundamental purpose: while they appear to successfully remove sensitive or \nharmful knowledge, this``forgotten\" information remains precariously recoverable", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.20230&hl=en&sa=X&d=5430884631176372149&ei=H__YaNGrGcasieoPpPjngQI&scisig=AAZF9b8eGKs-7c5sFt28ImeCtkNx&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Harmful Prompt Laundering: Jailbreaking LLMs with Abductive Styles and Symbolic Encoding", "first_label": ["LLM"], "second_label": [], "data": "S Joo, H Koh, K Jung- arXiv preprint arXiv:2509.10931, 2025\nLarge Language Models (LLMs) have demonstrated remarkable capabilities across \ndiverse tasks, but their potential misuse for harmful purposes remains a significant \nconcern. To strengthen defenses against such vulnerabilities, it is essential to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.10931&hl=en&sa=X&d=7785240652024916599&ei=H__YaNGrGcasieoPpPjngQI&scisig=AAZF9b-lQwRskC9IEbTA9AG879iC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Standard vs. Modular Sampling: Best Practices for Reliable LLM Unlearning", "first_label": ["LLM"], "second_label": [], "data": "P Bushipaka, L Passaro, T Cucinotta- arXiv preprint arXiv:2509.05316, 2025\nA conventional LLM Unlearning setting consists of two subsets-\" forget\" and\" retain\", \nwith the objectives of removing the undesired knowledge from the forget set while \npreserving the remaining knowledge from the retain. In privacy-focused unlearning", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05316%3F&hl=en&sa=X&d=15276445221595613731&ei=H__YaNGrGcasieoPpPjngQI&scisig=AAZF9b_OE1DXKQI_RHcvSUGaI0fY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Revealing Potential Biases in LLM-Based Recommender Systems in the Cold Start Setting", "first_label": ["LLM"], "second_label": [], "data": "A Andre, G Roy, E Dyer, K Wang- arXiv preprint arXiv:2508.20401, 2025\nLarge Language Models (LLMs) are increasingly used for recommendation tasks \ndue to their general-purpose capabilities. While LLMs perform well in rich-context \nsettings, their behavior in cold-start scenarios, where only limited signals such as", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.20401%3F&hl=en&sa=X&d=14157156363092404303&ei=H__YaNGrGcasieoPpPjngQI&scisig=AAZF9b95JVATA_nzKnQYQUR0MKqQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Counterfactual Sensitivity for Faithful Reasoning in Language Models", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "IF Shihab, S Akter, A Sharma- arXiv preprint arXiv:2509.01544, 2025\nLarge language models (LLMs) often produce correct answers while relying on \nflawed or irrelevant reasoning traces, undermining their trustworthiness in high-\nstakes domains. We propose Counterfactual Sensitivity Regularization (CSR), a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01544&hl=en&sa=X&d=16973430102837298098&ei=H__YaNGrGcasieoPpPjngQI&scisig=AAZF9b-nLRKB4WgajHq7UxZ_NYzW&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "OpenAIs HealthBench in Action: Evaluating an LLM-Based Medical Assistant on Realistic Clinical Queries", "first_label": ["LLM"], "second_label": [], "data": "S Ravichandran, S Kumar, RC Da Silva, M Romano- arXiv preprint arXiv, 2025\nEvaluating large language models (LLMs) on their ability to generate high-quality, \naccurate, situationally aware answers to clinical questions requires going beyond \nconventional benchmarks to assess how these systems behave in complex, high\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.02594&hl=en&sa=X&d=17247662421928146650&ei=H__YaNGrGcasieoPpPjngQI&scisig=AAZF9b-_LEreqIKMwlEfCEFVqc1k&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Investigating Security Implications of Automatically Generated Code on the Software Supply Chain", "first_label": ["Code"], "second_label": [], "data": "X Li, X Gao- arXiv preprint arXiv:2509.20277, 2025\nIn recent years, various software supply chain (SSC) attacks have posed significant \nrisks to the global community. Severe consequences may arise if developers \nintegrate insecure code snippets that are vulnerable to SSC attacks into their \nproducts. Particularly, code generation techniques, such as large language models \n(LLMs), have been widely utilized in the developer community. However, LLMs are \nknown to suffer from inherent issues when generating code, including fabrication\nCites: Thanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.20277&hl=en&sa=X&d=2296943167312732667&ei=Hf_YaKXsL8asieoPpPjngQI&scisig=AAZF9b-8NoLnJec2thOZdzkxyd9r&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le", "1 new citation to articles by Thanh Le-Cong"]}
{"title": "Integration of Federated Learning and Blockchain in Healthcare: A Tutorial on Medical Data, Architectures, Privacy, Security, and Regulatory Compliance", "first_label": ["Blockchain"], "second_label": [], "data": "Y Shahsavaria, Y Baseria, A Hafida, OA Dambrib\nAbstract The convergence of Artificial Intelligence (AI), Blockchain (BC) technology, \nand healthcare represents one of the most transformative but technically challenging \nfrontiers in computational medicine. As healthcare systems worldwide transition \ntoward data-driven paradigms for precision medicine, clinical decision support, and \npopulation health management, the imperative for secure, privacypreserving, and \ncollaborative learning frameworks has reached critical importance. This tutorial\nCites: Smart contract development: Challenges and opportunities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Yaser-Baseri/publication/393444796_Integration_of_Federated_Learning_and_Blockchain_in_Healthcare_A_Tutorial_on_Medical_Data_Architectures_Privacy_Security_and_Regulatory_Compliance_Preprint/links/68c089c573c8345b7a5b1a17/Integration-of-Federated-Learning-and-Blockchain-in-Healthcare-A-Tutorial-on-Medical-Data-Architectures-Privacy-Security-and-Regulatory-Compliance-Preprint.pdf&hl=en&sa=X&d=10705310331546246656&ei=Hf_YaKXsL8asieoPpPjngQI&scisig=AAZF9b-EVXPlZrCF6HLeWzFPV8Jc&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "Socio-Technical Well-Being of Quantum Software Communities: An Overview on Community Smells", "first_label": [], "second_label": [], "data": "S Lambiase, M De Stefano, F Palomba, F Ferrucci- Euromicro Conference on, 2025\nQuantum computing has gained significant attention due to its potential to solve \ncomputational problems beyond the capabilities of classical computers. With major \ncorporations and academic institutions investing in quantum hardware and software\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1007/978-3-032-04207-1_4&hl=en&sa=X&d=5411773039029841438&ei=Hv_YaNjkH5u1ieoPmM6V8Q0&scisig=AAZF9b_i645xnTco7Kl-oDI6QBjy&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=1&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines", "first_label": ["LLM"], "second_label": ["Search"], "data": "Z Zhang, T Ma, Z Wang, Y Li, S Hou, W Sun, K Shi- arXiv preprint arXiv, 2025\nCutting-edge Artificial Intelligence (AI) techniques keep reshaping our view of the \nworld. For example, Large Language Models (LLMs) based applications such as \nChatGPT have shown the capability of generating human-like conversation on \nextensive topics. Due to the impressive performance on a variety of language-related \ntasks (eg, open-domain question answering, translation, and document \nsummarization), one can envision the far-reaching impacts that can be brought by\nCites: Bugsinpy: a database of existing bugs in python programs to\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19580&hl=en&sa=X&d=1816044627885700729&ei=Hf_YaKjmH9vTieoPv4yi2QM&scisig=AAZF9b8CyxErowR38S6wIhjHkLbk&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["1 new citation to articles by Hong Jin Kang", "6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Parallel Fuzzing based on Sub-tasks Scheduling", "first_label": ["Fuzzing"], "second_label": [], "data": "T Gu, T Wang, X Li, S Lu, Y Nie, Z Zhang, X Kuang- ACM Transactions on Software\nParallel fuzzing introduces two key steps: task division and task merging to improve \nefficiency and effectiveness. However, existing works lack effective analysis of task \nresults during task merging; they employ simple differential seed distribution", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3766542&hl=en&sa=X&d=2693574529684625139&ei=Hv_YaI2ELuvD6rQP-pzPsQ4&scisig=AAZF9b9aadL5OeSioZ8HLhUivWic&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Conversational Automated Program Repair for ARM Assembly Code using LLMs", "first_label": ["APR", "LLM", "Code"], "second_label": ["Repair"], "data": "J Gomes, D Silveira, T Jorge\nThis paper explores the development of the Automated Program Repair (APR) field, \nwith a specific emphasis on the use of Large Language Models (LLMs) to tackle the \nchallenges of ARM assembly code in the AIR project, a joint initiative between GMV", "link": "https://scholar.google.com/scholar_url?url=https://www.horizon-schumann.eu/wp-content/uploads/2025/07/Conversational_Automated_Program_Repair_for_ARM_Assembly_Code_using_LLMs_final.pdf&hl=en&sa=X&d=4367788842176228212&ei=Hv_YaI2ELuvD6rQP-pzPsQ4&scisig=AAZF9b_8xrU3osMG0qpQXxLpnrK7&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FuzzRDUCC: Fuzzing with Reconstructed Def-Use Chain Coverage", "first_label": ["Fuzzing"], "second_label": [], "data": "K Feng, J Singer, AK Marnerides- arXiv preprint arXiv:2509.04967, 2025\nBinary-only fuzzing often struggles with achieving thorough code coverage and \nuncovering hidden vulnerabilities due to limited insight into a program's internal \ndataflows. Traditional grey-box fuzzers guide test case generation primarily using", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04967&hl=en&sa=X&d=12793668697793724612&ei=Hv_YaI2ELuvD6rQP-pzPsQ4&scisig=AAZF9b9DbASTknJLZ9Qw2muyThkA&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Fuzzing JavaScript JIT compilers with a high-quality differential test oracle", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "J Li, H Xu, Y Wang, Z Jiang, H Chun, P Xie, Y Chen- Computers & Security, 2025\nAbstract Modern JavaScript engines use Just-In-Time (JIT) compilers to convert \nfrequently executed code into machine instructions, boosting performance for web \napplications and cross-platform systems. However, the optimizations in JIT compilers", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825003499&hl=en&sa=X&d=7438620869129233397&ei=Hv_YaI2ELuvD6rQP-pzPsQ4&scisig=AAZF9b8tN2mMloCI7htWicorKtpq&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FuzzBox: Blending Fuzzing into Emulation for Binary-Only Embedded Targets", "first_label": ["Fuzzing"], "second_label": [], "data": "C Cesarano, R Natella- arXiv preprint arXiv:2509.05643, 2025\nCoverage-guided fuzzing has been widely applied to address zero-day \nvulnerabilities in general-purpose software and operating systems. This approach \nrelies on instrumenting the target code at compile time. However, applying it to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05643&hl=en&sa=X&d=4585422960426806286&ei=Hv_YaI2ELuvD6rQP-pzPsQ4&scisig=AAZF9b-p7mmDlvT3yh-ZhB_TgxIV&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=6&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Leveraging SystemC-TLM-based Virtual Prototypes for Embedded Software Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "C Ghinami, J Winzer, N Bosbach, LM Reimann- arXiv preprint arXiv, 2025\nSystemC-based virtual prototypes have emerged as widely adopted tools to test \nsoftware ahead of hardware availability, reducing the time-to-market and improving \nsoftware reliability. Recently, fuzzing has become a popular method for automated", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01318&hl=en&sa=X&d=1341175212014518141&ei=Hv_YaI2ELuvD6rQP-pzPsQ4&scisig=AAZF9b9xqbJnzFJ8oCl2uemQ46wF&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=7&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Syntactic multilingual probing of pre-trained language models of code", "first_label": ["LLM", "Code"], "second_label": [], "data": "JAH Lpez, M Weyssow, JS Cuadrado, H Sahraoui- Journal of Systems and, 2026\nPre-trained language models (PLMs) have demonstrated remarkable abilities in \ncoding tasks, establishing themselves as a state-of-the-art technique in machine \nlearning for code. However, due to their deep neural network-based structure, PLMs\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225002730&hl=en&sa=X&d=912414639058686127&ei=Hv_YaI2ELuvD6rQP-pzPsQ4&scisig=AAZF9b_JpbZnEYTzTsY6dFTnCppp&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=8&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "On the Effectiveness of Zero-shot and Few-shot Pretrained Language Models for Software Requirement Classification", "first_label": ["LLM"], "second_label": [], "data": "M Shafikuzzaman, MR Islam, S Zaman, A Ma, AI Sifat- IEEE Access, 2025\nAccurate classification of software requirements, particularly distinguishing between \nfunctional and non-functional requirements, is essential for enabling traceability, \nguiding system design, and ensuring project success. Traditional supervised\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/10820123/11153850.pdf&hl=en&sa=X&d=11947882102757591897&ei=HP_YaLjmOsnXieoPvqrN8Qs&scisig=AAZF9b8nTkSrJUN-rA-zvTdkgh4M&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Unleashing the Power of Open Source Large Language Models for Cybersecurity: Key Insights and Challenges", "first_label": ["LLM"], "second_label": [], "data": "M Basbas, B Djamaa, MR Senouci - 2025\nThe rising rate of cyberattacks and dearth of skilled cybersecurity professionals \nrequire innovative solutions beyond traditional security measures. Large Language \nModels (LLMs), famed for their natural language processing abilities, present a \nviable way to improve cybersecurity defenses. However, despite LLMs' exploration in \nvarious security applications, systematic research aligning LLMs' contributions with \nestablished cybersecurity frameworks is lacking. To bridge this gap, this paper\nCites: Program Repair and Trusted Automatic Programming", "link": "https://scholar.google.com/scholar_url?url=https://www.authorea.com/doi/pdf/10.22541/au.175825816.67299409&hl=en&sa=X&d=7583441569753563379&ei=Hv_YaKeaEaDWieoP0ZmP6AE&scisig=AAZF9b-bMh8f4rZ32m-VifMQqQ9a&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Protocol Testing with I/O Grammars", "first_label": ["Software Testing"], "second_label": [], "data": "A Liggesmeyer, JAZ Amaya, A Zeller- arXiv preprint arXiv:2509.20308, 2025\nGenerating software tests faces two fundamental problems. First, one needs to \n_generate inputs_ that are syntactically and semantically correct, yet sufficiently \ndiverse to cover behavior. Second, one needs an _oracle_ to _check outputs_ \nwhether a test case is correct or not. Both problems become apparent in _protocol \ntesting_, where inputs are messages exchanged between parties, and outputs are \nthe responses of these parties. In this paper, we propose a novel approach to\nCites: Smart greybox fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.20308&hl=en&sa=X&d=5108415156373008412&ei=Hv_YaKeaEaDWieoP0ZmP6AE&scisig=AAZF9b_h6X_FdEIK8pFVpuWl7m91&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "FuzzyDoo: a Framework for Finding Flaws in the 5G Landscape", "first_label": ["Fuzzing"], "second_label": [], "data": "RG Garroppo, M Pagano, G Pongelli- Computer Networks, 2025\nThe increasing complexity and criticality of 5G networks demand rigorous security \ntesting methodologies, particularly in black-box environments where source code \naccess is restricted. This paper introduces FuzzyDoo, an open-source, mutation-\nbased structure-aware fuzzing framework designed to assess the robustness and \nsecurity of 5G Core (5GC) network functions under black-box conditions. FuzzyDoo \nadvances the state of the art by enabling dynamic test message generation for\nCites: AFLNet: a greybox fuzzer for network protocols", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1389128625007005&hl=en&sa=X&d=10812254043391783482&ei=Hv_YaKeaEaDWieoP0ZmP6AE&scisig=AAZF9b_kbsdyHL5ZIfP0tEIafn2k&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Application of Machine Learning in Program and Malware Analysis", "first_label": [], "second_label": [], "data": "M Yang - 2025\nProgram and malware analysis tools are important for computer security. Recently, \nmachine learning has been applied to help with program and malware analysis. In \nthis thesis, we investigate a few areas in which the application of machine learning \ncan be used to improve program analysis. We find several cases where \nunderstanding the problem domain of program analysis can be more important than \nachieving raw machine learning capabilities on its own.\nCites: Neuro-Symbolic Execution: Augmenting Symbolic Execution with\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://security.csl.toronto.edu/wp-content/uploads/2025/09/syang_phd_thesis_2025.pdf&hl=en&sa=X&d=7680184589514584257&ei=Hv_YaKeaEaDWieoP0ZmP6AE&scisig=AAZF9b9OvPJINVKEXyI4mEpk0XK7&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Adversarial Bug Reports as a Security Risk in Language Model-Based Automated Program Repair", "first_label": ["APR", "LLM", "Bug"], "second_label": ["Repair"], "data": "P Przymus, A Happe, J Cito- arXiv preprint arXiv:2509.05372, 2025\nLarge Language Model (LLM)-based Automated Program Repair (APR) systems are \nincreasingly integrated into modern software development workflows, offering \nautomated patches in response to natural language bug reports. However, this", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05372&hl=en&sa=X&d=17856431439942945890&ei=Hf_YaKyLD9q06rQPy6vVkAI&scisig=AAZF9b9iNtxXJTJlEQXG_3JYQbs1&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Richard Fang - new related research"]}
{"title": "From Cryptic to Clear-Training on LLM Explanations to Detect Smart Contract Vulnerabilities", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": [], "data": "Y Chen, Z Sun, G Wang, Q Liang, X Yu, D Hao- ACM Transactions on Software, 2025\nSmart contracts have revolutionized the way transactions are executed, offering \ndecentralized and immutable frameworks. The immutability of smart contracts poses \nsignificant risks when vulnerabilities exist in their code, leading to financial losses", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3765753&hl=en&sa=X&d=10696251976758637118&ei=Hf_YaKyLD9q06rQPy6vVkAI&scisig=AAZF9b9ZBf4NQYTpgMU9yATSPdqf&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "GTVD: a multi-level aggregation vulnerability detection method based on full-dependency program graph", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "H He, S Li, Y Li, Y Li- Cluster Computing, 2025\nIn modern software development life cycles, proactive vulnerability discovery and \nremediation play crucial roles in ensuring application security. However, current \ndeep learning-based vulnerability detection methods frequently face limitations due\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10586-025-05506-7&hl=en&sa=X&d=9365356712912853263&ei=Hf_YaKyLD9q06rQPy6vVkAI&scisig=AAZF9b_DdZ4fyL1mLj90wo4wpBRq&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "The Question Neighbourhood Approach for Systematic Evaluation of Code-Generating LLMs", "first_label": ["LLM", "Code"], "second_label": [], "data": "S Honarvar, M Rei, A Donaldson- IEEE Transactions on Software Engineering, 2025\nWe present the concept of a question neighbourhood for systematically evaluating \ninstruction-tuned large language models (LLMs) for code generation via a new \nbenchmark, Turbulence. Turbulence consists of a large set of natural language", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11175086/&hl=en&sa=X&d=12331338329639325411&ei=Kr_XaKHVAsnXieoPvqrN8Qs&scisig=AAZF9b8Ies8RuQhW4d_WHfainK40&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language", "first_label": ["LLM", "Software Testing"], "second_label": ["Agent"], "data": "S Salva, R Taguelmimt- arXiv preprint arXiv:2509.19136, 2025\nThe use of natural language (NL) test cases for validating graphical user interface \n(GUI) applications is emerging as a promising direction to manually written \nexecutable test scripts, which are costly to develop and difficult to maintain. Recent", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19136&hl=en&sa=X&d=14763218273592887225&ei=Kr_XaKHVAsnXieoPvqrN8Qs&scisig=AAZF9b-UHW8cguy7BjMGIC6z7CK9&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "2 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research", "Thanh Le-Cong - new related research"]}
{"title": "LLM-based Vulnerability Discovery through the Lens of Code Metrics", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": [], "data": "F Weissberg, L Pirch, E Imgrund, J Mller, T Eisenhofer- arXiv preprint arXiv, 2025\nLarge language models (LLMs) excel in many tasks of software engineering, yet \nprogress in leveraging them for vulnerability discovery has stalled in recent years. To \nunderstand this phenomenon, we investigate LLMs through the lens of classic code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19117&hl=en&sa=X&d=9123199236929215814&ei=Kr_XaKHVAsnXieoPvqrN8Qs&scisig=AAZF9b9NYfbk81y_m-4rkRbLeJNM&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "Richard Fang - new related research", "David Lo - new related research", "Thanh Le-Cong - new related research"]}
{"title": "A Two-Stage Framework Integrating Prompt Learning and Fine-Tuning for Code Summarization", "first_label": ["Code"], "second_label": [], "data": "X Sun, S Lv, W Wan, Y Qin, G Hu- International Conference on Artificial Neural, 2025\nSource code summarization automates the generation of natural comments, \nenhancing efficiency in software development and maintenance. With the \nemergence of large language models (LLMs), significant progress has been made in", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-04549-2_24&hl=en&sa=X&d=10692364299398052856&ei=Kr_XaKHVAsnXieoPvqrN8Qs&scisig=AAZF9b8xi2Iw8kWBWVSILvm4_TwI&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "SR-Eval: Evaluating LLMs on Code Generation under Stepwise Requirement Refinement", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Z Zhan, S Gao, R Hu, C Gao- arXiv preprint arXiv:2509.18808, 2025\nLarge language models (LLMs) have achieved remarkable progress in code \ngeneration. However, existing benchmarks mainly formalize the task as a static, \nsingle-turn problem, overlooking the stepwise requirement changes and iterative", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18808&hl=en&sa=X&d=14162583223826256111&ei=Kr_XaKHVAsnXieoPvqrN8Qs&scisig=AAZF9b_T6fIKaT-uWP6LDsRQQhRF&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "OSATG-GPT: Instruction-Tuning Large Language Models with Open-Source Atomic Tasks in GitHub", "first_label": ["LLM"], "second_label": [], "data": "F Han, L Ma, F Bi, Y Wang, M You, W Wang, J Peng- Expert Systems with, 2025\nAcross numerous application scenarios in Natural Language Processing (NLP), \nLarge Language Models (LLMs) have demonstrated exceptional capabilities in text \ncomprehension and generation. These models exhibit significant potential across", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0957417425034347&hl=en&sa=X&d=10572613471784520706&ei=Kr_XaKHVAsnXieoPvqrN8Qs&scisig=AAZF9b-FcEMG2-uR0o8kT9-BQScY&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "Evaluating the Source Code Review Performance of LLM-based AI Chatbots", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "T Kakimoto, H Inayoshi, H Uwano, A Monden\nSource code review plays a critical role in ensuring software quality by identifying \nbugs early in the development process. Although recent studies have explored the \nuse of large language models (LLMs) for tasks such as vulnerability detection and\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Akito-Monden/publication/395728251_Evaluating_the_Source_Code_Review_Performance_of_LLM-based_AI_Chatbots/links/68d2399868064a19c0b971f7/Evaluating-the-Source-Code-Review-Performance-of-LLM-based-AI-Chatbots.pdf&hl=en&sa=X&d=15470312918337070369&ei=Kr_XaKHVAsnXieoPvqrN8Qs&scisig=AAZF9b-tyw2eYIWihY9d7dojU-qG&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Toward efficient vibe coding: An LLM-based agent for low-code software development", "first_label": ["LLM", "Code"], "second_label": ["Agent"], "data": "N Malamas, E Tsardoulias, K Panayiotou- Journal of Computer, 2025\nAbstract The Software Engineering (SE) domain increasingly adopts low-code and \nno-code approaches to simplify application development and deployment. Two \ndominant paradigms have emerged in this space: Model-driven Engineering (MDE), \nleveraging Domain-specific Languages (DSLs) to abstract implementation and \nreduce the knowledge and expertise required, and LLM-based vibe coding, where \ndevelopers interact with Large Language Models (LLMs) using natural language\nCites: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S259011842500053X&hl=en&sa=X&d=14193155343073234717&ei=Jr_XaIWpO-vD6rQP-pzPsQ4&scisig=AAZF9b-LMPQ2q6J-9eobpharqYge&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 new citation to articles by Thanh Le-Cong", "3 new citations to articles by Bach Le"]}
{"title": "WeMu: Effective and Scalable Emulation of Microarchitectural Weird Machines", "first_label": [], "second_label": [], "data": "D Vanspauwen, KU DistriNet, LA Daniel, J Van Bulck\nAbstract Recent research on Microarchitectural Weird Machines (WMs) has shown \nthat microarchitectural optimization features, originally exploited for data exfiltration, \ncan also facilitate hidden computation. Emerging WMs, enabled by dedicated \ncompilers, have become increasingly practical, evading conventional analysis tools \nby executing complex cryptographic algorithms and unpacking malware entirely \nwithin the microarchitectural domain. To address the lack of defensive capabilities\nCites: oo7: Low-overhead defense against spectre attacks via program\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://vanbulck.net/files/uasc26-wemu.pdf&hl=en&sa=X&d=11417229871611200833&ei=KL_XaI3nLqSgieoPmvLA-Ac&scisig=AAZF9b86FUlK5wIkmbZ4jhFfJu4x&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
{"title": "ArchiteCAD: a large-scale architectural CAD dataset for symbol spotting towards CAD-to-BIM conversion", "first_label": [], "second_label": [], "data": "Q Zhao, L Zhou, Y Wang, P Wang, Q Li- International Journal on Document Analysis, 2025\nAbstract Building Information Modeling (BIM) is integral to the Architecture, \nEngineering, Construction and Operations (AECO) industry, facilitating efficient \nproject management and lifecycle maintenance. However, obtaining BIM models for", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10032-025-00557-3&hl=en&sa=X&d=7550212691038930422&ei=J7_XaLDLD-ak6rQP4M2KgAY&scisig=AAZF9b8s4a37jGaRnsYUhdnheJNR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models", "first_label": ["LLM", "Bug", "Repository-Level"], "second_label": [], "data": "J Liu, Z Liu, Z Cheng, M He, X Shi, Y Guo, X Zhu, Y Guo- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have exhibited significant proficiency in code \ndebugging, especially in automatic program repair, which may substantially reduce \nthe time consumption of developers and enhance their efficiency. Significant\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04078%3F&hl=en&sa=X&d=12419661760319839544&ei=J7_XaLDLD-ak6rQP4M2KgAY&scisig=AAZF9b8SHef7li0_lXitWcja8LI-&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Improving Software Defect Detection with LSTM-Based Semantic Modeling and Class Imbalance Handling", "first_label": ["Software Defect"], "second_label": ["Detection"], "data": "H Andrade, N Pombo, S Pais- IEEE Open Journal of the Computer Society, 2025\nSoftware Defect Prediction (SDP) plays a vital role in maintaining software quality, \nespecially as modern systems grow in size and complexity. Traditional SDP models \nthat rely on static code metrics often fail to capture the semantic and contextual \nrelationships inherent in source code, limiting their prediction accuracy and ability to \ngeneralize across projects. In this study, we propose a Deep Learning (DL)-based \napproach that combines Long Short-Term Memory (LSTM) networks with semantic\nCites: Benchmarking Large Language Models for Multi-Language", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/8782664/9024218/11175486.pdf&hl=en&sa=X&d=9555248039218663585&ei=KL_XaOOEA8asieoPpPjngQI&scisig=AAZF9b9b1_M5cgKwrTlgRQcKrwb0&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang", "2 new citations to articles by Xin ZHOU"]}
{"title": "CoRaCMG: Contextual Retrieval-Augmented Framework for Commit Message Generation", "first_label": ["Commit Message"], "second_label": ["Generation"], "data": "B Xiong, L Zhang, C Wang, P Liang- arXiv preprint arXiv:2509.18337, 2025\nCommit messages play a key role in documenting the intent behind code changes. \nHowever, they are often low-quality, vague, or incomplete, limiting their usefulness. \nCommit Message Generation (CMG) aims to automatically generate descriptive \ncommit messages from code diffs to reduce developers' effort and improve message \nquality. Although recent advances in LLMs have shown promise in automating CMG, \ntheir performance remains limited. This paper aims to enhance CMG performance by\nCites: Cc2vec: Distributed representations of code changes", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18337&hl=en&sa=X&d=15529871488308136613&ei=KL_XaOOEA8asieoPpPjngQI&scisig=AAZF9b83TNlhuoSOkfEGOwe9NMXv&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang"]}
{"title": "Learning Resource Center, Jiangsu College of Engineering and Technology; School of Information Science and Technology, Nantong University", "first_label": [], "second_label": [], "data": "Y Fan, XIA Hongling\n. \n, , \n. \n,  \n(prediction based on data augmentation, PDA) . PDA , \n,  4 . \nCites: Cc2vec: Distributed representations of code changes\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ngzke.cbpt.cnki.net/portal/journal/portal/client/paper/b0c24bd5a0fce0534e51952aa7416cf0&hl=en&sa=X&d=16235849338654281840&ei=KL_XaOOEA8asieoPpPjngQI&scisig=AAZF9b_zipgKxI4KAFY0FFN-_los&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang"]}
{"title": "Locus: Agentic Predicate Synthesis for Directed Fuzzing", "first_label": ["Fuzzing"], "second_label": ["Agent"], "data": "J Zhu, C Shen, Z Li, J Yu, Y Chen, K Pei- arXiv preprint arXiv:2508.21302, 2025\nDirected fuzzing aims to find program inputs that lead to specified target program \nstates. It has broad applications, such as debugging system crashes, confirming \nreported bugs, and generating exploits for potential vulnerabilities. This task is\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21302&hl=en&sa=X&d=2138932734315377454&ei=Kr_XaJTIDp6sieoPwu_ngQ4&scisig=AAZF9b9iXz21pxlN8QAQ_QbeooKc&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Detection of security smells in IaC scripts through semantics-aware code and language processing", "first_label": ["Code"], "second_label": ["Detection"], "data": "A War, AA Rawass, AK Kabore, J Samhi, J Klein- arXiv preprint arXiv, 2025\nInfrastructure as Code (IaC) automates the provisioning and management of IT \ninfrastructure through scripts and tools, streamlining software deployment. Prior \nstudies have shown that IaC scripts often contain recurring security", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18790&hl=en&sa=X&d=1329338443620150235&ei=KL_XaMrRPOvD6rQP-pzPsQ4&scisig=AAZF9b9fvPQ3UZ03xSIuiTX5fpid&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=1&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Security smells in infrastructure as code: a taxonomy update beyond the seven sins", "first_label": ["Code"], "second_label": [], "data": "A War, SLB Nikiema, J Samhi, J Klein, TF Bissyande- arXiv preprint arXiv, 2025\nInfrastructure as Code (IaC) has become essential for modern software \nmanagement, yet security flaws in IaC scripts can have severe consequences, as \nexemplified by the recurring exploits of Cloud Web Services. Prior work has", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18761&hl=en&sa=X&d=4584619337256832365&ei=KL_XaMrRPOvD6rQP-pzPsQ4&scisig=AAZF9b87fl3YPXxXEp2VEu21mnOM&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Vulnerability Detection in Solidity Smart Contracts via Machine Learning: A Qualitative Analysis", "first_label": ["Vulnerabilities", "Smart Contracts"], "second_label": ["Detection"], "data": "D Ressi, A Span, L Benetollo, M Bugliesi, C Piazza- Blockchain: Research and, 2025\nSmart contracts are central to most blockchain applications, from financial \ntransactions to supply chain management. However, their adoption is hindered by \nsecurity vulnerabilities that can result in significant financial losses. Most vulnerability\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S2096720925001174&hl=en&sa=X&d=2151998906183719167&ei=KL_XaMrRPOvD6rQP-pzPsQ4&scisig=AAZF9b838SuJ8zfdDwRNltkfkdiB&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=3&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "2 new citations to articles by Xin ZHOU"]}
{"title": "Safe and Effective Post-Fine-tuning Alignment in Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "M Jiang, Y Yang, X Xie, P Ke, G Liu- Knowledge-Based Systems, 2025\nFine-tuning is critical to customizing Large Language Models (LLMs) in various \napplications, but it inevitably disrupts the safety alignment of the models. Current \nalignment methods tackle harmful fine-tuning challenges but frequently compromise \nmodel usefulness, resulting in unsatisfactory downstream task performance. To \naddress this issue, we propose a Safe and Effective post-fine-tuning Alignment (SEA) \nfrom a knowledge disentanglement perspective. SEA introduces a novel two-level\nCites: Removing rlhf protections in gpt-4 via fine-tuning", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S095070512501562X&hl=en&sa=X&d=9680225592681546011&ei=J7_XaNKiIJXP6rQPo4LniQU&scisig=AAZF9b_4Aqi8lJbTDoFQwa4yTUWn&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Beekeeper: Accelerating Honeypot Analysis with LLM-driven Feedback", "first_label": ["LLM"], "second_label": [], "data": "N Ilg, D Germek, P Duplys, M Menth- IEEE Access, 2025\nHoneypots are decoy resources intended to entice adversaries and collect threat \nintelligence in the process. The amount and quality of the collected insights strongly \ncorrelate with the honeypot's credibility to the adversary. However, the development \nof medium to high interaction honeypots, so, environments that offer at minimum a \nshell to the attacker, is laborious and complex. Additionally, getting feedback on a \nhoneypot is often expensive and time-consuming, slowing down development and\nCites: Llm agents can autonomously hack websites\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11175384.pdf&hl=en&sa=X&d=10963313873632792203&ei=J7_XaNKiIJXP6rQPo4LniQU&scisig=AAZF9b9Y5QfsbgUHObnBpBtzTRq7&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Paladin: Defending LLM-enabled Phishing Emails with a New Trigger-Tag Paradigm", "first_label": ["LLM"], "second_label": [], "data": "Y Pang, W Meng, X Liao, T Wang- arXiv preprint arXiv:2509.07287, 2025\nWith the rapid development of large language models, the potential threat of their \nmalicious use, particularly in generating phishing content, is becoming increasingly \nprevalent. Leveraging the capabilities of LLMs, malicious users can synthesize", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.07287&hl=en&sa=X&d=841142860163656335&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b9zUiVve_NVtg5_7UjR-gXJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Backdoor Attacks and Defenses in Computer Vision Domain: A Survey", "first_label": [], "second_label": [], "data": "BH Abbasi, Y Zhang, L Zhang, S Gao- arXiv preprint arXiv:2509.07504, 2025\nBackdoor (trojan) attacks embed hidden, controllable behaviors into machine-\nlearning models so that models behave normally on benign inputs but produce \nattacker-chosen outputs when a trigger is present. This survey reviews the rapidly", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.07504&hl=en&sa=X&d=3269854252125827141&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b9hUL9vDNoEXnWcZIb5H3Bf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Leveraging CVAE Encoding for Backdoor Attacks in Few-Shot Learning with Prototypical Networks", "first_label": [], "second_label": [], "data": "Q Yan, S Liang, A Ullah- IEEE Transactions on Dependable and Secure, 2025\nFew-shot learning (FSL) has demonstrated tremendous potential when challenged \nwith limited training data, but the assessment of its vulnerability to backdoor attacks is \nstill at an early stage. However, recent research revealed this deep learning", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11152502/&hl=en&sa=X&d=6687930075784700670&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b9ptsbEWBr80FGSyzcZR2Er&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Prototype-Guided Robust Learning against Backdoor Attacks", "first_label": [], "second_label": [], "data": "W Guo, M Pintor, A Demontis, B Biggio- arXiv preprint arXiv:2509.08748, 2025\nBackdoor attacks poison the training data to embed a backdoor in the model, \ncausing it to behave normally on legitimate inputs but maliciously when specific \ntrigger signals appear. Training a benign model from a dataset poisoned by", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.08748&hl=en&sa=X&d=9079518275239981489&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b8nbcMJrz3EP9De5YM82FpF&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Exploit Tool Invocation Prompt for Tool Behavior Hijacking in LLM-Based Agentic System", "first_label": ["LLM"], "second_label": ["Agent", "Exploit"], "data": "Y Liu, Y Xie, M Luo, Z Liu, Z Zhang, K Zhang, Z Li- arXiv preprint arXiv, 2025\nLLM-based agentic systems leverage large language models to handle user queries, \nmake decisions, and execute external tools for complex tasks across domains like \nchatbots, customer service, and software engineering. A critical component of these", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05755%3F&hl=en&sa=X&d=7380962265010499197&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b_WNN5iEJzU4LQ3fLBGGpF6&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Oyster-I: Beyond Refusal--Constructive Safety Alignment for Responsible Language Models", "first_label": ["LLM"], "second_label": [], "data": "R Duan, J Liu, X Jia, S Zhao, R Cheng, F Wang, C Wei- arXiv preprint arXiv, 2025\nLarge language models (LLMs) typically deploy safety mechanisms to prevent \nharmful content generation. Most current approaches focus narrowly on risks posed \nby malicious actors, often framing risks as adversarial events and relying on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01909%3F&hl=en&sa=X&d=6590160868100905669&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b8p2pmNGwnqdehrNy547NkZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Jailbreak Attack with Multimodal Virtual Scenario Hypnosis for Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "X Shi, S Chen, G Zhang, W Wei, Y Li, Z Fan, J Liu- Pattern Recognition, 2025\nDue to the inherent vulnerabilities of large Vision-Language Models (VLMs), security \ngovernance has emerged as a critical concern, particularly given the risks posed by \nnoisy and biased training data as well as adversarial attacks, including data", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0031320325010520&hl=en&sa=X&d=18404876866865125967&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b9xJx3YOX0I9CBN24pCw_YG&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Why language models hallucinate", "first_label": ["LLM"], "second_label": [], "data": "AT Kalai, O Nachum, SS Vempala, E Zhang- arXiv preprint arXiv:2509.04664, 2025\nLike students facing hard exam questions, large language models sometimes guess \nwhen uncertain, producing plausible yet incorrect statements instead of admitting \nuncertainty. Such\" hallucinations\" persist even in state-of-the-art systems and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04664&hl=en&sa=X&d=17470905045322269269&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b9-xvJdrsXYLi4Kkc78fX8P&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A Decade of Blockchain in Finance: Bibliometric Analysis and Research Directions", "first_label": ["Blockchain"], "second_label": ["Search"], "data": "K Harish Kumar- Journal of Business and Social Sciences, 2025\nBlockchain technology has rapidly emerged as a transformative force across sectors \nsuch as healthcare, supply chains, energy, and voting systems. Its decentralized, \ntransparent, and secure architecture improves efficiency, enhances trust, and \nreduces costs. Among these domains, finance has experienced the greatest \ndisruption, with blockchain reshaping banking by fostering transparency, security, \nand efficiency. This study presents a bibliometric analysis of blockchain in finance\nCites: Smart contract development: Challenges and opportunities", "link": "https://scholar.google.com/scholar_url?url=http://eprints.intimal.edu.my/2186/1/jobss2025_9.pdf&hl=en&sa=X&d=10616597400148191896&ei=KL_XaLOCEpCq6rQPzKzJyAY&scisig=AAZF9b8gAs4suTcLPzezisu9FGf-&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "ChopChop: a Programmable Framework for Semantically Constraining the Output of Language Models", "first_label": ["LLM"], "second_label": [], "data": "S Nagy, T Zhou, N Polikarpova, L D'Antoni- arXiv preprint arXiv:2509.00360, 2025\nLanguage models (LMs) can generate code, but cannot guarantee its correctness--\nproducing outputs that often violate type safety, program invariants, or semantic \nequivalence. Constrained decoding offers a solution by restricting generation to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.00360&hl=en&sa=X&d=15761961036894749958&ei=KL_XaL7PIMmk6rQPwcXzuAc&scisig=AAZF9b9gFg_U0FktMXuQ5DX2sTxT&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Generic Adversarial Smart Contract Detection with Semantics and Uncertainty-Aware LLM", "first_label": ["Smart Contracts", "LLM"], "second_label": ["Detection"], "data": "Y Liu, X Su, H Wu, S Li, Y Cheng, F Xu, S Zhong- arXiv preprint arXiv:2509.18934, 2025\nAdversarial smart contracts, mostly on EVM-compatible chains like Ethereum and \nBSC, are deployed as EVM bytecode to exploit vulnerable smart contracts typically \nfor financial gains. Detecting such malicious contracts at the time of deployment is an", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18934&hl=en&sa=X&d=13248780610884419900&ei=KL_XaL7PIMmk6rQPwcXzuAc&scisig=AAZF9b8ZyuD68cpLgk5pKTuBk84S&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Security Evaluation of Android apps in budget African Mobile Devices", "first_label": [], "second_label": [], "data": "A Diallo, A Diop, AK Kabore, J Samhi, A Pilgun- arXiv preprint arXiv, 2025\nAndroid's open-source nature facilitates widespread smartphone accessibility, \nparticularly in price-sensitive markets. System and vendor applications that come pre-\ninstalled on budget Android devices frequently operate with elevated privileges, yet\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18800&hl=en&sa=X&d=6613736328542570603&ei=KL_XaL7PIMmk6rQPwcXzuAc&scisig=AAZF9b9YjkOqw5_ynkAveNeMK2j4&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Benchmarking and Studying the LLM-based Code Review", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "Z Zeng, R Shi, K Han, Y Li, K Sun, Y Wang, Z Yu, R Xie- arXiv preprint arXiv, 2025\nAutomated Code Review (ACR) is crucial for software quality, yet existing \nbenchmarks often fail to reflect real-world complexities, hindering the evaluation of \nmodern Large Language Models (LLMs). Current benchmarks frequently focus on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01494&hl=en&sa=X&d=9924101107475937857&ei=J7_XaOuuMNq06rQPy6vVkAI&scisig=AAZF9b9CW-Ez1-ukRHGu-p7F6_IT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "PromeFuzz: A Knowledge-Driven Approach to Fuzzing Harness Generation with Large Language Models", "first_label": ["LLM", "Fuzzing"], "second_label": ["Generation"], "data": "Y Liu, J Deng, X Jia, Y Wang, M Wang, L Huang, T Wei\nFuzzing has long been recognized as an effective technique for uncovering security \nvulnerabilities by automatically generating and executing a diverse set of inputs [2, 3, \n6, 8, 14, 15, 18, 20, 24, 26, 30, 32, 34, 46, 52, 53, 55, 58]. Traditional fuzzing tools", "link": "https://scholar.google.com/scholar_url?url=https://pvz122.github.io/pdf/25-promefuzz.pdf&hl=en&sa=X&d=12396611312661296556&ei=Kb_XaNyDDZu1ieoPmM6V8Q0&scisig=AAZF9b-wSitwHBsEc3RIko2Rlc5c&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Fuzzing JavaScript Engines by Fusing JavaScript and WebAssembly", "first_label": ["Fuzzing"], "second_label": [], "data": "J Lin, C Luo, M Zhang, L Lin, P Li, C Qian - 2026\nJavaScript engines are a fundamental part of modern browsers, and many efforts \nhave been invested in testing them to enhance their security. However, the \nincorporation of WebAssembly into JavaScript engines introduces new attack\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://peng-hui.github.io/data/paper/icse26:mad-eye.pdf&hl=en&sa=X&d=7025301240690243176&ei=Kb_XaNyDDZu1ieoPmM6V8Q0&scisig=AAZF9b87H2l6opoFTjGi99T54n3u&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
