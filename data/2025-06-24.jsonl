{"title": "HornBro: Homotopy-Like Method for Automated Quantum Program Repair", "first_label": ["APR"], "second_label": ["Repair"], "data": "S Tan, L Lu, D Xiang, T Chu, C Lang, J Chen, X Hu\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nQuantum programs provide exponential speedups compared to classical programs \nin certain areas, but they also inevitably encounter logical faults. Automatically \nrepairing quantum programs is much more challenging than repairing classical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715751&hl=en&sa=X&d=13228585835236654799&ei=S3pZaLzlIMy8ieoPt5yl6Qk&scisig=AAZF9b-8_CqaMqv576h_a4v0IZHT&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Thanh Le-Cong - new related research", "Bach Le - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Directed Testing in MLIR: Unleashing Its Potential by Overcoming the Limitations of Random Fuzzing", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "W Tong, Z Wang, Z Tang, J Fang, Y Zhang, G Ye\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMLIR is a new way of creating compiler infrastructures that can be easily reused and \nextended. Current MLIR fuzzing methods focus primarily on test case generation or \nmutation using randomly selected passes. However, they often overlook the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729372&hl=en&sa=X&d=10225165863736020095&ei=S3pZaLzlIMy8ieoPt5yl6Qk&scisig=AAZF9b9XDaU-7-dG1ms-uNWhw7no&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "KRAKEN: Program-Adaptive Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A ZHOU, H HUANG, C ZHANG - 2025\nDespite numerous advances, most existing fuzzers still require more than 24 hours to \nthoroughly test the target programs to achieve satisfactory code coverage or bug \ndetection results [7, 32, 42, 64]. Recently, as cloud-based computing and multicore\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://seviezhou.github.io/files/kraken.pdf&hl=en&sa=X&d=6944396394299119143&ei=S3pZaLzlIMy8ieoPt5yl6Qk&scisig=AAZF9b9QILhkfV1b1x87AW8NkoEo&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "DuoReduce: Bug Isolation for Multi-layer Extensible Compilation", "first_label": ["Bug"], "second_label": [], "data": "J Wang, Y Qiu, B Limpanukorn, HJ Kang, Q Zhang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, the MLIR framework has had explosive growth due to the need for \nextensible deep learning compilers for hardware accelerators. Such examples \ninclude Triton, CIRCT, and ONNX-MLIR. MLIR compilers introduce significant \ncomplexities in localizing bugs or inefficiencies because of their layered optimization \nand transformation process with compilation passes. While existing delta debugging \ntechniques can be used to identify a minimum subset of IR code that reproduces a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFuzzing MLIR by Synthesizing Custom Mutations\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715747&hl=en&sa=X&d=16704826441152364364&ei=S3pZaM6FFvuvieoPxs6ggQU&scisig=AAZF9b8GmmhtQmNd80UBCU8gRDJz&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["6 new citations to articles by Hong Jin Kang"]}
{"title": "An Adaptive Language-Agnostic Pruning Method for Greener Language Models for Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "M Saad, JAH L\\xc3\\xb3pez, B Chen, D Varr\\xc3\\xb3, T Sharma\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models of code have demonstrated remarkable performance across \nvarious software engineering and source code analysis tasks. However, their \ndemanding computational resource requirements and consequential environmental \nfootprint remain as significant challenges. This work introduces ALPINE, an adaptive \nprogramming language-agnostic pruning technique designed to substantially reduce \nthe computational overhead of these models. The proposed method offers a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaGreening large language models of code\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715773&hl=en&sa=X&d=7944316343425442468&ei=S3pZaM6FFvuvieoPxs6ggQU&scisig=AAZF9b_df9m6q87B5fG6FvHqqLve&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["6 new citations to articles by Hong Jin Kang", "6 new citations to articles by Bach Le", "David Lo - new related research", "Bach Le - new related research", "Xin ZHOU - new related research", "3 new citations to articles by Thanh Le-Cong"]}
{"title": "Towards Understanding Fine-Grained Programming Mistakes and Fixing Patterns in Data Science", "first_label": [], "second_label": [], "data": "WH Chen, JL Cheoh, M Keim, S Brunswicker, T Zhang\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nProgramming is an essential activity in data science (DS). Unlike regular software \ndevelopers, DS programmers often use Jupyter notebooks instead of conventional \nIDEs. Moreover, DS programmers focus on statistics, data analytics, and modeling \nrather than writing production-ready code following best practices in software \nengineering. Thus, in order to provide effective tool support to improve their \nproductivity, it is important to understand what kinds of errors they make and how\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBugsinpy: a database of existing bugs in python programs to\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729352&hl=en&sa=X&d=4967321802917596921&ei=S3pZaM6FFvuvieoPxs6ggQU&scisig=AAZF9b9ROLubcyywTR6xiUHl1JhM&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["6 new citations to articles by Hong Jin Kang"]}
{"title": "CoverUp: Effective High Coverage Test Generation for Python", "first_label": ["Software Testing"], "second_label": ["Generation"], "data": "J Altmayer Pizzorno, ED Berger\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nTesting is an essential part of software development. Test generation tools attempt to \nautomate the otherwise labor-intensive task of test creation, but generating high-\ncoverage tests remains challenging. This paper proposes CoverUp, a novel \napproach to driving the generation of high-coverage Python regression tests. \nCoverUp combines coverage analysis, code context, and feedback in prompts that \niteratively guide the LLM to generate tests that improve line and branch coverage\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBugsinpy: a database of existing bugs in python programs to\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729398&hl=en&sa=X&d=9453066305056140904&ei=S3pZaM6FFvuvieoPxs6ggQU&scisig=AAZF9b8inc8roC06uMigZcBWOfIr&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=3&folt=cit", "author": ["Hong Jin Kang"], "ref": ["6 new citations to articles by Hong Jin Kang", "Hong Jin Kang - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Blended Analysis for Predictive Execution", "first_label": [], "second_label": [], "data": "Y Li, H Dhulipala, A Yadavally, X Rong, S Wang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAlthough Large Language Models (LLMs) are highly proficient in understanding \nsource code and descriptive texts, they have limitations in reasoning on dynamic \nprogram behaviors, such as execution trace and code coverage prediction, and \nruntime error prediction, which usually require actual program execution. To advance \nthe ability of LLMs in predicting dynamic behaviors, we leverage the strengths of both \napproaches, Program Analysis (PA) and LLM, in building PredEx, a predictive\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBugsinpy: a database of existing bugs in python programs to\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729402&hl=en&sa=X&d=12319963630633609851&ei=S3pZaM6FFvuvieoPxs6ggQU&scisig=AAZF9b-pnWdpjaCZBdaNQKch-wnN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=4&folt=cit", "author": ["Hong Jin Kang"], "ref": ["6 new citations to articles by Hong Jin Kang"]}
{"title": "FLITSR: Improved Spectrum-Based Localization of Multiple Faults by Iterative Test Suite Reduction", "first_label": ["Software Testing"], "second_label": ["Localization"], "data": "D Callaghan, B Fischer\\xc2\\xa0- ACM Transactions on Software Engineering and\\xc2\\xa0\\xe2\\x80\\xa6\nSpectrum-based fault localization (SBFL) works well for single-fault programs but its \naccuracy decays for increasing fault numbers. We present FLITSR (Fault Localization \nby Iterative Test Suite Reduction), a novel SBFL approach that improves the \nlocalization of a given SBFL base metric specifically in the presence of multiple \nfaults. FLITSR iteratively selects reduced versions of the test suite that better localize \nthe individual faults in the system. This allows it to identify and re-rank faults ranked\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBugsinpy: a database of existing bugs in python programs to\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3745027&hl=en&sa=X&d=5640068453836852237&ei=S3pZaM6FFvuvieoPxs6ggQU&scisig=AAZF9b-2SWRLczBs-Dy_Q4W-sJVB&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=5&folt=cit", "author": ["Hong Jin Kang"], "ref": ["6 new citations to articles by Hong Jin Kang", "Thanh Le-Cong - new related research"]}
{"title": "Demystifying Memorization in LLM-Based Program Repair via a General Hypothesis Testing Framework", "first_label": ["APR", "LLM", "Software Testing"], "second_label": ["Repair"], "data": "J Kong, X Xie, S Liu\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nLarge Language Models (LLMs) have achieved remarkable success in various \napplications, particularly in code-related tasks such as code generation and program \nrepair, setting new performance benchmarks. However, the extensive use of large\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729390&hl=en&sa=X&d=1963173140402968809&ei=S3pZaKShFO2rieoPk6bG-Qo&scisig=AAZF9b9ZsiWvyL5PU9a54w9waTFt&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Bach Le - new related research", "10 new citations to articles by Abhik Roychoudhury", "Quang-Cuong Bui - new related research", "4 new citations to articles by Xin ZHOU"]}
{"title": "Demystifying LLM-Based Software Engineering Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "CS Xia, Y Deng, S Dunn, L Zhang\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nRecent advancements in large language models (LLMs) have significantly advanced \nthe automation of software development tasks, including code synthesis, program \nrepair, and test generation. More recently, researchers and industry practitioners\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715754&hl=en&sa=X&d=5908066739003088477&ei=S3pZaKShFO2rieoPk6bG-Qo&scisig=AAZF9b_taKJ3CIbZZT9Trx17_y8o&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "6 new citations to articles by Bach Le", "Xin ZHOU - new related research", "10 new citations to articles by Abhik Roychoudhury", "Richard Fang - new related research", "Lingming Zhang - new articles"]}
{"title": "Element-Based Automated DNN Repair with Fine-Tuned Masked Language Model", "first_label": ["LLM"], "second_label": ["Repair"], "data": "X Wang, M Zhang, X Meng, J Zhang, Y Liu, C Hu\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeep Neural Networks (DNNs) are prevalent across a wide range of applications. \nDespite their success, the complexity and opaque nature of DNNs pose significant \nchallenges in debugging and repairing DNN models, limiting their reliability and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715716&hl=en&sa=X&d=9954951256051044219&ei=S3pZaKShFO2rieoPk6bG-Qo&scisig=AAZF9b_bSPID4_lMjXeiweVi0haI&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research", "Bach Le - new related research", "Xin ZHOU - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Error Delayed Is Not Error Handled: Understanding and Fixing Propagated Error-Handling Bugs", "first_label": ["Bug"], "second_label": [], "data": "H Liu, S Li, Z Jia, Y Zhang, L Bai, S Zheng, X Mao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nError handling is critical for software reliability. In software systems, error handling \nmay be delayed to other functions. Such propagated error handling (PEH) could \neasily be missed and lead to bugs. Our research reveals that PEH bugs are\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729384&hl=en&sa=X&d=16292578031927877887&ei=S3pZaKShFO2rieoPk6bG-Qo&scisig=AAZF9b-vEOE8PpFPNNDfVMrGe4CJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "6 new citations to articles by Bach Le", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "VulBinLLM: LLM-powered Vulnerability Detection for Stripped Binaries", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "N Hussain, H Chen, C Tran, P Huang, Z Li, P Chugh\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecognizing vulnerabilities in stripped binary files presents a significant challenge in \nsoftware security. Although some progress has been made in generating human-\nreadable information from decompiled binary files with Large Language Models\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22010&hl=en&sa=X&d=10332909566617513173&ei=S3pZaKShFO2rieoPk6bG-Qo&scisig=AAZF9b_uFh0VfBD1MzUN8jZA2T1m&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Evaluating Large Language Models for Code Review", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "U Cihan, A \\xc4\\xb0\\xc3\\xa7\\xc3\\xb6z, V Haratian, E T\\xc3\\xbcz\\xc3\\xbcn\\xc2\\xa0- arXiv preprint arXiv:2505.20206, 2025\nContext: Code reviews are crucial for software quality. Recent AI advances have \nallowed large language models (LLMs) to review and fix code; now, there are tools \nthat perform these reviews. However, their reliability and accuracy have not yet been\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20206&hl=en&sa=X&d=15665831858314714693&ei=S3pZaKShFO2rieoPk6bG-Qo&scisig=AAZF9b_nX5EjD1ohxo-XwLW6C4w4&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "DiSCo: Towards Decompiling EVM Bytecode to Source Code using Large Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "X Su, H Liang, H Wu, B Niu, F Xu, S Zhong\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nUnderstanding the Ethereum smart contract bytecode is essential for ensuring \ncryptoeconomics security. However, existing decompilers primarily convert bytecode \ninto pseudocode, which is not easily comprehensible for general users, potentially \nleading to misunderstanding of contract behavior and increased vulnerability to \nscams or exploits. In this paper, we propose DiSCo, the first LLMs-based EVM \ndecompilation pipeline, which aims to enable LLMs to understand the opaque\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLeveraging large language model for automatic patch correctness\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729373&hl=en&sa=X&d=6825382788494923258&ei=S3pZaPrGF86r6rQPxrLf-As&scisig=AAZF9b_54ioqHXj50vXuyqs60xhA&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["6 new citations to articles by Bach Le", "David Lo - new related research", "Xin ZHOU - new related research", "Quang-Cuong Bui - new related research", "3 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Xin ZHOU"]}
{"title": "10 Years Later: Revisiting How Developers Search for Code", "first_label": ["Code"], "second_label": ["Search"], "data": "KT Stolee, T Welp, C Sadowski, S Elbaum\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode search is an integral part of a developer's workflow. In 2015, researchers \npublished a paper reflecting on the code search practices at Google of 27 \ndevelopers who used the internal Code Search tool. That paper had first-hand \naccounts for why those developers were using code search and highlighted how \noften and in what situations developers were searching for code. In the past decade, \nmuch has changed in the landscape of developer support. New languages have\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaThanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715774&hl=en&sa=X&d=11723757379990126168&ei=S3pZaPrGF86r6rQPxrLf-As&scisig=AAZF9b-NLeL8kUtJfKqwsGvuACMG&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["6 new citations to articles by Bach Le", "3 new citations to articles by Thanh Le-Cong"]}
{"title": "Mystique: Automated Vulnerability Patch Porting with Semantic and Syntactic-Enhanced LLM", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "S Wu, R Wang, Y Cao, B Chen, Z Zhou, Y Huang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBranching repositories facilitates efficient software development but can also \ninadvertently propagate vulnerabilities. When an original branch is patched, other \nunfixed branches remain vulnerable unless the patch is successfully ported. \nHowever, due to inherent discrepancies between branches, many patches cannot be \ndirectly applied and require manual intervention, which is time-consuming and leads \nto delays in patch porting, increasing vulnerability risks. Existing automated patch\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRecommending code changes for automatic backporting of Linux\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715718&hl=en&sa=X&d=11530525622372618368&ei=S3pZaPrGF86r6rQPxrLf-As&scisig=AAZF9b9yqIVccQ4Nd-ePg8_hnlN3&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=4&folt=cit", "author": ["Bach Le"], "ref": ["6 new citations to articles by Bach Le", "David Lo - new related research"]}
{"title": "Statement-Level Adversarial Attack on Vulnerability Detection Models via Out-of-Distribution Features", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "X Du, M Wen, H Wang, Z Wei, H Jin\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode vulnerability detection is crucial to ensure software security. Recent \nadvancements, particularly with the emergence of Code Pre-Trained Models \n(CodePTMs) and Large Language Models (LLMs), have led to significant progress in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729403&hl=en&sa=X&d=636801605143479768&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b-FRDekIihP8NdkTYE0Awpq&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Xin ZHOU - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "One-for-All Does Not Work! Enhancing Vulnerability Detection by Mixture-of-Experts (MoE)", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "X Yang, S Wang, J Zhou, W Zhu\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nDeep Learning-based Vulnerability Detection (DLVD) techniques have garnered \nsignificant interest due to their ability to automatically learn vulnerability patterns from \npreviously compromised code. Despite the notable accuracy demonstrated by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715736&hl=en&sa=X&d=12277895505706496557&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b8ONAy_HONHWhHAz0g3LZ3L&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research", "4 new citations to articles by Xin ZHOU"]}
{"title": "A Causal Learning Framework for Enhancing Robustness of Source Code Models", "first_label": ["Code"], "second_label": [], "data": "J Ye, Z Li, X Tang, D Zou, S Xu, W Qiang, H Jin\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeep Learning (DL) models are useful for many software engineering tasks. \nHowever, these models are susceptible to adversarial attacks, partly because they \nlearn spurious features that incur spurious correlations between these features and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729387&hl=en&sa=X&d=4612536251679664691&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b-o31NbcZmTVBWrQfvAS4kz&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Constrained Sampling for Language Models Should Be Easy: An MCMC Perspective", "first_label": ["LLM"], "second_label": [], "data": "EA Gonzalez, S Vaidya, K Park, R Ji, T Berg-Kirkpatrick\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nConstrained decoding enables Language Models (LMs) to produce samples that \nprovably satisfy hard constraints. However, existing constrained-decoding \napproaches often distort the underlying model distribution, a limitation that is\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05754%3F&hl=en&sa=X&d=4553768187136981789&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b9AgkL70JOv2CQQ4cjhA1vo&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Smaller but Better: Self-Paced Knowledge Distillation for Lightweight yet Effective LCMs", "first_label": [], "second_label": [], "data": "Y Chen, Y Ye, Z Li, Y Ma, C Gao\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nLarge code models (LCMs) have remarkably advanced the field of code generation. \nDespite their impressive capabilities, they still face practical deployment issues, such \nas high inference costs, limited accessibility of proprietary LCMs, and adaptability\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729405&hl=en&sa=X&d=9026610720938696778&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b_7eWek5V1HaAc6YKgS4o4U&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "A Knowledge Enhanced Large Language Model for Bug Localization", "first_label": ["LLM", "Bug"], "second_label": ["Localization"], "data": "Y Li, B Liu, T Zhang, Z Wang, D Lo, L Yang, J Lyu\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nA significant number of bug reports are generated every day as software systems \ncontinue to develop. Large Language Models (LLMs) have been used to correlate \nbug reports with source code to locate bugs automatically. The existing research has\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729356&hl=en&sa=X&d=16532092839572238040&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b-PmFlcmxHgFCjDtRfes5nX&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Enhancing Bug Assignment with Developer-Specific Feature Extraction and Hybrid Deep Learning", "first_label": ["Bug"], "second_label": [], "data": "G Yang, J Ji, D Kim\\xc2\\xa0- Electronics, 2025\nThe increasing reliance on software in diverse domains has led to a surge in user-\nreported functional enhancements and unexpected bugs. In large-scale open-source \nprojects like Eclipse and Mozilla, initial bug assignment frequently faces challenges\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2079-9292/14/12/2493&hl=en&sa=X&d=17183169801774588772&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b9RluOxd4JkSjNXwplMouZK&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Teaching AI the 'Why'and 'How'of Software Vulnerability Fixes", "first_label": ["Vulnerabilities"], "second_label": [], "data": "A Gao, Z Zhang, S Wang, L Huang, S Wei, V Ng\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nUnderstanding software vulnerabilities and their resolutions is crucial for securing \nmodern software systems. This study presents a novel traceability model that links a \npair of sentences describing at least one of the three types of semantics (triggers\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729360&hl=en&sa=X&d=7711343863691178810&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b9vszGN_K61wmdgdZlrmFxs&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "1 new citation to articles by Quang-Cuong Bui"]}
{"title": "Standing on the Shoulders of Giants: Bug-Aware Automated GUI Testing via Retrieval Augmentation", "first_label": ["Bug", "Software Testing"], "second_label": [], "data": "M Chen, Z Liu, C Chen, J Wang, B Wu, J Hu, Q Wang\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn software development, similar apps often encounter similar bugs due to shared \nfunctionalities and implementation methods. However, current automated GUI testing \nmethods mainly focus on generating test scripts to cover more pages by analyzing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715755&hl=en&sa=X&d=11872138283674414812&ei=S3pZaN70GvfWieoP1-jt-QU&scisig=AAZF9b9RaubVxD9RcGpAV9MEKEUq&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Training Language Models to Generate Quality Code with Program Analysis Feedback", "first_label": ["LLM", "Code"], "second_label": [], "data": "F Yao, Z Wang, L Liu, J Cui, L Zhong, X Fu, H Mai\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode generation with large language models (LLMs), often termed vibe coding, is \nincreasingly adopted in production but fails to ensure code quality, particularly in \nsecurity (eg, SQL injection vulnerabilities) and maintainability (eg, missing type\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22704&hl=en&sa=X&d=13720297852295427429&ei=S3pZaN3KEte5ieoP58CikQE&scisig=AAZF9b9qU1hJff-ona5ynwmi0w3O&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=4&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Li, J Ding, C Peng, B Zhao, X Gao, H Gao, X Gu\\xc2\\xa0- arXiv preprint arXiv:2506.05692, 2025\nThe code generation capabilities of large language models (LLMs) have emerged as \na critical dimension in evaluating their overall performance. However, prior research \nhas largely overlooked the security risks inherent in the generated code. In this work\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05692&hl=en&sa=X&d=5492650506064335063&ei=S3pZaN3KEte5ieoP58CikQE&scisig=AAZF9b_VqkMkad8wzoS_QoQNt7_G&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=5&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "An Empirical Study of Code Clones from Commercial AI Code Generators", "first_label": ["Code"], "second_label": [], "data": "W Wu, H Hu, Z Fan, Y Qiao, Y Huang, Y Li, Z Zheng\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeep learning (DL) has revolutionized various software engineering tasks. \nParticularly, the emergence of AI code generators has pushed the boundaries of \nautomatic programming to synthesize entire programs based on user-defined\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729397&hl=en&sa=X&d=12837448834344751203&ei=S3pZaNS_KO2rieoPk6bG-Qo&scisig=AAZF9b8qk8ta7P66byZJBCjO3g78&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "The Struggles of LLMs in Cross-Lingual Code Clone Detection", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "MB Moumoula, AK Kabor\\xc3\\xa9, J Klein, TF Bissyand\\xc3\\xa9\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the involvement of multiple programming languages in modern software \ndevelopment, cross-lingual code clone detection has gained traction within the \nsoftware engineering community. Numerous studies have explored this topic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715764&hl=en&sa=X&d=13415771137676208664&ei=S3pZaNS_KO2rieoPk6bG-Qo&scisig=AAZF9b94b9bfALws5oAEMt0gH9Lv&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Doc2OracLL: Investigating the Impact of Documentation on LLM-Based Test Oracle Generation", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "SB Hossain, R Taylor, M Dwyer\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nCode documentation is a critical artifact of software development, bridging human \nunderstanding and machine-readable code. Beyond aiding developers in code \ncomprehension and maintenance, documentation also plays a critical role in\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729354&hl=en&sa=X&d=13766729628373229449&ei=S3pZaNS_KO2rieoPk6bG-Qo&scisig=AAZF9b8n5QGiXT1EhOFHjese5ohv&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=9&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "VLATest: Testing and Evaluating Vision-Language-Action Models for Robotic Manipulation", "first_label": ["Software Testing"], "second_label": [], "data": "Z Wang, Z Zhou, J Song, Y Huang, Z Shu, L Ma\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of generative AI and multi-modal foundation models has \nshown significant potential in advancing robotic manipulation. Vision-language-\naction (VLA) models, in particular, have emerged as a promising approach for \nvisuomotor control by leveraging large-scale vision-language data and robot \ndemonstrations. However, current VLA models are typically evaluated using a limited \nset of hand-crafted scenes, leaving their general performance and robustness in\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729343&hl=en&sa=X&d=506655532696745030&ei=S3pZaMzAHIOuieoPyIM7&scisig=AAZF9b_KD49T8pFFd508jDN9nluz&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "CRISPE: Semantic-Guided Execution Planning and Dynamic Reasoning for Enhancing Code Coverage Prediction", "first_label": ["Code"], "second_label": ["Reasoning"], "data": "H Dhulipala, A Yadavally, SS Patel, TN Nguyen\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWhile LLMs excel in understanding source code and descriptive texts for tasks like \ncode generation, code completion, etc., they exhibit weaknesses in predicting \ndynamic program behavior, such as code coverage and runtime error detection, \nwhich typically require program execution. Aiming to advance the capability of LLMs \nin reasoning and predicting the program behavior at runtime, we present CRISPE \n(short for Coverage Rationalization and Intelligent Selection ProcedurE), a novel\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFuzzing: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729401&hl=en&sa=X&d=13034209954716732251&ei=S3pZaMzAHIOuieoPyIM7&scisig=AAZF9b_MZal7JTKsXTVuw6mWEYgj&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Detecting and Reducing the Factual Hallucinations of Large Language Models with Metamorphic Testing", "first_label": ["LLM", "Software Testing"], "second_label": ["Detection"], "data": "W Wu, Y Cao, N Yi, R Ou, Z Zheng\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nQuestion answering (QA) is a fundamental task of large language models (LLMs), \nwhich requires LLMs to automatically answer human-posed questions in natural \nlanguage. However, LLMs are known to distort facts and make non-factual \nstatements (ie, hallucinations) when dealing with QA tasks, which may affect the \ndeployment of LLMs in real-life situations. In this work, we propose DrHall, a \nframework for detecting and reducing the factual hallucinations of black-box LLMs\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRe-factoring based Program Repair applied to Programming\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715784&hl=en&sa=X&d=11797333735455069810&ei=S3pZaMzAHIOuieoPyIM7&scisig=AAZF9b9Z20oO8KlHtjr9eWxe6MS9&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "LLMDroid: Enhancing Automated Mobile App GUI Testing Coverage with Large Language Model Guidance", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "C Wang, T Liu, Y Zhao, M Yang, H Wang\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the rapid development of Large Language Models (LLMs), their integration into \nautomated mobile GUI testing has emerged as a promising research direction. \nHowever, existing LLM-based testing approaches face significant challenges, \nincluding time inefficiency and high costs due to constant LLM querying. To address \nthese issues, this paper introduces LLMDroid, a novel testing framework designed to \nenhance existing automated mobile GUI testing tools by leveraging LLMs more\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTime-travel Testing of Android Apps\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715763&hl=en&sa=X&d=2859160406263160913&ei=S3pZaMzAHIOuieoPyIM7&scisig=AAZF9b-dbskoW25EIxHBG-CQIUEz&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "UnitCon: Synthesizing Targeted Unit Tests for Java Runtime Exceptions", "first_label": ["Software Testing"], "second_label": [], "data": "S Jang, Y Ryou, H Lee, K Heo\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nWe present UnitCon, a system for synthesizing targeted unit testsfor runtime \nexceptions in Java programs. Targeted unit tests aim to reveal a bug at a specific \nlocation in the program under test. This capability benefits various tasks in software \ndevelopment, such as patch testing, crash reproduction, or static analysis alarm \ninspection. However, conventional unit test generation tools are mainly designed for \nregression tests by maximizing code coverage; hence they are not effective at such\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729362&hl=en&sa=X&d=18094050204048994153&ei=S3pZaMzAHIOuieoPyIM7&scisig=AAZF9b9SIjsGhd6q-sKxVUvxgveC&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Towards Understanding Docker Build Faults in Practice: Symptoms, Root Causes, and Fix Patterns", "first_label": [], "second_label": [], "data": "Y Wu, Y Zhang, T Wang, B Ding, H Wang\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDocker building is a critical component of containerization in modern software \ndevelopment, automating the process of packaging and converting sources into \ncontainer images. It is not uncommon to find that Docker build faults (DBFs) occur\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715757&hl=en&sa=X&d=13481132424010785922&ei=S3pZaOfzHqKr6rQP49vTsAY&scisig=AAZF9b8BktiKib9aNBAJU8o1Ads5&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=3&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Beyond PEFT: Layer-Wise Optimization for More Effective and Efficient Large Code Model Tuning", "first_label": ["Code"], "second_label": [], "data": "C Wang, J Feng, S Gao, C Gao, Z Li, T Peng, H Huang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Code Models (LCMs) have demonstrated remarkable effectiveness across \nvarious code intelligence tasks. Supervised fine-tuning is essential to optimize their \nperformance for specific downstream tasks. Compared with the traditional full-\nparameter fine-tuning (FFT) method, Parameter-Efficient Fine-Tuning (PEFT) \nmethods can train LCMs with substantially reduced resource consumption and have \ngained widespread attention among researchers and practitioners. While existing\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaExploring Parameter-Efficient Fine-Tuning Techniques for Code\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729341&hl=en&sa=X&d=8815703461560510716&ei=S3pZaJrWI6alieoP6s6swAY&scisig=AAZF9b-oO7hHgThBtV-5S6CgGuhJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "Your Agent Can Defend Itself against Backdoor Attacks", "first_label": [], "second_label": ["Agent"], "data": "L Changjiang, L Jiacheng, C Bochuan, C Jinghui\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite their growing adoption across domains, large language model (LLM)-\npowered agents face significant security risks from backdoor attacks during training \nand fine-tuning. These compromised agents can subsequently be manipulated to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08336&hl=en&sa=X&d=9281612337423238890&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b8EnIakTDvZQGsyv1duPVA5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Adversarial Preference Learning for Robust LLM Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Wang, P Wang, C Xi, B Tang, J Zhu, W Wei, C Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern language models often rely on Reinforcement Learning from Human \nFeedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to \nadversarial attacks due to three key limitations:(1) the inefficiency and high cost of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24369%3F&hl=en&sa=X&d=11526575995055803369&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b_ilBi9AMSJoKPXxHc_hWg5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SecurityLingua: Efficient Defense of LLM Jailbreak Attacks via Security-Aware Prompt Compression", "first_label": ["LLM"], "second_label": [], "data": "Y Li, S Ahn, H Jiang, AH Abdi, Y Yang, L Qiu\\xc2\\xa0- arXiv preprint arXiv:2506.12707, 2025\nLarge language models (LLMs) have achieved widespread adoption across \nnumerous applications. However, many LLMs are vulnerable to malicious attacks \neven after safety alignment. These attacks typically bypass LLMs' safety guardrails by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12707&hl=en&sa=X&d=8418273368991399970&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b8AOJ5PQ2S2DYr5nVOYpqTl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge", "first_label": ["LLM"], "second_label": [], "data": "S Li, C Xu, J Wang, X Gong, C Chen, J Zhang, J Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable intelligence across \nvarious tasks, which has inspired the development and widespread adoption of LLM-\nas-a-Judge systems for automated model testing, such as red teaming and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09443&hl=en&sa=X&d=2052322274134661445&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b9u9cyhYi06xXXt37CLZpdh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Syntactic paraphrase-based synthetic data generation for backdoor attacks against Chinese language models", "first_label": ["LLM"], "second_label": ["Generation"], "data": "M Hu, Y Yang, D Pan, Z Guo, L Xiao, D Lin, S Zhao\\xc2\\xa0- Information Fusion, 2025\nAbstract Language Models (LMs) have shown significant advancements in various \nNatural Language Processing (NLP) tasks. However, recent studies indicate that \nLMs are particularly susceptible to malicious backdoor attacks, where attackers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S156625352500449X&hl=en&sa=X&d=11939540759867308872&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b_omHEFDqgnSwVne_pfKwnY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Through the Stealth Lens: Rethinking Attacks and Defenses in RAG", "first_label": [], "second_label": [], "data": "S Choudhary, N Palumbo, A Hooda, KD Dvijotham\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRetrieval-augmented generation (RAG) systems are vulnerable to attacks that inject \npoisoned passages into the retrieved set, even at low corruption rates. We show that \nexisting attacks are not designed to be stealthy, allowing reliable detection and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04390&hl=en&sa=X&d=15468735482968103516&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b8u2OUJdUy7skXRySPRbZz3&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AsFT: Anchoring Safety During LLM Fine-Tuning Within Narrow Safety Basin", "first_label": ["LLM"], "second_label": [], "data": "S Yang, Q Zhang, Y Liu, Y Huang, X Jia, K Ning, J Yao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are vulnerable to safety risks during fine-tuning, \nwhere small amounts of malicious or harmless data can compromise safeguards. In \nthis paper, building on the concept of alignment direction--defined by the weight\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08473%3F&hl=en&sa=X&d=15059004078714992755&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b-cmQJQ2nP1jAOJlM9iLuaf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Enhancing Reasoning Capabilities of Small Language Models with Blueprints and Prompt Template Search", "first_label": ["LLM"], "second_label": ["Search", "Reasoning"], "data": "D Han, M Xia, DM Diaz, S Kessler, A Mallick, X Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSmall language models (SLMs) offer promising and efficient alternatives to large \nlanguage models (LLMs). However, SLMs' limited capacity restricts their reasoning \ncapabilities and makes them sensitive to prompt variations. To address these\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08669%3F&hl=en&sa=X&d=15704474230557976749&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b8p3WkTiOwxN4IoT6Yx5Fu_&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Cost of Dynamic Reasoning: Demystifying AI Agents and Test-Time Scaling from an AI Infrastructure Perspective", "first_label": ["Software Testing"], "second_label": ["Agent", "Reasoning"], "data": "J Kim, B Shin, J Chung, M Rhu\\xc2\\xa0- arXiv preprint arXiv:2506.04301, 2025\nLarge-language-model (LLM)-based AI agents have recently showcased impressive \nversatility by employing dynamic reasoning, an adaptive, multi-step process that \ncoordinates with external tools. This shift from static, single-turn inference to agentic\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04301&hl=en&sa=X&d=3072272730677106970&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b-t8XUoljKdp6JjL-hJnilf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Y Mao, T Cui, P Liu, D You, H Zhu\\xc2\\xa0- arXiv preprint arXiv:2506.15170, 2025\nLarge language models (LLMs) are rapidly evolving from single-modal systems to \nmultimodal LLMs and intelligent agents, significantly expanding their capabilities \nwhile introducing increasingly severe security risks. This paper presents a systematic \nsurvey of the growing complexity of jailbreak attacks and corresponding defense \nmechanisms within the expanding LLM ecosystem. We first trace the developmental \ntrajectory from LLMs to MLLMs and Agents, highlighting the core security challenges\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAdaptive attacks break defenses against indirect prompt injection\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15170&hl=en&sa=X&d=16427093263132639213&ei=bfRXaNbtKffWieoP1-jt-QU&scisig=AAZF9b-zqUEdPZ8IyWJxfUDycl5Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang", "Richard Fang - new related research"]}
{"title": "Red teaming large language models: A comprehensive review and critical analysis", "first_label": ["LLM"], "second_label": [], "data": "MS Jabbar, S Al-Azani, A Alotaibi, M Ahmed\\xc2\\xa0- Information Processing & Management, 2025\nSecuring large language models (LLMs) remains a critical challenge as their \nadoption across various sectors rapidly grows. While advancements in LLM \ndevelopment have enhanced their capabilities, inherent vulnerabilities continue to \npose significant risks, exposing these models to various forms of attack. This study \nprovides a comprehensive review of LLMs' red teaming, distinguished by its broad \ncoverage and intuitive organization. It systematically explores a range of red teaming\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0306457325001803&hl=en&sa=X&d=5668631129952397970&ei=bfRXaNbtKffWieoP1-jt-QU&scisig=AAZF9b8yq_zp48Y4DCmxQzzy_BHh&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Visualization Task Taxonomy to Understand the Fuzzing Internals", "first_label": ["Fuzzing"], "second_label": [], "data": "S Kummita, M Miao, E Bodden, S Wei\\xc2\\xa0- ACM Transactions on Software Engineering\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGreybox fuzzing is used extensively in research and practice. There are umpteen \npublications that improve greybox fuzzing. However, to what extent do these \nimprovements affect the internal components or internals of a given fuzzer is not yet\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3718346&hl=en&sa=X&d=6310038100822609560&ei=bfRXaPfRL6u26rQPmuu-OA&scisig=AAZF9b_Ue_jmzHRI425oDGHolQub&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "RIMFuzz: real-time impact-aware mutation for library API fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "X Wang, L Zhao\\xc2\\xa0- Journal of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs libraries merely expose APIs to developers rather than directly handling user \ninput, applying fuzzing to libraries requires fuzz drivers to help process fuzzer-\nprovided input and invoke APIs. To reduce manual effort and avoid reliance on\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00050-1&hl=en&sa=X&d=11566396351270247841&ei=bfRXaPfRL6u26rQPmuu-OA&scisig=AAZF9b9NzGapAGT-Gt26V3wejXNn&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "deepSURF: Detecting Memory Safety Vulnerabilities in Rust Through Fuzzing LLM-Augmented Harnesses", "first_label": ["Vulnerabilities", "LLM", "Fuzzing"], "second_label": ["Detection"], "data": "G Androutsopoulos, A Bianchi\\xc2\\xa0- arXiv preprint arXiv:2506.15648, 2025\nAlthough Rust ensures memory safety by default, it also permits the use of unsafe \ncode, which can introduce memory safety vulnerabilities if misused. Unfortunately, \nexisting tools for detecting memory bugs in Rust typically exhibit limited detection\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15648&hl=en&sa=X&d=5470473754710042022&ei=bfRXaPfRL6u26rQPmuu-OA&scisig=AAZF9b-QLCAPbmOGA94zxamaJ1DB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Hong Jin Kang - new related research"]}
{"title": "A Multi-agent LLM-based JUit Test Generation with Strong Oracles", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation", "Agent"], "data": "Q Xu, G Wang, L Briand, K Liu\\xc2\\xa0- arXiv preprint arXiv:2506.02943, 2025\nUnit testing plays a critical role in ensuring software correctness. However, writing \nunit tests manually is laborious, especially for strong typed languages like Java, \nmotivating the need for automated approaches. Traditional methods primarily rely on\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02943&hl=en&sa=X&d=9080051622854454343&ei=bfRXaPfRL6u26rQPmuu-OA&scisig=AAZF9b-W733SKwSoE4FIE6fi3cJw&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "LLM-Powered Test Case Generation for Detecting Bugs in Plausible Programs", "first_label": ["LLM", "Bug", "Software Testing"], "second_label": ["Detection", "Generation"], "data": "K Liu, Z Chen, Y Liu, JM Zhang, M Harman, Y Han\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 63rd\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDetecting tricky bugs in plausible programs, those that pass existing test suites yet \nstill contain bugs, remains a significant challenge in software testing. To address this \nproblem, we propose TrickCatcher, an LLM-powered approach to generating test\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://chenzhenpeng18.github.io/papers/ACL25_AID.pdf&hl=en&sa=X&d=1138877347567479720&ei=bfRXaPfRL6u26rQPmuu-OA&scisig=AAZF9b9cIXBHNvROwFBS9vlx4ynw&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "David Lo - new related research", "Bach Le - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "An Empirical Study on Strong-Weak Model Collaboration for Repo-level Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "S Gandhi, A Naik, Y Xie, C Rose\\xc2\\xa0- arXiv preprint arXiv:2505.20182, 2025\nWe study cost-efficient collaboration between strong and weak language models for \nrepository-level code generation, where the weak model handles simpler tasks at \nlower cost, and the most challenging tasks are delegated to the strong model. While\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20182%3F&hl=en&sa=X&d=13261729674581282450&ei=bfRXaPfRL6u26rQPmuu-OA&scisig=AAZF9b_OpsNe4LRB8V9VkgGHB_Qn&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "David Lo - new related research"]}
{"title": "Formal verification for multi-agent path execution in stochastic environments", "first_label": ["Verification"], "second_label": ["Agent"], "data": "X Wang, J Liu, CD Nugent, S Xu, Y Xu\\xc2\\xa0- Engineering Applications of Artificial\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMulti-agent pathfinding aims to determine conflict-free paths for multiple agents in a \nshared environment. However, real-world uncertainties can disrupt preplanned \npaths, leading to delays and new conflicts. Addressing these challenges requires \nrobust strategies for path execution and adjustment. While many multi-agent \npathfinding algorithms have been proposed, this work does not introduce a new \nalgorithm. Instead, it presents an adjustment solution based on a set of constraint\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaExploring true test overfitting in dynamic automated program repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0952197625012679&hl=en&sa=X&d=6091033612981446249&ei=bfRXaMSwK4OuieoPyIM7&scisig=AAZF9b9KoklKCieLTbzKmviYCa6z&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["1 new citation to articles by Bach Le"]}
{"title": "System Prompt Extraction Attacks and Defenses in Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "BC Das, MH Amini, Y Wu\\xc2\\xa0- arXiv preprint arXiv:2505.23817, 2025\nThe system prompt in Large Language Models (LLMs) plays a pivotal role in guiding \nmodel behavior and response generation. Often containing private configuration \ndetails, user roles, and operational instructions, the system prompt has become an\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23817&hl=en&sa=X&d=8359490024520200495&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b9kewGVoQUmVLeek21BFko2&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift", "first_label": ["LLM"], "second_label": [], "data": "S Liang, J Liang, T Pang, C Du, A Liu, M Zhu, X Cao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInstruction tuning enhances large vision-language models (LVLMs) but increases \ntheir vulnerability to backdoor attacks due to their open design. Unlike prior studies in \nstatic settings, this paper explores backdoor attacks in LVLM instruction tuning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.pdf&hl=en&sa=X&d=5142527777954789704&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b_Zz7b9xsyiBVRqo7nDX3YO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, M Dras, U Naseem\\xc2\\xa0- arXiv preprint arXiv:2506.02442, 2025\nThis paper presents a systematic evaluation of Large Language Models'(LLMs) \nbehavior on long-tail distributed (encrypted) texts and their safety implications. We \nintroduce a two-dimensional framework for assessing LLM safety:(1) instruction\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02442&hl=en&sa=X&d=15102350404536711280&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b_4gGVOvmiHUrKGvn2E4Vhh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems", "first_label": ["LLM"], "second_label": ["Agent", "Search"], "data": "X Li, J Chen, X Fang, S Ding, H Duan, Q Liu, K Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown remarkable capabilities in solving \ndiverse tasks. However, their proficiency in iteratively optimizing complex solutions \nthrough learning from previous feedback remains insufficiently explored. To bridge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10764&hl=en&sa=X&d=1134890120116902745&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b8s_mGNSGwzfKFs6o2hgsbd&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents", "first_label": ["LLM", "Code"], "second_label": ["Agent", "Reasoning"], "data": "K Hariharan, U Girit, A Wang, J Andreas\\xc2\\xa0- arXiv preprint arXiv:2506.00172, 2025\nBenchmarks for large language models (LLMs) have predominantly assessed short-\nhorizon, localized reasoning. Existing long-horizon suites (eg SWE-bench) rely on \nmanually curated issues, so expanding or tuning difficulty demands expensive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00172&hl=en&sa=X&d=7723120566071680437&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b-MEatAoZUO5Dw1f9NQmtaH&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Lifelong Safety Alignment for Language Models", "first_label": ["LLM"], "second_label": [], "data": "H Wang, Z Qin, Y Zhao, C Du, M Lin, X Wang, T Pang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLMs have made impressive progress, but their growing capabilities also expose \nthem to highly flexible jailbreaking attacks designed to bypass safety alignment. \nWhile many existing defenses focus on known types of attacks, it is more critical to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20259%3F&hl=en&sa=X&d=16834372085988299596&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b9d_59vHSVRWjToyCIlG2f5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "An Embarrassingly Simple Defense Against LLM Abliteration Attacks", "first_label": ["LLM"], "second_label": [], "data": "HA Shairah, HAAK Hammoud, B Ghanem, G Turkiyyah\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are typically aligned to comply with safety guidelines \nby refusing harmful instructions. A recent attack, termed abliteration, isolates and \nsuppresses the single latent direction most responsible for refusal behavior, enabling\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19056&hl=en&sa=X&d=3737202939224050048&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b8QKV5yRTnfm0WbZVG9RAGO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring", "first_label": ["LLM"], "second_label": [], "data": "Y Li, Q Sheng, Y Yang, X Zhang, J Cao\\xc2\\xa0- arXiv preprint arXiv:2506.09996, 2025\nThough safety alignment has been applied to most large language models (LLMs), \nLLM service providers generally deploy a subsequent moderation as the external \nsafety guardrail in real-world products. Existing moderators mainly practice a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09996&hl=en&sa=X&d=8967671192696781749&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b-I099JquXawda445fWweEs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Securing AI Agents with Information-Flow Control", "first_label": [], "second_label": ["Agent"], "data": "M Costa, B K\\xc3\\xb6pf, A Kolluri, A Paverd, M Russinovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI agents become increasingly autonomous and capable, ensuring their security \nagainst vulnerabilities such as prompt injection becomes critical. This paper explores \nthe use of information-flow control (IFC) to provide security guarantees for AI agents\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23643%3F&hl=en&sa=X&d=4534448032257376326&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b-ruPZ7fbYUs0K6HirRZr2z&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "FrontendBench: A Benchmark for Evaluating LLMs on Front-End Development via Automatic Evaluation", "first_label": ["LLM"], "second_label": [], "data": "H Zhu, Y Zhang, B Zhao, J Ding, S Liu, T Liu, D Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have made significant strides in front-end code \ngeneration. However, existing benchmarks exhibit several critical limitations: many \ntasks are overly simplistic, test cases often lack rigor, and end-to-end validation is\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13832&hl=en&sa=X&d=2112639698671840186&ei=bfRXaLDxLMy8ieoPt5yl6Qk&scisig=AAZF9b8od9psvT-Kt0tqTsCNZNad&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Legal Compliance Evaluation of Smart Contracts Generated By Large Language Models", "first_label": ["Smart Contracts", "LLM"], "second_label": [], "data": "C Wijayakoon, H Dong, HMN Bandara, Z Tari, A Soin\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSmart contracts can implement and automate parts of legal contracts, but ensuring \ntheir legal compliance remains challenging. Existing approaches such as formal \nspecification, verification, and model-based development require expertise in both\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00943&hl=en&sa=X&d=17006763348946692535&ei=bfRXaLDxLMy8ieoPt5yl6Qk&scisig=AAZF9b-0RVHMvQ2FmTdQzcshenfV&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "\\xe2\\x80\\x9cWe've met some problems\\xe2\\x80\\x9d: Developers' Issues With Privacy-Preserving Computation Techniques on Stack Overflow", "first_label": [], "second_label": [], "data": "D Reinhardt\nSoftware developers must adhere to privacy regulations and apply privacy principles. \nHowever, developers may not be privacy experts and hence are likely to encounter \nissues when choosing, applying, and implementing the corresponding Privacy\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://uni-goettingen.de/de/document/download/98c61f26e263a2856498e45d770845c8.pdf/kuehtreiber_IFIP_SEC2025.pdf&hl=en&sa=X&d=419570402408453543&ei=bfRXaLDxLMy8ieoPt5yl6Qk&scisig=AAZF9b96aDq9sNPVaEfiw8GIvHhe&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "An Android API Recommendation Approach Based on API Dependency Paths Learning", "first_label": [], "second_label": [], "data": "J Deng, J Liu, Y Liu, Y Yin, Y Xiao\\xc2\\xa0- Concurrency and Computation: Practice and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware development plays a crucial role in the modern mobile application domain, \nreflecting its significance through widespread application. With the continuous \nevolution and vast number of Android APIs, developers need to invest considerable\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.70159&hl=en&sa=X&d=1581092059695033857&ei=bfRXaLDxLMy8ieoPt5yl6Qk&scisig=AAZF9b_lc8pukNV90HXNbOurpw7s&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Technical Debt of Software Projects Based on Merge Code Comments", "first_label": ["Code"], "second_label": [], "data": "MHM de Ara\\xc3\\xbajo, C Costa, A Font\\xc3\\xa3o\\xc2\\xa0- Journal of Software Engineering Research and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDevelopers use code comments for a variety of reasons, such as explaining code, \ndocumenting specifications, communicating with other developers, and highlighting \nupcoming tasks. Software projects with minimal documentation often have a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://journals-sol.sbc.org.br/index.php/jserd/article/download/4801/3278&hl=en&sa=X&d=15287621864696684133&ei=bfRXaLDxLMy8ieoPt5yl6Qk&scisig=AAZF9b9fCCpMaXCkPjmdQDDH9aZ7&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Spec2RTL-Agent: Automated Hardware Code Generation from Complex Specifications Using LLM Agent Systems", "first_label": ["LLM", "Code"], "second_label": ["Generation", "Agent"], "data": "Z Yu, M Liu, M Zimmer, YC Lin, Y Liu, H Ren\\xc2\\xa0- arXiv preprint arXiv:2506.13905, 2025\nDespite recent progress in generating hardware RTL code with LLMs, existing \nsolutions still suffer from a substantial gap between practical application scenarios \nand the requirements of real-world RTL code development. Prior approaches either\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13905&hl=en&sa=X&d=12888586433964838774&ei=bfRXaLDxLMy8ieoPt5yl6Qk&scisig=AAZF9b84TVQbUOuys7zzXHXK7j0W&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Sharp Tools: How Developers Wield Agentic AI in Real Software Engineering Tasks", "first_label": [], "second_label": ["Agent"], "data": "A Kumar, Y Bajpai, S Gulwani, G Soares, E Murphy-Hill\\xc2\\xa0- arXiv e-prints, 2025\nAbstract Software Engineering Agents (SWE agents) can autonomously perform \ndevelopment tasks on benchmarks like SWE Bench, but still face challenges when \ntackling complex and ambiguous real-world tasks. Consequently, SWE agents are\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ui.adsabs.harvard.edu/abs/2025arXiv250612347K/abstract&hl=en&sa=X&d=312805220486512243&ei=bfRXaLDxLMy8ieoPt5yl6Qk&scisig=AAZF9b_8Q0dcc27PgpFMnFt8FiPo&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Zheng, X Qian, H Zhou, S Yang, Y He, S Jana\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models (LMs) show promise for vulnerability detection but struggle with \nlong, real-world code due to sparse and uncertain vulnerability locations. These \nissues, exacerbated by token limits, often cause models to miss vulnerability-related\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17460&hl=en&sa=X&d=9334848497739178959&ei=bfRXaJ66KKKr6rQP49vTsAY&scisig=AAZF9b_EDz61GJXVBfE-c2mGro5g&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "LEDGE: Leveraging Dependency Graphs for Enhanced Context Aware Documentation Generation", "first_label": [], "second_label": ["Generation", "Graph"], "data": "M Panchal, A Deo, V Prabhu, P Doshi, C Bhadane\\xe2\\x80\\xa6 - 2025\nIn software engineering, effective documentation is crucial for understanding \ncomplex codebases, yet it often remains incomplete or outdated, hindering \ndeveloper productivity. This paper introduces LEDGE (Leveraging Dependency\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchsquare.com/article/rs-6827966/latest&hl=en&sa=X&d=7398073546507241007&ei=bfRXaJ66KKKr6rQP49vTsAY&scisig=AAZF9b8FvrTM6Xo_TWLAo9mCTojQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Scalable Verification with Applications to Hardware Security", "first_label": ["Verification"], "second_label": [], "data": "S Dinesh - 2025\nHardware design is currently at a pivotal juncture. With Moore's law reaching its limits \nand generative AI (GAI) workloads demanding unprecedented amounts of resources \n[162], hardware architects increasingly rely on sophisticated microarchitectural \noptimizations to extract maximal performance from available resources. However, \nhistory shows that these advanced optimizations often inadvertently introduce new \nmicroarchitectural vulnerabilities [125, 137, 210, 203, 217, 43, 215, 216], leaking\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-133.pdf&hl=en&sa=X&d=4884069570554781401&ei=bfRXaPeuLtSWieoP9obCkQw&scisig=AAZF9b-elcZmuXpSc6HbMcgIubbe&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": "How to Solve Cybersecurity Once and For All", "first_label": [], "second_label": [], "data": "M B\\xc3\\xb6hme\\xc2\\xa0- IEEE Security & Privacy, 2025\nAt last year's Pwn2Own competition, one individual successfully exploited all major \nbrowsers\\xe2\\x80\\x94Chrome, Firefox, Safari, and Edge\\xe2\\x80\\x94used by billions of people worldwide. \nDespite decades of security research, the discovery of new vulnerabilities in \nimportant software systems continues unabated.\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Program Repair\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11038978/&hl=en&sa=X&d=7239506873235168075&ei=bfRXaPeuLtSWieoP9obCkQw&scisig=AAZF9b8hsmaumJjrES0J5v6cAeQf&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Make a Feint to the East While Attacking in the West: Blinding LLM-Based Code Auditors with Flashboom Attacks", "first_label": ["LLM", "Code"], "second_label": [], "data": "X Li, Y Li, H Wu, Y Zhang, K Xu, X Cheng, S Zhong\\xe2\\x80\\xa6\\xc2\\xa0- 2025 IEEE Symposium on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM-based vulnerability auditors (eg, GitHub Copilot) represent a significant \nadvancement in automated code analysis, offering precise detection of security \nvulnerabilities. This paper explores the potential to circumvent LLM-based \nvulnerability auditors by diverting their focus, decided by the LLM attention \nmechanism, away from real vulnerable code segments. In these LLM-based \nvulnerability auditors, the attention mechanism is supposed to focus on potentially\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection and repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11023369/&hl=en&sa=X&d=3487901414580867567&ei=bfRXaIShMu2rieoPk6bG-Qo&scisig=AAZF9b8iBerXg9jQTJQuotoI1IuT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "AI Assisted Validation and Verification of Software: Enhancing System Test Verification Processes through Large Language Model Classification", "first_label": ["Verification", "LLM", "Software Testing"], "second_label": [], "data": "T Wallin, K Widholm - 2025\nAs the automotive industry becomes increasingly software-driven, the complexity of \nvalidation and verification processes in embedded systems continues to grow. Within \nthe Powertrain Control department at Scania CV AB, ensuring alignment between \nsystem test protocols and test scripts is a critical yet time-consuming task, currently \nperformed manually. This thesis investigates the potential of leveraging Large \nLanguage Models (LLMs), a subfield of Natural Language Processing (NLP), in a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAssessing generalizability of codebert\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.diva-portal.org/smash/get/diva2:1965211/FULLTEXT01.pdf&hl=en&sa=X&d=18163299097298700087&ei=bfRXaIShMu2rieoPk6bG-Qo&scisig=AAZF9b-_SbQQoN6cBehYNLwhIltv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "Teaching an Old LLM Secure Coding: Localized Preference Optimization on Distilled Preferences", "first_label": ["LLM"], "second_label": ["Localization"], "data": "M Saqib, S Chakraborty, S Karmaker\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM generated code often contains security issues. We address two key challenges \nin improving secure code generation. First, obtaining high quality training data \ncovering a broad set of security issues is critical. To address this, we introduce a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00419&hl=en&sa=X&d=3471320712326210844&ei=bfRXaPuiNbXCieoPsbu2sQ4&scisig=AAZF9b-zP6iuspafIpJ9gFQhBsZE&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "LEGO: Synthesizing IoT Device Components Based on Static Analysis and Large Language Models", "first_label": ["LLM", "Static Analysis"], "second_label": [], "data": "L Liu, T Wang, W Chen, J Wei, W Wang, G Wu\\xc2\\xa0- \\xe2\\x80\\xa6\\xc2\\xa0of the ACM on Interactive, Mobile\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIoT device components---digital representations of IoT devices within a platform and \ntypically developed using Software Development Kits (SDKs)---are essential for \nensuring seamless connectivity between IoT platforms and physical devices\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729482&hl=en&sa=X&d=4697730062038414973&ei=bfRXaPuiNbXCieoPsbu2sQ4&scisig=AAZF9b9mKRftAARYz21wA4iN9Vpv&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Impact of Developer Queries on the Effectiveness of Conversational Large Language Models in Programming", "first_label": ["LLM"], "second_label": [], "data": "V Taneski, S Karakati\\xc4\\x8d, P Rek, G Jo\\xc5\\xa1t\\xc2\\xa0- Applied Sciences, 2025\nThis study investigates the effects of LLM-based coding assistance on web \napplication development by students using a frontend framework. Rather than \ncomparing different models, it focuses on how students interact with LLM tools to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2076-3417/15/12/6836&hl=en&sa=X&d=17897532974991926623&ei=bfRXaPuiNbXCieoPsbu2sQ4&scisig=AAZF9b8V0NAX5f9cFyas36iVdpxe&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Advancing Bug Report Management: Graph-Based Modeling, Large Language Models, and Quality Improvement", "first_label": ["LLM", "Bug"], "second_label": ["Graph"], "data": "J Acharya - 2025\nSoftware maintenance is a critical, cost-intensive phase of software development, \nheavily dependent on effective bug report management. Bug reports are vital artifacts \nin this process, enabling developers to identify, prioritize, and resolve software\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ucalgary.scholaris.ca/bitstreams/ee6b9951-a0ca-403d-98a4-72a8ee61d178/download&hl=en&sa=X&d=13389235140432076353&ei=bfRXaPuiNbXCieoPsbu2sQ4&scisig=AAZF9b_1pKjCkp47yio9LkXZADAe&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Beyond LLMs: An Exploration of Small Open-source Language Models in Logging Statement Generation", "first_label": ["LLM"], "second_label": ["Generation"], "data": "R Zhong, Y Li, G Yu, W Gu, J Kuang, Y Huo, MR Lyu\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nEffective software maintenance heavily relies on high-quality logging statements, but \nmanual logging is challenging, error-prone, and insufficiently standardized, often \nleading to inconsistent log quality. While large language models have shown\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16590&hl=en&sa=X&d=4658939216487304827&ei=bfRXaP3INtGM6rQPs-LTyAw&scisig=AAZF9b8Yps4YxHXbX2rxYMABN_xG&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
