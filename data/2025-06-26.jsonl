{"title": "Can Large Language Models Understand Intermediate Representations in Compilers?", "first_label": ["LLM"], "second_label": [], "data": "H Jiang, J Zhu, Y Wan, B Fang, H Zhang, R Jin, Q Guan\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nIntermediate Representations (IRs) play a critical role in compiler design and \nprogram analysis, yet their comprehension by* Large Language Models*(LLMs) \nremains underexplored. In this paper, we present an explorative empirical study\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/forum%3Fid%3DzDieh7VWfN&hl=en&sa=X&d=13871753026296865586&ei=wDtbaKjiFtzM6rQPqc-H8Qs&scisig=AAZF9b95A-B5ycfwccjF6qtGrlcf&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Text Recognition on Curved Metal Surface: An Enhanced Approach using EasyOCR and OpenCV", "first_label": [], "second_label": [], "data": "ATN Charany, SN Kumar\\xc2\\xa0- 2025 5th International Conference on Pervasive\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nText is a fundamental system of symbolic representation, and it plays a major role in \nhuman culture and communication. Its ability to convey the rich semantic information \nhas become very essential in vision-based applications. With the advancement of \ndeep learning, computer vision techniques particularly in text detection and \nrecognition has undergone significant evolution. This paper investigates the \ntransformative impact of deep learning on scene text detection and recognition\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSAFL: A self-attention scene text recognizer with focal loss\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11035881/&hl=en&sa=X&d=8000156528618499099&ei=wDtbaOiJEfuvieoPotyokQU&scisig=AAZF9b-qC-Sy78k8ZrLcSCvf8xtQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 new citation to articles by Thanh Le-Cong"]}
{"title": "EffFix: Efficient and Effective Repair of Pointer Manipulating Programs", "first_label": [], "second_label": ["Repair"], "data": "Y ZHANG, A COSTEA, R SHARIFFDEEN, D MCCALL\\xe2\\x80\\xa6 - 2025\nThis work introduces EffFix, a tool that applies a novel static analysis-driven \nautomated program repair (APR) technique for fixing memory errors. APR tools \ntypically rely on a given test-suite to guide the repair process. Apart from the need to\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://repository.tudelft.nl/file/File_c36ad721-bb1f-4dfe-8824-466e4b04886d&hl=en&sa=X&d=17945240611634876158&ei=wDtbaJyrErXCieoPx6Gs6Q4&scisig=AAZF9b-qcr_XfesNbksjYvDRvG1A&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "2 new citations to articles by Abhik Roychoudhury", "1 new citation to articles by Xin ZHOU", "Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Efficient Neural Network Verification via Order Leading Exploration of Branch-and-Bound Trees", "first_label": ["Verification"], "second_label": [], "data": "G Zhang, K Fukuda, Z Zhang, HMND Bandara, S Chen\\xe2\\x80\\xa6\nThe vulnerability of neural networks to adversarial perturbations has necessitated \nformal verification techniques that can rigorously certify the quality of neural \nnetworks. As the state-of-the-art, branchand-bound (BaB) is a \\xe2\\x80\\x9cdivide-and-conquer\\xe2\\x80\\x9d \nstrategy that applies off-the-shelf verifiers to sub-problems for which they perform \nbetter. While BaB can identify the sub-problems that are necessary to be split, it \nexplores the space of these sub-problems in a naive \\xe2\\x80\\x9cfirst-come-first-served\\xe2\\x80\\x9d manner\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFuzz Testing based Data Augmentation to Improve Robustness of\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://yuleisui.github.io/publications/ecoop25a.pdf&hl=en&sa=X&d=4859687653067077162&ei=wDtbaO-cGMy8ieoPq9flOA&scisig=AAZF9b9oNiZ5aYngXYyEL_Cj0OAn&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
{"title": "Vulnerability-Aware Alignment: Mitigating Uneven Forgetting in Harmful Fine-Tuning", "first_label": ["Vulnerabilities"], "second_label": [], "data": "C Liang, X Han, L Shen, J Bai, KF Wong\\xc2\\xa0- Forty-second International Conference on\\xc2\\xa0\\xe2\\x80\\xa6\nHarmful fine-tuning (HFT), performed directly on open-source LLMs or through Fine-\ntuning-as-a-Service, breaks safety alignment and poses significant threats. Existing \nmethods aim to mitigate HFT risks by learning robust representation on alignment \ndata or making harmful data unlearnable, but they treat each data sample equally, \nleaving data vulnerability patterns understudied. In this work, we reveal that certain \nsubsets of alignment data are consistently more prone to forgetting during HFT\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DEMHED4WTHT&hl=en&sa=X&d=13921773924420883512&ei=wDtbaKn2E4OuieoPsICzsQc&scisig=AAZF9b_KwBmptOT83bx1ZKahDGS0&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang"]}
{"title": "Mystique: Automated Vulnerability Patch Porting with Semantic and Syntactic-Enhanced LLM", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "S Wu, R Wang, Y Cao, B Chen, Z Zhou, Y Huang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBranching repositories facilitates efficient software development but can also \ninadvertently propagate vulnerabilities. When an original branch is patched, other \nunfixed branches remain vulnerable unless the patch is successfully ported\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715718&hl=en&sa=X&d=11530525622372618368&ei=wDtbaM_UIfuvieoPotyokQU&scisig=AAZF9b9yqIVccQ4Nd-ePg8_hnlN3&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Quang-Cuong Bui - new related research", "6 new citations to articles by Bach Le", "David Lo - new related research"]}
{"title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Li, J Ding, C Peng, B Zhao, X Gao, H Gao, X Gu\\xc2\\xa0- arXiv preprint arXiv:2506.05692, 2025\nThe code generation capabilities of large language models (LLMs) have emerged as \na critical dimension in evaluating their overall performance. However, prior research \nhas largely overlooked the security risks inherent in the generated code. In this work\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05692%3F&hl=en&sa=X&d=5492650506064335063&ei=wDtbaMajFau26rQPs7aQsAo&scisig=AAZF9b_uwkPsOhWMHWjfdGwYFezG&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Bach Le - new related research"]}
{"title": "Visualization Task Taxonomy to Understand the Fuzzing Internals", "first_label": ["Fuzzing"], "second_label": [], "data": "S Kummita, M Miao, E Bodden, S Wei\\xc2\\xa0- ACM Transactions on Software Engineering\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGreybox fuzzing is used extensively in research and practice. There are umpteen \npublications that improve greybox fuzzing. However, to what extent do these \nimprovements affect the internal components or internals of a given fuzzer is not yet\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3718346&hl=en&sa=X&d=6310038100822609560&ei=wDtbaMHEG6alieoPiP2v6Qk&scisig=AAZF9b_Ue_jmzHRI425oDGHolQub&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "RIMFuzz: real-time impact-aware mutation for library API fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "X Wang, L Zhao\\xc2\\xa0- Journal of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs libraries merely expose APIs to developers rather than directly handling user \ninput, applying fuzzing to libraries requires fuzz drivers to help process fuzzer-\nprovided input and invoke APIs. To reduce manual effort and avoid reliance on\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00050-1&hl=en&sa=X&d=11566396351270247841&ei=wDtbaMHEG6alieoPiP2v6Qk&scisig=AAZF9b9NzGapAGT-Gt26V3wejXNn&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Trailblazer: Practical End-to-end Web API Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "L Pan, S Cohney, T Murray, VT Pham\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThere are two key challenges in automatically testing web APIs:(a) determine where \nto send API requests and (b) identify how to make a valid payload for a given \nrequest. Both challenges are sometimes addressed by the presence of a machine\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3731717&hl=en&sa=X&d=13250706246401116236&ei=wDtbaMHEG6alieoPiP2v6Qk&scisig=AAZF9b-ohQDK3DHvGNmHJasK8R14&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "On the Applicability of Benford's Law to Detect Saturation in Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "J Lee, H Lee, S Park, SK Cha\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nKnowing when a fuzzing campaign has reached saturation is crucial for practitioners \nto avoid unnecessarily lengthy campaigns without missing bugs within given \nresources. Unfortunately, existing solutions for determining the saturation point rely\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3731723&hl=en&sa=X&d=16464785359231774820&ei=wDtbaMHEG6alieoPiP2v6Qk&scisig=AAZF9b-hP7JkI_Vp2sP6UiYyub7W&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Malo in the Code Jungle: Explainable Fault Localization for Decentralized Applications", "first_label": ["Fault Localization", "Code"], "second_label": ["Localization"], "data": "H Zhang, J Wu, Z Wu, Z Chen, D Lin, J Chen, Y Zhou\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDecentralized applications (DApps) have long been sitting ducks for hackers due to \ntheir valuable cryptocurrency assets, exposing them to various security risks. When a \nDApp is attacked, promptly identifying faults is crucial to minimizing financial losses\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11034691/&hl=en&sa=X&d=7651709202352945146&ei=wDtbaMHEG6alieoPiP2v6Qk&scisig=AAZF9b8cw1Hmz_K4wN9ajW1PUmQk&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "LPASS: Linear Probes as Stepping Stones for vulnerability detection using compressed LLMs", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "L Ibanez-Lissen, L Gonzalez-Manzano, JM de Fuentes\\xe2\\x80\\xa6\\xc2\\xa0- Journal of Information\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAbstract Large Language Models (LLMs) are being extensively used for \ncybersecurity purposes. One of them is the detection of vulnerable codes. For the \nsake of efficiency and effectiveness, compression and fine-tuning techniques are\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S2214212625001620&hl=en&sa=X&d=2394315711310610645&ei=wDtbaOf_GdSWieoPzP3EKA&scisig=AAZF9b9MPtMj-GI0yJ_uOc0N8zMN&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Y Mao, T Cui, P Liu, D You, H Zhu\\xc2\\xa0- arXiv preprint arXiv:2506.15170, 2025\nLarge language models (LLMs) are rapidly evolving from single-modal systems to \nmultimodal LLMs and intelligent agents, significantly expanding their capabilities \nwhile introducing increasingly severe security risks. This paper presents a systematic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15170&hl=en&sa=X&d=16427093263132639213&ei=wDtbaMnRH-2rieoPvZemkQw&scisig=AAZF9b-zqUEdPZ8IyWJxfUDycl5Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Yuan, Y Xu, J Shi, P Zhou, L Sun\\xc2\\xa0- arXiv preprint arXiv:2505.23561, 2025\nModel merging for Large Language Models (LLMs) directly fuses the parameters of \ndifferent models finetuned on various tasks, creating a unified model for multi-domain \ntasks. However, due to potential vulnerabilities in models available on open-source\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23561&hl=en&sa=X&d=6617189016454156514&ei=wDtbaMnRH-2rieoPvZemkQw&scisig=AAZF9b-hKaNf3ql6GqPXtJeaxsCC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift", "first_label": ["LLM"], "second_label": [], "data": "S Liang, J Liang, T Pang, C Du, A Liu, M Zhu, X Cao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInstruction tuning enhances large vision-language models (LVLMs) but increases \ntheir vulnerability to backdoor attacks due to their open design. Unlike prior studies in \nstatic settings, this paper explores backdoor attacks in LVLM instruction tuning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.pdf&hl=en&sa=X&d=5142527777954789704&ei=wDtbaMnRH-2rieoPvZemkQw&scisig=AAZF9b_Zz7b9xsyiBVRqo7nDX3YO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, M Dras, U Naseem\\xc2\\xa0- arXiv preprint arXiv:2506.02442, 2025\nThis paper presents a systematic evaluation of Large Language Models'(LLMs) \nbehavior on long-tail distributed (encrypted) texts and their safety implications. We \nintroduce a two-dimensional framework for assessing LLM safety:(1) instruction\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02442&hl=en&sa=X&d=15102350404536711280&ei=wDtbaMnRH-2rieoPvZemkQw&scisig=AAZF9b_4gGVOvmiHUrKGvn2E4Vhh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems", "first_label": ["LLM"], "second_label": ["Agent", "Search"], "data": "X Li, J Chen, X Fang, S Ding, H Duan, Q Liu, K Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown remarkable capabilities in solving \ndiverse tasks. However, their proficiency in iteratively optimizing complex solutions \nthrough learning from previous feedback remains insufficiently explored. To bridge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10764&hl=en&sa=X&d=1134890120116902745&ei=wDtbaMnRH-2rieoPvZemkQw&scisig=AAZF9b8s_mGNSGwzfKFs6o2hgsbd&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents", "first_label": ["LLM", "Code"], "second_label": ["Agent", "Reasoning"], "data": "K Hariharan, U Girit, A Wang, J Andreas\\xc2\\xa0- arXiv preprint arXiv:2506.00172, 2025\nBenchmarks for large language models (LLMs) have predominantly assessed short-\nhorizon, localized reasoning. Existing long-horizon suites (eg SWE-bench) rely on \nmanually curated issues, so expanding or tuning difficulty demands expensive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00172&hl=en&sa=X&d=7723120566071680437&ei=wDtbaMnRH-2rieoPvZemkQw&scisig=AAZF9b-MEatAoZUO5Dw1f9NQmtaH&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring", "first_label": ["LLM"], "second_label": [], "data": "Y Li, Q Sheng, Y Yang, X Zhang, J Cao\\xc2\\xa0- arXiv preprint arXiv:2506.09996, 2025\nThough safety alignment has been applied to most large language models (LLMs), \nLLM service providers generally deploy a subsequent moderation as the external \nsafety guardrail in real-world products. Existing moderators mainly practice a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09996&hl=en&sa=X&d=8967671192696781749&ei=wDtbaMnRH-2rieoPvZemkQw&scisig=AAZF9b-I099JquXawda445fWweEs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Backdoor Attack on Vision Language Models with Stealthy Semantic Manipulation", "first_label": ["LLM"], "second_label": [], "data": "Z Zhong, Z Sun, Y Liu, X He, G Tao\\xc2\\xa0- arXiv preprint arXiv:2506.07214, 2025\nVision Language Models (VLMs) have shown remarkable performance, but are also \nvulnerable to backdoor attacks whereby the adversary can manipulate the model's \noutputs through hidden triggers. Prior attacks primarily rely on single-modality\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07214&hl=en&sa=X&d=13852487448298011741&ei=wDtbaMnRH-2rieoPvZemkQw&scisig=AAZF9b_pfJDrPo270Aj4VCR1rEcM&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Securing AI Agents with Information-Flow Control", "first_label": [], "second_label": ["Agent"], "data": "M Costa, B K\\xc3\\xb6pf, A Kolluri, A Paverd, M Russinovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI agents become increasingly autonomous and capable, ensuring their security \nagainst vulnerabilities such as prompt injection becomes critical. This paper explores \nthe use of information-flow control (IFC) to provide security guarantees for AI agents\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23643%3F&hl=en&sa=X&d=4534448032257376326&ei=wDtbaMnRH-2rieoPvZemkQw&scisig=AAZF9b-ruPZ7fbYUs0K6HirRZr2z&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Mitigating Safety Fallback in Editing-based Backdoor Injection on LLMs", "first_label": ["LLM"], "second_label": [], "data": "H Jiang, Z Zhao, J Fang, H Ma, R Wang, Y Deng\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have shown strong performance across natural \nlanguage tasks, but remain vulnerable to backdoor attacks. Recent model editing-\nbased approaches enable efficient backdoor injection by directly modifying\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13285&hl=en&sa=X&d=2170150226017896735&ei=wDtbaMnRH-2rieoPvZemkQw&scisig=AAZF9b_hV_fa4zxO0uXWAh_ZXAMQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "HornBro: Homotopy-Like Method for Automated Quantum Program Repair", "first_label": ["APR"], "second_label": ["Repair"], "data": "S Tan, L Lu, D Xiang, T Chu, C Lang, J Chen, X Hu\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nQuantum programs provide exponential speedups compared to classical programs \nin certain areas, but they also inevitably encounter logical faults. Automatically \nrepairing quantum programs is much more challenging than repairing classical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715751&hl=en&sa=X&d=13228585835236654799&ei=S3pZaLzlIMy8ieoPt5yl6Qk&scisig=AAZF9b-8_CqaMqv576h_a4v0IZHT&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Thanh Le-Cong - new related research", "Bach Le - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Directed Testing in MLIR: Unleashing Its Potential by Overcoming the Limitations of Random Fuzzing", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "W Tong, Z Wang, Z Tang, J Fang, Y Zhang, G Ye\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMLIR is a new way of creating compiler infrastructures that can be easily reused and \nextended. Current MLIR fuzzing methods focus primarily on test case generation or \nmutation using randomly selected passes. However, they often overlook the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729372&hl=en&sa=X&d=10225165863736020095&ei=S3pZaLzlIMy8ieoPt5yl6Qk&scisig=AAZF9b9XDaU-7-dG1ms-uNWhw7no&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "KRAKEN: Program-Adaptive Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A ZHOU, H HUANG, C ZHANG - 2025\nDespite numerous advances, most existing fuzzers still require more than 24 hours to \nthoroughly test the target programs to achieve satisfactory code coverage or bug \ndetection results [7, 32, 42, 64]. Recently, as cloud-based computing and multicore\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://seviezhou.github.io/files/kraken.pdf&hl=en&sa=X&d=6944396394299119143&ei=S3pZaLzlIMy8ieoPt5yl6Qk&scisig=AAZF9b9QILhkfV1b1x87AW8NkoEo&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "DuoReduce: Bug Isolation for Multi-layer Extensible Compilation", "first_label": ["Bug"], "second_label": [], "data": "J Wang, Y Qiu, B Limpanukorn, HJ Kang, Q Zhang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, the MLIR framework has had explosive growth due to the need for \nextensible deep learning compilers for hardware accelerators. Such examples \ninclude Triton, CIRCT, and ONNX-MLIR. MLIR compilers introduce significant \ncomplexities in localizing bugs or inefficiencies because of their layered optimization \nand transformation process with compilation passes. While existing delta debugging \ntechniques can be used to identify a minimum subset of IR code that reproduces a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFuzzing MLIR by Synthesizing Custom Mutations\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715747&hl=en&sa=X&d=16704826441152364364&ei=S3pZaM6FFvuvieoPxs6ggQU&scisig=AAZF9b8GmmhtQmNd80UBCU8gRDJz&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["6 new citations to articles by Hong Jin Kang"]}
{"title": "An Adaptive Language-Agnostic Pruning Method for Greener Language Models for Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "M Saad, JAH L\\xc3\\xb3pez, B Chen, D Varr\\xc3\\xb3, T Sharma\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models of code have demonstrated remarkable performance across \nvarious software engineering and source code analysis tasks. However, their \ndemanding computational resource requirements and consequential environmental \nfootprint remain as significant challenges. This work introduces ALPINE, an adaptive \nprogramming language-agnostic pruning technique designed to substantially reduce \nthe computational overhead of these models. The proposed method offers a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaGreening large language models of code\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715773&hl=en&sa=X&d=7944316343425442468&ei=S3pZaM6FFvuvieoPxs6ggQU&scisig=AAZF9b_df9m6q87B5fG6FvHqqLve&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["6 new citations to articles by Hong Jin Kang", "6 new citations to articles by Bach Le", "David Lo - new related research", "Bach Le - new related research", "Xin ZHOU - new related research", "3 new citations to articles by Thanh Le-Cong"]}
{"title": "Towards Understanding Fine-Grained Programming Mistakes and Fixing Patterns in Data Science", "first_label": [], "second_label": [], "data": "WH Chen, JL Cheoh, M Keim, S Brunswicker, T Zhang\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nProgramming is an essential activity in data science (DS). Unlike regular software \ndevelopers, DS programmers often use Jupyter notebooks instead of conventional \nIDEs. Moreover, DS programmers focus on statistics, data analytics, and modeling \nrather than writing production-ready code following best practices in software \nengineering. Thus, in order to provide effective tool support to improve their \nproductivity, it is important to understand what kinds of errors they make and how\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBugsinpy: a database of existing bugs in python programs to\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729352&hl=en&sa=X&d=4967321802917596921&ei=S3pZaM6FFvuvieoPxs6ggQU&scisig=AAZF9b9ROLubcyywTR6xiUHl1JhM&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["6 new citations to articles by Hong Jin Kang"]}
{"title": "CoverUp: Effective High Coverage Test Generation for Python", "first_label": ["Software Testing"], "second_label": ["Generation"], "data": "J Altmayer Pizzorno, ED Berger\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nTesting is an essential part of software development. Test generation tools attempt to \nautomate the otherwise labor-intensive task of test creation, but generating high-\ncoverage tests remains challenging. This paper proposes CoverUp, a novel \napproach to driving the generation of high-coverage Python regression tests. \nCoverUp combines coverage analysis, code context, and feedback in prompts that \niteratively guide the LLM to generate tests that improve line and branch coverage\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBugsinpy: a database of existing bugs in python programs to\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729398&hl=en&sa=X&d=9453066305056140904&ei=S3pZaM6FFvuvieoPxs6ggQU&scisig=AAZF9b8inc8roC06uMigZcBWOfIr&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=3&folt=cit", "author": ["Hong Jin Kang"], "ref": ["6 new citations to articles by Hong Jin Kang", "Hong Jin Kang - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Blended Analysis for Predictive Execution", "first_label": [], "second_label": [], "data": "Y Li, H Dhulipala, A Yadavally, X Rong, S Wang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAlthough Large Language Models (LLMs) are highly proficient in understanding \nsource code and descriptive texts, they have limitations in reasoning on dynamic \nprogram behaviors, such as execution trace and code coverage prediction, and \nruntime error prediction, which usually require actual program execution. To advance \nthe ability of LLMs in predicting dynamic behaviors, we leverage the strengths of both \napproaches, Program Analysis (PA) and LLM, in building PredEx, a predictive\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBugsinpy: a database of existing bugs in python programs to\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729402&hl=en&sa=X&d=12319963630633609851&ei=S3pZaM6FFvuvieoPxs6ggQU&scisig=AAZF9b-pnWdpjaCZBdaNQKch-wnN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=4&folt=cit", "author": ["Hong Jin Kang"], "ref": ["6 new citations to articles by Hong Jin Kang"]}
{"title": "FLITSR: Improved Spectrum-Based Localization of Multiple Faults by Iterative Test Suite Reduction", "first_label": ["Software Testing"], "second_label": ["Localization"], "data": "D Callaghan, B Fischer\\xc2\\xa0- ACM Transactions on Software Engineering and\\xc2\\xa0\\xe2\\x80\\xa6\nSpectrum-based fault localization (SBFL) works well for single-fault programs but its \naccuracy decays for increasing fault numbers. We present FLITSR (Fault Localization \nby Iterative Test Suite Reduction), a novel SBFL approach that improves the \nlocalization of a given SBFL base metric specifically in the presence of multiple \nfaults. FLITSR iteratively selects reduced versions of the test suite that better localize \nthe individual faults in the system. This allows it to identify and re-rank faults ranked\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBugsinpy: a database of existing bugs in python programs to\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3745027&hl=en&sa=X&d=5640068453836852237&ei=S3pZaM6FFvuvieoPxs6ggQU&scisig=AAZF9b-2SWRLczBs-Dy_Q4W-sJVB&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=5&folt=cit", "author": ["Hong Jin Kang"], "ref": ["6 new citations to articles by Hong Jin Kang", "Thanh Le-Cong - new related research"]}
{"title": "Demystifying Memorization in LLM-Based Program Repair via a General Hypothesis Testing Framework", "first_label": ["APR", "LLM", "Software Testing"], "second_label": ["Repair"], "data": "J Kong, X Xie, S Liu\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nLarge Language Models (LLMs) have achieved remarkable success in various \napplications, particularly in code-related tasks such as code generation and program \nrepair, setting new performance benchmarks. However, the extensive use of large\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729390&hl=en&sa=X&d=1963173140402968809&ei=S3pZaKShFO2rieoPk6bG-Qo&scisig=AAZF9b9ZsiWvyL5PU9a54w9waTFt&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Bach Le - new related research", "10 new citations to articles by Abhik Roychoudhury", "Quang-Cuong Bui - new related research", "4 new citations to articles by Xin ZHOU"]}
{"title": "Demystifying LLM-Based Software Engineering Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "CS Xia, Y Deng, S Dunn, L Zhang\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nRecent advancements in large language models (LLMs) have significantly advanced \nthe automation of software development tasks, including code synthesis, program \nrepair, and test generation. More recently, researchers and industry practitioners\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715754&hl=en&sa=X&d=5908066739003088477&ei=S3pZaKShFO2rieoPk6bG-Qo&scisig=AAZF9b_taKJ3CIbZZT9Trx17_y8o&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "6 new citations to articles by Bach Le", "Xin ZHOU - new related research", "10 new citations to articles by Abhik Roychoudhury", "Richard Fang - new related research", "Lingming Zhang - new articles"]}
{"title": "Element-Based Automated DNN Repair with Fine-Tuned Masked Language Model", "first_label": ["LLM"], "second_label": ["Repair"], "data": "X Wang, M Zhang, X Meng, J Zhang, Y Liu, C Hu\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeep Neural Networks (DNNs) are prevalent across a wide range of applications. \nDespite their success, the complexity and opaque nature of DNNs pose significant \nchallenges in debugging and repairing DNN models, limiting their reliability and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715716&hl=en&sa=X&d=9954951256051044219&ei=S3pZaKShFO2rieoPk6bG-Qo&scisig=AAZF9b_bSPID4_lMjXeiweVi0haI&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research", "Bach Le - new related research", "Xin ZHOU - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Error Delayed Is Not Error Handled: Understanding and Fixing Propagated Error-Handling Bugs", "first_label": ["Bug"], "second_label": [], "data": "H Liu, S Li, Z Jia, Y Zhang, L Bai, S Zheng, X Mao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nError handling is critical for software reliability. In software systems, error handling \nmay be delayed to other functions. Such propagated error handling (PEH) could \neasily be missed and lead to bugs. Our research reveals that PEH bugs are\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729384&hl=en&sa=X&d=16292578031927877887&ei=S3pZaKShFO2rieoPk6bG-Qo&scisig=AAZF9b-vEOE8PpFPNNDfVMrGe4CJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "6 new citations to articles by Bach Le", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "VulBinLLM: LLM-powered Vulnerability Detection for Stripped Binaries", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "N Hussain, H Chen, C Tran, P Huang, Z Li, P Chugh\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecognizing vulnerabilities in stripped binary files presents a significant challenge in \nsoftware security. Although some progress has been made in generating human-\nreadable information from decompiled binary files with Large Language Models\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22010&hl=en&sa=X&d=10332909566617513173&ei=S3pZaKShFO2rieoPk6bG-Qo&scisig=AAZF9b_uFh0VfBD1MzUN8jZA2T1m&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Evaluating Large Language Models for Code Review", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "U Cihan, A \\xc4\\xb0\\xc3\\xa7\\xc3\\xb6z, V Haratian, E T\\xc3\\xbcz\\xc3\\xbcn\\xc2\\xa0- arXiv preprint arXiv:2505.20206, 2025\nContext: Code reviews are crucial for software quality. Recent AI advances have \nallowed large language models (LLMs) to review and fix code; now, there are tools \nthat perform these reviews. However, their reliability and accuracy have not yet been\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20206&hl=en&sa=X&d=15665831858314714693&ei=S3pZaKShFO2rieoPk6bG-Qo&scisig=AAZF9b_nX5EjD1ohxo-XwLW6C4w4&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "DiSCo: Towards Decompiling EVM Bytecode to Source Code using Large Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "X Su, H Liang, H Wu, B Niu, F Xu, S Zhong\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nUnderstanding the Ethereum smart contract bytecode is essential for ensuring \ncryptoeconomics security. However, existing decompilers primarily convert bytecode \ninto pseudocode, which is not easily comprehensible for general users, potentially \nleading to misunderstanding of contract behavior and increased vulnerability to \nscams or exploits. In this paper, we propose DiSCo, the first LLMs-based EVM \ndecompilation pipeline, which aims to enable LLMs to understand the opaque\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLeveraging large language model for automatic patch correctness\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729373&hl=en&sa=X&d=6825382788494923258&ei=S3pZaPrGF86r6rQPxrLf-As&scisig=AAZF9b_54ioqHXj50vXuyqs60xhA&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["6 new citations to articles by Bach Le", "David Lo - new related research", "Xin ZHOU - new related research", "Quang-Cuong Bui - new related research", "3 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Xin ZHOU"]}
{"title": "10 Years Later: Revisiting How Developers Search for Code", "first_label": ["Code"], "second_label": ["Search"], "data": "KT Stolee, T Welp, C Sadowski, S Elbaum\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode search is an integral part of a developer's workflow. In 2015, researchers \npublished a paper reflecting on the code search practices at Google of 27 \ndevelopers who used the internal Code Search tool. That paper had first-hand \naccounts for why those developers were using code search and highlighted how \noften and in what situations developers were searching for code. In the past decade, \nmuch has changed in the landscape of developer support. New languages have\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaThanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715774&hl=en&sa=X&d=11723757379990126168&ei=S3pZaPrGF86r6rQPxrLf-As&scisig=AAZF9b-NLeL8kUtJfKqwsGvuACMG&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["6 new citations to articles by Bach Le", "3 new citations to articles by Thanh Le-Cong"]}
{"title": "Statement-Level Adversarial Attack on Vulnerability Detection Models via Out-of-Distribution Features", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "X Du, M Wen, H Wang, Z Wei, H Jin\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode vulnerability detection is crucial to ensure software security. Recent \nadvancements, particularly with the emergence of Code Pre-Trained Models \n(CodePTMs) and Large Language Models (LLMs), have led to significant progress in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729403&hl=en&sa=X&d=636801605143479768&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b-FRDekIihP8NdkTYE0Awpq&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Xin ZHOU - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "One-for-All Does Not Work! Enhancing Vulnerability Detection by Mixture-of-Experts (MoE)", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "X Yang, S Wang, J Zhou, W Zhu\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nDeep Learning-based Vulnerability Detection (DLVD) techniques have garnered \nsignificant interest due to their ability to automatically learn vulnerability patterns from \npreviously compromised code. Despite the notable accuracy demonstrated by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715736&hl=en&sa=X&d=12277895505706496557&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b8ONAy_HONHWhHAz0g3LZ3L&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research", "4 new citations to articles by Xin ZHOU"]}
{"title": "A Causal Learning Framework for Enhancing Robustness of Source Code Models", "first_label": ["Code"], "second_label": [], "data": "J Ye, Z Li, X Tang, D Zou, S Xu, W Qiang, H Jin\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeep Learning (DL) models are useful for many software engineering tasks. \nHowever, these models are susceptible to adversarial attacks, partly because they \nlearn spurious features that incur spurious correlations between these features and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729387&hl=en&sa=X&d=4612536251679664691&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b-o31NbcZmTVBWrQfvAS4kz&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Constrained Sampling for Language Models Should Be Easy: An MCMC Perspective", "first_label": ["LLM"], "second_label": [], "data": "EA Gonzalez, S Vaidya, K Park, R Ji, T Berg-Kirkpatrick\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nConstrained decoding enables Language Models (LMs) to produce samples that \nprovably satisfy hard constraints. However, existing constrained-decoding \napproaches often distort the underlying model distribution, a limitation that is\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05754%3F&hl=en&sa=X&d=4553768187136981789&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b9AgkL70JOv2CQQ4cjhA1vo&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Smaller but Better: Self-Paced Knowledge Distillation for Lightweight yet Effective LCMs", "first_label": [], "second_label": [], "data": "Y Chen, Y Ye, Z Li, Y Ma, C Gao\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nLarge code models (LCMs) have remarkably advanced the field of code generation. \nDespite their impressive capabilities, they still face practical deployment issues, such \nas high inference costs, limited accessibility of proprietary LCMs, and adaptability\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729405&hl=en&sa=X&d=9026610720938696778&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b_7eWek5V1HaAc6YKgS4o4U&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "A Knowledge Enhanced Large Language Model for Bug Localization", "first_label": ["LLM", "Bug"], "second_label": ["Localization"], "data": "Y Li, B Liu, T Zhang, Z Wang, D Lo, L Yang, J Lyu\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nA significant number of bug reports are generated every day as software systems \ncontinue to develop. Large Language Models (LLMs) have been used to correlate \nbug reports with source code to locate bugs automatically. The existing research has\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729356&hl=en&sa=X&d=16532092839572238040&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b-PmFlcmxHgFCjDtRfes5nX&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Enhancing Bug Assignment with Developer-Specific Feature Extraction and Hybrid Deep Learning", "first_label": ["Bug"], "second_label": [], "data": "G Yang, J Ji, D Kim\\xc2\\xa0- Electronics, 2025\nThe increasing reliance on software in diverse domains has led to a surge in user-\nreported functional enhancements and unexpected bugs. In large-scale open-source \nprojects like Eclipse and Mozilla, initial bug assignment frequently faces challenges\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2079-9292/14/12/2493&hl=en&sa=X&d=17183169801774588772&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b9RluOxd4JkSjNXwplMouZK&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Teaching AI the 'Why'and 'How'of Software Vulnerability Fixes", "first_label": ["Vulnerabilities"], "second_label": [], "data": "A Gao, Z Zhang, S Wang, L Huang, S Wei, V Ng\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nUnderstanding software vulnerabilities and their resolutions is crucial for securing \nmodern software systems. This study presents a novel traceability model that links a \npair of sentences describing at least one of the three types of semantics (triggers\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729360&hl=en&sa=X&d=7711343863691178810&ei=S3pZaK2-KvuvieoPxs6ggQU&scisig=AAZF9b9vszGN_K61wmdgdZlrmFxs&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "1 new citation to articles by Quang-Cuong Bui"]}
{"title": "Standing on the Shoulders of Giants: Bug-Aware Automated GUI Testing via Retrieval Augmentation", "first_label": ["Bug", "Software Testing"], "second_label": [], "data": "M Chen, Z Liu, C Chen, J Wang, B Wu, J Hu, Q Wang\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn software development, similar apps often encounter similar bugs due to shared \nfunctionalities and implementation methods. However, current automated GUI testing \nmethods mainly focus on generating test scripts to cover more pages by analyzing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715755&hl=en&sa=X&d=11872138283674414812&ei=S3pZaN70GvfWieoP1-jt-QU&scisig=AAZF9b9RaubVxD9RcGpAV9MEKEUq&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Training Language Models to Generate Quality Code with Program Analysis Feedback", "first_label": ["LLM", "Code"], "second_label": [], "data": "F Yao, Z Wang, L Liu, J Cui, L Zhong, X Fu, H Mai\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode generation with large language models (LLMs), often termed vibe coding, is \nincreasingly adopted in production but fails to ensure code quality, particularly in \nsecurity (eg, SQL injection vulnerabilities) and maintainability (eg, missing type\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22704&hl=en&sa=X&d=13720297852295427429&ei=S3pZaN3KEte5ieoP58CikQE&scisig=AAZF9b9qU1hJff-ona5ynwmi0w3O&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=4&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "An Empirical Study of Code Clones from Commercial AI Code Generators", "first_label": ["Code"], "second_label": [], "data": "W Wu, H Hu, Z Fan, Y Qiao, Y Huang, Y Li, Z Zheng\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeep learning (DL) has revolutionized various software engineering tasks. \nParticularly, the emergence of AI code generators has pushed the boundaries of \nautomatic programming to synthesize entire programs based on user-defined\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729397&hl=en&sa=X&d=12837448834344751203&ei=S3pZaNS_KO2rieoPk6bG-Qo&scisig=AAZF9b8qk8ta7P66byZJBCjO3g78&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "The Struggles of LLMs in Cross-Lingual Code Clone Detection", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "MB Moumoula, AK Kabor\\xc3\\xa9, J Klein, TF Bissyand\\xc3\\xa9\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the involvement of multiple programming languages in modern software \ndevelopment, cross-lingual code clone detection has gained traction within the \nsoftware engineering community. Numerous studies have explored this topic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715764&hl=en&sa=X&d=13415771137676208664&ei=S3pZaNS_KO2rieoPk6bG-Qo&scisig=AAZF9b94b9bfALws5oAEMt0gH9Lv&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Doc2OracLL: Investigating the Impact of Documentation on LLM-Based Test Oracle Generation", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "SB Hossain, R Taylor, M Dwyer\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nCode documentation is a critical artifact of software development, bridging human \nunderstanding and machine-readable code. Beyond aiding developers in code \ncomprehension and maintenance, documentation also plays a critical role in\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729354&hl=en&sa=X&d=13766729628373229449&ei=S3pZaNS_KO2rieoPk6bG-Qo&scisig=AAZF9b8n5QGiXT1EhOFHjese5ohv&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=9&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "VLATest: Testing and Evaluating Vision-Language-Action Models for Robotic Manipulation", "first_label": ["Software Testing"], "second_label": [], "data": "Z Wang, Z Zhou, J Song, Y Huang, Z Shu, L Ma\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of generative AI and multi-modal foundation models has \nshown significant potential in advancing robotic manipulation. Vision-language-\naction (VLA) models, in particular, have emerged as a promising approach for \nvisuomotor control by leveraging large-scale vision-language data and robot \ndemonstrations. However, current VLA models are typically evaluated using a limited \nset of hand-crafted scenes, leaving their general performance and robustness in\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729343&hl=en&sa=X&d=506655532696745030&ei=S3pZaMzAHIOuieoPyIM7&scisig=AAZF9b_KD49T8pFFd508jDN9nluz&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "CRISPE: Semantic-Guided Execution Planning and Dynamic Reasoning for Enhancing Code Coverage Prediction", "first_label": ["Code"], "second_label": ["Reasoning"], "data": "H Dhulipala, A Yadavally, SS Patel, TN Nguyen\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWhile LLMs excel in understanding source code and descriptive texts for tasks like \ncode generation, code completion, etc., they exhibit weaknesses in predicting \ndynamic program behavior, such as code coverage and runtime error detection, \nwhich typically require program execution. Aiming to advance the capability of LLMs \nin reasoning and predicting the program behavior at runtime, we present CRISPE \n(short for Coverage Rationalization and Intelligent Selection ProcedurE), a novel\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFuzzing: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729401&hl=en&sa=X&d=13034209954716732251&ei=S3pZaMzAHIOuieoPyIM7&scisig=AAZF9b_MZal7JTKsXTVuw6mWEYgj&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Detecting and Reducing the Factual Hallucinations of Large Language Models with Metamorphic Testing", "first_label": ["LLM", "Software Testing"], "second_label": ["Detection"], "data": "W Wu, Y Cao, N Yi, R Ou, Z Zheng\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nQuestion answering (QA) is a fundamental task of large language models (LLMs), \nwhich requires LLMs to automatically answer human-posed questions in natural \nlanguage. However, LLMs are known to distort facts and make non-factual \nstatements (ie, hallucinations) when dealing with QA tasks, which may affect the \ndeployment of LLMs in real-life situations. In this work, we propose DrHall, a \nframework for detecting and reducing the factual hallucinations of black-box LLMs\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRe-factoring based Program Repair applied to Programming\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715784&hl=en&sa=X&d=11797333735455069810&ei=S3pZaMzAHIOuieoPyIM7&scisig=AAZF9b9Z20oO8KlHtjr9eWxe6MS9&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "LLMDroid: Enhancing Automated Mobile App GUI Testing Coverage with Large Language Model Guidance", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "C Wang, T Liu, Y Zhao, M Yang, H Wang\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the rapid development of Large Language Models (LLMs), their integration into \nautomated mobile GUI testing has emerged as a promising research direction. \nHowever, existing LLM-based testing approaches face significant challenges, \nincluding time inefficiency and high costs due to constant LLM querying. To address \nthese issues, this paper introduces LLMDroid, a novel testing framework designed to \nenhance existing automated mobile GUI testing tools by leveraging LLMs more\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTime-travel Testing of Android Apps\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715763&hl=en&sa=X&d=2859160406263160913&ei=S3pZaMzAHIOuieoPyIM7&scisig=AAZF9b-dbskoW25EIxHBG-CQIUEz&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "UnitCon: Synthesizing Targeted Unit Tests for Java Runtime Exceptions", "first_label": ["Software Testing"], "second_label": [], "data": "S Jang, Y Ryou, H Lee, K Heo\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nWe present UnitCon, a system for synthesizing targeted unit testsfor runtime \nexceptions in Java programs. Targeted unit tests aim to reveal a bug at a specific \nlocation in the program under test. This capability benefits various tasks in software \ndevelopment, such as patch testing, crash reproduction, or static analysis alarm \ninspection. However, conventional unit test generation tools are mainly designed for \nregression tests by maximizing code coverage; hence they are not effective at such\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729362&hl=en&sa=X&d=18094050204048994153&ei=S3pZaMzAHIOuieoPyIM7&scisig=AAZF9b9SIjsGhd6q-sKxVUvxgveC&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Towards Understanding Docker Build Faults in Practice: Symptoms, Root Causes, and Fix Patterns", "first_label": [], "second_label": [], "data": "Y Wu, Y Zhang, T Wang, B Ding, H Wang\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDocker building is a critical component of containerization in modern software \ndevelopment, automating the process of packaging and converting sources into \ncontainer images. It is not uncommon to find that Docker build faults (DBFs) occur\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715757&hl=en&sa=X&d=13481132424010785922&ei=S3pZaOfzHqKr6rQP49vTsAY&scisig=AAZF9b8BktiKib9aNBAJU8o1Ads5&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=3&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Beyond PEFT: Layer-Wise Optimization for More Effective and Efficient Large Code Model Tuning", "first_label": ["Code"], "second_label": [], "data": "C Wang, J Feng, S Gao, C Gao, Z Li, T Peng, H Huang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Code Models (LCMs) have demonstrated remarkable effectiveness across \nvarious code intelligence tasks. Supervised fine-tuning is essential to optimize their \nperformance for specific downstream tasks. Compared with the traditional full-\nparameter fine-tuning (FFT) method, Parameter-Efficient Fine-Tuning (PEFT) \nmethods can train LCMs with substantially reduced resource consumption and have \ngained widespread attention among researchers and practitioners. While existing\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaExploring Parameter-Efficient Fine-Tuning Techniques for Code\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729341&hl=en&sa=X&d=8815703461560510716&ei=S3pZaJrWI6alieoP6s6swAY&scisig=AAZF9b-oO7hHgThBtV-5S6CgGuhJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "Your Agent Can Defend Itself against Backdoor Attacks", "first_label": [], "second_label": ["Agent"], "data": "L Changjiang, L Jiacheng, C Bochuan, C Jinghui\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite their growing adoption across domains, large language model (LLM)-\npowered agents face significant security risks from backdoor attacks during training \nand fine-tuning. These compromised agents can subsequently be manipulated to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08336&hl=en&sa=X&d=9281612337423238890&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b8EnIakTDvZQGsyv1duPVA5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Adversarial Preference Learning for Robust LLM Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Wang, P Wang, C Xi, B Tang, J Zhu, W Wei, C Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern language models often rely on Reinforcement Learning from Human \nFeedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to \nadversarial attacks due to three key limitations:(1) the inefficiency and high cost of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24369%3F&hl=en&sa=X&d=11526575995055803369&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b_ilBi9AMSJoKPXxHc_hWg5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SecurityLingua: Efficient Defense of LLM Jailbreak Attacks via Security-Aware Prompt Compression", "first_label": ["LLM"], "second_label": [], "data": "Y Li, S Ahn, H Jiang, AH Abdi, Y Yang, L Qiu\\xc2\\xa0- arXiv preprint arXiv:2506.12707, 2025\nLarge language models (LLMs) have achieved widespread adoption across \nnumerous applications. However, many LLMs are vulnerable to malicious attacks \neven after safety alignment. These attacks typically bypass LLMs' safety guardrails by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12707&hl=en&sa=X&d=8418273368991399970&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b8AOJ5PQ2S2DYr5nVOYpqTl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge", "first_label": ["LLM"], "second_label": [], "data": "S Li, C Xu, J Wang, X Gong, C Chen, J Zhang, J Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable intelligence across \nvarious tasks, which has inspired the development and widespread adoption of LLM-\nas-a-Judge systems for automated model testing, such as red teaming and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09443&hl=en&sa=X&d=2052322274134661445&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b9u9cyhYi06xXXt37CLZpdh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Syntactic paraphrase-based synthetic data generation for backdoor attacks against Chinese language models", "first_label": ["LLM"], "second_label": ["Generation"], "data": "M Hu, Y Yang, D Pan, Z Guo, L Xiao, D Lin, S Zhao\\xc2\\xa0- Information Fusion, 2025\nAbstract Language Models (LMs) have shown significant advancements in various \nNatural Language Processing (NLP) tasks. However, recent studies indicate that \nLMs are particularly susceptible to malicious backdoor attacks, where attackers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S156625352500449X&hl=en&sa=X&d=11939540759867308872&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b_omHEFDqgnSwVne_pfKwnY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Through the Stealth Lens: Rethinking Attacks and Defenses in RAG", "first_label": [], "second_label": [], "data": "S Choudhary, N Palumbo, A Hooda, KD Dvijotham\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRetrieval-augmented generation (RAG) systems are vulnerable to attacks that inject \npoisoned passages into the retrieved set, even at low corruption rates. We show that \nexisting attacks are not designed to be stealthy, allowing reliable detection and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04390&hl=en&sa=X&d=15468735482968103516&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b8u2OUJdUy7skXRySPRbZz3&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AsFT: Anchoring Safety During LLM Fine-Tuning Within Narrow Safety Basin", "first_label": ["LLM"], "second_label": [], "data": "S Yang, Q Zhang, Y Liu, Y Huang, X Jia, K Ning, J Yao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are vulnerable to safety risks during fine-tuning, \nwhere small amounts of malicious or harmless data can compromise safeguards. In \nthis paper, building on the concept of alignment direction--defined by the weight\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08473%3F&hl=en&sa=X&d=15059004078714992755&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b-cmQJQ2nP1jAOJlM9iLuaf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Enhancing Reasoning Capabilities of Small Language Models with Blueprints and Prompt Template Search", "first_label": ["LLM"], "second_label": ["Search", "Reasoning"], "data": "D Han, M Xia, DM Diaz, S Kessler, A Mallick, X Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSmall language models (SLMs) offer promising and efficient alternatives to large \nlanguage models (LLMs). However, SLMs' limited capacity restricts their reasoning \ncapabilities and makes them sensitive to prompt variations. To address these\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08669%3F&hl=en&sa=X&d=15704474230557976749&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b8p3WkTiOwxN4IoT6Yx5Fu_&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Cost of Dynamic Reasoning: Demystifying AI Agents and Test-Time Scaling from an AI Infrastructure Perspective", "first_label": ["Software Testing"], "second_label": ["Agent", "Reasoning"], "data": "J Kim, B Shin, J Chung, M Rhu\\xc2\\xa0- arXiv preprint arXiv:2506.04301, 2025\nLarge-language-model (LLM)-based AI agents have recently showcased impressive \nversatility by employing dynamic reasoning, an adaptive, multi-step process that \ncoordinates with external tools. This shift from static, single-turn inference to agentic\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04301&hl=en&sa=X&d=3072272730677106970&ei=S3pZaJrXJte5ieoP58CikQE&scisig=AAZF9b-t8XUoljKdp6JjL-hJnilf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
