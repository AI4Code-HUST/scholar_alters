{"title": "Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift", "first_label": ["LLM"], "second_label": [], "data": "S Liang, J Liang, T Pang, C Du, A Liu, M Zhu, X Cao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInstruction tuning enhances large vision-language models (LVLMs) but increases \ntheir vulnerability to backdoor attacks due to their open design. Unlike prior studies in \nstatic settings, this paper explores backdoor attacks in LVLM instruction tuning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.pdf&hl=en&sa=X&d=5142527777954789704&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b_Zz7b9xsyiBVRqo7nDX3YO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, M Dras, U Naseem\\xc2\\xa0- arXiv preprint arXiv:2506.02442, 2025\nThis paper presents a systematic evaluation of Large Language Models'(LLMs) \nbehavior on long-tail distributed (encrypted) texts and their safety implications. We \nintroduce a two-dimensional framework for assessing LLM safety:(1) instruction\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02442&hl=en&sa=X&d=15102350404536711280&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b_4gGVOvmiHUrKGvn2E4Vhh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Evaluatiing the efficacy of LLM Safety Solutions: The Palit Benchmark Dataset", "first_label": ["LLM"], "second_label": [], "data": "S Palit, D Woods\\xc2\\xa0- arXiv preprint arXiv:2505.13028, 2025\nLarge Language Models (LLMs) are increasingly integrated into critical systems in \nindustries like healthcare and finance. Users can often submit queries to LLM-\nenabled chatbots, some of which can enrich responses with information retrieved\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13028%3F&hl=en&sa=X&d=1273460049730580919&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b9ByON4eaZyjRTpM1-cA_zU&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Ip leakage attacks targeting llm-based multi-agent systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Wang, W Wang, S Wang, Z Li, Z Ji, Z Lyu, D Wu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Large Language Models (LLMs) has led to the \nemergence of Multi-Agent Systems (MAS) to perform complex tasks through \ncollaboration. However, the intricate nature of MAS, including their architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12442&hl=en&sa=X&d=8825331941370095164&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b_j6hKF2Zy8dNMOx-tobM6E&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning", "first_label": ["LLM"], "second_label": [], "data": "P Yang, Q Wang, Z Huang, T Liu, C Zhang, B Han\\xc2\\xa0- arXiv preprint arXiv:2505.11953, 2025\nLoss reweighting has shown significant benefits for machine unlearning with large \nlanguage models (LLMs). However, their exact functionalities are left unclear and the \noptimal strategy remains an open question, thus impeding the understanding and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11953%3F&hl=en&sa=X&d=10115741309441283535&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b_qGRbxQa3QaxEAOlNnGTTW&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Ripple Effect: On Unforeseen Complications of Backdoor Attacks", "first_label": [], "second_label": [], "data": "R Zhang, Y Shen, H Li, W Jiang, H Chen, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent research highlights concerns about the trustworthiness of third-party Pre-\nTrained Language Models (PTLMs) due to potential backdoor attacks. These \nbackdoored PTLMs, however, are effective only for specific pre-defined downstream\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11586&hl=en&sa=X&d=15157304470732077928&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b997v4XRj8-KVQslhBMZvqE&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "first_label": ["LLM"], "second_label": [], "data": "G Chen, F Song, Z Zhao, X Jia, Y Liu, Y Qiao, W Zhang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreak attacks to Large audio-language models (LALMs) are studied recently, but \nthey achieve suboptimal effectiveness, applicability, and practicability, particularly, \nassuming that the adversary can fully manipulate user prompts. In this work, we first\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14103&hl=en&sa=X&d=12355582258955555442&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b84twuHlVXU1hPFciKO3AfT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Securing AI Agents with Information-Flow Control", "first_label": [], "second_label": ["Agent"], "data": "M Costa, B K\\xc3\\xb6pf, A Kolluri, A Paverd, M Russinovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI agents become increasingly autonomous and capable, ensuring their security \nagainst vulnerabilities such as prompt injection becomes critical. This paper explores \nthe use of information-flow control (IFC) to provide security guarantees for AI agents\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23643%3F&hl=en&sa=X&d=4534448032257376326&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b-ruPZ7fbYUs0K6HirRZr2z&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SVA-ICL: Improving LLM-based software vulnerability assessment via in-context learning and information fusion", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "C Gao, X Chen, G Zhang\\xc2\\xa0- Information and Software Technology, 2025\nContext: Software vulnerability assessment (SVA) is critical for identifying, evaluating, \nand prioritizing security weaknesses in software applications. Objective: Despite the \nincreasing application of large language models (LLMs) in various software\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.10008&hl=en&sa=X&d=1264413811272727540&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b8ALX06m_riBYkcPk3CfsTb&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents", "first_label": [], "second_label": ["Agent", "Reasoning"], "data": "X Yu, B Peng, R Xu, M Galley, H Cheng, S Nath, J Gao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent progress in reasoning with large language models (LLMs), such as \nDeepSeek-R1, demonstrates impressive capabilities in domains like mathematics \nand coding, by exhibiting complex cognitive behaviors such as verification, goal\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00320&hl=en&sa=X&d=5278749394870424961&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b9b-0jt4alWRaYfXuIUsA9R&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Understanding Software Engineering Agents Through the Lens of Traceability: An Empirical Study", "first_label": [], "second_label": ["Agent"], "data": "I Ceka, S Pujar, S Ramji, L Buratti, G Kaiser, B Ray\\xc2\\xa0- arXiv preprint arXiv:2506.08311, 2025\nWith the advent of large language models (LLMs), software engineering agents \n(SWE agents) have emerged as a powerful paradigm for automating a range of \nsoftware tasks--from code generation and repair to test case synthesis. These agents\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08311&hl=en&sa=X&d=15551141672916262062&ei=HPVNaN3dCsOr6rQPmID_oA8&scisig=AAZF9b_bf5rYaWtKTaAySzqwEBNs&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Bach Le - new related research", "David Lo - new related research", "3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Multi-source cross-domain vulnerability detection based on code pre-trained model", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "Y Cao, Y Dong\\xc2\\xa0- Information and Software Technology, 2025\nContext: In recent years, deep learning-based vulnerability detection methods have \nachieved significant success. These methods predict vulnerabilities by automatically \nlearning patterns from code annotated with vulnerability information. However\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S095058492500103X&hl=en&sa=X&d=15955544814733929240&ei=HPVNaN3dCsOr6rQPmID_oA8&scisig=AAZF9b81Qmv0jwO9frlyKQ4ruxkr&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming", "first_label": ["LLM"], "second_label": [], "data": "X Yang, Z Liu, C Huang, J Zhang, T Zhang, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWhile recent research increasingly emphasizes the value of human-LLM \ncollaboration in competitive programming and proposes numerous empirical \nmethods, a comprehensive understanding remains elusive due to the fragmented\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16667%3F&hl=en&sa=X&d=12301434090185084314&ei=HPVNaN3dCsOr6rQPmID_oA8&scisig=AAZF9b9tTvxcX5KbZYQ_r65OszA_&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "LLM Contribution Summarization in Software Projects", "first_label": ["LLM"], "second_label": [], "data": "R Corsi Ferrao, FR de Miranda, D Pavan Soler\\xc2\\xa0- arXiv e-prints, 2025\nThis full paper in innovative practice provides an automated tool to summarize \nindividual code contributions in project-based courses with external clients. Real \nindustry projects offer valuable learning opportunities by immersing students in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ui.adsabs.harvard.edu/abs/2025arXiv250517710C/abstract&hl=en&sa=X&d=2924767007286761413&ei=HPVNaKCnF_uvieoPlKmY8Ag&scisig=AAZF9b_Y1Z5q_NBLq3-QXm64AzIV&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Selective Code Generation for Functional Guarantees", "first_label": ["Code"], "second_label": ["Generation"], "data": "J Jeong, T Kim, S Park\\xc2\\xa0- arXiv preprint arXiv:2505.13553, 2025\nLarge language models (LLMs) show human-level performance and their \nspecialized descendants, code generation models, play core roles in solving \ncomplex tasks, including mathematical reasoning and software development. On the\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13553%3F&hl=en&sa=X&d=10618887701165566141&ei=HPVNaKCnF_uvieoPlKmY8Ag&scisig=AAZF9b_uNrZGuMhLrQI8_eSOoX4J&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "FuzzCode: Code Large Language Model-Based Fuzz Testing for Industrial IoT Programs", "first_label": ["LLM", "Fuzzing", "Code", "Software Testing"], "second_label": [], "data": "L Yang, C Wei, J Yang, W Xia, Y Yang, Y Luo, D Niyato\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Internet of Things\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFuzz testing is an dynamic program analysis technique designed for discovering \nvulnerabilities in IoT systems. The core goal is to deliberately feed maliciously crafted \ninputs into an IoT device or service, triggering vulnerabilities such as system crashes\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11028927/&hl=en&sa=X&d=8104462651931100859&ei=HPVNaLXfGL2W6rQP-8qayAk&scisig=AAZF9b8NEppCb0nwiT9UFTmtv4yr&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Go Source Code Vulnerability Detection Method Based on Graph Neural Network", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection", "Graph"], "data": "L Yuan, Y Fang, Q Zhang, Z Liu, Y Xu\\xc2\\xa0- Applied Sciences, 2025\nWith the widespread application of the Go language, the demand for vulnerability \ndetection in Go programs is increasing. Existing detection models and methods have \ndeficiencies in extracting source code features of Go programs and mainly focus on\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2076-3417/15/12/6524&hl=en&sa=X&d=1520445956479606427&ei=HPVNaLXfGL2W6rQP-8qayAk&scisig=AAZF9b-uiS-nVflS0tUcia7Ts2wb&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Boosting Rust Unit Test Coverage through Hybrid Program Analysis and Large Language Models", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "B Chu, Y Feng, K Liu, H Shi, Z Nan, Z Guo, B Xu\\xc2\\xa0- arXiv preprint arXiv:2506.09002, 2025\nUnit testing is essential for ensuring software reliability and correctness. Classic \nSearch-Based Software Testing (SBST) methods and concolic execution-based \napproaches for generating unit tests often fail to achieve high coverage due to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09002&hl=en&sa=X&d=14169512283310140838&ei=HPVNaLXfGL2W6rQP-8qayAk&scisig=AAZF9b_gp7PsvepNWNWQE1trZg2v&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Boosting symbolic execution for vulnerability detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "H TU - 2025\nSoftware systems written by humans tend to be unreliable and insecure, hence bugs \nor vulnerabilities in them are inevitable. Symbolic execution has shown considerable \npotential in detecting diverse types of software bugs and also vulnerabilities that\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ink.library.smu.edu.sg/cgi/viewcontent.cgi%3Farticle%3D1702%26context%3Detd_coll&hl=en&sa=X&d=3920640297285392836&ei=HPVNaLXfGL2W6rQP-8qayAk&scisig=AAZF9b_cpEXSZl5wcaWni5FjQSLY&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Zheng, X Qian, H Zhou, S Yang, Y He, S Jana\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models (LMs) show promise for vulnerability detection but struggle with \nlong, real-world code due to sparse and uncertain vulnerability locations. These \nissues, exacerbated by token limits, often cause models to miss vulnerability-related\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17460&hl=en&sa=X&d=9334848497739178959&ei=HPVNaPGdCffWieoPkIfZ2Q8&scisig=AAZF9b_EDz61GJXVBfE-c2mGro5g&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Using Large Language Models for Aerospace Code Generation: Methods, Benchmarks, and Potential Values", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "R He, L Zhang, M Lyu, L Lyu, C Xue\\xc2\\xa0- Aerospace, 2025\nIn recent years, Large Language Models (LLMs) have witnessed rapid \nadvancements, revolutionizing various domains. Within the realm of software \ndevelopment, code generation technology powered by LLMs has emerged as a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2226-4310/12/6/498&hl=en&sa=X&d=10774117724622108555&ei=HPVNaPCRD8y8ieoP6KaDYQ&scisig=AAZF9b_rdKO7Y_152Nx4dsGU87hA&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A File-Statement Approach for Bug Localization: Optimizing IRBL and Combination Strategy", "first_label": ["Bug"], "second_label": ["Localization"], "data": "Z Guo, X Xu, X Chen, C Geng\\xc2\\xa0- IEEE Access, 2025\nOne of the main objectives of software testing is to locate the position of bugs. Bug \nlocalization is generally categorized into statement-level and file-level localization. \nFile-level bug localization is typically performed using information retrieval-based\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11028032.pdf&hl=en&sa=X&d=3135869785806186788&ei=HPVNaPCRD8y8ieoP6KaDYQ&scisig=AAZF9b-RHaCL_MTzyWKVQP6ob0pX&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Differences between Neurodivergent and Neurotypical Software Engineers: Analyzing the 2022 Stack Overflow Survey", "first_label": [], "second_label": [], "data": "P Verma, MV Cruz, G Liebel\\xc2\\xa0- arXiv preprint arXiv:2506.03840, 2025\nNeurodiversity describes variation in brain function among people, including \ncommon conditions such as Autism spectrum disorder (ASD), Attention deficit \nhyperactivity disorder (ADHD), and dyslexia. While Software Engineering (SE)\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03840&hl=en&sa=X&d=17371332141025912649&ei=HPVNaPCRD8y8ieoP6KaDYQ&scisig=AAZF9b_KDLc1Jt-BJLnmOipanZpT&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Chaos Engineering in the Wild: Findings from GitHub", "first_label": [], "second_label": [], "data": "J Owotogbe, I Kumara, D Di Nucci, DA Tamburri\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nChaos engineering aims to improve the resilience of software systems by \nintentionally injecting faults to identify and address system weaknesses that cause \noutages in production environments. Although many tools for chaos engineering\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13654&hl=en&sa=X&d=4195159524352258371&ei=HPVNaPCRD8y8ieoP6KaDYQ&scisig=AAZF9b_WRW9pwu6TVrg6WbqMqMx8&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Design Patterns for Securing LLM Agents against Prompt Injections", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Beurer-Kellner, BBAM Cre\\xc5\\xa3u, E Debenedetti\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI agents powered by Large Language Models (LLMs) become increasingly \nversatile and capable of addressing a broad spectrum of tasks, ensuring their \nsecurity has become a critical challenge. Among the most pressing threats are\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/abs/2506.08837&hl=en&sa=X&d=2124308329893910985&ei=HPVNaPCRD8y8ieoP6KaDYQ&scisig=AAZF9b_aF8Go0WFp_k9j_u4oGfds&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Which Prompting Technique Should I Use? An Empirical Investigation of Prompting Techniques for Software Engineering Tasks", "first_label": [], "second_label": [], "data": "EG Santana Jr, G Benjamin, M Araujo, H Santos\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nA growing variety of prompt engineering techniques has been proposed for Large \nLanguage Models (LLMs), yet systematic evaluation of each technique on individual \nsoftware engineering (SE) tasks remains underexplored. In this study, we present a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05614&hl=en&sa=X&d=4559781597299000274&ei=HPVNaPCRD8y8ieoP6KaDYQ&scisig=AAZF9b_AF-dA0y6FLiHUrH36iEtZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Visualization Task Taxonomy to Understand the Fuzzing Internals", "first_label": ["Fuzzing"], "second_label": [], "data": "S Kummita, M Miao, E Bodden, S Wei\\xc2\\xa0- ACM Transactions on Software Engineering\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGreybox fuzzing is used extensively in research and practice. There are umpteen \npublications that improve greybox fuzzing. However, to what extent do these \nimprovements affect the internal components or internals of a given fuzzer is not yet\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3718346&hl=en&sa=X&d=6310038100822609560&ei=HPVNaKGtE6alieoPsZriwAs&scisig=AAZF9b_Ue_jmzHRI425oDGHolQub&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "KRAKEN: Program-Adaptive Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A ZHOU, H HUANG, C ZHANG - 2025\nDespite numerous advances, most existing fuzzers still require more than 24 hours to \nthoroughly test the target programs to achieve satisfactory code coverage or bug \ndetection results [7, 32, 42, 64]. Recently, as cloud-based computing and multicore\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://seviezhou.github.io/files/kraken.pdf&hl=en&sa=X&d=6944396394299119143&ei=HPVNaKGtE6alieoPsZriwAs&scisig=AAZF9b9QILhkfV1b1x87AW8NkoEo&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Systematic exploration of fuzzing in IoT: techniques, vulnerabilities, and open challenges", "first_label": ["Vulnerabilities", "Fuzzing"], "second_label": [], "data": "A Touqir, F Iradat, W Iqbal, A Rakib, N Taskin\\xe2\\x80\\xa6\\xc2\\xa0- The Journal of\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs our dependence on the internet and digital platforms grows, the risk of cyber \nthreats rises, making it essential to implement effective measures to safeguard \nsensitive information through cybersecurity, ensure system integrity, and prevent\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11227-025-07371-y&hl=en&sa=X&d=6083537071761720509&ei=HPVNaKGtE6alieoPsZriwAs&scisig=AAZF9b9_2tGbhprfWVgY0gWilcYB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Bridging the Gap between Hardware Fuzzing and Industrial Verification", "first_label": ["Verification", "Fuzzing"], "second_label": [], "data": "R Ma, T Wei, J Zhang, C Yang, J Yi, G Luo\\xc2\\xa0- arXiv preprint arXiv:2506.00461, 2025\nAs hardware design complexity increases, hardware fuzzing emerges as a promising \ntool for automating the verification process. However, a significant gap still exists \nbefore it can be applied in industry. This paper aims to summarize the current\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00461&hl=en&sa=X&d=14385885432995434427&ei=HPVNaKGtE6alieoPsZriwAs&scisig=AAZF9b9ExAQfYB5BQiwy0_OZzW8C&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Dynamic Mitigation of RESTful Service Failures Using LLMs", "first_label": ["LLM"], "second_label": [], "data": "S Salva, J Sue\nThis paper presents a novel self-healing approach for RESTful services, leveraging \nthe capabilities of large language models (LLMs) to generate source code that \nimplement fine-grained mitigations. The proposed solution introduces 18 healing \noperators tailored for RESTful services, accommodating both grey-box and black-box \nperspectives. These operators implement a dual-mitigation strategy. The first \nmitigation employs encapsulation techniques, enabling dynamic service adaptation\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://perso.limos.fr/~sesalva/publication/icsoft25/icsoft25.pdf&hl=en&sa=X&d=1091410930778564032&ei=HPVNaPTUENSWieoP89D1uAI&scisig=AAZF9b_2KnIffn6-QuaGJNSdTjFl&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Fuzzing Test Data Generation Technique to Cyber-Physical System by Exploring Token Tree", "first_label": ["Fuzzing", "Software Testing"], "second_label": ["Generation"], "data": "I Shin\\xc2\\xa0- Journal of Internet of Things and Convergence, 2025\nAbstract The Korea Internet of Things Society. In particular, Internet of Things (IoTs) \ndevices, which are composed of Cyber Physical Systems (CPS), which combine \ncyber systems and physical systems, have a greater impact from potential \nvulnerabilities than other Information Technologies (IT) systems due to their \ncharacteristics of operating in public places. Therefore, fuzzing tests are useful as a \ntool for improving security by identifying vulnerabilities in such IoT devices and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAFLNet: a greybox fuzzer for network protocols\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://koreascience.kr/article/JAKO202516236003159.pdf&hl=en&sa=X&d=3240172125295905899&ei=HPVNaPTUENSWieoP89D1uAI&scisig=AAZF9b8xnC6fyDwn1T9PyGo1ixcD&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Implementing undetectable backdoor attacks in AI models", "first_label": [], "second_label": [], "data": "TT van Harskamp, SS Picek, LL Batina - 2025\nIn this thesis we describe different ways of planting undetectable backdoors in AI \nmodels. The notion of an undetectable backdoor can differ, so we will look at both so-\ncalled black-box and white-box undetectable backdoors. We focus mostly on the \npractical implementation of these backdoors. We show the implementation of two \nblack-box and two white-box undetectable backdoors. The two black-box \nundetectable backdoors use the RSA and Unbalanced Oil and Vinegar signature\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaStealthy backdoor attack for code models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.cs.ru.nl/masters-theses/2025/T_van_Harskamp___Implementing_undetectable_backdoor_attacks_in_AI_models.pdf&hl=en&sa=X&d=14043002036521238704&ei=HPVNaLKTDIOuieoPg4C8kAY&scisig=AAZF9b8xodwfbCZ1lc4ibSHqDdPw&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang"]}
{"title": "Pattern-Based Graph Classification: Comparison of Quality Measures and Importance of Preprocessing", "first_label": [], "second_label": ["Graph"], "data": "L Potin, R Figueiredo, V Labatut, C Largeron\\xc2\\xa0- ACM Transactions on Knowledge\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGraph classification aims to categorize graphs based on their structural and attribute \nfeatures, with applications in diverse fields such as social network analysis and \nbioinformatics. Among the methods proposed to solve this task, those relying on \npatterns (ie subgraphs) provide good explainability, as the patterns used for \nclassification can be directly interpreted. To identify meaningful patterns, a standard \napproach is to use a quality measure, ie a function that evaluates the discriminative\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaActive learning of discriminative subgraph patterns for api misuse\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3743143&hl=en&sa=X&d=1589827619687434893&ei=HPVNaLKTDIOuieoPg4C8kAY&scisig=AAZF9b8Ir3rVvWnaQSKIUZoewoqR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang"]}
{"title": "LLMs as Evaluators: A Novel Approach to Commit Message Quality Assessment", "first_label": ["LLM", "Commit Message"], "second_label": [], "data": "A Kumar, S Sankar, S Haiduc, PP Das, PP Chakrabarti\\xc2\\xa0- 2025 IEEE/ACM 47th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nEvaluating the quality of commit messages is a challenging task in software \nengineering. Existing evaluation approaches, such as automatic metrics like BLEU, \nROUGE and METEOR, as well as manual human assessments have notable \nlimitations. Automatic metrics often overlook semantic relevance and context, while \nhuman evaluations are time consuming and costly. To address these challenges, we \nexplore the potential of using Large Language Models (LLMs) as an alternative\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCc2vec: Distributed representations of code changes\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11023957/&hl=en&sa=X&d=9472711919149824888&ei=HPVNaLKTDIOuieoPg4C8kAY&scisig=AAZF9b-Nwmxk5n7wb9Zz0DkMudxO&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang"]}
{"title": "DockInsight: A Knowledge-Augmented Dependency Extraction Approach for Dockerfile", "first_label": [], "second_label": [], "data": "Z Zhu, T Chen, Y Zhong, Q Song\\xc2\\xa0- 2025 IEEE/ACM 22nd International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDevOps enhances software production through IT automation, continuous \nintegration, and deployment, with Docker as a key tool that packages applications \nand their environments into standardized images for consistent and efficient \ndeployment. Dockerfiles, which are text-based configuration files, define the \ncomposition and runtime actions of these images. Mismanagement of dependencies \nbetween Dockerfile instructions can cause build failures, highlighting the need for\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDockercleaner: Automatic repair of security smells in dockerfiles\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11024505/&hl=en&sa=X&d=5013678824898105456&ei=HPVNaMXIDdGM6rQP7_O2WA&scisig=AAZF9b8vSs841lxLIysaljFAk4Pf&oi=scholaralrt&hist=ylyK0_8AAAAJ:5615766320347152220:AAZF9b9Qy0LEut_atU8F20t2CTM_&html=&pos=0&folt=cit", "author": ["Quang-Cuong Bui"], "ref": ["1 new citation to articles by Quang-Cuong Bui"]}
{"title": "Large Language Models for Multilingual Vulnerability Detection: How Far Are We?", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "H Shu, M Fu, J Yu, D Wang, C Tantithamthavorn\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nVarious deep learning-based approaches utilizing pre-trained language models \n(PLMs) have been proposed for automated vulnerability detection. With recent \nadvancements in large language models (LLMs), several studies have begun\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07503&hl=en&sa=X&d=16921324525434229917&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b_NVmGqeviNJG8TX3MzY9vb&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "2 new citations to articles by Xin ZHOU"]}
{"title": "Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Reasoning"], "data": "XC Wen, Y Yang, C Gao, Y Xiao, D Ye\\xc2\\xa0- arXiv preprint arXiv:2506.07390, 2025\nLarge language models (LLMs) demonstrate considerable proficiency in numerous \ncoding-related tasks; however, their capabilities in detecting software vulnerabilities \nremain limited. This limitation primarily stems from two factors:(1) the absence of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07390&hl=en&sa=X&d=10299031030894150274&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b8vcpW_SfG5zRJX336Xr84s&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "2 new citations to articles by Xin ZHOU"]}
{"title": "UCP: a unified framework for code generation with pseudocode-based multi-task learning and reinforcement alignment", "first_label": ["Code"], "second_label": ["Generation"], "data": "Y Wen, Z Cui, Y Liu, Z Zhang, J Zhou, L Tang\\xc2\\xa0- The Journal of Supercomputing, 2025\nPre-trained large language models (LLMs) have been widely applied to natural \nlanguage-based code generation. However, because code generation tasks are \nhighly sensitive to structured information and exhibit diverse logical forms, directly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11227-025-07487-1&hl=en&sa=X&d=264978427275781755&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b8HnhQLRB1NFzaWU0iyGBfI&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research", "Bach Le - new related research"]}
{"title": "Adversarial Attack Classification and Robustness Testing for Large Language Models for Code", "first_label": ["LLM", "Code", "Software Testing"], "second_label": [], "data": "Y Liu, A Foundjem, F Khomh, H Li\\xc2\\xa0- arXiv preprint arXiv:2506.07942, 2025\nLarge Language Models (LLMs) have become vital tools in software development \ntasks such as code generation, completion, and analysis. As their integration into \nworkflows deepens, ensuring robustness against vulnerabilities especially those\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07942&hl=en&sa=X&d=10411796502631711196&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b-eMQpfZUdxJwBqS5XD673H&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation", "Reasoning"], "data": "C Deng, YD Tsai, GT Liu, Z Yu, H Ren\\xc2\\xa0- arXiv preprint arXiv:2506.05566, 2025\nRecent advances in large language models (LLMs) have enabled near-human \nperformance on software coding benchmarks, but their effectiveness in RTL code \ngeneration remains limited due to the scarcity of high-quality training data. While\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05566&hl=en&sa=X&d=12705396645248113526&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b_ry1MNtEw3XIAjhRirpsJ9&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Li, J Ding, C Peng, B Zhao, X Gao, H Gao, X Gu\\xc2\\xa0- arXiv preprint arXiv:2506.05692, 2025\nThe code generation capabilities of large language models (LLMs) have emerged as \na critical dimension in evaluating their overall performance. However, prior research \nhas largely overlooked the security risks inherent in the generated code. In this work\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05692&hl=en&sa=X&d=5492650506064335063&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b_VqkMkad8wzoS_QoQNt7_G&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "Bach Le - new related research"]}
{"title": "DesignBench: A Comprehensive Benchmark for MLLM-based Front-end Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Xiao, M Wang, MH Lam, Y Wan, J Liu, Y Huo, MR Lyu\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMultimodal Large Language Models (MLLMs) have demonstrated remarkable \ncapabilities in automated front-end engineering, eg, generating UI code from visual \ndesigns. However, existing front-end UI code generation benchmarks have the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.06251&hl=en&sa=X&d=17951328836556884213&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b9zlbZwsJl10-fahiXKUBZ3&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "An LLM Agent for Functional Bug Detection in Network Protocols", "first_label": ["LLM", "Bug"], "second_label": ["Detection", "Agent"], "data": "M Zheng, C Wang, X Liu, J Guo, S Feng, X Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.00714, 2025\nFunctional correctness is critical for ensuring the reliability and security of network \nprotocol implementations. Functional bugs, instances where implementations \ndiverge from behaviors specified in RFC documents, can lead to severe\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00714&hl=en&sa=X&d=14025741833580725532&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b8vkBixnPr2fRq2ZYFDK47O&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A Framework for Creating Non-Regressive Test Cases via Branch Consistency Analysis Driven by Descriptions", "first_label": ["Software Testing"], "second_label": [], "data": "Y Zhang, P Xue, Z Yang, X Ren, X Li, L Wu, J Zhao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomated test-generation research overwhelmingly assumes the correctness of \nfocal methods, yet practitioners routinely face non-regression scenarios where the \nfocal method may be defective. A baseline evaluation of EvoSuite and two leading\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07486&hl=en&sa=X&d=12300473129148860276&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b8EYaZUm5p8en4HDg1pCFjV&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "To Protect the LLM Agent Against the Prompt Injection Attack with Polymorphic Prompt", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Z Wang, N Nagaraja, L Zhang, H Bahsi, P Patil, P Liu\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM agents are widely used as agents for customer support, content generation, and \ncode assistance. However, they are vulnerable to prompt injection attacks, where \nadversarial inputs manipulate the model's behavior. Traditional defenses like input\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05739&hl=en&sa=X&d=8621477909179484491&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b-p03ag5mevr_Qw6WxvJKN1&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Beyond Surface Similarity: Evaluating LLM-Based Test Refactorings with Structural and Semantic Awareness", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "WC Ou\\xc3\\xa9draogo, Y Li, X Dang, X Zhou, A Koyuncu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly employed to automatically refactor \nunit tests, aiming to enhance readability, naming, and structural clarity while \npreserving functional behavior. However, evaluating such refactorings remains\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.06767&hl=en&sa=X&d=6563163690120506226&ei=qkVMaM3lMKalieoP4J3H2A8&scisig=AAZF9b9xD9hAdx6dPyiL2w3mENFA&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Neuro-Symbolic Reinforcement Learning for Context-Aware Decision Making in Safe Autonomous Vehicles", "first_label": [], "second_label": [], "data": "P Muniyandy, TDYAB El, DDNPD Ebiary\nAutonomous vehicles need to be equipped with smart, understandable, and context-\naware decision-making frameworks to drive safely within crowded environments. \nCurrent deep learning approaches tend to generalize poorly, lack transparency, and \nperform inadequately in dealing with uncertainty within dynamic city environments. \nTowards overcoming these deficiencies, this study suggests a new hybrid approach \nthat combines Neuro-Symbolic reasoning with a Convolutional Neural Network\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSurveying neuro-symbolic approaches for reliable artificial\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Janjhyam-Ramesh/publication/392377131_Neuro-Symbolic_Reinforcement_Learning_for_Context-Aware_Decision_Making_in_Safe_Autonomous_Vehicles/links/6847abd6df0e3f544f5dee53/Neuro-Symbolic-Reinforcement-Learning-for-Context-Aware-Decision-Making-in-Safe-Autonomous-Vehicles.pdf&hl=en&sa=X&d=4583605719457932112&ei=qkVMaI6uMr2W6rQPjI6v-QY&scisig=AAZF9b9r5v_YzoexIy5EAyH_B1m5&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["1 new citation to articles by Hong Jin Kang"]}
{"title": "Deployability-Centric Infrastructure-as-Code Generation: An LLM-based Iterative Framework", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "T Zhang, S Pan, Z Zhang, Z Xing, X Sun\\xc2\\xa0- arXiv preprint arXiv:2506.05623, 2025\nInfrastructure-as-Code (IaC) generation holds significant promise for automating \ncloud infrastructure provisioning. Recent advances in Large Language Models \n(LLMs) present a promising opportunity to democratize IaC development by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05623&hl=en&sa=X&d=4489224540223539289&ei=q0VMaMKVAYqIieoPrumR8AU&scisig=AAZF9b8IIvUBCWLOE3kaL0BXAX6G&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "IntenTest: Stress Testing for Intent Integrity in API-Calling LLM Agents", "first_label": ["LLM", "Software Testing"], "second_label": ["Agent"], "data": "S Feng, X Xu, X Chen, K Zhang, SY Ahmed, Z Su\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM agents are increasingly deployed to automate real-world tasks by invoking APIs \nthrough natural language instructions. While powerful, they often suffer from \nmisinterpretation of user intent, leading to the agent's actions that diverge from the \nuser's intended goal, especially as external toolkits evolve. Traditional software \ntesting assumes structured inputs and thus falls short in handling the ambiguity of \nnatural language. We introduce IntenTest, an API-centric stress testing framework\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07524&hl=en&sa=X&d=5483501088938509317&ei=qkVMaI-sL-Ws6rQPpf7X-Aw&scisig=AAZF9b8ToxhJhlHy6Z6YJ25UePxA&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang", "6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Information-Theoretic Detection of Unusual Source Code Changes", "first_label": ["Code", "Code Change"], "second_label": ["Detection"], "data": "A Torres, S Baltes, C Treude, M Wagner\\xc2\\xa0- arXiv preprint arXiv:2506.06508, 2025\nThe code base of software projects evolves essentially through inserting and \nremoving information to and from the source code. We can measure this evolution \nvia the elements of information-tokens, words, nodes-of the respective representation\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.06508&hl=en&sa=X&d=16408897699757615593&ei=q0VMaMz3Asy8ieoP89mfwQY&scisig=AAZF9b9hxGcjnj0zZ77CRsYy74NR&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Exploring Fine-Grained Bug Report Categorization with Large Language Models and Prompt Engineering: An Empirical Study", "first_label": ["LLM", "Bug"], "second_label": [], "data": "A Koyuncu\\xc2\\xa0- ACM Transactions on Software Engineering and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAccurate classification of issues is essential for effective project management and \ntimely responses, as the volume of issue reports continues to grow. Manual \nclassification is labor-intensive and error-prone, necessitating automated solutions\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3736408&hl=en&sa=X&d=1221326668322558367&ei=q0VMaMz3Asy8ieoP89mfwQY&scisig=AAZF9b94qGcVVVtNwHBRf1PSh6nk&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Dynamic graph contrastive learning based on learnable view generators", "first_label": [], "second_label": ["Graph"], "data": "M Zhu, L Qiu, W Zhao\\xc2\\xa0- Knowledge-Based Systems, 2025\nDynamic graph representation learning aims to capture graphs' evolving structure \nand properties by learning embedded representations of nodes and edges over time. \nGraph self-supervised learning, particularly graph contrastive learning, has garnered \nsignificant attention recently. However, existing dynamic graph contrastive learning \nmethods are vulnerable to data distribution imbalances, leading to model overfitting \non active nodes and edges, and they are also prone to capturing meaningless\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaToward the analysis of graph neural networks\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950705125008913&hl=en&sa=X&d=10908481830653854755&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b9MycfNw-D9zP9uf2FqAtGZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le", "1 new citation to articles by Thanh Le-Cong"]}
{"title": "Decentralized certificate issuance and verification system using Ethereum blockchain technology", "first_label": ["Verification", "Ethereum", "Blockchain"], "second_label": [], "data": "TR Sree\\xc2\\xa0- Journal of Network and Computer Applications, 2025\nThe increasing prevalence of fraudulent and inefficient centralized certificate systems \nposes significant challenges across various sectors, undermining trust and hindering \nefficient verification processes. This paper aims to overcome these difficulties by \noffering a decentralized certificate issuance and verification system based on \nEthereum blockchain technology and Goerli testnet. It is developed to provide a \nreliable and transparent way to create and validate credentials in various industries\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1084804525000876&hl=en&sa=X&d=15636684545320754745&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b_IC195LBTc1nY7SaUriyQu&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "Cybersecurity Challenges in Blockchain-Based Accounting Systems", "first_label": ["Blockchain"], "second_label": [], "data": "AL Paul\nBlockchain technology has emerged as a transformative force in the realm of digital \naccounting, promising transparency, immutability, and decentralized verification. As \naccounting systems increasingly migrate to blockchain-based infrastructures, they \nencounter a new class of cybersecurity threats. While blockchain offers improved \ntrust and integrity of financial records, it is not impervious to vulnerabilities. This \npaper explores the primary cybersecurity challenges in blockchain-based accounting\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Anthony-Paul-2/publication/392519552_Cybersecurity_Challenges_in_Blockchain-Based_Accounting_Systems/links/6846c8d6df0e3f544f5dbbf1/Cybersecurity-Challenges-in-Blockchain-Based-Accounting-Systems.pdf&hl=en&sa=X&d=14753631704336139104&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b8-We9Baae8zAtvYnbluxur&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "The Influence of Digital Governance Tools on Public Investment Strategies", "first_label": [], "second_label": [], "data": "AL Paul\nDigital governance tools have increasingly become critical instruments in shaping \nand optimizing public investment strategies globally. This paper examines how \ndigital platforms, data analytics, blockchain technology, and e-governance systems \ninfluence decision-making, transparency, efficiency, and accountability in public \ninvestment. By integrating case studies and empirical data, this study highlights the \ntransformative impact of digital governance on public sector financial planning and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Anthony-Paul-2/publication/392519391_The_Influence_of_Digital_Governance_Tools_on_Public_Investment_Strategies/links/6846cb07d1054b0207fac047/The-Influence-of-Digital-Governance-Tools-on-Public-Investment-Strategies.pdf&hl=en&sa=X&d=14107208868790362796&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b-FOaezUIcBesA_xcD22LX-&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=3&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "Digital Twins in Auditing: A Technological Leap for Real-Time Financial Monitoring", "first_label": [], "second_label": [], "data": "AL Paul\nThe auditing profession is undergoing a transformative shift driven by rapid \nadvancements in digital technologies. Digital twin technology, a virtual \nrepresentation of physical systems that updates in real-time, is emerging as a \npromising innovation to enhance auditing processes, particularly in financial \nmonitoring. This paper explores the potential of digital twins to revolutionize auditing \nby enabling continuous, real-time oversight of financial data, thereby improving the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Anthony-Paul-2/publication/392519545_Digital_Twins_in_Auditing_A_Technological_Leap_for_Real-Time_Financial_Monitoring/links/6846c806df0e3f544f5dbbdc/Digital-Twins-in-Auditing-A-Technological-Leap-for-Real-Time-Financial-Monitoring.pdf&hl=en&sa=X&d=25655615642885322&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b_zUlFTE6Q31iPStek7j4o3&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=4&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "Technological Innovations and Their Role in Enhancing Transparency in Public Sector Budgeting", "first_label": [], "second_label": [], "data": "AL Paul\nTransparency in public sector budgeting is critical for accountable governance, \nefficient resource allocation, and strengthening public trust. Technological \ninnovations, especially digital tools and systems, have increasingly become pivotal \nin transforming public budgeting processes by improving openness, accuracy, and \ncitizen engagement. This paper explores the range of technological innovations \nshaping transparency in public sector budgeting, including blockchain, big data\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Anthony-Paul-2/publication/392519205_Technological_Innovations_and_Their_Role_in_Enhancing_Transparency_in_Public_Sector_Budgeting/links/6846c995d1054b0207fabfea/Technological-Innovations-and-Their-Role-in-Enhancing-Transparency-in-Public-Sector-Budgeting.pdf&hl=en&sa=X&d=7642411289453450086&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b8iCzXCAeUdcHC1uN1WHAWu&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=5&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "The Integration of Robotic Process Automation (RPA) in Corporate Accounting: Efficiency vs. Compliance", "first_label": [], "second_label": [], "data": "AL Paul\nAbstract Robotic Process Automation (RPA) has become a transformative force in \ncorporate accounting, enabling organizations to enhance operational efficiency by \nautomating repetitive and rule-based tasks. While RPA promises significant benefits \nsuch as cost savings, improved accuracy, and faster processing times, its integration \nraises important compliance and governance concerns. This article examines the \ndual impact of RPA on corporate accounting, analyzing how firms can leverage\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Anthony-Paul-2/publication/392519398_The_Integration_of_Robotic_Process_Automation_RPA_in_Corporate_Accounting_Efficiency_vs_Compliance/links/6846cd158a76251f22ec69b3/The-Integration-of-Robotic-Process-Automation-RPA-in-Corporate-Accounting-Efficiency-vs-Compliance.pdf&hl=en&sa=X&d=8575867070192944103&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b8V9d_IBbaiXJf07fpd1JcJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=6&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "Auditing in the Age of the Metaverse: Challenges and Opportunities", "first_label": [], "second_label": [], "data": "R Ajax\nThe emergence of the Metaverse\\xe2\\x80\\x94a convergence of immersive technologies, \ndecentralized digital platforms, and virtual economies\\xe2\\x80\\x94is redefining the landscape \nof corporate operations, financial transactions, and regulatory oversight. As \nbusinesses increasingly engage in virtual real estate, digital assets, and \nblockchainenabled ecosystems, the auditing profession faces an inflection point. \nThis paper explores the transformative impact of the Metaverse on auditing, focusing\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Raymond-Ajax/publication/392519430_Auditing_in_the_Age_of_the_Metaverse_Challenges_and_Opportunities/links/6846c6b6df0e3f544f5dbbb7/Auditing-in-the-Age-of-the-Metaverse-Challenges-and-Opportunities.pdf&hl=en&sa=X&d=11506361248134588570&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b-mtpSvDOOTIUcEC1MV0xot&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=7&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "Blockchain Technology and Its Impact on Investor Behavior and Market Sensitivity", "first_label": ["Blockchain"], "second_label": [], "data": "R Ajax\nBlockchain technology, as a decentralized and distributed ledger system, has rapidly \nevolved from a niche innovation underpinning cryptocurrencies to a disruptive force \nreshaping global financial markets. This paper critically examines the extensive \nimpact of blockchain on investor behavior and market sensitivity by integrating \ninsights from behavioral finance, market microstructure, and emerging blockchain \napplications. Blockchain's core attributes\\xe2\\x80\\x94transparency, immutability, and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Raymond-Ajax/publication/392519192_Blockchain_Technology_and_Its_Impact_on_Investor_Behavior_and_Market_Sensitivity/links/6846c584d1054b0207fabf42/Blockchain-Technology-and-Its-Impact-on-Investor-Behavior-and-Market-Sensitivity.pdf&hl=en&sa=X&d=4598368271639172027&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b_pm_uXqNI9sZnvTgnxWeym&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=8&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "Assessing the Impact of FinTech Innovations on Private and Public Investment Sensitivity", "first_label": [], "second_label": [], "data": "R Ajax\nThe accelerating rise of Financial Technology (FinTech) has introduced \ntransformative changes across global financial markets, impacting how both private \nentities and public institutions make investment decisions. This research investigates \nthe extent to which FinTech innovations\\xe2\\x80\\x94such as blockchain, peer-to-peer lending, \ndigital advisory services, and decentralized finance\\xe2\\x80\\x94affect the sensitivity of private \nand public investments to macroeconomic indicators, including interest rates\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Raymond-Ajax/publication/392518908_Assessing_the_Impact_of_FinTech_Innovations_on_Private_and_Public_Investment_Sensitivity/links/6846c485df0e3f544f5dbb78/Assessing-the-Impact-of-FinTech-Innovations-on-Private-and-Public-Investment-Sensitivity.pdf&hl=en&sa=X&d=13839664669455761442&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b_0KX6ScY2YVXBqXIPDhk-z&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=9&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "Agent4Vul: multimodal LLM agents for smart contract vulnerability detection", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection", "Agent"], "data": "W Jie, W Qiu, H Yang, M Guo, X Huang, T Lei, Q Zhang\\xe2\\x80\\xa6\\xc2\\xa0- Science China Information\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSmart contract vulnerabilities have emerged as a significant threat to blockchain \nsystem security under the Web 3.0 ecosystem. According to recent research, large \nlanguage models (LLMs) have demonstrated immense potential in smart contract\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=http://scis.scichina.com/en/2025/160101.pdf&hl=en&sa=X&d=2236818715129249300&ei=qkVMaLKoOL_N6rQPzuHnkAg&scisig=AAZF9b8B05xE_kt2qfr8AdX4qU1X&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=3&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Evaluating LLMs Effectiveness in Detecting and Correcting Test Smells: An Empirical Study", "first_label": ["LLM", "Software Testing"], "second_label": ["Detection"], "data": "EG Santana Jr, JPS Junior, EP Almeida, I Ahmed\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nTest smells indicate poor development practices in test code, reducing \nmaintainability and reliability. While developers often struggle to prevent or refactor \nthese issues, existing tools focus primarily on detection rather than automated\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07594&hl=en&sa=X&d=9420305687673894867&ei=qkVMaLKoOL_N6rQPzuHnkAg&scisig=AAZF9b9BvLiiGG9H_DI2P6brMLCH&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=5&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "SWE-Dev: Building Software Engineering Agents with Training and Inference Scaling", "first_label": [], "second_label": ["Agent"], "data": "H Wang, Z Hou, Y Wei, J Tang, Y Dong\\xc2\\xa0- arXiv preprint arXiv:2506.07636, 2025\nLarge language models (LLMs) have advanced rapidly from conversational problem \nsolving to addressing real-world tasks involving tool use, such as software \nengineering (SWE). Recent LLM-powered toolkits, such as OpenAI Codex and \nCursor, have offered end-to-end automation of the software development process. \nHowever, building effective SWE agents remains challenging due to the lack of high-\nquality training data and effective test cases. To address this issue, we present SWE\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07636&hl=en&sa=X&d=11131145750035336718&ei=qkVMaNPwNqKr6rQPlpCs6Q0&scisig=AAZF9b-KipotiAFWL0ISr76hyMZy&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research"]}
{"title": "CP-Bench: Evaluating Large Language Models for Constraint Modelling", "first_label": ["LLM"], "second_label": [], "data": "K Michailidis, D Tsouros, T Guns\\xc2\\xa0- arXiv preprint arXiv:2506.06052, 2025\nCombinatorial problems are present in a wide range of industries. Constraint \nProgramming (CP) is a well-suited problem-solving paradigm, but its core process, \nnamely constraint modelling, is a bottleneck for wider adoption. Aiming to alleviate \nthis bottleneck, recent studies have explored using Large Language Models (LLMs) \nas modelling assistants, transforming combinatorial problem descriptions to \nexecutable constraint models, similar to coding assistants. However, the existing\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.06052&hl=en&sa=X&d=6142141515041502582&ei=qkVMaNPwNqKr6rQPlpCs6Q0&scisig=AAZF9b_8uOW0NJbL4CH57_toiNGB&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Does It Run and Is That Enough? Revisiting Text-to-Chart Generation with a Multi-Agent Approach", "first_label": [], "second_label": ["Generation", "Agent"], "data": "J Ford, A Rios\\xc2\\xa0- arXiv preprint arXiv:2506.06175, 2025\nLarge language models can translate natural-language chart descriptions into \nrunnable code, yet approximately 15\\\\% of the generated scripts still fail to execute, \neven after supervised fine-tuning and reinforcement learning. We investigate \nwhether this persistent error rate stems from model limitations or from reliance on a \nsingle-prompt design. To explore this, we propose a lightweight multi-agent pipeline \nthat separates drafting, execution, repair, and judgment, using only an off-the-shelf\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.06175&hl=en&sa=X&d=8866180754591147613&ei=qkVMaNPwNqKr6rQPlpCs6Q0&scisig=AAZF9b9fHFvja6mIFZHI_GxaIfcG&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "CAFault: Enhance Fault Injection Technique in Practical Distributed Systems via Abundant Fault-Dependent Configurations.", "first_label": [], "second_label": [], "data": "Y Chen, F Ma, Y Zhou, Z Yan, Y Jiang\nTo ensure high reliability and availability, distributed systems are designed to be \nresilient to various faults in complex environments. Fault injection techniques are \ncommonly used to test whether a distributed system can correctly handle different \npotential faults. However, existing fault injection testing is typically performed under a \nfixed default configuration, overlooking the impact of varying configurations (which \ncan differ in real-world applications) on testing execution paths. This results in many\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaGreybox fuzzing of distributed systems\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=http://www.wingtecher.com/themes/WingTecherResearch/assets/papers/paper_from_25/CAFault_ATC25.pdf&hl=en&sa=X&d=2762221814591141395&ei=qkVMaNPwNqKr6rQPlpCs6Q0&scisig=AAZF9b9Uh0jF7NeR0Ohy6c6j7llS&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Human Side of Smart Contract Fuzzing: An Empirical Study", "first_label": ["Smart Contracts", "Fuzzing"], "second_label": [], "data": "G Qiao, PP Paul\\xc2\\xa0- arXiv preprint arXiv:2506.07389, 2025\nSmart contract (SC) fuzzing is a critical technique for detecting vulnerabilities in \nblockchain applications. However, its adoption remains challenging for practitioners \ndue to fundamental differences between SCs and traditional software systems. In this \nstudy, we investigate the challenges practitioners face when adopting SC fuzzing \ntools by conducting an inductive content analysis of 381 GitHub issues from two \nwidely used SC fuzzers: Echidna and Foundry. Furthermore, we conducted a user\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaStateful Greybox Fuzzing\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07389&hl=en&sa=X&d=987875138291859575&ei=qkVMaNPwNqKr6rQPlpCs6Q0&scisig=AAZF9b_6teo9n12SCXA1fbQcy514&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Enhancing Graph Based Models for Automatic Program Repair", "first_label": ["APR"], "second_label": ["Repair", "Graph"], "data": "V Singh, J Srivastava\\xc2\\xa0- International Conference on Soft Computing and its\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware development teams are confronted with substantial problems when it \ncomes to software flaws, which can result in reduced user experience, compromised \nsecurity, and lower reliability. For software systems to be robust and mitigated\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-88039-1_20&hl=en&sa=X&d=4498114304407797139&ei=qkVMaK_bLfiJ6rQPkqSymQY&scisig=AAZF9b9LrBdztlF3BnOO33ftE2p4&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Yuan, Y Xu, J Shi, P Zhou, L Sun\\xc2\\xa0- arXiv preprint arXiv:2505.23561, 2025\nModel merging for Large Language Models (LLMs) directly fuses the parameters of \ndifferent models finetuned on various tasks, creating a unified model for multi-domain \ntasks. However, due to potential vulnerabilities in models available on open-source\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23561&hl=en&sa=X&d=6617189016454156514&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b-hKaNf3ql6GqPXtJeaxsCC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "PandaGuard: Systematic Evaluation of LLM Safety in the Era of Jailbreaking Attacks", "first_label": ["LLM"], "second_label": [], "data": "G Shen, D Zhao, L Feng, X He, J Wang, S Shen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have achieved remarkable capabilities but remain \nvulnerable to adversarial prompts known as jailbreaks, which can bypass safety \nalignment and elicit harmful outputs. Despite growing efforts in LLM safety research\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13862&hl=en&sa=X&d=7957433049052051517&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b8uuohndjng7lcz2CFokw4p&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based Backdoor Attacks for Jailbreaking Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "J Kong, H Fang, X Yang, K Gao, B Chen, ST Xia\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSupervised fine-tuning (SFT) aligns large language models (LLMs) with human \nintent by training them on labeled task-specific data. Recent studies have shown that \nmalicious attackers can inject backdoors into these models by embedding triggers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17601%3F&hl=en&sa=X&d=14932585774719166007&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b-bRcbQ7r2VSTXuEVUTZE69&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack", "first_label": ["LLM"], "second_label": [], "data": "S Cappelletti, T Poppi, S Poppi, ZX Yong\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly evaluated on multiple-choice \nquestion answering (MCQA) tasks using* first-token probability*(FTP), which selects \nthe answer option whose initial token has the highest likelihood. While efficient, FTP\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15323%3F&hl=en&sa=X&d=5513891085179250670&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b8ts6vJnVnPKgZRZk2J59vT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Lifelong Safety Alignment for Language Models", "first_label": ["LLM"], "second_label": [], "data": "H Wang, Z Qin, Y Zhao, C Du, M Lin, X Wang, T Pang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLMs have made impressive progress, but their growing capabilities also expose \nthem to highly flexible jailbreaking attacks designed to bypass safety alignment. \nWhile many existing defenses focus on known types of attacks, it is more critical to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20259%3F&hl=en&sa=X&d=16834372085988299596&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b9d_59vHSVRWjToyCIlG2f5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "PS Pandey, S Simko, K Pelrine, Z Jin\\xc2\\xa0- arXiv preprint arXiv:2505.16789, 2025\nAs large language models gain popularity, their vulnerability to adversarial attacks \nremains a primary concern. While fine-tuning models on domain-specific datasets is \noften employed to improve model performance, it can introduce vulnerabilities within\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16789%3F&hl=en&sa=X&d=9827187220639785834&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b-hRa3CIybDfceUhaRlecWD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution", "first_label": [], "second_label": [], "data": "J Guo, X Wen, W Jiang, C Huang, J Li, H Li\\xc2\\xa0- arXiv preprint arXiv:2505.15308, 2025\nWith the widespread application of super-resolution (SR) in various fields, \nresearchers have begun to investigate its security. Previous studies have \ndemonstrated that SR models can also be subjected to backdoor attacks through\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15308&hl=en&sa=X&d=13335437674086498390&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b8WmdvUXiuzvPutlRNCBmNP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "An Embarrassingly Simple Defense Against LLM Abliteration Attacks", "first_label": ["LLM"], "second_label": [], "data": "HA Shairah, HAAK Hammoud, B Ghanem, G Turkiyyah\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are typically aligned to comply with safety guidelines \nby refusing harmful instructions. A recent attack, termed abliteration, isolates and \nsuppresses the single latent direction most responsible for refusal behavior, enabling\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19056&hl=en&sa=X&d=3737202939224050048&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b8QKV5yRTnfm0WbZVG9RAGO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Poison in the Well: Feature Embedding Disruption in Backdoor Attacks", "first_label": [], "second_label": [], "data": "Z Feng, J Chen, C Zhou, Y Pu, Q Li, S Ji\\xc2\\xa0- arXiv preprint arXiv:2505.19821, 2025\nBackdoor attacks embed malicious triggers into training data, enabling attackers to \nmanipulate neural network behavior during inference while maintaining high \naccuracy on benign inputs. However, existing backdoor attacks face limitations\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19821&hl=en&sa=X&d=8217579378668490954&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b89XZjYdu_nSk8rXx0clM5e&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Backdoor Attack on Vision Language Models with Stealthy Semantic Manipulation", "first_label": ["LLM"], "second_label": [], "data": "Z Zhong, Z Sun, Y Liu, X He, G Tao\\xc2\\xa0- arXiv preprint arXiv:2506.07214, 2025\nVision Language Models (VLMs) have shown remarkable performance, but are also \nvulnerable to backdoor attacks whereby the adversary can manipulate the model's \noutputs through hidden triggers. Prior attacks primarily rely on single-modality\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07214&hl=en&sa=X&d=13852487448298011741&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b_pfJDrPo270Aj4VCR1rEcM&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
