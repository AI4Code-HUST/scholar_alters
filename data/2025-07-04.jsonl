{"title": "TypyBench: Evaluating LLM Type Inference for Untyped Python Repositories", "first_label": ["LLM"], "second_label": [], "data": "H Dong, J Yang, X Deng, Y Jiang, G Pekhimenko\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nType inference for dynamic languages like Python is a persistent challenge in \nsoftware engineering. While large language models (LLMs) have shown promise in \ncode understanding, their type inference capabilities remain underexplored. We\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dxl9sv9vEDy&hl=en&sa=X&d=5590401666570182726&ei=5MJmaImEGaKr6rQPqZWmoQU&scisig=AAZF9b_1v2ZiYt35IkKDr0FkrnZ_&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Nemotron-CORTEXA: Enhancing LLM Agents for Software Engineering Tasks via Improved Localization and Solution Diversity", "first_label": ["LLM"], "second_label": ["Agent", "Localization"], "data": "A Sohrabizadeh, J Song, M Liu, R Roy, C Lee\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nLarge Language Models (LLMs) have demonstrated significant potential in code \ngeneration by following natural language instructions. Unfortunately, crucial real-\nworld software engineering tasks, such as debugging or repository-level feature\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dk6p8UKRdH7&hl=en&sa=X&d=951048739864022913&ei=5MJmaImEGaKr6rQPqZWmoQU&scisig=AAZF9b-H11fzuFCoL6Gk97_KnR7i&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Li, J Ding, C Peng, B Zhao, X Gao, H Gao, X Gu\\xc2\\xa0- arXiv preprint arXiv:2506.05692, 2025\nThe code generation capabilities of large language models (LLMs) have emerged as \na critical dimension in evaluating their overall performance. However, prior research \nhas largely overlooked the security risks inherent in the generated code. In this work\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05692%3F&hl=en&sa=X&d=5492650506064335063&ei=5MJmaImEGaKr6rQPqZWmoQU&scisig=AAZF9b_uwkPsOhWMHWjfdGwYFezG&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "David Lo - new related research", "Bach Le - new related research"]}
{"title": "FuzzCode: Code Large Language Model-Based Fuzz Testing for Industrial IoT Programs", "first_label": ["LLM", "Fuzzing", "Code", "Software Testing"], "second_label": [], "data": "L Yang, C Wei, J Yang, W Xia, Y Yang, Y Luo, D Niyato\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Internet of Things\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFuzz testing is an dynamic program analysis technique designed for discovering \nvulnerabilities in IoT systems. The core goal is to deliberately feed maliciously crafted \ninputs into an IoT device or service, triggering vulnerabilities such as system crashes\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11028927/&hl=en&sa=X&d=8104462651931100859&ei=5MJmaL7_JM2l6rQPh4i_0AE&scisig=AAZF9b8NEppCb0nwiT9UFTmtv4yr&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "AdaptiveLLM: A Framework for Selecting Optimal Cost-Efficient LLM for Code-Generation Based on CoT Length", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Cheng, F Liu, C Wu, L Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.10525, 2025\nWhile Large Language Models (LLMs) have significantly advanced code generation \nefficiency, they face inherent challenges in balancing performance and inference \ncosts across diverse programming tasks. Dynamically selecting the optimal LLM\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10525&hl=en&sa=X&d=12946040656504681529&ei=5MJmaL7_JM2l6rQPh4i_0AE&scisig=AAZF9b8m2TloB0C3Hd11YMxRGFIR&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Adversarial Attack Classification and Robustness Testing for Large Language Models for Code", "first_label": ["LLM", "Code", "Software Testing"], "second_label": [], "data": "Y Liu, A Foundjem, F Khomh, H Li\\xc2\\xa0- arXiv preprint arXiv:2506.07942, 2025\nLarge Language Models (LLMs) have become vital tools in software development \ntasks such as code generation, completion, and analysis. As their integration into \nworkflows deepens, ensuring robustness against vulnerabilities especially those\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07942&hl=en&sa=X&d=10411796502631711196&ei=5MJmaL7_JM2l6rQPh4i_0AE&scisig=AAZF9b-eMQpfZUdxJwBqS5XD673H&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "A First Look at Bugs in LLM Inference Engines", "first_label": ["LLM", "Bug"], "second_label": [], "data": "M Liu, S Zhong, W Bi, Y Zhang, Z Chen, Z Chen, X Liu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language model-specific inference engines (in short as\\\\emph {LLM inference \nengines}) have become a fundamental component of modern AI infrastructure, \nenabling the deployment of LLM-powered applications (LLM apps) across cloud and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09713&hl=en&sa=X&d=1829118811417287869&ei=5MJmaL7_JM2l6rQPh4i_0AE&scisig=AAZF9b9PFvonW4DF-GngDik42RDE&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Thanh Le-Cong - new related research"]}
{"title": "ZTaint-Havoc: From Havoc Mode to Zero-Execution Fuzzing-Driven Taint Inference", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Xie, W Zhang, D She\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nFuzzing is a popular software testing technique for discovering vulnerabilities. A \ncentral problem in fuzzing is identifying hot bytes that can influence program \nbehavior. Taint analysis can track the data flow of hot bytes in a white-box fashion\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728916&hl=en&sa=X&d=11807420278266769302&ei=5MJmaL7_JM2l6rQPh4i_0AE&scisig=AAZF9b8qJKOy3h08rQgyQ5y4FnqB&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Reasoning"], "data": "XC Wen, Y Yang, C Gao, Y Xiao, D Ye\\xc2\\xa0- arXiv preprint arXiv:2506.07390, 2025\nLarge language models (LLMs) demonstrate considerable proficiency in numerous \ncoding-related tasks; however, their capabilities in detecting software vulnerabilities \nremain limited. This limitation primarily stems from two factors:(1) the absence of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07390%3F&hl=en&sa=X&d=10299031030894150274&ei=5MJmaL7_JM2l6rQPh4i_0AE&scisig=AAZF9b_gI2XqGy6iUeaE4tdr-c1h&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "HPCTransCompile: An AI Compiler Generated Dataset for High-Performance CUDA Transpilation and LLM Preliminary Exploration", "first_label": ["LLM"], "second_label": [], "data": "J Lv, X He, Y Liu, X Dai, Y Hu, S Yin\\xc2\\xa0- arXiv preprint arXiv:2506.10401, 2025\nThe rapid growth of deep learning has driven exponential increases in model \nparameters and computational demands. NVIDIA GPUs and their CUDA-based \nsoftware ecosystem provide robust support for parallel computing, significantly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10401&hl=en&sa=X&d=14309937792901999617&ei=5MJmaL7_JM2l6rQPh4i_0AE&scisig=AAZF9b_LyVd5W0C0U28-mRiJrH9j&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Reductive Analysis with Compiler-Guided Large Language Models for Input-Centric Code Optimizations", "first_label": ["LLM", "Code"], "second_label": [], "data": "X Wang, X Hui, C Liao, X Shen\\xc2\\xa0- Proceedings of the ACM on Programming\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInput-centric program optimization aims to optimize code by considering the relations \nbetween program inputs and program behaviors. Despite its promise, a long-\nstanding barrier for its adoption is the difficulty of automatically identifying critical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729282&hl=en&sa=X&d=4066048552262082451&ei=5MJmaL7_JM2l6rQPh4i_0AE&scisig=AAZF9b_cHHDNeP008iH4qW9Tn7JR&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Not One to Rule Them All: Mining Meaningful Code Review Orders From GitHub", "first_label": ["Code Review", "Code"], "second_label": [], "data": "A Bouraffa, C Brandt, A Zaidmann, W Maalej\\xc2\\xa0- arXiv preprint arXiv:2506.10654, 2025\nDevelopers use tools such as GitHub pull requests to review code, discuss proposed \nchanges, and request modifications. While changed files are commonly presented in \nalphabetical order, this does not necessarily coincide with the reviewer's preferred\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10654&hl=en&sa=X&d=3992668249292818405&ei=5MJmaL7_JM2l6rQPh4i_0AE&scisig=AAZF9b9_WwY7lVF-4S1NfuqiNPEi&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Advancing Conversational Information System: Enhanced Context Understanding, Knowledge Grounding, and Synergistic Framework", "first_label": [], "second_label": [], "data": "D Yang - 2025\nThe increasing prevalence of conversational interfaces necessitates the \ndevelopment of robust Conversational Information Systems (CIS) capable of \nunderstanding context-dependent user needs and providing accurate, grounded \ninformation through interactive dialogue. However, designing effective CIS faces \nsignificant challenges, including resolving linguistic ambiguity, managing evolving \ncontext, ensuring knowledge grounding (especially with Large Language Models)\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLess is More: DocString Compression in Code Generation\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/dcd156ed838ff2fdca9a65e67f991f5c/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=en&sa=X&d=4612361548396681082&ei=5MJmaJaWIPuvieoPzc2EkQE&scisig=AAZF9b_2xTkEObkyCq5cOKzgArAP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "Comparative Analysis of Pre-trained Code Language Models for Automated Program Repair via Code Infill Generation", "first_label": ["APR", "LLM", "Code"], "second_label": ["Repair", "Generation"], "data": "I Hemati Moghadam, O Lijzenga, V Zaytsev\\xc2\\xa0- Proceedings of the 24th ACM SIGPLAN\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomated Program Repair (APR) has advanced significantly with the emergence of \npre-trained Code Language Models (CLMs), enabling the generation of high-quality \npatches. However, selecting the most suitable CLM for APR remains challenging due \nto a range of factors, including accuracy, efficiency, and scalability, among others. \nThese factors are interdependent and interact in complex ways, making the selection \nof a CLM for APR a multifaceted problem. This study systematically evaluates 20 pre\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection and repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3742876.3742881&hl=en&sa=X&d=11951497710352161825&ei=5MJmaJaWIPuvieoPzc2EkQE&scisig=AAZF9b9-BqtiHspvo0wtqxVHXHXZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU", "4 new citations to articles by Abhik Roychoudhury"]}
{"title": "RIMFuzz: real-time impact-aware mutation for library API fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "X Wang, L Zhao\\xc2\\xa0- Journal of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs libraries merely expose APIs to developers rather than directly handling user \ninput, applying fuzzing to libraries requires fuzz drivers to help process fuzzer-\nprovided input and invoke APIs. To reduce manual effort and avoid reliance on\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00050-1&hl=en&sa=X&d=11566396351270247841&ei=5MJmaOHNHe2rieoP-PKl6QY&scisig=AAZF9b9NzGapAGT-Gt26V3wejXNn&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Trailblazer: Practical End-to-end Web API Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "L Pan, S Cohney, T Murray, VT Pham\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThere are two key challenges in automatically testing web APIs:(a) determine where \nto send API requests and (b) identify how to make a valid payload for a given \nrequest. Both challenges are sometimes addressed by the presence of a machine\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3731717&hl=en&sa=X&d=13250706246401116236&ei=5MJmaOHNHe2rieoP-PKl6QY&scisig=AAZF9b-ohQDK3DHvGNmHJasK8R14&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "On the Applicability of Benford's Law to Detect Saturation in Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "J Lee, H Lee, S Park, SK Cha\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nKnowing when a fuzzing campaign has reached saturation is crucial for practitioners \nto avoid unnecessarily lengthy campaigns without missing bugs within given \nresources. Unfortunately, existing solutions for determining the saturation point rely\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3731723&hl=en&sa=X&d=16464785359231774820&ei=5MJmaOHNHe2rieoP-PKl6QY&scisig=AAZF9b-hP7JkI_Vp2sP6UiYyub7W&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Leveraging activation and optimisation layers as dynamic strategies in the multi-task fuzzing scheme", "first_label": ["Fuzzing"], "second_label": [], "data": "S Bamohabbat Chafjiri, P Legg, MA Tsompanas\\xe2\\x80\\xa6 - 2025\nFuzzing is a common technique for identifying vulnerabilities in software. Recent \napproaches, like She et al.'s Multi-Task Fuzzing (MTFuzz), use neural networks to \nimprove fuzzing efficiency. However, key elements like network architecture and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1016/j.csi.2025.104011&hl=en&sa=X&d=18210490462320417689&ei=5MJmaOHNHe2rieoP-PKl6QY&scisig=AAZF9b-SniAFgKPoPY_eeSgA0SFX&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Y Mao, T Cui, P Liu, D You, H Zhu\\xc2\\xa0- arXiv preprint arXiv:2506.15170, 2025\nLarge language models (LLMs) are rapidly evolving from single-modal systems to \nmultimodal LLMs and intelligent agents, significantly expanding their capabilities \nwhile introducing increasingly severe security risks. This paper presents a systematic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15170&hl=en&sa=X&d=16427093263132639213&ei=5MJmaKziIczM6rQP_8mNwQs&scisig=AAZF9b-zqUEdPZ8IyWJxfUDycl5Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Emoji attack: Enhancing jailbreak attacks against judge llm detection", "first_label": ["LLM"], "second_label": ["Detection"], "data": "Z Wei, Y Liu, NB Erichson\\xc2\\xa0- Forty-second International Conference on Machine\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreaking techniques trick Large Language Models (LLMs) into producing \nrestricted output, posing a potential threat. One line of defense is to use another LLM \nas a Judge to evaluate the harmfulness of generated text. However, we reveal that\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DQ0rKYiVEZq&hl=en&sa=X&d=17491126507172914063&ei=5MJmaKziIczM6rQP_8mNwQs&scisig=AAZF9b_yTB1R20z-t6ApkecZnFST&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift", "first_label": ["LLM"], "second_label": [], "data": "S Liang, J Liang, T Pang, C Du, A Liu, M Zhu, X Cao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInstruction tuning enhances large vision-language models (LVLMs) but increases \ntheir vulnerability to backdoor attacks due to their open design. Unlike prior studies in \nstatic settings, this paper explores backdoor attacks in LVLM instruction tuning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=http://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.pdf&hl=en&sa=X&d=5142527777954789704&ei=5MJmaKziIczM6rQP_8mNwQs&scisig=AAZF9b9_2Tz_lMykq3n8fQAVehJc&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, M Dras, U Naseem\\xc2\\xa0- arXiv preprint arXiv:2506.02442, 2025\nThis paper presents a systematic evaluation of Large Language Models'(LLMs) \nbehavior on long-tail distributed (encrypted) texts and their safety implications. We \nintroduce a two-dimensional framework for assessing LLM safety:(1) instruction\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02442&hl=en&sa=X&d=15102350404536711280&ei=5MJmaKziIczM6rQP_8mNwQs&scisig=AAZF9b_4gGVOvmiHUrKGvn2E4Vhh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems", "first_label": ["LLM"], "second_label": ["Agent", "Search"], "data": "X Li, J Chen, X Fang, S Ding, H Duan, Q Liu, K Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown remarkable capabilities in solving \ndiverse tasks. However, their proficiency in iteratively optimizing complex solutions \nthrough learning from previous feedback remains insufficiently explored. To bridge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10764&hl=en&sa=X&d=1134890120116902745&ei=5MJmaKziIczM6rQP_8mNwQs&scisig=AAZF9b8s_mGNSGwzfKFs6o2hgsbd&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "L Jiang, Z Zhang, Z Wang, X Sun, Z Li, L Zhen, X Xu\\xc2\\xa0- arXiv preprint arXiv:2506.16760, 2025\nLarge Vision-Language Models (LVLMs) demonstrate exceptional performance \nacross multimodal tasks, yet remain vulnerable to jailbreak attacks that bypass built-\nin safety mechanisms to elicit restricted content generation. Existing black-box\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16760&hl=en&sa=X&d=12136733750645262486&ei=5MJmaKziIczM6rQP_8mNwQs&scisig=AAZF9b8NosIP6RI9jYFVbBgmH01C&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring", "first_label": ["LLM"], "second_label": [], "data": "Y Li, Q Sheng, Y Yang, X Zhang, J Cao\\xc2\\xa0- arXiv preprint arXiv:2506.09996, 2025\nThough safety alignment has been applied to most large language models (LLMs), \nLLM service providers generally deploy a subsequent moderation as the external \nsafety guardrail in real-world products. Existing moderators mainly practice a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09996&hl=en&sa=X&d=8967671192696781749&ei=5MJmaKziIczM6rQP_8mNwQs&scisig=AAZF9b-I099JquXawda445fWweEs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM Jailbreak Oracle", "first_label": ["LLM"], "second_label": [], "data": "S Lin, A Suri, A Oprea, C Tan\\xc2\\xa0- arXiv preprint arXiv:2506.17299, 2025\nAs large language models (LLMs) become increasingly deployed in safety-critical \napplications, the lack of systematic methods to assess their vulnerability to jailbreak \nattacks presents a critical security gap. We introduce the jailbreak oracle problem\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17299&hl=en&sa=X&d=13276394224623482198&ei=5MJmaKziIczM6rQP_8mNwQs&scisig=AAZF9b9_2v0eFVwHwueuxrSl-vyP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Use Property-Based Testing to Bridge LLM Code Generation and Validation", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation"], "data": "L He, Z Chen, Z Zhang, J Shao, X Gao, L Sheng\\xc2\\xa0- arXiv preprint arXiv:2506.18315, 2025\nLarge Language Models (LLMs) excel at code generation, but ensuring their outputs \nto be functionally correct, especially in complex programming tasks, is a persistent \nchallenge. While traditional Test-Driven Development (TDD) offers a path for code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18315&hl=en&sa=X&d=3101719763251668573&ei=5MJmaKziIczM6rQP_8mNwQs&scisig=AAZF9b8VwRdS0BYT5dVQlhiDylYe&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning", "first_label": ["LLM"], "second_label": [], "data": "GJ Perin, R Chen, X Chen, NST Hirata, Z Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have become indispensable in real-world \napplications. However, their widespread adoption raises significant safety concerns, \nparticularly in responding to socially harmful questions. Despite substantial efforts to\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15606&hl=en&sa=X&d=5494164285246185827&ei=5MJmaKziIczM6rQP_8mNwQs&scisig=AAZF9b83jkzg6GWJfE0yBor7b9qA&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "CodeGuard: A Generalized and Stealthy Backdoor Watermarking for Generative Code Models", "first_label": ["Code"], "second_label": [], "data": "H Li, J Zhang, X Sun, X Luo\\xc2\\xa0- arXiv preprint arXiv:2506.20926, 2025\nGenerative code models (GCMs) significantly enhance development efficiency \nthrough automated code generation and code summarization. However, building \nand training these models require computational resources and time, necessitating\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.20926&hl=en&sa=X&d=12705964701535948625&ei=5MJmaK7SGte5ieoPgIGkkA0&scisig=AAZF9b_p9Xy86R1TMXdZFb75lIco&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research", "2 new citations to articles by Hong Jin Kang"]}
{"title": "Retrieval-Augmented Code Review Comment Generation", "first_label": ["Code Review", "Code"], "second_label": ["Generation"], "data": "H Hong, J Baik\\xc2\\xa0- arXiv preprint arXiv:2506.11591, 2025\nAutomated code review comment generation (RCG) aims to assist developers by \nautomatically producing natural language feedback for code changes. Existing \napproaches are primarily either generation-based, using pretrained language\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11591&hl=en&sa=X&d=15885059784306332833&ei=5MJmaK7SGte5ieoPgIGkkA0&scisig=AAZF9b-1WT7RGxAC1bABTNtyDxhD&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Towards More Effective Fault Detection in LLM-Based Unit Test Generation", "first_label": ["LLM", "Software Testing"], "second_label": ["Detection", "Generation"], "data": "G Wang, Q Xu, LC Briand, K Liu\\xc2\\xa0- arXiv preprint arXiv:2506.02954, 2025\nUnit tests play a vital role in uncovering potential faults in software. While tools like \nEvoSuite focus on maximizing code coverage, recent advances in large language \nmodels (LLMs) have shifted attention toward LLM-based test generation. However\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02954&hl=en&sa=X&d=5602972151000617790&ei=5MJmaK7SGte5ieoPgIGkkA0&scisig=AAZF9b-teZsjTIJdP31OgBwjNz0D&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "EvoTaint: Incremental static taint analysis of evolving Android apps", "first_label": [], "second_label": [], "data": "J Guo, H Cai\\xc2\\xa0- ACM Transactions on Software Engineering and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn the last decade, Android applications have emerged as a primary interface in \nconsumer technology. With approximately 2.5 billion mobile devices running Android \nglobally, security threats to the Android ecosystem due to vulnerabilities in it become\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3743132&hl=en&sa=X&d=11445709114946387781&ei=5MJmaK7SGte5ieoPgIGkkA0&scisig=AAZF9b9djAo7wpfGO6n5JUWFRTnH&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Leveraging Reward Models for Guiding Code Review Comment Generation", "first_label": ["Code Review", "Code"], "second_label": ["Generation"], "data": "OB Sghaier, R Tufano, G Bavota, H Sahraoui\\xc2\\xa0- arXiv preprint arXiv:2506.04464, 2025\nCode review is a crucial component of modern software development, involving the \nevaluation of code quality, providing feedback on potential issues, and refining the \ncode to address identified problems. Despite these benefits, code review can be\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04464%3F&hl=en&sa=X&d=7473922244289456987&ei=5MJmaK7SGte5ieoPgIGkkA0&scisig=AAZF9b-ibsr_HAOdLSyl3I1iDboX&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A Multi-agent LLM-based JUit Test Generation with Strong Oracles", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation", "Agent"], "data": "Q Xu, G Wang, L Briand, K Liu\\xc2\\xa0- arXiv preprint arXiv:2506.02943, 2025\nUnit testing plays a critical role in ensuring software correctness. However, writing \nunit tests manually is laborious, especially for strong typed languages like Java, \nmotivating the need for automated approaches. Traditional methods primarily rely on\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02943&hl=en&sa=X&d=9080051622854454343&ei=5MJmaK7SGte5ieoPgIGkkA0&scisig=AAZF9b-W733SKwSoE4FIE6fi3cJw&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Spectre: Automated Aliasing Specifications Generation for Library APIs with Fuzzing", "first_label": ["Fuzzing"], "second_label": ["Generation"], "data": "S Kan, Y Li, W He, Z Xing, L Zhu, Y Sui\\xc2\\xa0- ACM Transactions on Software Engineering\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nStatic program analysis of real-world software that integrates numerous library \nApplication Programming Interfaces (APIs) faces significant challenges due to \ninaccessible or highly complex source code. A common workaround is to use\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3725811&hl=en&sa=X&d=2352067302594285580&ei=5MJmaK7SGte5ieoPgIGkkA0&scisig=AAZF9b8vKjatyW94SPNBNu4L2TwN&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "UCP: a unified framework for code generation with pseudocode-based multi-task learning and reinforcement alignment", "first_label": ["Code"], "second_label": ["Generation"], "data": "Y Wen, Z Cui, Y Liu, Z Zhang, J Zhou, L Tang\\xc2\\xa0- The Journal of Supercomputing, 2025\nPre-trained large language models (LLMs) have been widely applied to natural \nlanguage-based code generation. However, because code generation tasks are \nhighly sensitive to structured information and exhibit diverse logical forms, directly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11227-025-07487-1&hl=en&sa=X&d=264978427275781755&ei=5MJmaJGPI7XCieoP3oeY-Qc&scisig=AAZF9b8HnhQLRB1NFzaWU0iyGBfI&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Mapping NVD Records to Their VFCs: How Hard is it?", "first_label": [], "second_label": [], "data": "HH Nguyen, DM Tran, Y Cheng, T Le-Cong, HJ Kang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMapping National Vulnerability Database (NVD) records to vulnerability-fixing \ncommits (VFCs) is crucial for vulnerability analysis but challenging due to sparse \nexplicit links in NVD references. This study explores this mapping's feasibility through\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09702&hl=en&sa=X&d=17350753801902205444&ei=5MJmaJGPI7XCieoP3oeY-Qc&scisig=AAZF9b9GdE1B-xLLhUOLme72JT4D&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "RAPRSUM: Retrieval-Augmented Code Summarization with Advanced Prototype Refinement", "first_label": ["Code"], "second_label": [], "data": "Y Lin, X Wang, S Zhan, D Wei, B Chen\\xc2\\xa0- International Journal of Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\n2 Yangbo Lin, Xingqi Wang, Shanggui Zhan, Dan Wei and Bin Chen tion retrieval \napproaches, which leverage similar summaries from a corpus, have shown \npromising results. These methods, however, often exhibit a heavy reliance on the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.worldscientific.com/doi/abs/10.1142/S0218194025500317&hl=en&sa=X&d=14414936619519920862&ei=5MJmaJGPI7XCieoP3oeY-Qc&scisig=AAZF9b_L2kFr3fCpNmvkMR20B-dE&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "AST2CVCode: A New Benchmark Dataset for Source Code Generation on Computer Vision Applications", "first_label": ["Code"], "second_label": ["Generation"], "data": "WS Alshehri, SK Jarraya, AA Allinjawi\\xc2\\xa0- International Conference on Advanced\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBenchmark datasets are important in evaluating various methods for source code \ngeneration tasks. In this paper, we present AST2CVCode, a new benchmark dataset \nto enhance deep learning models for source code generation. AST2CVCode is\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-91337-2_46&hl=en&sa=X&d=15545214955806460595&ei=5MJmaJGPI7XCieoP3oeY-Qc&scisig=AAZF9b-xEY_Bo700rs_NZO5gdshG&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "On Predicting Vulnerability Severity Using In-Context Learning: An Industrial Case Study", "first_label": ["Vulnerabilities"], "second_label": [], "data": "D Rodriguez-Cardenas, DN Palacio, A Schmedding\\xe2\\x80\\xa6 - 2025\nModern software systems demand earlier vulnerability severity detection to protect \nsystems from critical issues such as data leaking or attacker access. Security \nanalysts are in charge of triaging the vulnerability severity by computing a score\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.authorea.com/doi/pdf/10.22541/au.175033470.05916058&hl=en&sa=X&d=13350311129524430544&ei=5MJmaJGPI7XCieoP3oeY-Qc&scisig=AAZF9b9J_sXjT3UaQPWnFl14GrrB&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=7&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Knowledge Enhanced Large Language Model for Bug Localization", "first_label": ["LLM", "Bug"], "second_label": ["Localization"], "data": "Y Li, B Liu, T Zhang, Z Wang, D Lo, L Yang, J Lyu\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nA significant number of bug reports are generated every day as software systems \ncontinue to develop. Large Language Models (LLMs) have been used to correlate \nbug reports with source code to locate bugs automatically. The existing research has\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729356&hl=en&sa=X&d=16532092839572238040&ei=5MJmaJGPI7XCieoP3oeY-Qc&scisig=AAZF9b-PmFlcmxHgFCjDtRfes5nX&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=8&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Automatic Qiskit Code Refactoring Using Large Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "JM Su\\xc3\\xa1rez, LM Bibb\\xc3\\xb3, J Bogado, A Fernandez\\xc2\\xa0- arXiv preprint arXiv:2506.14535, 2025\nAs quantum software frameworks evolve, developers face increasing challenges in \nmaintaining compatibility with rapidly changing APIs. In this work, we present a novel \nmethodology for refactoring Qiskit code using large language models (LLMs). We\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.14535&hl=en&sa=X&d=4707492068215582196&ei=5MJmaJGPI7XCieoP3oeY-Qc&scisig=AAZF9b8ijIjD2XcJlduBt3t6lA4m&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=9&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Microarchitecture Evaluation Framework for Transient Execution Attack Vulnerability: Metrics, Fuzzing, and Sensitivity Analysis", "first_label": ["Vulnerabilities", "Fuzzing"], "second_label": [], "data": "J McGhee, N Lujano, A Peterson, H Duwe, A Tyagi\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the Great\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn this paper, we present a unified vulnerability analysis framework for transient \nexecution attacks in out-of-order processors. We illustrate with a representative \nSpectre attack template and fuzzing to expose the range of speculative window sizes \nexhibited by a microarchitecture. Our results show small, medium, and large BOOM \ncores with speculative window sizes of 30-185 cycles, 40-370 cycles, and 70-540 \ncycles, respectively. Large speculative windows allow us to examine multi-byte\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaoo7: Low-overhead defense against spectre attacks via program\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3716368.3735225&hl=en&sa=X&d=17893294608724403454&ei=5MJmaLCJHMmQ6rQPzMjc4AI&scisig=AAZF9b-bAYPwAsh-oNi_k2e80AZY&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Imperative Program Synthesis by Abstract Static Analysis and SMT Mutations", "first_label": ["Static Analysis"], "second_label": [], "data": "AS Dimovski\\xc2\\xa0- Proceedings of the 24th ACM SIGPLAN International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis paper introduces a novel technique for synthesizing imperative programs that \nmeet behavioral specifications given in the form of assumptions and assertions (logic \nformulas). In particular, we combine basic statement-directed enumerative search, \nstatic analysis via abstract interpretation, and expression-directed enumerative \nsearch via (incremental) SMT-based mutations to efficiently explore all candidate \ncomplete programs generated from an input program template (with statement and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAngelix: Scalable multiline program patch synthesis via symbolic\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3742876.3742884&hl=en&sa=X&d=6310375418077748141&ei=5MJmaLCJHMmQ6rQPzMjc4AI&scisig=AAZF9b-U6a6lPVu34gneG1RVYGer&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Run-time Attestation and Auditing: The Verifier's Perspective", "first_label": ["Software Testing"], "second_label": [], "data": "AI Caulfield, N Rattanavipanon, IDO Nunes\\xc2\\xa0- 18th ACM Conference on Security and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn run-time attestation schemes, including Control Flow Attestation (CFA) and Data \nFlow Attestation (DFA), a remote Verifier (V rf) requests a potentially compromised \nProver device (P rv) to generate evidence of its execution control flow path (in CFA) \nand optionally execution data inputs (in DFA). Recent advances in this space also \nguarantee that V rf eventually receives run-time evidence from P rv, even when P rv \nis fully compromised. Reliable delivery, in theory, enables run-time auditing in\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBinary Rewriting without Control Flow Recovery\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3734477.3734710&hl=en&sa=X&d=1351254296585644338&ei=5MJmaLCJHMmQ6rQPzMjc4AI&scisig=AAZF9b9my-N3-6edy4PIj35WIEaZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Walls Have Ears: Demystifying Notification Listener Usage in Android Apps", "first_label": [], "second_label": [], "data": "J Deng, T Liu, Y Zhao, C Wang, L Zhang, H Wang\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe Notification Listener Service (NLS) in Android allows third-party apps to monitor \nand process device notifications, enabling powerful features but also introducing \nsecurity and privacy risks. Despite the special permission required to access NLS, it\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728898&hl=en&sa=X&d=5254092448648347629&ei=v7VkaIykM-2rieoPqNCcqA8&scisig=AAZF9b_haGdL95DBvdLyCsrMhBg1&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Boosting Vulnerability Detection with Inter-function Multilateral Association Insights", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "S Qiu, M Huang, J Cheng\\xc2\\xa0- arXiv preprint arXiv:2506.21014, 2025\nVulnerability detection is a crucial yet challenging technique for ensuring the security \nof software systems. Currently, most deep learning-based vulnerability detection \nmethods focus on stand-alone functions, neglecting the complex inter-function\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.21014&hl=en&sa=X&d=9469201270328440896&ei=v7VkaIykM-2rieoPqNCcqA8&scisig=AAZF9b9Yokho81UwUeqKbJY0D-Yb&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "Empirical Evaluation of Generalizable Automated Program Repair with Large Language Models", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "V Campos, R Shariffdeen, A Ulges, Y Noller\\xc2\\xa0- arXiv preprint arXiv:2506.03283, 2025\nAutomated Program Repair (APR) proposes bug fixes to aid developers in \nmaintaining software. The state of the art in this domain focuses on using LLMs, \nleveraging their strong capabilities to comprehend specifications in natural language\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03283&hl=en&sa=X&d=200998896991037433&ei=v7VkaIykM-2rieoPqNCcqA8&scisig=AAZF9b_9W2A-NQAXxkYzgRHwtFh8&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Your Agent Can Defend Itself against Backdoor Attacks", "first_label": [], "second_label": ["Agent"], "data": "L Changjiang, L Jiacheng, C Bochuan, C Jinghui\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite their growing adoption across domains, large language model (LLM)-\npowered agents face significant security risks from backdoor attacks during training \nand fine-tuning. These compromised agents can subsequently be manipulated to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08336&hl=en&sa=X&d=9281612337423238890&ei=v7VkaKqxMNSWieoP7PPKiQQ&scisig=AAZF9b8EnIakTDvZQGsyv1duPVA5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SecurityLingua: Efficient Defense of LLM Jailbreak Attacks via Security-Aware Prompt Compression", "first_label": ["LLM"], "second_label": [], "data": "Y Li, S Ahn, H Jiang, AH Abdi, Y Yang, L Qiu\\xc2\\xa0- arXiv preprint arXiv:2506.12707, 2025\nLarge language models (LLMs) have achieved widespread adoption across \nnumerous applications. However, many LLMs are vulnerable to malicious attacks \neven after safety alignment. These attacks typically bypass LLMs' safety guardrails by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12707&hl=en&sa=X&d=8418273368991399970&ei=v7VkaKqxMNSWieoP7PPKiQQ&scisig=AAZF9b8AOJ5PQ2S2DYr5nVOYpqTl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge", "first_label": ["LLM"], "second_label": [], "data": "S Li, C Xu, J Wang, X Gong, C Chen, J Zhang, J Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable intelligence across \nvarious tasks, which has inspired the development and widespread adoption of LLM-\nas-a-Judge systems for automated model testing, such as red teaming and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09443&hl=en&sa=X&d=2052322274134661445&ei=v7VkaKqxMNSWieoP7PPKiQQ&scisig=AAZF9b9u9cyhYi06xXXt37CLZpdh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Syntactic paraphrase-based synthetic data generation for backdoor attacks against Chinese language models", "first_label": ["LLM"], "second_label": ["Generation"], "data": "M Hu, Y Yang, D Pan, Z Guo, L Xiao, D Lin, S Zhao\\xc2\\xa0- Information Fusion, 2025\nAbstract Language Models (LMs) have shown significant advancements in various \nNatural Language Processing (NLP) tasks. However, recent studies indicate that \nLMs are particularly susceptible to malicious backdoor attacks, where attackers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S156625352500449X&hl=en&sa=X&d=11939540759867308872&ei=v7VkaKqxMNSWieoP7PPKiQQ&scisig=AAZF9b_omHEFDqgnSwVne_pfKwnY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas", "first_label": ["LLM"], "second_label": ["Search"], "data": "C Si, T Hashimoto, D Yang\\xc2\\xa0- arXiv preprint arXiv:2506.20803, 2025\nLarge Language Models (LLMs) have shown promise in accelerating the scientific \nresearch pipeline. A key capability for this process is the ability to generate novel \nresearch ideas, and prior studies have found settings in which LLM-generated\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.20803&hl=en&sa=X&d=12936314858694523072&ei=v7VkaKqxMNSWieoP7PPKiQQ&scisig=AAZF9b9OO1DSvhRdAUtwVxkfCQ2j&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Through the Stealth Lens: Rethinking Attacks and Defenses in RAG", "first_label": [], "second_label": [], "data": "S Choudhary, N Palumbo, A Hooda, KD Dvijotham\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRetrieval-augmented generation (RAG) systems are vulnerable to attacks that inject \npoisoned passages into the retrieved set, even at low corruption rates. We show that \nexisting attacks are not designed to be stealthy, allowing reliable detection and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04390&hl=en&sa=X&d=15468735482968103516&ei=v7VkaKqxMNSWieoP7PPKiQQ&scisig=AAZF9b8u2OUJdUy7skXRySPRbZz3&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AsFT: Anchoring Safety During LLM Fine-Tuning Within Narrow Safety Basin", "first_label": ["LLM"], "second_label": [], "data": "S Yang, Q Zhang, Y Liu, Y Huang, X Jia, K Ning, J Yao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are vulnerable to safety risks during fine-tuning, \nwhere small amounts of malicious or harmless data can compromise safeguards. In \nthis paper, building on the concept of alignment direction--defined by the weight\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08473%3F&hl=en&sa=X&d=15059004078714992755&ei=v7VkaKqxMNSWieoP7PPKiQQ&scisig=AAZF9b-cmQJQ2nP1jAOJlM9iLuaf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "UTBoost: Rigorous Evaluation of Coding Agents on SWE-Bench", "first_label": [], "second_label": ["Agent"], "data": "B Yu, Y Zhu, P He, D Kang\\xc2\\xa0- arXiv preprint arXiv:2506.09289, 2025\nThe advent of Large Language Models (LLMs) has spurred the development of \ncoding agents for real-world code generation. As a widely used benchmark for \nevaluating the code generation capabilities of these agents, SWE-Bench uses real\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09289&hl=en&sa=X&d=11182501873954298604&ei=v7VkaKqxMNSWieoP7PPKiQQ&scisig=AAZF9b_2PIQ56ufLjIxE0_sQz9BZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Arms Race in Deep Learning: A Survey of Backdoor Defenses and Adaptive Attacks", "first_label": [], "second_label": [], "data": "X Mo, N Sun, LY Zhang, W Luo, S Gao, Y Xiang\\xc2\\xa0- Pacific-Asia Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeep neural networks (DNNs) face a growing threat from backdoor attacks, which \nembed hidden malicious functionalities triggered by specific inputs. This survey \nexamines the escalating arms race between backdoor defenses and increasingly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-96-8183-9_24&hl=en&sa=X&d=4258756518287065675&ei=v7VkaKqxMNSWieoP7PPKiQQ&scisig=AAZF9b80XRQuOtBuq86IspbsVv3h&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Cost of Dynamic Reasoning: Demystifying AI Agents and Test-Time Scaling from an AI Infrastructure Perspective", "first_label": ["Software Testing"], "second_label": ["Agent", "Reasoning"], "data": "J Kim, B Shin, J Chung, M Rhu\\xc2\\xa0- arXiv preprint arXiv:2506.04301, 2025\nLarge-language-model (LLM)-based AI agents have recently showcased impressive \nversatility by employing dynamic reasoning, an adaptive, multi-step process that \ncoordinates with external tools. This shift from static, single-turn inference to agentic\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04301&hl=en&sa=X&d=3072272730677106970&ei=v7VkaKqxMNSWieoP7PPKiQQ&scisig=AAZF9b-t8XUoljKdp6JjL-hJnilf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "PatchPilot: A Cost-Efficient Software Engineering Agent with Early Attempts on Formal Verification", "first_label": ["Verification"], "second_label": ["Agent"], "data": "H Li, Y Tang, S Wang, W Guo\\xc2\\xa0- Forty-second International Conference on Machine\\xc2\\xa0\\xe2\\x80\\xa6\nRecent research builds various patching agents that combine large language \nmodels (LLMs) with non-ML tools and achieve promising results on the state-of-the-\nart (SOTA) software patching benchmark, SWE-bench. Based on how to determine \nthe patching workflows, existing patching agents can be categorized as agent-based \nplanning methods, which rely on LLMs for planning, and rule-based planning \nmethods, which follow a pre-defined workflow. At a high level, agent-based planning\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSpecRover: Code Intent Extraction via LLMs\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DybODpT8ydV&hl=en&sa=X&d=15886473230868587853&ei=v7VkaLmPK9SWieoP7PPKiQQ&scisig=AAZF9b9tmFMxKKkqSZugCBhDMX8b&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research"]}
{"title": "Grammarinator Meets LibFuzzer: A Structure-Aware In-Process Approach", "first_label": ["Fuzzing"], "second_label": [], "data": "R Hodov\\xc3\\xa1n, A Kiss - 2025\nFuzzing involves generating a large number of inputs and running them through a \ntarget application to detect unusual behavior. Modern general-purpose guided \nfuzzers are effective at testing various programs, but their lack of structure awareness \nmakes it difficult for them to induce unexpected behavior beyond the parser. \nConversely, structure-aware fuzzers can generate well-formed inputs but are often \nunguided, preventing them from leveraging feedback mechanisms. In this paper, we\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart greybox fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Akos-Kiss-5/publication/392985729_Grammarinator_Meets_LibFuzzer_A_Structure-Aware_In-Process_Approach/links/685d626992697d42903b3f9c/Grammarinator-Meets-LibFuzzer-A-Structure-Aware-In-Process-Approach.pdf&hl=en&sa=X&d=15391317677628993407&ei=v7VkaLmPK9SWieoP7PPKiQQ&scisig=AAZF9b897vaqpbmM4C40_lej8pH5&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Intelligent Fuzzing Method for Aviation Information Systems as Part of the Secure Software Development Cycle", "first_label": ["Fuzzing"], "second_label": [], "data": "IS Antipov, SS Arustamyan, AA Ganichev, AS Markov\\xe2\\x80\\xa6\\xc2\\xa0- Russian Engineering\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe article is dedicated to the study of intelligent fuzzing methods aimed at improving \nthe security of aviation systems software using machine learning algorithms. \nSoftware used to control aviation systems, such as on-board networks and air traffic \ncontrol systems, requires special attention due to the high risks of unauthorized \ntampering. Analysis of conventional fuzzing methods has revealed their \ndisadvantages, such as redundancy of input data and significant computational\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.3103/S1068798X25700728&hl=en&sa=X&d=3447279779830326576&ei=v7VkaLmPK9SWieoP7PPKiQQ&scisig=AAZF9b8domAIa_4haqIqYJmD8o0U&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "ArgvFuzz: Argv-Sensitive Multi-Target Directed Greybox Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "C Hu, Z Zhang, L Chen, G Shi\\xc2\\xa0- 2025 28th International Conference on Computer\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMulti-target directed greybox fuzzing plays a crucial role in discovering software \nvulnerabilities by guiding fuzzers to explore specific program paths and achieving \nmultiple targets in a single test. However, even the most advanced fuzzing \ntechniques still fail to reach certain targets. These targets may require specific argvs \n(argument vectors, also known as command-line options) to reach. Different argvs \nwill guide the exploration towards different program branches, allowing the program\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11033270/&hl=en&sa=X&d=17267260826316286265&ei=v7VkaLmPK9SWieoP7PPKiQQ&scisig=AAZF9b8o17mm4CHLMcWCNN1BoK3x&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Efficient Adaptation of Large Language Models for Smart Contract Vulnerability Detection", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection"], "data": "F Sikder, Y Lei, Y Ji\\xc2\\xa0- Proceedings of the 21st International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSmart contracts underpin decentralized applications but face significant security risks \nfrom vulnerabilities, while traditional analysis methods have limitations. Large \nLanguage Models (LLMs) offer promise for vulnerability detection, yet adapting these\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3727582.3728688&hl=en&sa=X&d=12782146568247701389&ei=v7VkaKu-LKalieoP0qP0qQs&scisig=AAZF9b_lXcm2k2EZkx3aCh_7xCei&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "A systematic literature review on cross-language source code clone detection", "first_label": ["Code"], "second_label": ["Detection"], "data": "AS Alshabib, S Mahmood, M Alshayeb\\xc2\\xa0- Computer Science Review, 2025\nAbstract Context Cross-language code Clone Detection (CLCCD) is crucial to \nmaintaining consistency and minimizing redundancy in modern software \ndevelopment, where similar code may appear in different projects written in various\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1574013725000620&hl=en&sa=X&d=11891027828376991131&ei=v7VkaKu-LKalieoP0qP0qQs&scisig=AAZF9b_ZX7JztniALLwHWpM69VL5&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=1&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Managing Data at Scale: From Data Products to Data Markets", "first_label": [], "second_label": [], "data": "S Driessen - 2025\nIn the 1990s, humanity reached a significant digital milestone: for the first time, the \namount of digitally stored information surpassed that of all physical books ever \nwritten combined. Today, we produce this amount of information approximately every \nhour. It is no surprise that the vast majority of this information is not read by \nindividuals. Governments, businesses, and other organizations increasingly rely on \nthe data they generate or acquire from others. Advances in data science, machine\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://research.tilburguniversity.edu/files/117889395/Digital_Version_Manuscript_-_Stefan_Driessen.pdf&hl=en&sa=X&d=10078730065523334160&ei=v7VkaPCqKI_WieoP7Z6h4Qk&scisig=AAZF9b8zz1R7cCL0NuQXNFZtckay&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["1 new citation to articles by Bach Le"]}
{"title": "deepSURF: Detecting Memory Safety Vulnerabilities in Rust Through Fuzzing LLM-Augmented Harnesses", "first_label": ["Vulnerabilities", "LLM", "Fuzzing"], "second_label": ["Detection"], "data": "G Androutsopoulos, A Bianchi\\xc2\\xa0- arXiv preprint arXiv:2506.15648, 2025\nAlthough Rust ensures memory safety by default, it also permits the use of unsafe \ncode, which can introduce memory safety vulnerabilities if misused. Unfortunately, \nexisting tools for detecting memory bugs in Rust typically exhibit limited detection\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15648&hl=en&sa=X&d=5470473754710042022&ei=v7VkaNTrLbXCieoPsuWcoAQ&scisig=AAZF9b-QLCAPbmOGA94zxamaJ1DB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Directed Testing in MLIR: Unleashing Its Potential by Overcoming the Limitations of Random Fuzzing", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "W Tong, Z Wang, Z Tang, J Fang, Y Zhang, G Ye\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMLIR is a new way of creating compiler infrastructures that can be easily reused and \nextended. Current MLIR fuzzing methods focus primarily on test case generation or \nmutation using randomly selected passes. However, they often overlook the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729372&hl=en&sa=X&d=10225165863736020095&ei=v7VkaNTrLbXCieoPsuWcoAQ&scisig=AAZF9b9XDaU-7-dG1ms-uNWhw7no&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "5Ghoul: Unleashing Chaos on 5 G Edge Devices Via Stateful Multi-Layer Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "ME Garbelini, Z Shang, S Luo, S Chattopadhyay, S Sun\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn this paper, we present 5Ghoul, a framework to systematically discover and \nreplicate security vulnerabilities on arbitrary 5 G edge devices (UE). At the core of \n5Ghoul is a stateful fuzzing strategy that provides full control to arbitrarily manipulate\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11045988/&hl=en&sa=X&d=1164049594712143600&ei=v7VkaNTrLbXCieoPsuWcoAQ&scisig=AAZF9b8yPzWDHsbg6u45oxtg30Za&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Malo in the Code Jungle: Explainable Fault Localization for Decentralized Applications", "first_label": ["Fault Localization", "Code"], "second_label": ["Localization"], "data": "H Zhang, J Wu, Z Wu, Z Chen, D Lin, J Chen, Y Zhou\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDecentralized applications (DApps) have long been sitting ducks for hackers due to \ntheir valuable cryptocurrency assets, exposing them to various security risks. When a \nDApp is attacked, promptly identifying faults is crucial to minimizing financial losses\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11034691/&hl=en&sa=X&d=7651709202352945146&ei=v7VkaNTrLbXCieoPsuWcoAQ&scisig=AAZF9b8cw1Hmz_K4wN9ajW1PUmQk&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Chroma Backdoor: A Stealthy Backdoor Attack Based on High-Frequency Wavelet Injection in the UV Channels", "first_label": [], "second_label": [], "data": "Y Fan, K Zhang, B Zheng, Y Zhou, J Zhou, W Pan\\xc2\\xa0- Symmetry, 2025\nWith the widespread adoption of deep learning in critical domains, such as computer \nvision, model security has become a growing concern. Backdoor attacks, as a highly \nstealthy threat, have emerged as a significant research topic in AI security. Existing \nbackdoor attack methods primarily introduce perturbations in the spatial domain of \nimages, which suffer from limitations, such as visual detectability and signal fragility. \nAlthough subsequent approaches, such as those based on steganography, have\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaStealthy backdoor attack for code models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2073-8994/17/7/1014&hl=en&sa=X&d=10362643532214051997&ei=v7VkaICQJ4OuieoPqtaP6Ag&scisig=AAZF9b_s8R0PBt6I157dgAnIQrUW&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang"]}
{"title": "Rethinking the effects of data contamination in Code Intelligence", "first_label": ["Code"], "second_label": [], "data": "Z Yang, H Lin, Y He, J Xu, Z Sun, S Liu, P Wang, Z Yu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, code intelligence has gained increasing importance in the field of \nautomated software engineering. Meanwhile, the widespread adoption of Pretrained \nLanguage Models (PLMs) and Large Language Models (LLMs) has raised concerns\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02791&hl=en&sa=X&d=13914802631128746138&ei=v7VkaNbgMde5ieoPw--gyAU&scisig=AAZF9b9FbJDsSBQv15gRiA2JZNoe&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "FuseApplyBench: Multilingual Benchmark for Trustworthy Code Edit Applying Task", "first_label": ["Code"], "second_label": [], "data": "M Liang, Q Zhang, Z Zuo, S Zheng, D Chen, W Jiang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 34th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the rise of Language Models (LMs) and Large Language Models (LLMs), their \npotential for code editing (CE) has gained attention. An approach is to have LLMs \ngenerate draft code modifications, which are then refined by smaller LMs in further\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3732929&hl=en&sa=X&d=7791836070318800823&ei=v7VkaNbgMde5ieoPw--gyAU&scisig=AAZF9b_-xxPAC4O-ILuaMHDNHkH0&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Mono: Is Your\" Clean\" Vulnerability Dataset Really Solvable? Exposing and Trapping Undecidable Patches and Beyond", "first_label": ["Vulnerabilities"], "second_label": [], "data": "Z Gao, J Zhou, B Zhang, Y He, C Zhang, Y Cui, H Wang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe quantity and quality of vulnerability datasets are essential for developing deep \nlearning solutions to vulnerability-related tasks. Due to the limited availability of \nvulnerabilities, a common approach to building such datasets is analyzing security\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03651&hl=en&sa=X&d=5611261347115113824&ei=v7VkaNbgMde5ieoPw--gyAU&scisig=AAZF9b8ZqDz-8m4J-1VYjUzHamnv&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Which Factors Make Code LLMs More Vulnerable to Backdoor Attacks? A Systematic Study", "first_label": ["LLM", "Code"], "second_label": [], "data": "C Wang, Z Yang, Y Harel, D Lo\\xc2\\xa0- arXiv preprint arXiv:2506.01825, 2025\nCode LLMs are increasingly employed in software development. However, studies \nhave shown that they are vulnerable to backdoor attacks: when a trigger (a specific \ninput pattern) appears in the input, the backdoor will be activated and cause the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.01825&hl=en&sa=X&d=16166340572421918430&ei=v7VkaNbgMde5ieoPw--gyAU&scisig=AAZF9b-phsc8qq-f3lOMccCIs3x-&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Evaluating Large Language Models on Non-Code Software Engineering Tasks", "first_label": ["LLM", "Code"], "second_label": [], "data": "FC Pe\\xc3\\xb1a, S Herbold\\xc2\\xa0- arXiv preprint arXiv:2506.10833, 2025\nLarge Language Models (LLMs) have demonstrated remarkable capabilities in code \nunderstanding and generation; however, their effectiveness on non-code Software \nEngineering (SE) tasks remains underexplored. We present the first comprehensive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10833&hl=en&sa=X&d=11330207664789335570&ei=v7VkaNbgMde5ieoPw--gyAU&scisig=AAZF9b-o1DrbJ7pUNkr3zs_CtfAF&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Multi-Dataset Evaluation of Models for Automated Vulnerability Repair", "first_label": ["Vulnerabilities"], "second_label": ["Repair"], "data": "ZA Khan, A Garg, Q Tang\\xc2\\xa0- arXiv preprint arXiv:2506.04987, 2025\nSoftware vulnerabilities pose significant security threats, requiring effective \nmitigation. While Automated Program Repair (APR) has advanced in fixing general \nbugs, vulnerability patching, a security-critical aspect of APR remains underexplored\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04987&hl=en&sa=X&d=8355847986163965479&ei=v7VkaNbgMde5ieoPw--gyAU&scisig=AAZF9b9iPSTGWnyCaOCv5RKilXRE&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=7&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Semi-supervised software vulnerability assessment via code lexical and structural information fusion", "first_label": ["Vulnerabilities", "Code"], "second_label": [], "data": "W Pei, Y Huang, X Chen, G Lu, Y Liu, C Ni\\xc2\\xa0- Automated Software Engineering, 2025\nIn recent years, data-driven approaches have become popular for software \nvulnerability assessment (SVA). However, these approaches need a large amount of \nlabeled SVA data to construct effective SVA models. This process demands security\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00526-4&hl=en&sa=X&d=12150716079684109674&ei=v7VkaNbgMde5ieoPw--gyAU&scisig=AAZF9b8zXJiBu6kjaWbL323Dh99f&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=8&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Code Execution as Grounded Supervision for LLM Reasoning", "first_label": ["LLM", "Code"], "second_label": ["Reasoning"], "data": "D Jung, W Zhou, M Chen\\xc2\\xa0- arXiv preprint arXiv:2506.10343, 2025\nTraining large language models (LLMs) with chain-of-thought (CoT) supervision has \nproven effective for enhancing their reasoning abilities. However, obtaining reliable \nand accurate reasoning supervision remains a significant challenge. We propose a\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10343&hl=en&sa=X&d=17674122244614595470&ei=v7VkaNbgMde5ieoPw--gyAU&scisig=AAZF9b9FVx8sOStQ10lLNlQUVvgU&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=9&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Boosting Open-Source LLMs for Program Repair via Reasoning Transfer and LLM-Guided Reinforcement Learning", "first_label": ["APR", "LLM"], "second_label": ["Repair", "Reasoning"], "data": "X Tang, J Klein, TF Bissyand\\xc3\\xa9\\xc2\\xa0- arXiv preprint arXiv:2506.03921, 2025\nSeveral closed-source LLMs have consistently outperformed open-source \nalternatives in program repair tasks, primarily due to their superior reasoning \ncapabilities and extensive pre-training. This paper introduces Repairity, a novel three\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03921&hl=en&sa=X&d=5236192915434052745&ei=v7VkaNzhKa6l6rQPgvqD4Ao&scisig=AAZF9b_Pyh0Or56hIIZbIHm5nDC2&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "LLM-Guided Scenario-based GUI Testing", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "S Yu, Y Ling, C Fang, Q Zhou, C Chen, S Zhu, Z Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe assurance of mobile app GUI is more and more significant. Automated GUI \ntesting approaches of different strategies have been developed, while there are still \nhuge gaps between the approaches and the app business logic, not taking the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05079&hl=en&sa=X&d=10587655884573272012&ei=v7VkaNzhKa6l6rQPgvqD4Ao&scisig=AAZF9b_9oZAteogzTFVCpm4ZVNB0&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Across Programming Language Silos: A Study on Cross-Lingual Retrieval-augmented Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "Q Zhu, J Cao, X Chen, Y Lu, H Lin, X Han, L Sun\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCurrent research on large language models (LLMs) with retrieval-augmented code \ngeneration (RACG) mainly focuses on single-language settings, leaving cross-\nlingual effectiveness and security unexplored. Multi-lingual RACG systems are\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03535&hl=en&sa=X&d=14758371788704078162&ei=v7VkaNzhKa6l6rQPgvqD4Ao&scisig=AAZF9b-dcuDDIx5KNKIkulVIbOZM&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A Preference-Driven Methodology for High-Quality Solidity Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "Z Peng, X Yin, C Ying, C Ni, Y Luo\\xc2\\xa0- arXiv preprint arXiv:2506.03006, 2025\nWhile Large Language Models (LLMs) have demonstrated remarkable progress in \ngenerating functionally correct Solidity code, they continue to face critical challenges \nin producing gas-efficient and secure code, which are critical requirements for real\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03006&hl=en&sa=X&d=17726484644696653033&ei=v7VkaNzhKa6l6rQPgvqD4Ao&scisig=AAZF9b-kQj0MkmtCeWsZksOvGyp1&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Characterizing Multi-Hunk Patches: Divergence, Proximity, and LLM Repair Challenges", "first_label": ["LLM"], "second_label": ["Repair"], "data": "N Nashid, D Ding, K Gallaba, AE Hassan, A Mesbah\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMulti-hunk bugs, where fixes span disjoint regions of code, are common in practice, \nyet remain underrepresented in automated repair. Existing techniques and \nbenchmarks pre-dominantly target single-hunk scenarios, overlooking the added\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04418&hl=en&sa=X&d=15657538929124675032&ei=v7VkaNzhKa6l6rQPgvqD4Ao&scisig=AAZF9b_-gIMENh8EU3j9mHDoC8N1&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "STRUT: Structured Seed Case Guided Unit Test Generation for C Programs using LLMs", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "J Liu, C Li, R Chen, S Li, B Gu, M Yang\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nUnit testing plays a crucial role in bug detection and ensuring software correctness. It \nhelps developers identify errors early in development, thereby reducing software \ndefects. In recent years, large language models (LLMs) have demonstrated\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728970&hl=en&sa=X&d=1614520279787105812&ei=v7VkaNzhKa6l6rQPgvqD4Ao&scisig=AAZF9b9flxdxiMt_SbAzLb96g6HF&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "A Basit, M Shao, H Asif, N Innan, M Kashif, A Marchisio\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent advances in Large Language Models (LLMs) have demonstrated strong \npotential in code generation, yet their effectiveness in quantum computing remains \nunderexplored. This paper benchmarks LLMs for PennyLane-based quantum code\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.20008&hl=en&sa=X&d=13309783802552972413&ei=v7VkaNzhKa6l6rQPgvqD4Ao&scisig=AAZF9b_yr5n7B6DQxWz1TC2t_xh0&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Reassessing Code Authorship Attribution in the Era of Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "AK Dipongkor, Z Yao, K Moran\\xc2\\xa0- arXiv preprint arXiv:2506.17120, 2025\nThe study of Code Stylometry, and in particular Code Authorship Attribution (CAA), \naims to analyze coding styles to identify the authors of code samples. CAA is crucial \nin cybersecurity and software forensics for addressing, detecting plagiarism, and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17120&hl=en&sa=X&d=12069506939304281396&ei=v7VkaNnMJffWieoPvsyt2AE&scisig=AAZF9b9OxubQtYi2lTNPr1YQmcjb&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "The Foundation Cracks: A Comprehensive Study on Bugs and Testing Practices in LLM Libraries", "first_label": ["LLM", "Bug", "Software Testing"], "second_label": [], "data": "W Jiang, X Zhang, X Xie, J Yu, Y Zhi, S Ma, C Shen\\xc2\\xa0- arXiv preprint arXiv:2506.12320, 2025\nLarge Language Model (LLM) libraries have emerged as the foundational \ninfrastructure powering today's AI revolution, serving as the backbone for LLM \ndeployment, inference optimization, fine-tuning, and production serving across\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12320&hl=en&sa=X&d=16202500750200898582&ei=v7VkaNnMJffWieoPvsyt2AE&scisig=AAZF9b--UIAtYzwloYca2LhAL11r&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "HornBro: Homotopy-Like Method for Automated Quantum Program Repair", "first_label": ["APR"], "second_label": ["Repair"], "data": "S Tan, L Lu, D Xiang, T Chu, C Lang, J Chen, X Hu\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nQuantum programs provide exponential speedups compared to classical programs \nin certain areas, but they also inevitably encounter logical faults. Automatically \nrepairing quantum programs is much more challenging than repairing classical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715751&hl=en&sa=X&d=13228585835236654799&ei=v7VkaLilJM2l6rQPrcnDyAw&scisig=AAZF9b-8_CqaMqv576h_a4v0IZHT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
