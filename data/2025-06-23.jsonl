{"title": "From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Y Mao, T Cui, P Liu, D You, H Zhu\\xc2\\xa0- arXiv preprint arXiv:2506.15170, 2025\nLarge language models (LLMs) are rapidly evolving from single-modal systems to \nmultimodal LLMs and intelligent agents, significantly expanding their capabilities \nwhile introducing increasingly severe security risks. This paper presents a systematic \nsurvey of the growing complexity of jailbreak attacks and corresponding defense \nmechanisms within the expanding LLM ecosystem. We first trace the developmental \ntrajectory from LLMs to MLLMs and Agents, highlighting the core security challenges\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAdaptive attacks break defenses against indirect prompt injection\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15170&hl=en&sa=X&d=16427093263132639213&ei=bfRXaNbtKffWieoP1-jt-QU&scisig=AAZF9b-zqUEdPZ8IyWJxfUDycl5Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang", "Richard Fang - new related research"]}
{"title": "Red teaming large language models: A comprehensive review and critical analysis", "first_label": ["LLM"], "second_label": [], "data": "MS Jabbar, S Al-Azani, A Alotaibi, M Ahmed\\xc2\\xa0- Information Processing & Management, 2025\nSecuring large language models (LLMs) remains a critical challenge as their \nadoption across various sectors rapidly grows. While advancements in LLM \ndevelopment have enhanced their capabilities, inherent vulnerabilities continue to \npose significant risks, exposing these models to various forms of attack. This study \nprovides a comprehensive review of LLMs' red teaming, distinguished by its broad \ncoverage and intuitive organization. It systematically explores a range of red teaming\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0306457325001803&hl=en&sa=X&d=5668631129952397970&ei=bfRXaNbtKffWieoP1-jt-QU&scisig=AAZF9b8yq_zp48Y4DCmxQzzy_BHh&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Visualization Task Taxonomy to Understand the Fuzzing Internals", "first_label": ["Fuzzing"], "second_label": [], "data": "S Kummita, M Miao, E Bodden, S Wei\\xc2\\xa0- ACM Transactions on Software Engineering\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGreybox fuzzing is used extensively in research and practice. There are umpteen \npublications that improve greybox fuzzing. However, to what extent do these \nimprovements affect the internal components or internals of a given fuzzer is not yet\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3718346&hl=en&sa=X&d=6310038100822609560&ei=bfRXaPfRL6u26rQPmuu-OA&scisig=AAZF9b_Ue_jmzHRI425oDGHolQub&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "RIMFuzz: real-time impact-aware mutation for library API fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "X Wang, L Zhao\\xc2\\xa0- Journal of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs libraries merely expose APIs to developers rather than directly handling user \ninput, applying fuzzing to libraries requires fuzz drivers to help process fuzzer-\nprovided input and invoke APIs. To reduce manual effort and avoid reliance on\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00050-1&hl=en&sa=X&d=11566396351270247841&ei=bfRXaPfRL6u26rQPmuu-OA&scisig=AAZF9b9NzGapAGT-Gt26V3wejXNn&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "deepSURF: Detecting Memory Safety Vulnerabilities in Rust Through Fuzzing LLM-Augmented Harnesses", "first_label": ["Vulnerabilities", "LLM", "Fuzzing"], "second_label": ["Detection"], "data": "G Androutsopoulos, A Bianchi\\xc2\\xa0- arXiv preprint arXiv:2506.15648, 2025\nAlthough Rust ensures memory safety by default, it also permits the use of unsafe \ncode, which can introduce memory safety vulnerabilities if misused. Unfortunately, \nexisting tools for detecting memory bugs in Rust typically exhibit limited detection\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15648&hl=en&sa=X&d=5470473754710042022&ei=bfRXaPfRL6u26rQPmuu-OA&scisig=AAZF9b-QLCAPbmOGA94zxamaJ1DB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Hong Jin Kang - new related research"]}
{"title": "A Multi-agent LLM-based JUit Test Generation with Strong Oracles", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation", "Agent"], "data": "Q Xu, G Wang, L Briand, K Liu\\xc2\\xa0- arXiv preprint arXiv:2506.02943, 2025\nUnit testing plays a critical role in ensuring software correctness. However, writing \nunit tests manually is laborious, especially for strong typed languages like Java, \nmotivating the need for automated approaches. Traditional methods primarily rely on\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02943&hl=en&sa=X&d=9080051622854454343&ei=bfRXaPfRL6u26rQPmuu-OA&scisig=AAZF9b-W733SKwSoE4FIE6fi3cJw&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "LLM-Powered Test Case Generation for Detecting Bugs in Plausible Programs", "first_label": ["LLM", "Bug", "Software Testing"], "second_label": ["Detection", "Generation"], "data": "K Liu, Z Chen, Y Liu, JM Zhang, M Harman, Y Han\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 63rd\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDetecting tricky bugs in plausible programs, those that pass existing test suites yet \nstill contain bugs, remains a significant challenge in software testing. To address this \nproblem, we propose TrickCatcher, an LLM-powered approach to generating test\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://chenzhenpeng18.github.io/papers/ACL25_AID.pdf&hl=en&sa=X&d=1138877347567479720&ei=bfRXaPfRL6u26rQPmuu-OA&scisig=AAZF9b9cIXBHNvROwFBS9vlx4ynw&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "David Lo - new related research", "Bach Le - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "An Empirical Study on Strong-Weak Model Collaboration for Repo-level Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "S Gandhi, A Naik, Y Xie, C Rose\\xc2\\xa0- arXiv preprint arXiv:2505.20182, 2025\nWe study cost-efficient collaboration between strong and weak language models for \nrepository-level code generation, where the weak model handles simpler tasks at \nlower cost, and the most challenging tasks are delegated to the strong model. While\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20182%3F&hl=en&sa=X&d=13261729674581282450&ei=bfRXaPfRL6u26rQPmuu-OA&scisig=AAZF9b_OpsNe4LRB8V9VkgGHB_Qn&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "David Lo - new related research"]}
{"title": "Formal verification for multi-agent path execution in stochastic environments", "first_label": ["Verification"], "second_label": ["Agent"], "data": "X Wang, J Liu, CD Nugent, S Xu, Y Xu\\xc2\\xa0- Engineering Applications of Artificial\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMulti-agent pathfinding aims to determine conflict-free paths for multiple agents in a \nshared environment. However, real-world uncertainties can disrupt preplanned \npaths, leading to delays and new conflicts. Addressing these challenges requires \nrobust strategies for path execution and adjustment. While many multi-agent \npathfinding algorithms have been proposed, this work does not introduce a new \nalgorithm. Instead, it presents an adjustment solution based on a set of constraint\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaExploring true test overfitting in dynamic automated program repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0952197625012679&hl=en&sa=X&d=6091033612981446249&ei=bfRXaMSwK4OuieoPyIM7&scisig=AAZF9b9KoklKCieLTbzKmviYCa6z&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["1 new citation to articles by Bach Le"]}
{"title": "System Prompt Extraction Attacks and Defenses in Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "BC Das, MH Amini, Y Wu\\xc2\\xa0- arXiv preprint arXiv:2505.23817, 2025\nThe system prompt in Large Language Models (LLMs) plays a pivotal role in guiding \nmodel behavior and response generation. Often containing private configuration \ndetails, user roles, and operational instructions, the system prompt has become an\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23817&hl=en&sa=X&d=8359490024520200495&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b9kewGVoQUmVLeek21BFko2&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift", "first_label": ["LLM"], "second_label": [], "data": "S Liang, J Liang, T Pang, C Du, A Liu, M Zhu, X Cao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInstruction tuning enhances large vision-language models (LVLMs) but increases \ntheir vulnerability to backdoor attacks due to their open design. Unlike prior studies in \nstatic settings, this paper explores backdoor attacks in LVLM instruction tuning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.pdf&hl=en&sa=X&d=5142527777954789704&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b_Zz7b9xsyiBVRqo7nDX3YO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, M Dras, U Naseem\\xc2\\xa0- arXiv preprint arXiv:2506.02442, 2025\nThis paper presents a systematic evaluation of Large Language Models'(LLMs) \nbehavior on long-tail distributed (encrypted) texts and their safety implications. We \nintroduce a two-dimensional framework for assessing LLM safety:(1) instruction\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02442&hl=en&sa=X&d=15102350404536711280&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b_4gGVOvmiHUrKGvn2E4Vhh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems", "first_label": ["LLM"], "second_label": ["Agent", "Search"], "data": "X Li, J Chen, X Fang, S Ding, H Duan, Q Liu, K Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown remarkable capabilities in solving \ndiverse tasks. However, their proficiency in iteratively optimizing complex solutions \nthrough learning from previous feedback remains insufficiently explored. To bridge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10764&hl=en&sa=X&d=1134890120116902745&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b8s_mGNSGwzfKFs6o2hgsbd&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents", "first_label": ["LLM", "Code"], "second_label": ["Agent", "Reasoning"], "data": "K Hariharan, U Girit, A Wang, J Andreas\\xc2\\xa0- arXiv preprint arXiv:2506.00172, 2025\nBenchmarks for large language models (LLMs) have predominantly assessed short-\nhorizon, localized reasoning. Existing long-horizon suites (eg SWE-bench) rely on \nmanually curated issues, so expanding or tuning difficulty demands expensive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00172&hl=en&sa=X&d=7723120566071680437&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b-MEatAoZUO5Dw1f9NQmtaH&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Lifelong Safety Alignment for Language Models", "first_label": ["LLM"], "second_label": [], "data": "H Wang, Z Qin, Y Zhao, C Du, M Lin, X Wang, T Pang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLMs have made impressive progress, but their growing capabilities also expose \nthem to highly flexible jailbreaking attacks designed to bypass safety alignment. \nWhile many existing defenses focus on known types of attacks, it is more critical to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20259%3F&hl=en&sa=X&d=16834372085988299596&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b9d_59vHSVRWjToyCIlG2f5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "An Embarrassingly Simple Defense Against LLM Abliteration Attacks", "first_label": ["LLM"], "second_label": [], "data": "HA Shairah, HAAK Hammoud, B Ghanem, G Turkiyyah\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are typically aligned to comply with safety guidelines \nby refusing harmful instructions. A recent attack, termed abliteration, isolates and \nsuppresses the single latent direction most responsible for refusal behavior, enabling\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19056&hl=en&sa=X&d=3737202939224050048&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b8QKV5yRTnfm0WbZVG9RAGO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring", "first_label": ["LLM"], "second_label": [], "data": "Y Li, Q Sheng, Y Yang, X Zhang, J Cao\\xc2\\xa0- arXiv preprint arXiv:2506.09996, 2025\nThough safety alignment has been applied to most large language models (LLMs), \nLLM service providers generally deploy a subsequent moderation as the external \nsafety guardrail in real-world products. Existing moderators mainly practice a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09996&hl=en&sa=X&d=8967671192696781749&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b-I099JquXawda445fWweEs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Securing AI Agents with Information-Flow Control", "first_label": [], "second_label": ["Agent"], "data": "M Costa, B K\\xc3\\xb6pf, A Kolluri, A Paverd, M Russinovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI agents become increasingly autonomous and capable, ensuring their security \nagainst vulnerabilities such as prompt injection becomes critical. This paper explores \nthe use of information-flow control (IFC) to provide security guarantees for AI agents\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23643%3F&hl=en&sa=X&d=4534448032257376326&ei=bfRXaKHbM_uvieoPxs6ggQU&scisig=AAZF9b-ruPZ7fbYUs0K6HirRZr2z&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "FrontendBench: A Benchmark for Evaluating LLMs on Front-End Development via Automatic Evaluation", "first_label": ["LLM"], "second_label": [], "data": "H Zhu, Y Zhang, B Zhao, J Ding, S Liu, T Liu, D Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have made significant strides in front-end code \ngeneration. However, existing benchmarks exhibit several critical limitations: many \ntasks are overly simplistic, test cases often lack rigor, and end-to-end validation is\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13832&hl=en&sa=X&d=2112639698671840186&ei=bfRXaLDxLMy8ieoPt5yl6Qk&scisig=AAZF9b8od9psvT-Kt0tqTsCNZNad&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Legal Compliance Evaluation of Smart Contracts Generated By Large Language Models", "first_label": ["Smart Contracts", "LLM"], "second_label": [], "data": "C Wijayakoon, H Dong, HMN Bandara, Z Tari, A Soin\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSmart contracts can implement and automate parts of legal contracts, but ensuring \ntheir legal compliance remains challenging. Existing approaches such as formal \nspecification, verification, and model-based development require expertise in both\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00943&hl=en&sa=X&d=17006763348946692535&ei=bfRXaLDxLMy8ieoPt5yl6Qk&scisig=AAZF9b-0RVHMvQ2FmTdQzcshenfV&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "\\xe2\\x80\\x9cWe've met some problems\\xe2\\x80\\x9d: Developers' Issues With Privacy-Preserving Computation Techniques on Stack Overflow", "first_label": [], "second_label": [], "data": "D Reinhardt\nSoftware developers must adhere to privacy regulations and apply privacy principles. \nHowever, developers may not be privacy experts and hence are likely to encounter \nissues when choosing, applying, and implementing the corresponding Privacy\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://uni-goettingen.de/de/document/download/98c61f26e263a2856498e45d770845c8.pdf/kuehtreiber_IFIP_SEC2025.pdf&hl=en&sa=X&d=419570402408453543&ei=bfRXaLDxLMy8ieoPt5yl6Qk&scisig=AAZF9b96aDq9sNPVaEfiw8GIvHhe&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "An Android API Recommendation Approach Based on API Dependency Paths Learning", "first_label": [], "second_label": [], "data": "J Deng, J Liu, Y Liu, Y Yin, Y Xiao\\xc2\\xa0- Concurrency and Computation: Practice and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware development plays a crucial role in the modern mobile application domain, \nreflecting its significance through widespread application. With the continuous \nevolution and vast number of Android APIs, developers need to invest considerable\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.70159&hl=en&sa=X&d=1581092059695033857&ei=bfRXaLDxLMy8ieoPt5yl6Qk&scisig=AAZF9b_lc8pukNV90HXNbOurpw7s&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Technical Debt of Software Projects Based on Merge Code Comments", "first_label": ["Code"], "second_label": [], "data": "MHM de Ara\\xc3\\xbajo, C Costa, A Font\\xc3\\xa3o\\xc2\\xa0- Journal of Software Engineering Research and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDevelopers use code comments for a variety of reasons, such as explaining code, \ndocumenting specifications, communicating with other developers, and highlighting \nupcoming tasks. Software projects with minimal documentation often have a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://journals-sol.sbc.org.br/index.php/jserd/article/download/4801/3278&hl=en&sa=X&d=15287621864696684133&ei=bfRXaLDxLMy8ieoPt5yl6Qk&scisig=AAZF9b9fCCpMaXCkPjmdQDDH9aZ7&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Spec2RTL-Agent: Automated Hardware Code Generation from Complex Specifications Using LLM Agent Systems", "first_label": ["LLM", "Code"], "second_label": ["Generation", "Agent"], "data": "Z Yu, M Liu, M Zimmer, YC Lin, Y Liu, H Ren\\xc2\\xa0- arXiv preprint arXiv:2506.13905, 2025\nDespite recent progress in generating hardware RTL code with LLMs, existing \nsolutions still suffer from a substantial gap between practical application scenarios \nand the requirements of real-world RTL code development. Prior approaches either\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13905&hl=en&sa=X&d=12888586433964838774&ei=bfRXaLDxLMy8ieoPt5yl6Qk&scisig=AAZF9b84TVQbUOuys7zzXHXK7j0W&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Sharp Tools: How Developers Wield Agentic AI in Real Software Engineering Tasks", "first_label": [], "second_label": ["Agent"], "data": "A Kumar, Y Bajpai, S Gulwani, G Soares, E Murphy-Hill\\xc2\\xa0- arXiv e-prints, 2025\nAbstract Software Engineering Agents (SWE agents) can autonomously perform \ndevelopment tasks on benchmarks like SWE Bench, but still face challenges when \ntackling complex and ambiguous real-world tasks. Consequently, SWE agents are\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ui.adsabs.harvard.edu/abs/2025arXiv250612347K/abstract&hl=en&sa=X&d=312805220486512243&ei=bfRXaLDxLMy8ieoPt5yl6Qk&scisig=AAZF9b_8Q0dcc27PgpFMnFt8FiPo&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Zheng, X Qian, H Zhou, S Yang, Y He, S Jana\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models (LMs) show promise for vulnerability detection but struggle with \nlong, real-world code due to sparse and uncertain vulnerability locations. These \nissues, exacerbated by token limits, often cause models to miss vulnerability-related\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17460&hl=en&sa=X&d=9334848497739178959&ei=bfRXaJ66KKKr6rQP49vTsAY&scisig=AAZF9b_EDz61GJXVBfE-c2mGro5g&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "LEDGE: Leveraging Dependency Graphs for Enhanced Context Aware Documentation Generation", "first_label": [], "second_label": ["Generation", "Graph"], "data": "M Panchal, A Deo, V Prabhu, P Doshi, C Bhadane\\xe2\\x80\\xa6 - 2025\nIn software engineering, effective documentation is crucial for understanding \ncomplex codebases, yet it often remains incomplete or outdated, hindering \ndeveloper productivity. This paper introduces LEDGE (Leveraging Dependency\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchsquare.com/article/rs-6827966/latest&hl=en&sa=X&d=7398073546507241007&ei=bfRXaJ66KKKr6rQP49vTsAY&scisig=AAZF9b8FvrTM6Xo_TWLAo9mCTojQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Scalable Verification with Applications to Hardware Security", "first_label": ["Verification"], "second_label": [], "data": "S Dinesh - 2025\nHardware design is currently at a pivotal juncture. With Moore's law reaching its limits \nand generative AI (GAI) workloads demanding unprecedented amounts of resources \n[162], hardware architects increasingly rely on sophisticated microarchitectural \noptimizations to extract maximal performance from available resources. However, \nhistory shows that these advanced optimizations often inadvertently introduce new \nmicroarchitectural vulnerabilities [125, 137, 210, 203, 217, 43, 215, 216], leaking\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-133.pdf&hl=en&sa=X&d=4884069570554781401&ei=bfRXaPeuLtSWieoP9obCkQw&scisig=AAZF9b-elcZmuXpSc6HbMcgIubbe&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": "How to Solve Cybersecurity Once and For All", "first_label": [], "second_label": [], "data": "M B\\xc3\\xb6hme\\xc2\\xa0- IEEE Security & Privacy, 2025\nAt last year's Pwn2Own competition, one individual successfully exploited all major \nbrowsers\\xe2\\x80\\x94Chrome, Firefox, Safari, and Edge\\xe2\\x80\\x94used by billions of people worldwide. \nDespite decades of security research, the discovery of new vulnerabilities in \nimportant software systems continues unabated.\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Program Repair\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11038978/&hl=en&sa=X&d=7239506873235168075&ei=bfRXaPeuLtSWieoP9obCkQw&scisig=AAZF9b8hsmaumJjrES0J5v6cAeQf&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Make a Feint to the East While Attacking in the West: Blinding LLM-Based Code Auditors with Flashboom Attacks", "first_label": ["LLM", "Code"], "second_label": [], "data": "X Li, Y Li, H Wu, Y Zhang, K Xu, X Cheng, S Zhong\\xe2\\x80\\xa6\\xc2\\xa0- 2025 IEEE Symposium on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM-based vulnerability auditors (eg, GitHub Copilot) represent a significant \nadvancement in automated code analysis, offering precise detection of security \nvulnerabilities. This paper explores the potential to circumvent LLM-based \nvulnerability auditors by diverting their focus, decided by the LLM attention \nmechanism, away from real vulnerable code segments. In these LLM-based \nvulnerability auditors, the attention mechanism is supposed to focus on potentially\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection and repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11023369/&hl=en&sa=X&d=3487901414580867567&ei=bfRXaIShMu2rieoPk6bG-Qo&scisig=AAZF9b8iBerXg9jQTJQuotoI1IuT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "AI Assisted Validation and Verification of Software: Enhancing System Test Verification Processes through Large Language Model Classification", "first_label": ["Verification", "LLM", "Software Testing"], "second_label": [], "data": "T Wallin, K Widholm - 2025\nAs the automotive industry becomes increasingly software-driven, the complexity of \nvalidation and verification processes in embedded systems continues to grow. Within \nthe Powertrain Control department at Scania CV AB, ensuring alignment between \nsystem test protocols and test scripts is a critical yet time-consuming task, currently \nperformed manually. This thesis investigates the potential of leveraging Large \nLanguage Models (LLMs), a subfield of Natural Language Processing (NLP), in a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAssessing generalizability of codebert\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.diva-portal.org/smash/get/diva2:1965211/FULLTEXT01.pdf&hl=en&sa=X&d=18163299097298700087&ei=bfRXaIShMu2rieoPk6bG-Qo&scisig=AAZF9b-_SbQQoN6cBehYNLwhIltv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "Teaching an Old LLM Secure Coding: Localized Preference Optimization on Distilled Preferences", "first_label": ["LLM"], "second_label": ["Localization"], "data": "M Saqib, S Chakraborty, S Karmaker\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM generated code often contains security issues. We address two key challenges \nin improving secure code generation. First, obtaining high quality training data \ncovering a broad set of security issues is critical. To address this, we introduce a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00419&hl=en&sa=X&d=3471320712326210844&ei=bfRXaPuiNbXCieoPsbu2sQ4&scisig=AAZF9b-zP6iuspafIpJ9gFQhBsZE&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "LEGO: Synthesizing IoT Device Components Based on Static Analysis and Large Language Models", "first_label": ["LLM", "Static Analysis"], "second_label": [], "data": "L Liu, T Wang, W Chen, J Wei, W Wang, G Wu\\xc2\\xa0- \\xe2\\x80\\xa6\\xc2\\xa0of the ACM on Interactive, Mobile\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIoT device components---digital representations of IoT devices within a platform and \ntypically developed using Software Development Kits (SDKs)---are essential for \nensuring seamless connectivity between IoT platforms and physical devices\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729482&hl=en&sa=X&d=4697730062038414973&ei=bfRXaPuiNbXCieoPsbu2sQ4&scisig=AAZF9b9mKRftAARYz21wA4iN9Vpv&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Impact of Developer Queries on the Effectiveness of Conversational Large Language Models in Programming", "first_label": ["LLM"], "second_label": [], "data": "V Taneski, S Karakati\\xc4\\x8d, P Rek, G Jo\\xc5\\xa1t\\xc2\\xa0- Applied Sciences, 2025\nThis study investigates the effects of LLM-based coding assistance on web \napplication development by students using a frontend framework. Rather than \ncomparing different models, it focuses on how students interact with LLM tools to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2076-3417/15/12/6836&hl=en&sa=X&d=17897532974991926623&ei=bfRXaPuiNbXCieoPsbu2sQ4&scisig=AAZF9b8V0NAX5f9cFyas36iVdpxe&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Advancing Bug Report Management: Graph-Based Modeling, Large Language Models, and Quality Improvement", "first_label": ["LLM", "Bug"], "second_label": ["Graph"], "data": "J Acharya - 2025\nSoftware maintenance is a critical, cost-intensive phase of software development, \nheavily dependent on effective bug report management. Bug reports are vital artifacts \nin this process, enabling developers to identify, prioritize, and resolve software\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ucalgary.scholaris.ca/bitstreams/ee6b9951-a0ca-403d-98a4-72a8ee61d178/download&hl=en&sa=X&d=13389235140432076353&ei=bfRXaPuiNbXCieoPsbu2sQ4&scisig=AAZF9b_1pKjCkp47yio9LkXZADAe&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Beyond LLMs: An Exploration of Small Open-source Language Models in Logging Statement Generation", "first_label": ["LLM"], "second_label": ["Generation"], "data": "R Zhong, Y Li, G Yu, W Gu, J Kuang, Y Huo, MR Lyu\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nEffective software maintenance heavily relies on high-quality logging statements, but \nmanual logging is challenging, error-prone, and insufficiently standardized, often \nleading to inconsistent log quality. While large language models have shown\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16590&hl=en&sa=X&d=4658939216487304827&ei=bfRXaP3INtGM6rQPs-LTyAw&scisig=AAZF9b8Yps4YxHXbX2rxYMABN_xG&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Unified Software Engineering agent as AI Software Engineer", "first_label": [], "second_label": ["Agent"], "data": "L Applis, Y Zhang, S Liang, N Jiang, L Tan\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe growth of Large Language Model (LLM) technology has raised expectations for \nautomated coding. However, software engineering is more than coding and is \nconcerned with activities including maintenance and evolution of a project. In this\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.14683&hl=en&sa=X&d=1343737154165269132&ei=OEhWaMCQH4OuieoPyIM7&scisig=AAZF9b8xZpv-JyJjXk2VF56_Q793&oi=scholaralrt&hist=ylyK0_8AAAAJ:17845465921536999430:AAZF9b8uxzftV24sircdvgSPVS-f&html=&pos=0&folt=art", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new articles", "Xin ZHOU - new related research", "Bach Le - new related research", "David Lo - new related research", "9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Empirical Evaluation of Large Language Models in Automated Program Repair", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "J Sun, F Li, X Qi, H Zhang, J Jiang\\xc2\\xa0- arXiv preprint arXiv:2506.13186, 2025\nThe increasing prevalence of software bugs has made automated program repair \n(APR) a key research focus. Large language models (LLMs) offer new opportunities \nfor APR, but existing studies mostly rely on smaller, earlier-generation models and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13186&hl=en&sa=X&d=14847840234469800688&ei=OEhWaLi_HdGM6rQPs-LTyAw&scisig=AAZF9b_y41VlOZ86kZEkYfQJ-XbI&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research", "8 new citations to articles by Bach Le", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "9 new citations to articles by Abhik Roychoudhury"]}
{"title": "From Empirical Evaluation to Context-Aware Enhancement: Repairing Regression Errors with LLMs", "first_label": ["LLM"], "second_label": ["Repair"], "data": "A Ho, T Le-Cong, B Le, C Rizkallah\\xc2\\xa0- arXiv preprint arXiv:2506.13182, 2025\n[...] Since then, various APR approaches, especially those leveraging the power of \nlarge language models (LLMs), have been rapidly developed to fix general software \nbugs. Unfortunately, the effectiveness of these advanced techniques in the context of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13182&hl=en&sa=X&d=16410952572033246035&ei=OEhWaLi_HdGM6rQPs-LTyAw&scisig=AAZF9b8A16cJdbkQ05iwE9pB-pF5&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "2 new citations to articles by Hong Jin Kang", "Thanh Le-Cong - new articles", "Bach Le - new articles", "4 new citations to articles by Thanh Le-Cong", "8 new citations to articles by Bach Le", "Quang-Cuong Bui - new related research", "9 new citations to articles by Abhik Roychoudhury"]}
{"title": "VulStamp: Vulnerability Assessment using Large Language Model", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "M Hu, X Xie, J Li, M Chen\\xc2\\xa0- arXiv preprint arXiv:2506.11484, 2025\nAlthough modern vulnerability detection tools enable developers to efficiently identify \nnumerous security flaws, indiscriminate remediation efforts often lead to superfluous \ndevelopment expenses. This is particularly true given that a substantial portion of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11484&hl=en&sa=X&d=10210371631874132603&ei=OEhWaLi_HdGM6rQPs-LTyAw&scisig=AAZF9b8D5-GPG5LVOP0Ejn5MaoBB&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "How Does LLM Reasoning Work for Code? A Survey and a Call to Action", "first_label": ["LLM", "Code"], "second_label": ["Reasoning"], "data": "I Ceka, S Pujar, I Manotas, G Kaiser, B Ray, S Ramji\\xc2\\xa0- arXiv preprint arXiv:2506.13932, 2025\nThe rise of large language models (LLMs) has led to dramatic improvements across \na wide range of natural language tasks. These advancements have extended into \nthe domain of code, facilitating complex tasks such as code generation, translation\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13932&hl=en&sa=X&d=2497012154074029495&ei=OEhWaLi_HdGM6rQPs-LTyAw&scisig=AAZF9b-zIykdYpRoGd_3N7etDyJQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Bach Le - new related research", "David Lo - new related research", "Hong Jin Kang - new related research", "9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Andromeda: Debugging Database Performance Issues with Retrieval-Augmented Large Language Models", "first_label": ["LLM", "Bug"], "second_label": [], "data": "P Wang, S Chen, J Fan, B Wu, N Tang, J Tan\\xc2\\xa0- Companion of the 2025 International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDebugging performance issues in a database management system (DBMS) is \ntedious and challenging, even for experienced database administrators (DBAs). \nThus, with the rapid advancement of large language models (LLMs), developing an\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3722212.3725080&hl=en&sa=X&d=11546786090620021914&ei=OEhWaLi_HdGM6rQPs-LTyAw&scisig=AAZF9b9ePwZ-JpKhnVkDq6wmWEpg&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Identifying Open-Source Threat Detection Resources on GitHub: A Scalable Machine Learning Approach", "first_label": [], "second_label": ["Detection"], "data": "M Kern, M Landauer, F Skopik, E Weippl\\xc2\\xa0- International Journal of Information\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMany businesses rely on open-source software modules to build their technology \nstacks. However, those who lack domain expertise may struggle to find the right \nsoftware due to unfamiliar terminology and specific names. As a consequence, \nsearch engines and other platforms often cannot be utilized effectively to discover \nappropriate solutions. There is thus a need for a more applicable approach to assist \nnon-domain experts in navigating the vastness of available repositories, enabling\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTopic Recommendation for GitHub Repositories: How Far Can\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10207-025-01069-1&hl=en&sa=X&d=5522668164929562503&ei=OEhWaJz5DLXCieoPsbu2sQ4&scisig=AAZF9b_4eNRxtIWbbSQ-wamWZZrj&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang", "David Lo - new related research", "4 new citations to articles by Thanh Le-Cong"]}
{"title": "Training Language Models to Generate Quality Code with Program Analysis Feedback", "first_label": ["LLM", "Code"], "second_label": [], "data": "F Yao, Z Wang, L Liu, J Cui, L Zhong, X Fu, H Mai\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode generation with large language models (LLMs), often termed vibe coding, is \nincreasingly adopted in production but fails to ensure code quality, particularly in \nsecurity (eg, SQL injection vulnerabilities) and maintainability (eg, missing type\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22704&hl=en&sa=X&d=13720297852295427429&ei=OEhWaNTwB9zM6rQPmJLS4Q8&scisig=AAZF9b9qU1hJff-ona5ynwmi0w3O&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution", "first_label": ["LLM"], "second_label": [], "data": "Y Wang, Z Peng, Y Wang, Z Wei, H Yu, Z Zhu\\xc2\\xa0- arXiv preprint arXiv:2506.12728, 2025\nLLMs demonstrate strong performance in auto-mated software engineering, \nparticularly for code generation and issue resolution. While proprietary models like \nGPT-4o achieve high benchmarks scores on SWE-bench, their API dependence\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12728&hl=en&sa=X&d=2604248405659445617&ei=OEhWaNTwB9zM6rQPmJLS4Q8&scisig=AAZF9b81DHSvOhQG3is-OJnqV2OF&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=3&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "David Lo - new related research", "4 new citations to articles by Xin ZHOU", "Abhik Roychoudhury - new related research"]}
{"title": "Reductive Analysis with Compiler-Guided Large Language Models for Input-Centric Code Optimizations", "first_label": ["LLM", "Code"], "second_label": [], "data": "X Wang, X Hui, C Liao, X Shen\\xc2\\xa0- Proceedings of the ACM on Programming\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInput-centric program optimization aims to optimize code by considering the relations \nbetween program inputs and program behaviors. Despite its promise, a long-\nstanding barrier for its adoption is the difficulty of automatically identifying critical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729282&hl=en&sa=X&d=4066048552262082451&ei=OEhWaKeTENzM6rQPmJLS4Q8&scisig=AAZF9b_cHHDNeP008iH4qW9Tn7JR&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "BugGen: A Self-Correcting Multi-Agent LLM Pipeline for Realistic RTL Bug Synthesis", "first_label": ["LLM", "Bug"], "second_label": ["Agent"], "data": "S Jasper, M Luu, E Pan, A Tyagi, M Quinn, J Hu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nHardware complexity continues to strain verification resources, motivating the \nadoption of machine learning (ML) methods to improve debug efficiency. However, \nML-assisted debugging critically depends on diverse and scalable bug datasets\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10501&hl=en&sa=X&d=18282061101799185605&ei=OEhWaKeTENzM6rQPmJLS4Q8&scisig=AAZF9b84MK6Vvw_jQZEsGjayFUqG&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "The Foundation Cracks: A Comprehensive Study on Bugs and Testing Practices in LLM Libraries", "first_label": ["LLM", "Bug", "Software Testing"], "second_label": [], "data": "W Jiang, X Zhang, X Xie, J Yu, Y Zhi, S Ma, C Shen\\xc2\\xa0- arXiv preprint arXiv:2506.12320, 2025\nLarge Language Model (LLM) libraries have emerged as the foundational \ninfrastructure powering today's AI revolution, serving as the backbone for LLM \ndeployment, inference optimization, fine-tuning, and production serving across\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12320&hl=en&sa=X&d=16202500750200898582&ei=OEhWaKeTENzM6rQPmJLS4Q8&scisig=AAZF9b--UIAtYzwloYca2LhAL11r&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "Automatic Qiskit Code Refactoring Using Large Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "JM Su\\xc3\\xa1rez, LM Bibb\\xc3\\xb3, J Bogado, A Fernandez\\xc2\\xa0- arXiv preprint arXiv:2506.14535, 2025\nAs quantum software frameworks evolve, developers face increasing challenges in \nmaintaining compatibility with rapidly changing APIs. In this work, we present a novel \nmethodology for refactoring Qiskit code using large language models (LLMs). We\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.14535&hl=en&sa=X&d=4707492068215582196&ei=OEhWaKeTENzM6rQPmJLS4Q8&scisig=AAZF9b8ijIjD2XcJlduBt3t6lA4m&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Incremental learning of code authors over time", "first_label": ["Code"], "second_label": [], "data": "S Gong, H Zhong\\xc2\\xa0- Journal of Systems and Software, 2025\nIdentifying code authors is essential in many research topics, and various \napproaches have been proposed. Recent studies show that the temporal effect can \nsignificantly affect existing approaches: their trained models rapidly become \noutdated and ineffective due to the evolution of code styles over time. To our \nknowledge, only a recent approach tries to alleviate the temporal effect. This \napproach treats the temporal effect problem as a cross-domain problem and uses\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaOn the Usage of Continual Learning for Out-of-Distribution\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225001955&hl=en&sa=X&d=6859829797092896473&ei=OEhWaJvZGaKr6rQP49vTsAY&scisig=AAZF9b9vU0kQT_Q4w4DcQMRitS09&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "VIS-Shepherd: Constructing Critic for LLM-based Data Visualization Generation", "first_label": ["LLM"], "second_label": ["Generation"], "data": "B Pan, Y Fu, K Wang, J Lu, L Pan, Z Qian, Y Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nData visualization generation using Large Language Models (LLMs) has shown \npromising results but often produces suboptimal visualizations that require human \nintervention for improvement. In this work, we introduce VIS-Shepherd, a specialized \nMultimodal Large Language Model (MLLM)-based critic to evaluate and provide \nfeedback for LLM-generated data visualizations. At the core of our approach is a \nframework to construct a high-quality visualization critique dataset, where we collect\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCodeultrafeedback: An llm-as-a-judge dataset for aligning large\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13326&hl=en&sa=X&d=3993740377334061467&ei=OEhWaJvZGaKr6rQP49vTsAY&scisig=AAZF9b8HSCvWaproKnemIEGbLJk1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "MalGuard: Towards Real-Time, Accurate, and Actionable Detection of Malicious Packages in PyPI Ecosystem", "first_label": [], "second_label": ["Detection"], "data": "X Gao, X Sun, S Cao, K Huang, D Wu, X Liu, X Lin\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMalicious package detection has become a critical task in ensuring the security and \nstability of the PyPI. Existing detection approaches have focused on advancing \nmodel selection, evolving from traditional machine learning (ML) models to large \nlanguage models (LLMs). However, as the complexity of the model increases, the \ntime consumption also increases, which raises the question of whether a lightweight \nmodel achieves effective detection. Through empirical research, we demonstrate that\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection and repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.14466&hl=en&sa=X&d=17613968064181352353&ei=OEhWaJvZGaKr6rQP49vTsAY&scisig=AAZF9b9f_Vwoe2-2WKWEQFGCqWDv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=3&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "Using LLMs for Security Advisory Investigations: How Far Are We?", "first_label": ["LLM"], "second_label": [], "data": "BF Abdullah, YS Nugroho, B Reid, RG Kula, K Shimari\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly used in software security, but their \ntrustworthiness in generating accurate vulnerability advisories remains uncertain. \nThis study investigates the ability of ChatGPT to (1) generate plausible security \nadvisories from CVE-IDs,(2) differentiate real from fake CVE-IDs, and (3) extract CVE-\nIDs from advisory descriptions. Using a curated dataset of 100 real and 100 fake \nCVE-IDs, we manually analyzed the credibility and consistency of the model's\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13161&hl=en&sa=X&d=14130687776360958501&ei=OEhWaMicBqu26rQPmuu-OA&scisig=AAZF9b8bF9Czw2J_XQJ4C7dB3TnU&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 new citations to articles by Thanh Le-Cong", "8 new citations to articles by Bach Le"]}
{"title": "Refactor Me If You Can: When AI Rewrites The Mess", "first_label": [], "second_label": [], "data": "E Neman, O Persson\\xc2\\xa0- LU-CS-EX, 2025\nMaintaining the quality of source code through refactoring is an important factor in \nachieving a sustainable software development process. Traditionally, refactoring has \nbeen a manual and time-consuming process, but Large Language Models (LLMs) \nhave shown promising capabilities in many software-related tasks, allowing \ndevelopers to use these models for automatic refactoring. Our research investigates \nthe code refactoring capabilities in improving the maintainability of a large, industrial\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaThanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://lup.lub.lu.se/luur/download%3Ffunc%3DdownloadFile%26recordOId%3D9200106%26fileOId%3D9200112&hl=en&sa=X&d=5695497971825654644&ei=OEhWaMicBqu26rQPmuu-OA&scisig=AAZF9b9a2ah-TzK0eiqGAJIgJAkm&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=2&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 new citations to articles by Thanh Le-Cong", "8 new citations to articles by Bach Le"]}
{"title": "A Framework for Blockchain-Based Secure Management of Mobile Healthcare (mHealth) Systems", "first_label": ["Blockchain"], "second_label": [], "data": "A Alkhalil, A Razzaq, A Ahmad, M Abdelrhman\\xe2\\x80\\xa6\\xc2\\xa0- Journal of Web Engineering, 2025\nIn recent years, several research and development initiatives have focused on \ndeveloping secure and trustworthy systems for the healthcare industry via pervasive \nand mobile healthcare (mHealth) solutions. State-of-the-art mHealth solutions \nprimarily rely on centralized storage, such as cloud computing servers, which may \nescalate the maintenance costs, require ever-increasing storage infrastructure, and \npose privacy and security risks to the health-critical data produced, consumed, and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/10243554/11037625/11037630.pdf&hl=en&sa=X&d=9468542096744583349&ei=OEhWaN3NDr2W6rQPs9Oj8A8&scisig=AAZF9b_hqimMR537VL3R1lifwp88&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=3&folt=cit", "author": ["Bach Le"], "ref": ["8 new citations to articles by Bach Le"]}
{"title": "Reusability in Blockchain", "first_label": ["Blockchain"], "second_label": [], "data": "M Ramachandran\\xc2\\xa0- Blockchain Engineering, 2025\nReusability in blockchain focuses on reusing pre-built components, such as smart \ncontracts, algorithms, and protocols, across multiple dApps. This reduces \ndevelopment time, cuts costs, and enhances system efficiency. The chapter \nintroduces Smart Contract as a Service (SCaaS), which provides reusable smart \ncontract templates to developers. Reusability aligns with blockchain sustainability by \nlowering energy consumption and promoting long-term system scalability. By\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-96-4360-8_6&hl=en&sa=X&d=169691411675943046&ei=OEhWaN3NDr2W6rQPs9Oj8A8&scisig=AAZF9b8gdEyXnNgDlZdiHIDoIcke&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=4&folt=cit", "author": ["Bach Le"], "ref": ["8 new citations to articles by Bach Le"]}
{"title": "The Socio-Economic Impact of Metaverse Technologies on Financial Institutions and Public Investments", "first_label": [], "second_label": [], "data": "AL Paul\nThe metaverse, an emerging digital frontier, is transforming how individuals, \nbusinesses, and governments interact in virtual environments. Envisioned as \ninterconnected immersive spaces enabled by technologies such as virtual reality \n(VR), augmented reality (AR), blockchain, and artificial intelligence (AI), the \nmetaverse is rapidly expanding beyond entertainment into sectors including finance \nand public governance. As financial institutions and public investors increasingly\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Anthony-Paul-2/publication/392704384_The_Socio-Economic_Impact_of_Metaverse_Technologies_on_Financial_Institutions_and_Public_Investments/links/684e6dc711be4823fbde7b68/The-Socio-Economic-Impact-of-Metaverse-Technologies-on-Financial-Institutions-and-Public-Investments.pdf&hl=en&sa=X&d=18375581120918309044&ei=OEhWaN3NDr2W6rQPs9Oj8A8&scisig=AAZF9b9BgvfNegcnMM0BIFEYKZN7&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=5&folt=cit", "author": ["Bach Le"], "ref": ["8 new citations to articles by Bach Le"]}
{"title": "Ethical Implications of AI-Driven Investment Tools in Public Sector Finance", "first_label": [], "second_label": [], "data": "R Ajax\nArtificial Intelligence (AI) is rapidly transforming public sector finance by enhancing \ninvestment analysis, improving resource allocation, and fostering data-driven \npolicymaking. However, the adoption of AI-driven investment tools also raises \npressing ethical concerns, particularly around algorithmic bias, transparency, \naccountability, data privacy, and public trust. As governments increasingly rely on AI \nto guide critical investment decisions, there is a growing need to scrutinize the ethical\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Raymond-Ajax/publication/392705933_Ethical_Implications_of_AI-Driven_Investment_Tools_in_Public_Sector_Finance/links/684e708e474abd185bd8e433/Ethical-Implications-of-AI-Driven-Investment-Tools-in-Public-Sector-Finance.pdf&hl=en&sa=X&d=10977577863542065423&ei=OEhWaN3NDr2W6rQPs9Oj8A8&scisig=AAZF9b9P-9xGKMtRMTb2FccLYqc6&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=6&folt=cit", "author": ["Bach Le"], "ref": ["8 new citations to articles by Bach Le"]}
{"title": "KRAKEN: Program-Adaptive Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A ZHOU, H HUANG, C ZHANG - 2025\nDespite numerous advances, most existing fuzzers still require more than 24 hours to \nthoroughly test the target programs to achieve satisfactory code coverage or bug \ndetection results [7, 32, 42, 64]. Recently, as cloud-based computing and multicore\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://seviezhou.github.io/files/kraken.pdf&hl=en&sa=X&d=6944396394299119143&ei=OEhWaNyHF-Ws6rQPkO7OyQk&scisig=AAZF9b9QILhkfV1b1x87AW8NkoEo&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Levels of Autonomy for AI Agents", "first_label": [], "second_label": ["Agent"], "data": "KJ Feng, DW McDonald, AX Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.12469, 2025\nAutonomy is a double-edged sword for AI agents, simultaneously unlocking \ntransformative possibilities and serious risks. How can agent developers calibrate \nthe appropriate levels of autonomy at which their agents should operate? We argue \nthat an agent's level of autonomy can be treated as a deliberate design decision, \nseparate from its capability and operational environment. In this work, we define five \nlevels of escalating agent autonomy, characterized by the roles a user can take when\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaVoice-Enabled AI Agents can Perform Common Scams\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12469&hl=en&sa=X&d=4354226690169182572&ei=OEhWaM_KCdGM6rQPs-LTyAw&scisig=AAZF9b-wYASRN4tKQ1VBXhiunkjk&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "SoK: The Privacy Paradox of Large Language Models: Advancements, Privacy Risks, and Mitigation", "first_label": ["LLM"], "second_label": [], "data": "Y Shanmugarasa, M Ding, MA Chamikara\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are sophisticated artificial intelligence systems that \nenable machines to generate human-like text with remarkable precision. While LLMs \noffer significant technological progress, their development using vast amounts of \nuser data scraped from the web and collected from extensive user interactions poses \nrisks of sensitive information leakage. Most existing surveys focus on the privacy \nimplications of the training data but tend to overlook privacy risks from user\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12699&hl=en&sa=X&d=11967645710981260650&ei=OEhWaM_KCdGM6rQPs-LTyAw&scisig=AAZF9b87RGce-US28ZZYdxSpzFit&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "From Promise to Peril: Rethinking Cybersecurity Red and Blue Teaming in the Age of LLMs", "first_label": ["LLM"], "second_label": [], "data": "A Abuadbba, C Hicks, K Moore, V Mavroudis\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are set to reshape cybersecurity by augmenting red \nand blue team operations. Red teams can exploit LLMs to plan attacks, craft phishing \ncontent, simulate adversaries, and generate exploit code. Conversely, blue teams \nmay deploy them for threat intelligence synthesis, root cause analysis, and \nstreamlined documentation. This dual capability introduces both transformative \npotential and serious risks. This position paper maps LLM applications across\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13434&hl=en&sa=X&d=2343985441905369680&ei=OEhWaM_KCdGM6rQPs-LTyAw&scisig=AAZF9b8oPWwA51ZflAK-U8wHonyY&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=2&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "AIRTBench: Measuring Autonomous AI Red Teaming Capabilities in Language Models", "first_label": ["LLM"], "second_label": [], "data": "A Dawson, R Mulla, N Landers, S Caldwell\\xc2\\xa0- arXiv preprint arXiv:2506.14682, 2025\nWe introduce AIRTBench, an AI red teaming benchmark for evaluating language \nmodels' ability to autonomously discover and exploit Artificial Intelligence and \nMachine Learning (AI/ML) security vulnerabilities. The benchmark consists of 70 \nrealistic black-box capture-the-flag (CTF) challenges from the Crucible challenge \nenvironment on the Dreadnode platform, requiring models to write python code to \ninteract with and compromise AI systems. Claude-3.7-Sonnet emerged as the clear\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites, 2024\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.14682&hl=en&sa=X&d=6408004129682148587&ei=OEhWaM_KCdGM6rQPs-LTyAw&scisig=AAZF9b8JqinYoexQ1D3nksq_I-Lu&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=3&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "VulBinLLM: LLM-powered Vulnerability Detection for Stripped Binaries", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "N Hussain, H Chen, C Tran, P Huang, Z Li, P Chugh\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecognizing vulnerabilities in stripped binary files presents a significant challenge in \nsoftware security. Although some progress has been made in generating human-\nreadable information from decompiled binary files with Large Language Models\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22010&hl=en&sa=X&d=10332909566617513173&ei=OEhWaKX4CuWs6rQPkO7OyQk&scisig=AAZF9b_uFh0VfBD1MzUN8jZA2T1m&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Rethinking the effects of data contamination in Code Intelligence", "first_label": ["Code"], "second_label": [], "data": "Z Yang, H Lin, Y He, J Xu, Z Sun, S Liu, P Wang, Z Yu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, code intelligence has gained increasing importance in the field of \nautomated software engineering. Meanwhile, the widespread adoption of Pretrained \nLanguage Models (PLMs) and Large Language Models (LLMs) has raised concerns\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02791&hl=en&sa=X&d=13914802631128746138&ei=OEhWaKX4CuWs6rQPkO7OyQk&scisig=AAZF9b9FbJDsSBQv15gRiA2JZNoe&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Anticipating Bugs: Ticket-Level Bug Prediction and Temporal Proximity Effects", "first_label": ["Bug"], "second_label": [], "data": "D La Prova, E Gentili, D Falessi\\xc2\\xa0- arXiv preprint arXiv:2506.14290, 2025\nThe primary goal of bug prediction is to optimize testing efforts by focusing on \nsoftware fragments, ie, classes, methods, commits (JIT), or lines of code, most likely \nto be buggy. However, these predicted fragments already contain bugs. Thus, the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.14290&hl=en&sa=X&d=7204056426952972327&ei=OEhWaKjnIPiJ6rQPh4zZ-Q8&scisig=AAZF9b-nd66JTlFIYlSHEhatnchG&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Quality Assessment of Python Tests Generated by Large Language Models", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "V Alves, C Bezerra, I Machado, L Rocha, T Virg\\xc3\\xadnio\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe manual generation of test scripts is a time-intensive, costly, and error-prone \nprocess, indicating the value of automated solutions. Large Language Models \n(LLMs) have shown great promise in this domain, leveraging their extensive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.14297&hl=en&sa=X&d=16755182731362667839&ei=OEhWaKjnIPiJ6rQPh4zZ-Q8&scisig=AAZF9b-bNUeNhFbiN2vZE3g48XeI&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Cloud Infrastructure Management in the Age of AI Agents", "first_label": [], "second_label": ["Agent"], "data": "Z Yang, A Bhatnagar, Y Qiu, T Miao, PTJ Kon, Y Xiao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCloud infrastructure is the cornerstone of the modern IT industry. However, managing \nthis infrastructure effectively requires considerable manual effort from the DevOps \nengineering team. We make a case for developing AI agents powered by large \nlanguage models (LLMs) to automate cloud infrastructure management tasks. In a \npreliminary study, we investigate the potential for AI agents to use different \ncloud/user interfaces such as software development kits (SDK), command line\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12270&hl=en&sa=X&d=14154561214130906357&ei=OEhWaO2EE6y16rQPzoCEgAc&scisig=AAZF9b_ifNq7e6gvpHIbtDlSaqx6&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Validating Interior Gateway Routing Protocols via Equivalent Topology Synthesis", "first_label": [], "second_label": [], "data": "B Shui, Y Zhou, J Wu, B Xu, Q Shi - 2025\nRouters, relying on routing protocols to determine how data packets travel across the \nInternet, serve as the backbone of modern networks. Vulnerable routing protocols \ncan lead to serious consequences, including data leaks and network congestion. \nThis work focuses on validating the implementation of a key class of routing protocols \nknown as Interior Gateway Protocols (IGPs). Unlike communication protocols such as \nTCP/IP, which define structured data packets and state machines to facilitate\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://qingkaishi.github.io/public_pdfs/CCS25.pdf&hl=en&sa=X&d=9088400310116954429&ei=OEhWaO2EE6y16rQPzoCEgAc&scisig=AAZF9b9Rkp6Qjekan02jkyADwsSr&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "SmartGuard: Making Prediction Verifiable through Transaction Sequences for Smart Contract Vulnerability Detection", "first_label": ["Vulnerabilities", "Smart Contracts"], "second_label": ["Detection"], "data": "J Chen, L Wang, H Zhu\\xc2\\xa0- IEEE Transactions on Information Forensics and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeep learning-based detectors have been widely proposed to predict vulnerabilities \nin smart contracts, yet their unreliable predictions pose severe security risks to \nfinancial transactions, making it critical to verify the reliability of vulnerability \npredictions. However, existing methods only produce prediction results, failing to \nprovide an evidence chain to check whether these predicted vulnerabilities \ngenuinely exist and deliver further guidance for fixing the vulnerabilities. Thus\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaNeuro-Symbolic Execution: Augmenting Symbolic Execution with\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11037432/&hl=en&sa=X&d=9556333083731351634&ei=OEhWaO2EE6y16rQPzoCEgAc&scisig=AAZF9b-YtrjQ3BDeJ28ZrSzr_tJq&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "INCOGNITOS: A Practical Unikernel Design for Full-System Obfuscation in Confidential Virtual Machines", "first_label": [], "second_label": [], "data": "KD Duy, J Kim, H Lim, H Lee\\xc2\\xa0- 2025 IEEE Symposium on Security and Privacy (SP), 2025\nRecent works have repeatedly proven the practicality of side-channel attacks in \nundermining the confidentiality guarantees of Trusted Execution Environments such \nas Intel SGX. Meanwhile, the trusted execution in the cloud is witnessing a trend shift \ntowards confidential virtual machines (CVMs). Unfortunately, several side-channel \nattacks have survived the shift and are feasible even for CVMs, along with the new \nattacks discovered on the CVM architectures. Previous works have explored\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBinary Rewriting without Control Flow Recovery\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11023442/&hl=en&sa=X&d=2075140509109417497&ei=OEhWaO2EE6y16rQPzoCEgAc&scisig=AAZF9b8N4mQwvAYfF5AA4TbHWwW0&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Variability Fault Localization by Abstract Interpretation and its Application to SPL Repair", "first_label": ["Fault Localization"], "second_label": ["Repair", "Localization"], "data": "AS Dimovski\\xc2\\xa0- Proceedings of the 18th ACM SIGPLAN International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFault localization is an important step in software debugging that aims to isolate and \nlocalize the bugs (errors) to a small part of the program. This becomes more \nchallenging in Software Product Lines (SPLs) due to the variable nature of bugs (so-\ncalled variability bugs). This paper introduces a novel variability fault localization \nalgorithm for SPLs. Moreover, we present its practical application for automatic repair \nof variability bugs in SPLs. Given a buggy SPL (program family) and an assertion to\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSemFix: Program Repair via Semantic Analysis\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3732771.3742722&hl=en&sa=X&d=16258344081663943125&ei=OEhWaO2EE6y16rQPzoCEgAc&scisig=AAZF9b9wdu8ALSmJOPUFmhWGRx81&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Your Agent Can Defend Itself against Backdoor Attacks", "first_label": [], "second_label": ["Agent"], "data": "L Changjiang, L Jiacheng, C Bochuan, C Jinghui\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite their growing adoption across domains, large language model (LLM)-\npowered agents face significant security risks from backdoor attacks during training \nand fine-tuning. These compromised agents can subsequently be manipulated to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08336&hl=en&sa=X&d=9281612337423238890&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b8EnIakTDvZQGsyv1duPVA5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Adversarial Preference Learning for Robust LLM Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Wang, P Wang, C Xi, B Tang, J Zhu, W Wei, C Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern language models often rely on Reinforcement Learning from Human \nFeedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to \nadversarial attacks due to three key limitations:(1) the inefficiency and high cost of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24369%3F&hl=en&sa=X&d=11526575995055803369&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b_ilBi9AMSJoKPXxHc_hWg5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SecurityLingua: Efficient Defense of LLM Jailbreak Attacks via Security-Aware Prompt Compression", "first_label": ["LLM"], "second_label": [], "data": "Y Li, S Ahn, H Jiang, AH Abdi, Y Yang, L Qiu\\xc2\\xa0- arXiv preprint arXiv:2506.12707, 2025\nLarge language models (LLMs) have achieved widespread adoption across \nnumerous applications. However, many LLMs are vulnerable to malicious attacks \neven after safety alignment. These attacks typically bypass LLMs' safety guardrails by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12707&hl=en&sa=X&d=8418273368991399970&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b8AOJ5PQ2S2DYr5nVOYpqTl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge", "first_label": ["LLM"], "second_label": [], "data": "S Li, C Xu, J Wang, X Gong, C Chen, J Zhang, J Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable intelligence across \nvarious tasks, which has inspired the development and widespread adoption of LLM-\nas-a-Judge systems for automated model testing, such as red teaming and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09443&hl=en&sa=X&d=2052322274134661445&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b9u9cyhYi06xXXt37CLZpdh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Syntactic paraphrase-based synthetic data generation for backdoor attacks against Chinese language models", "first_label": ["LLM"], "second_label": ["Generation"], "data": "M Hu, Y Yang, D Pan, Z Guo, L Xiao, D Lin, S Zhao\\xc2\\xa0- Information Fusion, 2025\nAbstract Language Models (LMs) have shown significant advancements in various \nNatural Language Processing (NLP) tasks. However, recent studies indicate that \nLMs are particularly susceptible to malicious backdoor attacks, where attackers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S156625352500449X&hl=en&sa=X&d=11939540759867308872&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b_omHEFDqgnSwVne_pfKwnY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Yuan, Y Xu, J Shi, P Zhou, L Sun\\xc2\\xa0- arXiv preprint arXiv:2505.23561, 2025\nModel merging for Large Language Models (LLMs) directly fuses the parameters of \ndifferent models finetuned on various tasks, creating a unified model for multi-domain \ntasks. However, due to potential vulnerabilities in models available on open-source\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23561&hl=en&sa=X&d=6617189016454156514&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b-hKaNf3ql6GqPXtJeaxsCC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Through the Stealth Lens: Rethinking Attacks and Defenses in RAG", "first_label": [], "second_label": [], "data": "S Choudhary, N Palumbo, A Hooda, KD Dvijotham\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRetrieval-augmented generation (RAG) systems are vulnerable to attacks that inject \npoisoned passages into the retrieved set, even at low corruption rates. We show that \nexisting attacks are not designed to be stealthy, allowing reliable detection and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04390&hl=en&sa=X&d=15468735482968103516&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b8u2OUJdUy7skXRySPRbZz3&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments", "first_label": [], "second_label": ["Agent"], "data": "X Wang, S Liang, Z Liu, Y Yu, Y Lu, X Cao, EC Chang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the growing integration of vision-language models (VLMs), mobile agents are \nnow widely used for tasks like UI automation and camera-based user assistance. \nThese agents are often fine-tuned on limited user-generated datasets, leaving them\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13205&hl=en&sa=X&d=16051255714568695875&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b_TBjYkLf7UFyh9GNeX1Max&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Cost of Dynamic Reasoning: Demystifying AI Agents and Test-Time Scaling from an AI Infrastructure Perspective", "first_label": ["Software Testing"], "second_label": ["Agent", "Reasoning"], "data": "J Kim, B Shin, J Chung, M Rhu\\xc2\\xa0- arXiv preprint arXiv:2506.04301, 2025\nLarge-language-model (LLM)-based AI agents have recently showcased impressive \nversatility by employing dynamic reasoning, an adaptive, multi-step process that \ncoordinates with external tools. This shift from static, single-turn inference to agentic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04301&hl=en&sa=X&d=3072272730677106970&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b-t8XUoljKdp6JjL-hJnilf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SLADE: Shielding against Dual Exploits in Large Vision-Language Models", "first_label": ["LLM"], "second_label": ["Exploit"], "data": "MZ Hossain, A Imteaj\\xc2\\xa0- Proceedings of the Computer Vision and Pattern\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAbstract Large Vision-Language Models (LVLMs) have emerged as transformative \ntools in multimodal tasks, seamlessly integrating pretrained vision encoders to align \nvisual and textual modalities. Prior works have highlighted the susceptibility of\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/CVPR2025/papers/Hossain_SLADE_Shielding_against_Dual_Exploits_in_Large_Vision-Language_Models_CVPR_2025_paper.pdf&hl=en&sa=X&d=15365021744232455122&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b_1fJe7OwiXTJjiVzlLPECb&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
