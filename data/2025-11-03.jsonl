{"title": "From Bugs to Breaches: How Agentic AI Protects the Software Supply Chain", "first_label": ["Bug"], "second_label": ["Agent"], "data": "V Saravanan- International Journal of Emerging Trends in Computer, 2025\nModern software supply chains have become highly sophisticated, prospecting \nvulnerabilities at all points of the development and deployment lifecycle. From CI/CD \npipelines to open-source components, security incidents frequently stem less from \ninsufficient information than from inability to respond quickly and discerningly. \nAdvances in Agentic Artificial Intelligence (AI) like autonomous reasoning, planning, \nand acting systems are transforming the ways in which software supply chains can\nCites: Evaluating SZZ implementations: An empirical study on the linux\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.ijetcsit.org/index.php/ijetcsit/article/download/422/374&hl=en&sa=X&d=2772267858030081049&ei=9n8GaaTPE_XSieoP5dXGqA0&scisig=ABGrvjJMiMJPeJioxRTSldI-dXoU&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:ABGrvjL7VxrFERkDgFky-TJkXnvY&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["1 new citation to articles by Hong Jin Kang"]}
{"title": "Backdoor-Powered Prompt Injection Attacks Nullify Defense Methods", "first_label": [], "second_label": [], "data": "Y Chen, H Li, Y Sui, Y Song, B Hooi- arXiv preprint arXiv:2510.03705, 2025\nWith the development of technology, large language models (LLMs) have dominated \nthe downstream natural language processing (NLP) tasks. However, because of the \nLLMs' instruction-following abilities and inability to distinguish the instructions in the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03705&hl=en&sa=X&d=9793005798347645046&ei=-H8Gaam2BIGpieoP_8jXuAM&scisig=ABGrvjJ2v68AhMUTz-vIWEu8QJ-h&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Genesis: Evolving Attack Strategies for LLM Web Agent Red-Teaming", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Z Zhang, J He, Y Cai, D Ye, P Zhao, R Feng, H Wang- arXiv preprint arXiv, 2025\nAs large language model (LLM) agents increasingly automate complex web tasks, \nthey boost productivity while simultaneously introducing new security risks. However, \nrelevant studies on web agent attacks remain limited. Existing red-teaming", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.18314&hl=en&sa=X&d=14799970374377988040&ei=-H8Gaam2BIGpieoP_8jXuAM&scisig=ABGrvjLlUwaYV7x4iFtGtsyDIHdw&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "MetaBreak: Jailbreaking Online LLM Services via Special Token Manipulation", "first_label": ["LLM"], "second_label": [], "data": "W Zhu, Z Xiang, W Niu, L Guan- arXiv preprint arXiv:2510.10271, 2025\nUnlike regular tokens derived from existing text corpora, special tokens are artificially \ncreated to annotate structured conversations during the fine-tuning process of Large \nLanguage Models (LLMs). Serving as metadata of training data, these tokens play a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10271%3F&hl=en&sa=X&d=10904776402205985786&ei=-H8Gaam2BIGpieoP_8jXuAM&scisig=ABGrvjL7g_73UHz_DwhnWsdL9iGk&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Webcloak: Characterizing and mitigating the threats of llm-driven web agents as intelligent scrapers", "first_label": ["LLM"], "second_label": ["Agent"], "data": "X Li, T Qiu, Y Jin, L Wang, H Guo, X Jia, X Wang- Proceedings of the 2026, 2026\nThe rise of web agents powered by large language models (LLMs) is reshaping the \nlandscape of human-computer interaction, enabling users to automate complex web \ntasks with natural language commands. However, this progress introduces serious", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Xinfeng-Li-7/publication/396418425_WebCloak_Characterizing_and_Mitigating_Threats_from_LLM-Driven_Web_Agents_as_Intelligent_Scrapers/links/68ea2bc4f3032e2b4be84935/WebCloak-Characterizing-and-Mitigating-Threats-from-LLM-Driven-Web-Agents-as-Intelligent-Scrapers.pdf&hl=en&sa=X&d=11222165444201781035&ei=-H8Gaam2BIGpieoP_8jXuAM&scisig=ABGrvjIK6rwNOFCGhsxEhJgoFqxB&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "C Ziakas, N Loo, N Jain, A Russo- arXiv preprint arXiv:2510.07239, 2025\nAutomated red-teaming has emerged as a scalable approach for auditing Large \nLanguage Models (LLMs) prior to deployment, yet existing approaches lack \nmechanisms to efficiently adapt to model-specific vulnerabilities at inference. We", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07239%3F&hl=en&sa=X&d=7730973334197366962&ei=-H8Gaam2BIGpieoP_8jXuAM&scisig=ABGrvjK7SFLw8g1qTWHeOk7VhS4x&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Investigating the Impact of Dark Patterns on LLM-Based Web Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "D Ersoy, B Lee, A Shreekumar, A Arunasalam- arXiv preprint arXiv, 2025\nAs users increasingly turn to large language model (LLM) based web agents to \nautomate online tasks, agents may encounter dark patterns: deceptive user interface \ndesigns that manipulate users into making unintended decisions. Although dark", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.18113&hl=en&sa=X&d=9332036408692793636&ei=-H8Gaam2BIGpieoP_8jXuAM&scisig=ABGrvjL2GoCmABLkIStSVW1f9lld&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Securing with Dual-LLM Architecture: ChatTEDU An Open Access Chatbot's Defense", "first_label": ["LLM"], "second_label": [], "data": "H Emekci, G Budakoglu- IEEE Access, 2025\nOpen access chatbots face escalating cybersecurity risks due to adversarial \nexploitation. This paper presents the case of ChatTEDU, a dual-LLM architecture \ndesigned to protect open-access AI systems from sophisticated adversarial attacks", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11207588.pdf&hl=en&sa=X&d=8815365068079578094&ei=-H8Gaam2BIGpieoP_8jXuAM&scisig=ABGrvjIotmfuTMIEf8JuZ6CJRHKR&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "ZeroDay-LLM: A Large Language Model Framework for Zero-Day Threat Detection in Cybersecurity", "first_label": ["LLM"], "second_label": ["Detection"], "data": "MA Alsuwaiket- Information, 2025\nZero-day attacks pose unprecedented challenges to modern cybersecurity \nframeworks, exploiting unknown vulnerabilities that evade traditional signature-\nbased detection systems. This paper presents ZeroDay-LLM, a novel large language", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2078-2489/16/11/939&hl=en&sa=X&d=17136140980942781837&ei=-H8Gaam2BIGpieoP_8jXuAM&scisig=ABGrvjIXNMdaikMuAqd5ZBX33YWD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research", "2 new citations to articles by Richard Fang"]}
{"title": "Categorized Privacy Neuron Editing: Addressing Heterogeneity for Privacy Leakage Mitigation in Language Models", "first_label": ["LLM"], "second_label": [], "data": "X Yang, P Wu- International Conference on Advanced Data Mining, 2025\nConventional neuron editing methods for language model privacy protection suffer \nfrom a critical limitation: uniform intervention strategies inadvertently exacerbate \ncross-category leakage via the privacy seesaw effect. Current methodologies", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-3456-2_9&hl=en&sa=X&d=16693435278691795213&ei=-H8Gaam2BIGpieoP_8jXuAM&scisig=ABGrvjKw_XM3Jyi0C8HSsmMIHP4o&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SMaRT: Select, Mix, and ReinvenT-A Strategy Fusion Framework for LLM-Driven Reasoning and Planning", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "N Verma, M Bharadwaj, W Jang, H Singh, Y Wang- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have redefined complex task automation with \nexceptional generalization capabilities. Despite these advancements, state-of-the-art \nmethods rely on single-strategy prompting, missing the synergy of diverse reasoning\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.18095&hl=en&sa=X&d=6260306680531832341&ei=-H8Gaam2BIGpieoP_8jXuAM&scisig=ABGrvjK3FnRszSUvTIH9jwxzNMjV&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A zero-shot framework for cross-project vulnerability detection in source code", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "R Haque, A Ali, S McClean, N Khan- Empirical Software Engineering, 2026\nThe growing prevalence of software vulnerabilities has increased the need for \neffective detection methods, particularly in cross-project settings where domain \ndifferences create significant challenges. Existing vulnerability detection models", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10749-4&hl=en&sa=X&d=5787044264909627309&ei=-H8GaavCH6PH6rQP48qQiAk&scisig=ABGrvjJ29zOgzha_sOP3xWytZM2T&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research", "Thanh Le-Cong - new related research", "David Lo - new related research", "Bach Le - new related research"]}
{"title": "FuzzAug: Data Augmentation by Coverage-guided Fuzzing for Neural Test Generation", "first_label": ["Fuzzing", "Software Testing"], "second_label": ["Generation"], "data": "Y He, J Wang, Y Rong, H Chen- Conference on Empirical Methods in Natural Language\nFigure 1: Data Augmentation by fuzzing for neural test generation. 1. extract unit test \nfunctions (Listing 1) 2. extract fuzzing targets (Listing 2). 3. instrument fuzz targets \nwith a reporter (Listing 3) for DA inputs. 4. transform fuzz targets into a unit test", "link": "https://scholar.google.com/scholar_url?url=https://yfhe.net/publications/he2025fuzzaug_slides.pdf&hl=en&sa=X&d=3828293808872487066&ei=-H8GaavCH6PH6rQP48qQiAk&scisig=ABGrvjIEhzMthxkJN1q1_cc5Clba&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Source Code Guardrail: AI Driven Solution to Distinguish Critical vs. Generic Code for Enterprise LLM Security", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Sharma, A Gupta- International Conference on Provable Security, 2025\nAbstract The adoption of Large Language Models (LLMs) in businesses raises the \npossibility of inadvertent intellectual property (IP) and secret data leaks to public \nartificial intelligence systems. Organizations are using security solutions, including", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-2961-2_23&hl=en&sa=X&d=5184326828152072441&ei=-H8GaavCH6PH6rQP48qQiAk&scisig=ABGrvjJOJG-OQ4wH-x-OhS5wRNe2&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Bach Le - new related research"]}
{"title": "GlassWing: A Tailored Static Analysis Approach for Flutter Android Apps", "first_label": ["Static Analysis"], "second_label": [], "data": "X Zhang, Y Su, L Fan, M Cai, S Chen\nThe variety of mobile operating systems available in the market has led to the \nemergence of cross-platform frameworks, which simplify the development and \ndeployment of mobile applications across multiple platforms simultaneously. Among", "link": "https://scholar.google.com/scholar_url?url=https://sen-chen.github.io/img_cs/pdf/ASE2025-GlassWing%2520A%2520Tailored%2520Static%2520Analysis%2520Approach%2520for%2520Flutter%2520Android%2520Apps.pdf&hl=en&sa=X&d=3861822635221850315&ei=-H8GaavCH6PH6rQP48qQiAk&scisig=ABGrvjLW9rFsIjIFaUpu9DnJki-m&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "2025 IEEE International Conference on Source Code Analysis & Manipulation (SCAM)| 979-8-3315-9698-9/25/$31.00 2025 IEEE| DOI: 10.1109/SCAM67354", "first_label": ["Code"], "second_label": [], "data": "IM Amer, R Atike, A Barrak, C Bischof, S Blyth\nAuthor Index Page 1 Author Index Amer, Ibrahim M. 55 Atike, Ridouane 110 Barrak, \n\r\nAmine 110 Bischof, Christian 116 Blyth, Scott 100 Businge, John 25 Chen, Yang 133 \n\r\nDe Meuter, Wolfgang 66 De Roover, Coen 13, 66 de Souza Santos, Ronnie 78 Dingel", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11189996/&hl=en&sa=X&d=4067468146815873614&ei=-H8GaavCH6PH6rQP48qQiAk&scisig=ABGrvjJbkmdi-UpNabERZq_01lo7&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "LLMs are All You Need? Improving Fuzz Testing for MOJO with Large Language Models", "first_label": ["LLM", "Fuzzing", "Software Testing"], "second_label": [], "data": "L Huang, P Zhao, H Chen- arXiv preprint arXiv:2510.10179, 2025\nThe rapid development of large language models (LLMs) has revolutionized \nsoftware testing, particularly fuzz testing, by automating the generation of diverse and \neffective test inputs. This advancement holds great promise for improving software", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10179%3F&hl=en&sa=X&d=1799101126036134381&ei=-H8GaavCH6PH6rQP48qQiAk&scisig=ABGrvjJpTzJLdPRF-_YdbFCpjP7v&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "PLSEMANTICSBENCH: Large Language Models As Programming Language Interpreters", "first_label": ["LLM"], "second_label": [], "data": "A Thimmaiah, J Zhang, J Srinivasa, JJ Li, M Gligoric- arXiv preprint arXiv:2510.03415, 2025\nAs large language models (LLMs) excel at code reasoning, a natural question arises: \ncan an LLM execute programs (ie, act as an interpreter) purely based on a \nprogramming language's formal semantics? If so, it will enable rapid prototyping of", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03415&hl=en&sa=X&d=2539578870795389971&ei=-H8GaavCH6PH6rQP48qQiAk&scisig=ABGrvjLDcDk0eY78Xm7hHQxmswny&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Do Large Language Models Respect Contracts? Evaluating and Enforcing Contract-Adherence in Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "S Lim, J Hahn, H Park, SK Ko, YS Han- arXiv preprint arXiv:2510.12047, 2025\nPrevailing code generation benchmarks, such as HumanEval+ and MBPP+, primarily \nevaluate large language models (LLMs) with pass@ k on functional correctness \nusing well-formed inputs. However, they ignore a crucial aspect of real-world", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12047&hl=en&sa=X&d=2889880949652380666&ei=-H8GaavCH6PH6rQP48qQiAk&scisig=ABGrvjJFxTBnu5WvPpefIV01qBsD&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Beyond Postconditions: Can Large Language Models infer Formal Contracts for Automatic Software Verification?", "first_label": ["Verification", "LLM"], "second_label": [], "data": "C Richter, H Wehrheim- arXiv preprint arXiv:2510.12702, 2025\nAutomatic software verifiers have become increasingly effective at the task of \nchecking software against (formal) specifications. Yet, their adoption in practice has \nbeen hampered by the lack of such specifications in real world code. Large", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12702%3F&hl=en&sa=X&d=17536797185387086304&ei=-H8GaavCH6PH6rQP48qQiAk&scisig=ABGrvjKsgwYyJpPZg-qfz6x4MI4l&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "When AI Takes the Wheel: Security Analysis of Framework-Constrained Program Generation", "first_label": [], "second_label": ["Generation"], "data": "Y Liu, Z Xing, S Pan, C Tantithamthavorn- arXiv preprint arXiv:2510.16823, 2025\nIn recent years, the AI wave has grown rapidly in software development. Even novice \ndevelopers can now design and generate complex framework-constrained software \nsystems based on their high-level requirements with the help of Large Language\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16823&hl=en&sa=X&d=3361222524844858675&ei=-H8GaavCH6PH6rQP48qQiAk&scisig=ABGrvjJKedL82jrVoYHkXEQqUTEv&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Bridging the Gap Between LLMs and Structured Program Vulnerability Analysis: An Agent Reasoning Approach with First-Order Logic Modeling", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Agent", "Reasoning"], "data": "Z Yin, J Li, Y Song, L Kong- Expert Systems with Applications, 2025\nLarge language models (LLMs) have shown promise in vulnerability detection but \noften produce hallucinations and lack precise logical reasoning, leading to high false \npositive rates and limited practical trust. The core challenge lies in reconciling the \nLLM's strength in semantic generalization with the need for precise numeric and \nlogical verification. To address this, we propose VulX, a framework that aims to \nachieve both high accuracy and high explainability in vulnerability detection. Our key\nCites: Large language model for vulnerability detection and repair\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0957417425037212&hl=en&sa=X&d=14694633820248525692&ei=938GaazWNIm16rQPw4j56AI&scisig=ABGrvjIx-CQZPxgCBIeDSoQDEB6e&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ABGrvjKBQMI3rG05-NPhg-jRvIpb&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["1 new citation to articles by Xin ZHOU"]}
{"title": "Fortifying LLM-Based Code Generation with Graph-Based Reasoning on Secure Coding Practices", "first_label": ["LLM", "Code"], "second_label": ["Generation", "Reasoning", "Graph"], "data": "R Patir, K Guo, H Cai, H Hu- arXiv preprint arXiv:2510.09682, 2025\nThe code generation capabilities of Large Language Models (LLMs) have \ntransformed the field of software development. However, this advancement also \npresents significant security challenges, as LLM-generated code often contains", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.09682&hl=en&sa=X&d=6457581180391498391&ei=-H8GaemSEpSQieoPpvjD8A0&scisig=ABGrvjJKh0qvAQhEQtaEmOGqxxp8&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Knowledge-Guided Multi-Agent Framework for Application-Level Software Code Generation", "first_label": ["Code"], "second_label": ["Generation", "Agent"], "data": "Q Xiong, B Yang, W Sun, Y Zhang, T Li, Y Liu, Z Jin- arXiv e-prints, 2025\nAutomated code generation driven by Large Language Models (LLMs) has \nenhanced development efficiency, yet generating complex application-level software \ncode remains challenging. Multi-agent frameworks show potential, but existing\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.19868&hl=en&sa=X&d=1387273773567360383&ei=-H8GaemSEpSQieoPpvjD8A0&scisig=ABGrvjIAUC8fRJVWxAEkJBebXKNv&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Survey for MQTT Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "SY Chowdhury, R Sun, B Dudley- Proceedings of the 2025 Workshop on Re-design, 2025\nMessage Queuing Telemetry Transport (MQTT) has emerged as a promising \ncommunication protocol for Internet of Things (IoT) ecosystems, enabling lightweight, \nscalable publish-subscribe messaging across resource-constrained devices. As", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3733823.3764515&hl=en&sa=X&d=13012329971672204999&ei=938GabW8FpvJieoPw4DvyAY&scisig=ABGrvjId2cO-K_7acZfnhIhoKULY&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "DynamiQ: Unlocking the Potential of Dynamic Task Allocation in Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "W Yan, T Murray, B Rubinstein, VT Pham- arXiv preprint arXiv:2510.04469, 2025\nWe present DynamiQ, a full-fledged and optimized successor to AFLTeam that \nsupports dynamic and adaptive parallel fuzzing. Unlike most existing approaches \nthat treat individual seeds as tasks, DynamiQ leverages structural information from", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04469&hl=en&sa=X&d=10962816615102660239&ei=938GabW8FpvJieoPw4DvyAY&scisig=ABGrvjJffOk8ddKWXV2Kdd4qJSnB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing", "first_label": ["LLM", "Fuzzing", "Bug"], "second_label": [], "data": "S Ou, Y Li, L Yu, C Wei, T Wen, Q Chen, Y Chen- IEEE Transactions on, 2025\nDeep learning (DL) frameworks serve as the backbone for a wide range of artificial \nintelligence applications. However, bugs within DL frameworks can cascade into \ncritical issues in higher-level applications, jeopardizing reliability and security. While", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/32/4359463/11201027.pdf&hl=en&sa=X&d=1422528139240657868&ei=938GabW8FpvJieoPw4DvyAY&scisig=ABGrvjI1tTlw2XwsJvzcyylBVxMq&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "CG-Bench: Can Language Models Assist Call Graph Construction in the Real World?", "first_label": ["LLM", "Static Analysis"], "second_label": ["Graph"], "data": "T Yuan, W Zhang, D Chen, J Wang- Proceedings of the 1st ACM SIGPLAN, 2025\nLanguage models for coding are shifting their focus from function-level to repository-\nlevel, with complex function invocations. We introduce CG-Bench, the first manually \nconstructed benchmark that measures the ability to understand call graphs for", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3759425.3763379&hl=en&sa=X&d=11570618845570061776&ei=938GabW8FpvJieoPw4DvyAY&scisig=ABGrvjJTTJMRIMAuaa7eEoue4X54&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Bach Le - new related research"]}
{"title": "Multi Language Models for On-the-Fly Syntax Highlighting", "first_label": ["LLM"], "second_label": [], "data": "ME Palma, P Rani, HC Gall- arXiv preprint arXiv:2510.04166, 2025\nSyntax highlighting is a critical feature in modern software development \nenvironments, enhancing code readability and developer productivity. However, \ndelivering accurate highlighting in real time remains challenging for online and web\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04166%3F&hl=en&sa=X&d=2254729212502568662&ei=938GabW8FpvJieoPw4DvyAY&scisig=ABGrvjIMpU0YGaMDVoPzEyw5QYUR&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=6&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "QueryIPI: Query-agnostic Indirect Prompt Injection on Coding Agents", "first_label": [], "second_label": ["Agent"], "data": "Y Xie, Z Liu, M Luo, Z Zhang, K Zhang, Z Li, P Chen- arXiv preprint arXiv, 2025\nModern coding agents integrated into IDEs combine powerful tools and system-level \nactions, exposing a high-stakes attack surface. Existing Indirect Prompt Injection (IPI) \nstudies focus mainly on query-specific behaviors, leading to unstable attacks with \nlower success rates. We identify a more severe, query-agnostic threat that remains \neffective across diverse user inputs. This challenge can be overcome by exploiting a \ncommon vulnerability: leakage of the agent's internal prompt, which turns the attack\nCites: Adaptive attacks break defenses against indirect prompt injection\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.23675&hl=en&sa=X&d=5198632406797716655&ei=9X8GaYzlLJvJieoPw4DvyAY&scisig=ABGrvjKq_HLOKQEMPc_KEhSPQvRA&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:ABGrvjIL7aJF81gdGo1gERw9ebUT&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Investigating Software Aging in LLM-Generated Software Systems", "first_label": ["LLM"], "second_label": [], "data": "C Santos, E Andrade, R Natella- arXiv preprint arXiv:2510.24188, 2025\nAutomatically generated software, especially code produced by Large Language \nModels (LLMs), is increasingly adopted to accelerate development and reduce \nmanual effort. However, little is known about the long-term reliability of such systems \nunder sustained execution. In this paper, we experimentally investigate the \nphenomenon of software aging in applications generated by LLM-based tools. Using \nthe Bolt platform and standardized prompts from Baxbench, we generated four\nCites: Automatic Programming: Large Language Models and Beyond\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.24188&hl=en&sa=X&d=5683841790792481505&ei=9n8GacHZNd7M6rQP173fsAE&scisig=ABGrvjKmI2Oue024B2HdCxASGpR7&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["1 new citation to articles by Abhik Roychoudhury"]}
{"title": "Enhancing Domain-Specific Code Completion via Collaborative Inference with Large and Small Language Models", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Yu, Z Gao, L Bao, Z Liu- ACM Transactions on Software Engineering and, 2025\nLarge language model-based code completion has demonstrated excellent \nperformance, but still encounters challenges in capturing domain-specific knowledge \nfor more precise completion within specific domains, ie, domain-specific code", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3770748&hl=en&sa=X&d=2019769577165862416&ei=9n8Gacz8AZvJieoPw4DvyAY&scisig=ABGrvjKO1fKaLDZwwCDDcSmDx0Da&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "ALMAS: an autonomous llm-based multi-agent software engineering framework", "first_label": ["LLM"], "second_label": ["Agent"], "data": "V Tawosi, K Ramani, S Alamir, X Liu- arXiv preprint arXiv:2510.03463, 2025\nMulti-agent Large Language Model (LLM) systems have been leading the way in \napplied LLM research across a number of fields. One notable area is software \ndevelopment, where researchers have advanced the automation of code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03463&hl=en&sa=X&d=6189494284468520954&ei=9n8Gacz8AZvJieoPw4DvyAY&scisig=ABGrvjJrdVeB80cic_brCTfqWIPK&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Real-VulLLM: An LLM Based Assessment Framework in the Wild", "first_label": ["LLM"], "second_label": [], "data": "R Safdar, D Mateen, ST Ali, W Hussain- arXiv preprint arXiv:2510.04056, 2025\nArtificial Intelligence (AI) and more specifically Large Language Models (LLMs) have \ndemonstrated exceptional progress in multiple areas including software engineering, \nhowever, their capability for vulnerability detection in the wild scenario and its\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04056&hl=en&sa=X&d=7464868966945655593&ei=9n8Gacz8AZvJieoPw4DvyAY&scisig=ABGrvjIaO4pEKfAZ4-It9iNMVajB&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "InstructRepair: Instruct Large Language Models with Rich Bug Information for Automated Program Repair", "first_label": ["APR", "LLM", "Bug"], "second_label": ["Repair"], "data": "A Fu, P Xu, J Li, B Kuang, Y Gao- IEEE Transactions on Information Forensics and, 2025\nAutomated Program Repair (APR) repairs software bugs based on buggy code \nsnippets automatically. It is instrumental in reducing the time and effort required for \nsoftware maintenance. Recently, large language models (LLMs) have been utilized", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11194216/&hl=en&sa=X&d=15287113091370652463&ei=9n8GabmkJIGpieoP_8jXuAM&scisig=ABGrvjKRQ4NA9Q2bph15_TI0m8Cp&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "LMFuzz: Program repair fuzzing based on large language models", "first_label": ["APR", "LLM", "Fuzzing"], "second_label": ["Repair"], "data": "R Lin, R Wang, G Hu, X Xu- Automated Software Engineering, 2026\nGenerating programs using large language models (LLMs) for fuzz testing has \nemerged as a significant testing methodology. While traditional fuzzers can produce \ncorrect programs, their effectiveness is limited by excessive constraints and restricted", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00568-8&hl=en&sa=X&d=16706984066078411801&ei=9n8GabmkJIGpieoP_8jXuAM&scisig=ABGrvjLMTxGR3-Z1Hr556q7Ejx9K&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Towards Speeding up Program Repair with Non-Autoregressive Model", "first_label": ["APR"], "second_label": ["Repair"], "data": "Z Yang, Y Pan, Z Yang, Z Yu- arXiv preprint arXiv:2510.01825, 2025\nEnlightened by the success of machine learning techniques in various application \nareas, recent years have witnessed a surge of research efforts on automatic program \nrepair (APR) using machine learning techniques. Previous machine learning-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01825&hl=en&sa=X&d=13565386759645709244&ei=9n8GabmkJIGpieoP_8jXuAM&scisig=ABGrvjLcaUrVIG2KVg-f03OTMEUr&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Selecting and Combining Large Language Models for Scalable Code Clone Detection", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "M Chochlov, GA Ahmed, JV Patten, Y Han, G Lu- arXiv preprint arXiv, 2025\nSource code clones pose risks ranging from intellectual property violations to \nunintended vulnerabilities. Effective and efficient scalable clone detection, especially \nfor diverged clones, remains challenging. Large language models (LLMs) have", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15480&hl=en&sa=X&d=9943637308311023337&ei=9n8GabmkJIGpieoP_8jXuAM&scisig=ABGrvjKwntTHj-gYFVYkC1ZboyXO&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "An Experimental Study of Real-Life LLM-Proposed Performance Improvements", "first_label": ["LLM"], "second_label": [], "data": "L Yi, G Gay, P Leitner- arXiv preprint arXiv:2510.15494, 2025\nLarge Language Models (LLMs) can generate code, but can they generate fast \ncode? In this paper, we study this question using a dataset of 65 real-world tasks \nmined from open-source Java programs. We specifically select tasks where", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15494&hl=en&sa=X&d=10640118915085146028&ei=9n8GabmkJIGpieoP_8jXuAM&scisig=ABGrvjLcRUj8NSio7-ggPhAhEwVg&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "X Yin, C Ni, X Li, L Chen, G Ma, X Yang\nRecently, Large Language Models (LLMs) have gained attention for their ability to \nhandle a broad range of tasks, including unit test generation. Despite their success, \nLLMs may exhibit hallucinations when generating unit tests for focal methods or", "link": "https://scholar.google.com/scholar_url?url=https://vinci-grape.github.io/papers/Enhancing_LLM_s_Ability_to_Generate_More_Repository_Aware_Unit_Tests_Through_Precise_Context_Injection.pdf&hl=en&sa=X&d=3506872574868649515&ei=9n8GabmkJIGpieoP_8jXuAM&scisig=ABGrvjKPA0zq2FXS1WyPoCr65qwT&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Enhanced Architecture of Structure Semantics for SyntaxAware Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "C Zhou, Z Li, H Huang, Y Xiang, F Liu, Z Hao- Software: Practice and Experience, 2025\nObjective The task of code generation aims to transform natural language \ndescriptions into corresponding target code. Among the various approaches, syntax\naware code generation has emerged as a significant approach that strives to\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.70025&hl=en&sa=X&d=17163292334780918507&ei=9n8GabmkJIGpieoP_8jXuAM&scisig=ABGrvjIEfWSCelZJddhXkIyGi8VD&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
