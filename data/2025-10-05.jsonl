{"title": "BloomAPR: A Bloom's Taxonomy-based Framework for Assessing the Capabilities of LLM-Powered APR Solutions", "first_label": ["LLM"], "second_label": [], "data": "Y Ma, J Shin, L Da Silva, Z Ming, S Wang, F Khomh- arXiv preprint arXiv, 2025\nRecent advances in large language models (LLMs) have accelerated the \ndevelopment of AI-driven automated program repair (APR) solutions. However, these \nsolutions are typically evaluated using static benchmarks such as Defects4J and \nSWE-bench, which suffer from two key limitations:(1) the risk of data contamination, \npotentially inflating evaluation results due to overlap with LLM training data, and (2) \nlimited ability to assess the APR capabilities in dynamic and diverse contexts. In this\nCites: PatchZero: Zero-shot automatic patch correctness assessment", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25465&hl=en&sa=X&d=11066311399156471814&ei=7QLhaIW7HMyR6rQP8M_xgAM&scisig=AAZF9b8-WlUSvsvzUFkBWMfotWY9&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le", "4 new citations to articles by Xin ZHOU", "10 new citations to articles by Abhik Roychoudhury", "4 new citations to articles by Thanh Le-Cong"]}
{"title": "A Benchmark for Localizing Code and Non-Code Issues in Software Projects", "first_label": ["Code"], "second_label": [], "data": "Z Zhang, J Wang, Q Yang, Y Pan, Y Tang, Y Li, Z Xing- arXiv preprint arXiv, 2025\nAccurate project localization (eg, files and functions) for issue resolution is a critical \nfirst step in software maintenance. However, existing benchmarks for issue \nlocalization, such as SWE-Bench and LocBench, are limited. They focus \npredominantly on pull-request issues and code locations, ignoring other evidence \nand non-code files such as commits, comments, configurations, and documentation. \nTo address this gap, we introduce MULocBench, a comprehensive dataset of 1,100\nCites: Thanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25242&hl=en&sa=X&d=9912554073922702978&ei=7QLhaIW7HMyR6rQP8M_xgAM&scisig=AAZF9b8mdC7vfC9M85hnC5hsZ66A&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le", "4 new citations to articles by Thanh Le-Cong", "Bach Le - new related research"]}
{"title": "Comparison of Language Models for Source Code Vulnerability Classification", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": [], "data": "KI Gladkikh, AA Zakharov- 2025 International Russian Automation Conference, 2025\nModern large language models (LLMs) have demonstrated strong performance in \nthe static analysis of source code for security vulnerabilities. With new LLMs \nemerging daily, they differ in architecture, prompting strategies, and their overall \ncapacity to understand source code. In this study, we developed a benchmarking \nframework to evaluate a range of LLMs on vulnerability detection tasks using multiple \nperformance metrics. The results indicate that models from the Qwen family achieve\nCites: Comparison of static application security testing tools and large", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11177346/&hl=en&sa=X&d=5404891364929924575&ei=7QLhaIW7HMyR6rQP8M_xgAM&scisig=AAZF9b8a5z_BUYvzSELnbAZ27iIJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le", "4 new citations to articles by Xin ZHOU", "4 new citations to articles by Thanh Le-Cong"]}
{"title": "From Vibe to Vise Coding: Addressing the AI-Generated Code Quality Crisis", "first_label": ["Code"], "second_label": [], "data": "D Farag- Softwaretechnik-Trends Band 45, Heft 3, 2025\nCurrent news claims that AI is replacing software developers [20, 31, 32]. However, \nsuch proclamations may primarily serve corporate narratives (like justifying layoffs or \npromoting AI products) rather than reflect reality. We examine data on AI adoption \nand its effects, revealing that AI-assisted software development (AI coding for short) \nimproves, but software engineering is far from full automation: The current hype often \nfails to distinguish between what large language models (LLMs) can and cannot do\nCites: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://dl.gi.de/server/api/core/bitstreams/f8fe787e-2367-4e40-a79c-ee2f183193de/content&hl=en&sa=X&d=17953142790972084078&ei=7QLhaIW7HMyR6rQP8M_xgAM&scisig=AAZF9b9zBjfXX4ndNh-g005IpefL&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=3&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le", "4 new citations to articles by Thanh Le-Cong"]}
{"title": "Towards Decentralizing the Fashion Industry: A Blockchain-Integrated System to Mitigate Dual Pricing of Branded Apparel", "first_label": ["Blockchain"], "second_label": [], "data": "AZU Rahat, A Das, A Dey- 2025 International Conference on Quantum Photonics, 2025\nDual pricing, where identical dresses are sold at different prices, can confuse \ncustomers. This practice makes it hard for customers to understand why they pay \nmore or less for the same dress. This absence of transparency can undermine the \ntrust between brands and their customers. Integrating blockchain technology into \nbranded apparel can revolutionize the industry by enhancing data security and \nensuring authenticity. This technology employs a decentralized digital ledger that\nCites: Smart contract development: Challenges and opportunities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11171920/&hl=en&sa=X&d=9570597781693908230&ei=7QLhaIW7HMyR6rQP8M_xgAM&scisig=AAZF9b-K-9uh2NjazJM4m8DsrkUT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=4&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le"]}
{"title": "A Scalable Vulnerability Detection System with Multi-View Graph Representations", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "S Dou, H Zheng, J Shan, Y Wu, D Zou, X Huang, Y Liu- ACM Transactions on, 2025\nDeep learning (DL) has been extensively utilized in source code vulnerability \ndetection due to its robust automatic feature extraction capabilities. To achieve \nscalable vulnerability scanning, some prior studies intend to process the source code \ndirectly by treating them as text. However, these text-based methods can not achieve \nthe best performance due to the lack utilizing program semantics. In contrast, other \napproaches aim to enhance accuracy by distilling program semantics into graph\nCites: Large language model for vulnerability detection and repair", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3770075&hl=en&sa=X&d=14953216934661661615&ei=7gLhaLuEMvKOieoP85S7oQk&scisig=AAZF9b-mdJedTULsxLZv6yXH09xW&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU", "Quang-Cuong Bui - new related research", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "PIPer: On-Device Environment Setup via Online Reinforcement Learning", "first_label": [], "second_label": [], "data": "A Kovrigin, A Eliseeva, K Grotov, E Bogomolov- arXiv preprint arXiv, 2025\nEnvironment setup-the process of configuring the system to work with a specific \nsoftware project-represents a persistent challenge in Software Engineering (SE). \nAutomated environment setup methods could assist developers by providing fully \nconfigured environments for arbitrary repositories without manual effort. This also \nhelps SE researchers to scale execution-based benchmarks. However, recent \nstudies reveal that even state-of-the-art Large Language Models (LLMs) achieve\nCites: Bridging Bug Localization and Issue Fixing: A Hierarchical", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25455&hl=en&sa=X&d=13210413856044566227&ei=7gLhaLuEMvKOieoP85S7oQk&scisig=AAZF9b9D_XOaYMX4HMhwkTYny83S&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "Red Teaming Program Repair Agents: When Correct Patches can Hide Vulnerabilities", "first_label": ["Vulnerabilities", "APR"], "second_label": ["Repair", "Agent"], "data": "S Chen, Y He, S Jana, B Ray- arXiv preprint arXiv:2509.25894, 2025\nLLM-based agents are increasingly deployed for software maintenance tasks such \nas automated program repair (APR). APR agents automatically fetch GitHub issues \nand use backend LLMs to generate patches that fix the reported bugs. However", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25894&hl=en&sa=X&d=17829160501867046335&ei=7gLhaMrZCq3M6rQPuqaCiA0&scisig=AAZF9b9xoBNSp2DVGtyfC25OhwWn&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "David Lo - new related research", "Bach Le - new related research", "Thanh Le-Cong - new related research", "Abhik Roychoudhury - new related research", "Xin ZHOU - new related research"]}
{"title": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation", "first_label": ["LLM", "Fault Localization"], "second_label": ["Localization"], "data": "F Liu, T Wang, L Zhang, Z Yang, J Jiang, Z Sun- arXiv preprint arXiv:2509.25676, 2025\nProviding timely and personalized guidance for students' programming assignments, \noffers significant practical value for helping students complete assignments and \nenhance their learning. In recent years, various automated Fault Localization (FL)", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25676&hl=en&sa=X&d=16831300563596066577&ei=7gLhaMrZCq3M6rQPuqaCiA0&scisig=AAZF9b8KiRs4870r1KbKTYTF0UyR&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "10 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research", "Thanh Le-Cong - new related research", "Abhik Roychoudhury - new related research", "Hong Jin Kang - new related research"]}
{"title": "Automated Code Repair for C/C++ Static Analysis", "first_label": ["Code", "Static Analysis"], "second_label": ["Repair"], "data": "D Svoboda, L Flynn, W Klieber, M Duggan, N Reimer - 2025\nStatic analysis (SA) tools produce many diagnostic alerts indicating that source code \nin C or C++ may be defective and potentially vulnerable to security exploits. Many of \nthese alerts are false positives. Identifying the true positive alerts and repairing the", "link": "https://scholar.google.com/scholar_url?url=https://kilthub.cmu.edu/ndownloader/files/58406428&hl=en&sa=X&d=11380272638430810579&ei=7gLhaMrZCq3M6rQPuqaCiA0&scisig=AAZF9b-e8jJ6aMdJzGxnIjtEdvZT&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=3&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Integrating Large Language Models in Automated Program Verification", "first_label": ["Verification", "LLM"], "second_label": [], "data": "N Narodytska- # PLACEHOLDER_PARENT_METADATA_VALUE#, 2025\nThe demonstrated code-understanding capabilities of large language models (LLMs) \nraise the question of whether they can be used for automated program verification\na task that typically demands high-level, abstract reasoning about program\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://repositum.tuwien.at/bitstream/20.500.12708/219532/1/Narodytska-2025-Integrating%2520Large%2520Language%2520Models%2520in%2520Automated%2520Program%2520Ve...-vor.pdf&hl=en&sa=X&d=7972569135923682675&ei=7gLhaMrZCq3M6rQPuqaCiA0&scisig=AAZF9b-NppojD7cBzbVaV891ND28&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=4&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Agentic Concolic Execution", "first_label": [], "second_label": ["Agent"], "data": "Z Luo, H Zhao, D Wolff, C Cadar, A Roychoudhury\nConcolic execution is a practical test generation technique that explores execution \npaths by coupling concrete execution with symbolic reasoning. It runs programs on \ngiven inputs while capturing symbolic path representations, then mutates and solves\n\u00a0\nThis message was sent by Google Scholar because you're following new articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://abhikrc.com/pdf/SP26.pdf&hl=en&sa=X&d=9830445453743327782&ei=7wLhaLX1GZ2N6rQP3enmuQg&scisig=AAZF9b8WNc-CT75hhTuLUEPV5ttV&oi=scholaralrt&hist=ylyK0_8AAAAJ:17845465921536999430:AAZF9b8uxzftV24sircdvgSPVS-f&html=&pos=0&folt=art", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new articles", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "CSnake: Detecting Self-Sustaining Cascading Failure via Causal Stitching of Fault Propagations", "first_label": [], "second_label": ["Detection"], "data": "S Qian, L Tan, Y Zhang- arXiv preprint arXiv:2509.26529, 2025\nRecent studies have revealed that self-sustaining cascading failures in distributed \nsystems frequently lead to widespread outages, which are challenging to contain \nand recover from. Existing failure detection techniques struggle to expose such \nfailures prior to deployment, as they typically require a complex combination of \nspecific conditions to be triggered. This challenge stems from the inherent nature of \ncascading failures, as they typically involve a sequence of fault propagations, each\nCites: Greybox fuzzing of distributed systems", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.26529&hl=en&sa=X&d=11252392900940553752&ei=7QLhaNfKOcyR6rQP8M_xgAM&scisig=AAZF9b-3HEhHrt4wYEVXZoe1IjcH&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Automatically Generating Web Applications from Requirements Via Multi-Agent Test-Driven Development", "first_label": ["Software Testing"], "second_label": ["Agent"], "data": "Y Wan, T Liang, J Xu, J Xiao, Y Huo, MR Lyu- arXiv preprint arXiv:2509.25297, 2025\nDeveloping full-stack web applications is complex and time-intensive, demanding \nproficiency across diverse technologies and frameworks. Although recent advances \nin multimodal large language models (MLLMs) enable automated webpage \ngeneration from visual inputs, current solutions remain limited to front-end tasks and \nfail to deliver fully functional applications. In this work, we introduce TDDev, the first \ntest-driven development (TDD)-enabled LLM-agent framework for end-to-end full\nCites: AutoCodeRover: Autonomous program improvement", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25297&hl=en&sa=X&d=4746521913476546533&ei=7QLhaNfKOcyR6rQP8M_xgAM&scisig=AAZF9b98ww75dGqDJ2dR99qJxeKd&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "How Does my Circuit Work?: Local Explanations for the Behavior of Sequential Circuits", "first_label": [], "second_label": [], "data": "A Nazari, M Amini, M Raghothaman- #, 2025\nThere has been a massive amount of work on algorithms to verify and synthesize \nsystems from temporal specifications. In contrast, there has been less work devoted \nto the problem of helping engineers to understand how and why their systems exhibit \ncertain behaviors. Such understanding is important for them to debug, validate, and \nmodify their implementations in response to changing needs. In this paper, we \npresent one possible formalization of this problem as the task of recovering\nCites: Angelix: Scalable multiline program patch synthesis via symbolic", "link": "https://scholar.google.com/scholar_url?url=https://repositum.tuwien.at/bitstream/20.500.12708/219535/1/Nazari-2025-How%2520Does%2520my%2520Circuit%2520Work%2520Local%2520Explanations%2520for%2520the%2520Behavior%2520...-vor.pdf&hl=en&sa=X&d=13897714025176351091&ei=7QLhaNfKOcyR6rQP8M_xgAM&scisig=AAZF9b-PwZYdENGpSwtpAX-BRpEq&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "SoK: AI-FLARE: An Exposition of AI Fuzzing Techniques via Reasoning with LLMs", "first_label": ["LLM", "Fuzzing"], "second_label": ["Reasoning"], "data": "M Alam, A Hussain, SK Paul, AW Hays, MI Huq\nAI models, including deep learning architectures and large language models (LLMs), \nare increasingly deployed in safety-critical settings, where unexpected behaviors can \nlead to serious consequences. AI model fuzzing, an automated technique that \nmutates inputs to uncover model failures, has emerged as a promising approach to \nexpose such vulnerabilities. Yet, we lack a systematic understanding of how well \nexisting fuzzers uncover safety-and security-relevant flaws or generalize across\nCites: Fuzz Testing based Data Augmentation to Improve Robustness of", "link": "https://scholar.google.com/scholar_url?url=https://spies.engr.tamu.edu/wp-content/uploads/sites/239/2025/09/SoK_AI_Fuzzing.pdf&hl=en&sa=X&d=6252389289193533272&ei=7QLhaNfKOcyR6rQP8M_xgAM&scisig=AAZF9b9St585ag9hhGvRHWsUivCw&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Optimizing CNN Inference on Multicore Scratchpad Architectures", "first_label": [], "second_label": [], "data": "C Daini, G Lipari, HE Zahaf, PE Hladik- 2025 28th International Symposium on Real, 2025\nMany Artificial Intelligence algorithms (eg Convolutional Neural Networks-CNNs) can \nbe modeled as a collection of functions which communicate with each other \naccording to a directed acyclic graph. The main goal of this paper is to optimize the \nexecution of CNNs on real-time embedded systems based on a multicore \narchitecture with scratchpad memory. In a typical multicore platform, cores share a \ncomplex memory hierarchy with one or more levels of cache memories, leading to\nCites: Scratchpad allocation for concurrent embedded software", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11172993/&hl=en&sa=X&d=1896698597977736208&ei=7QLhaNfKOcyR6rQP8M_xgAM&scisig=AAZF9b9CRVTBgThs9z-zVLMuTWj5&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Robust Embedded Software in Extreme Environments", "first_label": [], "second_label": [], "data": "A El Yaacoub - 2025\nEmbedded systems deployed in extreme environments must be designed to be \nrobust so that they can operate correctly. For example, satellites must tolerate \nradiation induced faults, and drones must tolerate strong winds. Designing robust \nsystems is challenging, especially for devices with limited hardware resources and \nreal-time requirements. In this dissertation, we address several problems related to \nthe design of robust real-time embedded systems. We address robustness on two\nCites: Chronos: A timing analyzer for embedded software", "link": "https://scholar.google.com/scholar_url?url=https://www.diva-portal.org/smash/get/diva2:1995314/FULLTEXT01.pdf&hl=en&sa=X&d=16189956222402914959&ei=7QLhaNfKOcyR6rQP8M_xgAM&scisig=AAZF9b9QDBTmG2wif1hW0QhMx8mL&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Integration of Expert Systems and Internet of Things for Real-time Decision Making: Review of Core Components, Architectures, Applications, and Future Prospects.", "first_label": [], "second_label": [], "data": "AC Ikegwu, JC Nnabue, HF Nweke, DE Mathew- Nature Journal of Emerging, 2025\nThe expansion of the Internet of Things (IoT) has enabled a unique ability to collect \ndata across multiple domains. However, conventional IoT systems face restrictions \nwhen trying to process this data for complicated, real-time decision-making because \nof challenges concerning latency, bandwidth, and inefficient computational power. \nThis review analyses the integration of expert systems with IoT to resolve these \nchallenges. Integrating rule-based reasoning and inference abilities straight into the\nCites: Surveying neuro-symbolic approaches for reliable artificial", "link": "https://scholar.google.com/scholar_url?url=https://naturerust.com/index.php/njesti/article/view/5&hl=en&sa=X&d=4863507403094697069&ei=7QLhaICqDaDWieoPvfCV6QI&scisig=AAZF9b8PhKuVP8hVelPPo64pULVM&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang"]}
{"title": "Neuro Symbolic Architectures with Artificial Intelligence for Collaborative Control and Intention Prediction", "first_label": [], "second_label": [], "data": "AK Ejalonibu - 2025\nNeuro symbolic architectures represent a paradigm shift in artificial intelligence, \ncombining the pattern recognition capabilities of neural networks with the logical \nreasoning power of symbolic systems. This review examines the current state of \nneuro symbolic AI in collaborative control systems and intention prediction \napplications. We explore foundational concepts, architectural designs, and \nimplementation strategies while analyzing challenges in integration, scalability, and\nCites: Surveying neuro-symbolic approaches for reliable artificial\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Adewale-Ejalonibu/publication/396001792_Neuro_Symbolic_Architectures_with_Artificial_Intelligence_for_Collaborative_Control_and_Intention_Prediction/links/68dc426602d6215259b76abe/Neuro-Symbolic-Architectures-with-Artificial-Intelligence-for-Collaborative-Control-and-Intention-Prediction.pdf&hl=en&sa=X&d=12551025877788280296&ei=7QLhaICqDaDWieoPvfCV6QI&scisig=AAZF9b9XQJovGoZgRxcJvxTChXYC&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang"]}
{"title": "Beyond Autoregression: An Empirical Study of Diffusion Large Language Models for Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Y Zhang, J Li, L Cai, G Li- arXiv preprint arXiv:2509.11252, 2025\nLLMs have become the mainstream approaches to code generation. Existing LLMs \nmainly employ autoregressive generation, ie generating code token-by-token from \nleft to right. However, the underlying autoregressive generation has two limitations in", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.11252%3F&hl=en&sa=X&d=14760542882128875800&ei=7QLhaM2eK8Sz6rQPyKGw-Ag&scisig=AAZF9b-R0PkwtsaKsfDOC73D1nEW&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "CLMTracing: Black-box User-level Watermarking for Code Language Model Tracing", "first_label": ["LLM", "Code"], "second_label": [], "data": "B Zhang, P He, T Du, X Zhang, L Yun, K Chow, J Yin- arXiv preprint arXiv, 2025\nWith the widespread adoption of open-source code language models (code LMs), \nintellectual property (IP) protection has become an increasingly critical concern. \nWhile current watermarking techniques have the potential to identify the code LM to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.13982&hl=en&sa=X&d=14851863240844447268&ei=7QLhaM2eK8Sz6rQPyKGw-Ag&scisig=AAZF9b9MnsfxxD6KbVrkei3eB0d6&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Generating High-Quality Datasets for Code Editing via Open-Source Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "Z Zhang, M Liu, Z Chen, L Liang, Y Chen, G Ou- arXiv preprint arXiv, 2025\nCode editing plays a vital role in software engineering, requiring developers to adjust \nexisting code according to natural language instructions while keeping functionality \nintact and avoiding unnecessary modifications. However, commit-based datasets", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25203&hl=en&sa=X&d=16003307718581653243&ei=7QLhaM2eK8Sz6rQPyKGw-Ag&scisig=AAZF9b-WX82g5S_NgG548uiHBBUN&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Bach Le - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "A Multi-Language Object-Oriented Programming Benchmark for Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "S Wang, L Ding, L Shen, Y Luo, H Hu, L Zhang, F Lin- arXiv preprint arXiv, 2025\nEstablishing fair and robust benchmarks is essential for evaluating intelligent code \ngeneration by large language models (LLMs). Our survey of 35 existing benchmarks \nuncovers three major imbalances: 85.7% focus on a single programming language;", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.26111&hl=en&sa=X&d=2388658668398987935&ei=7QLhaM2eK8Sz6rQPyKGw-Ag&scisig=AAZF9b9Ub4HZbeKJo7hOj_F50uM3&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "The Impact of Security Mindset on the Use of AI Assistants in Computing Education", "first_label": [], "second_label": [], "data": "J Yuan, Y Li- IEEE Transactions on Education, 2025\nThe recent advances in large-language models (LLMs) have started shifting the way \ncomputing-related students write codes. LLM-based AI assistants, such as ChatGPT \nand Copilot, are now increasingly adopted to produce functional code by computing", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11182622/&hl=en&sa=X&d=14447870908413552944&ei=7QLhaM2eK8Sz6rQPyKGw-Ag&scisig=AAZF9b9oylvg-unEXZvQBW3lEPCl&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Local Agentic RAG-Based Information System Development for Intelligent Analysis of GitHub Code Repositories in Computer Science Education", "first_label": ["Code"], "second_label": ["Agent"], "data": "Z Hu, MM Paprotskyi, V Vysotska, L Chyrun, Y Ushenko\nThis study presents the development and evaluation of a local agent-based Retrieval-\nAugmented Generation (Agentic RAG) system designed for the intelligent analysis of \nGitHub repositories in computer science education and IT practice. The novelty of", "link": "https://scholar.google.com/scholar_url?url=https://www.mecs-press.org/ijmecs/ijmecs-v17-n5/IJMECS-V17-N5-7.pdf&hl=en&sa=X&d=15899062735032558573&ei=7QLhaM2eK8Sz6rQPyKGw-Ag&scisig=AAZF9b9zpITZz-kJHGT1UMgEWtn4&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "Evaluating SAP Joule for Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "J Heisler, J Reisinger, A Fischer- arXiv preprint arXiv:2509.24828, 2025\nSAP has released its own proprietary generative model SAP Joule, intended for \nvarious generative tasks, including serving as a code assistant for software \nengineers. While Joule is yet not focused on SAP-specific ABAP code generation, it", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24828&hl=en&sa=X&d=3752269403016204218&ei=7QLhaM2eK8Sz6rQPyKGw-Ag&scisig=AAZF9b99WxxwInMhTJnAhqJdbCXJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "UFROSFA: Unified Feature Representation and Oppositional Structure Feature Alignment for MixedProject Heterogeneous Defect Prediction", "first_label": ["Software Defect"], "second_label": [], "data": "Y Zou, H Wang, H Lv, S Zhao- Journal of Software: Evolution and Process, 2025\nHeterogeneous defect prediction (HDP) plays a crucial role in software engineering \nby enabling the early detection of software defects across projects with \nheterogeneous feature spaces. Recently, some mixedproject HDP (MPHDP)", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.70049&hl=en&sa=X&d=364923038290244081&ei=7QLhaM2eK8Sz6rQPyKGw-Ag&scisig=AAZF9b-E5cxhXgoDR9kKlLYk-LrA&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "VeriExploit: Automatic Bug Reproduction in Smart Contracts via LLMs and Formal Methods", "first_label": ["Smart Contracts", "LLM", "Bug"], "second_label": ["Exploit"], "data": "C Wei, S Cai, Y Charalambous, T Wu, S Godboley- 40th IEEE/ACM International, 2025\nBug reproduction is becoming an important task in the security analysis of Solidity \nsmart contracts. By simulating attacks, developers and auditors can better \nunderstand how a vulnerability is triggered in practice. To reproduce a bug, one often\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://research.manchester.ac.uk/en/publications/veriexploit-automatic-bug-reproduction-in-smart-contracts-via-llm&hl=en&sa=X&d=5506893362899541967&ei=7QLhaM2eK8Sz6rQPyKGw-Ag&scisig=AAZF9b_Hk5alIs4O8KEMSDLg-SH9&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models", "first_label": ["LLM", "Bug", "Repository-Level"], "second_label": [], "data": "J Liu, Z Liu, Z Cheng, M He, X Shi, Y Guo, X Zhu, Y Guo- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have exhibited significant proficiency in code \ndebugging, especially in automatic program repair, which may substantially reduce \nthe time consumption of developers and enhance their efficiency. Significant\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04078%3F&hl=en&sa=X&d=12419661760319839544&ei=7ALhaJC7GZ6sieoP2PTggQg&scisig=AAZF9b8SHef7li0_lXitWcja8LI-&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=4&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Cross-Domain Evaluation of Transformer-Based Vulnerability Detection on Open & Industry Data", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "M Mock, T Forrer, B Russo- arXiv preprint arXiv:2509.09313, 2025\nDeep learning solutions for vulnerability detection proposed in academic research \nare not always accessible to developers, and their applicability in industrial settings \nis rarely addressed. Transferring such technologies from academia to industry", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.09313&hl=en&sa=X&d=3896104068122220271&ei=7ALhaPPBOp2N6rQP3enmuQg&scisig=AAZF9b-3QAzHZH6Dtl2JLErNC_cZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "SLD-Spec: Enhancement LLM-assisted Specification Generation for Complex Loop Functions via Program Slicing and Logical Deletion", "first_label": ["LLM"], "second_label": ["Generation"], "data": "Z Chen, L Zhang, Z Zhang, JJ Zhang, R Zhou, Y Shen- arXiv preprint arXiv, 2025\nAutomatically generating formal specifications from program code can greatly \nenhance the efficiency of program verification and enable end-to-end automation \nfrom requirements to reliable software. However, existing LLM-based approaches", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.09917&hl=en&sa=X&d=2122673112308488324&ei=7ALhaPPBOp2N6rQP3enmuQg&scisig=AAZF9b-CuDfsPWCmN1n_oNohxVgn&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Fuzzing as editor feedback", "first_label": ["Fuzzing"], "second_label": [], "data": "M Garus, J Lincke, R Hirschfeld- Companion Proceedings of the 9th International, 2025\nLive programming requires concrete examples, but coming up with examples takes \neffort. However, there are ways to execute code without specifying examples, such \nas fuzzing. Fuzzing is a technique that synthesizes program inputs to find bugs in", "link": "https://scholar.google.com/scholar_url?url=https://drops.dagstuhl.de/storage/01oasics/oasics-vol134-programming2025/OASIcs.Programming.2025.8/OASIcs.Programming.2025.8.pdf&hl=en&sa=X&d=4846729257551256103&ei=7gLhaOaPGJ2qieoPz8OP6Qo&scisig=AAZF9b_a936tJ2euestamYofC9hC&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Lita: Light Agent Uncovers the Agentic Coding Capabilities of LLMs", "first_label": ["LLM"], "second_label": ["Agent"], "data": "H Dai, M Wang, M Qi, Y Zhang, Z Jin, Y Yao, Y Huang- arXiv preprint arXiv, 2025\nLarge language models (LLMs) are increasingly being applied to programming \ntasks, ranging from single-turn code completion to autonomous agents. Current code \nagent designs frequently depend on complex, hand-crafted workflows and tool sets", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25873&hl=en&sa=X&d=5924892323788224733&ei=7gLhaOaPGJ2qieoPz8OP6Qo&scisig=AAZF9b-H2WTgCqmXbga4bh28v3WG&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Semantic-Aware Fuzzing: An Empirical Framework for LLM-Guided, Reasoning-Driven Input Mutation", "first_label": ["LLM", "Fuzzing"], "second_label": ["Reasoning"], "data": "M Lu, S Ding, F Alaca, P Charland- arXiv preprint arXiv:2509.19533, 2025\nSecurity vulnerabilities in Internet-of-Things devices, mobile platforms, and \nautonomous systems remain critical. Traditional mutation-based fuzzers--while \neffectively explore code paths--primarily perform byte-or bit-level edits without", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19533&hl=en&sa=X&d=537743905954534716&ei=7gLhaOaPGJ2qieoPz8OP6Qo&scisig=AAZF9b8SCOpQdg1OxBk00igQIrJA&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "STAFF: Stateful Taint-Assisted Full-system Firmware Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A Izzillo, R Lazzeretti, E Coppa- arXiv preprint arXiv:2509.18039, 2025\nModern embedded Linux devices, such as routers, IP cameras, and IoT gateways, \nrely on complex software stacks where numerous daemons interact to provide \nservices. Testing these devices is crucial from a security perspective since vendors", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18039&hl=en&sa=X&d=14471577617811823956&ei=7gLhaOaPGJ2qieoPz8OP6Qo&scisig=AAZF9b8iiNsdPIPeQqPwlBXEq_w5&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Better Privilege Separation for Agents by Restricting Data Types", "first_label": [], "second_label": ["Agent"], "data": "D Jacob, E Alghamdi, Z Hu, B Alomair, D Wagner- arXiv preprint arXiv:2509.25926, 2025\nLarge language models (LLMs) have become increasingly popular due to their \nability to interact with unstructured content. As such, LLMs are now a key driver \nbehind the automation of language processing systems, such as AI agents", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25926&hl=en&sa=X&d=10551647277433403691&ei=7gLhaOaPGJ2qieoPz8OP6Qo&scisig=AAZF9b_u9GtNZYs_dE6jRQKic3Ok&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Richard Fang - new related research"]}
{"title": "PromeFuzz: A Knowledge-Driven Approach to Fuzzing Harness Generation with Large Language Models", "first_label": ["LLM", "Fuzzing"], "second_label": ["Generation"], "data": "Y Liu, J Deng, X Jia, Y Wang, M Wang, L Huang, T Wei\nFuzzing has long been recognized as an effective technique for uncovering security \nvulnerabilities by automatically generating and executing a diverse set of inputs [2, 3, \n6, 8, 14, 15, 18, 20, 24, 26, 30, 32, 34, 46, 52, 53, 55, 58]. Traditional fuzzing tools", "link": "https://scholar.google.com/scholar_url?url=https://pvz122.github.io/pdf/25-promefuzz.pdf&hl=en&sa=X&d=12396611312661296556&ei=7gLhaOaPGJ2qieoPz8OP6Qo&scisig=AAZF9b-wSitwHBsEc3RIko2Rlc5c&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=6&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Evaluating the Effectiveness of Coverage-Guided Fuzzing for Testing Deep Learning Library APIs", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "F Qin, MM Naziri, H Ai, S Dutta, M d'Amorim- arXiv preprint arXiv:2509.14626, 2025\nDeep Learning (DL) libraries such as PyTorch provide the core components to build \nmajor AI-enabled applications. Finding bugs in these libraries is important and \nchallenging. Prior approaches have tackled this by performing either API-level", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.14626&hl=en&sa=X&d=11350896954294303435&ei=7gLhaOaPGJ2qieoPz8OP6Qo&scisig=AAZF9b_GT4mzQ2w1NTOQ8RIfpK9G&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=7&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "R1-Fuzz: Specializing Language Models for Textual Fuzzing via Reinforcement Learning", "first_label": ["LLM", "Fuzzing"], "second_label": [], "data": "J Lin, L Su, J Li, C Qian- arXiv preprint arXiv:2509.20384, 2025\nFuzzing is effective for vulnerability discovery but struggles with complex targets such \nas compilers, interpreters, and database engines, which accept textual input that \nmust satisfy intricate syntactic and semantic constraints. Although language models", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.20384&hl=en&sa=X&d=1649136629077213896&ei=7gLhaOaPGJ2qieoPz8OP6Qo&scisig=AAZF9b9A_fC3MFUyhQ5sK9VXroDy&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=8&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Syntactic multilingual probing of pre-trained language models of code", "first_label": ["LLM", "Code"], "second_label": [], "data": "JAH Lpez, M Weyssow, JS Cuadrado, H Sahraoui- Journal of Systems and, 2026\nPre-trained language models (PLMs) have demonstrated remarkable abilities in \ncoding tasks, establishing themselves as a state-of-the-art technique in machine \nlearning for code. However, due to their deep neural network-based structure, PLMs", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225002730&hl=en&sa=X&d=912414639058686127&ei=7wLhaMnKJcasieoP3am_iQM&scisig=AAZF9b_JpbZnEYTzTsY6dFTnCppp&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Detecting and Fixing API Misuses of Data Science Libraries Using Large Language Models", "first_label": ["LLM"], "second_label": ["Detection"], "data": "A Galappaththi, F Ribeiro, S Nadi- arXiv preprint arXiv:2509.25378, 2025\nData science libraries, such as scikit-learn and pandas, specialize in processing and \nmanipulating data. The data-centric nature of these libraries makes the detection of \nAPI misuse in them more challenging. This paper introduces DSCHECKER, an LLM", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25378&hl=en&sa=X&d=14058605386697265462&ei=7wLhaMnKJcasieoP3am_iQM&scisig=AAZF9b9IShG12tfy_E6MI3bYz_8z&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Adversarial Bug Reports as a Security Risk in Language Model-Based Automated Program Repair", "first_label": ["APR", "LLM", "Bug"], "second_label": ["Repair"], "data": "P Przymus, A Happe, J Cito- arXiv preprint arXiv:2509.05372, 2025\nLarge Language Model (LLM)-based Automated Program Repair (APR) systems are \nincreasingly integrated into modern software development workflows, offering \nautomated patches in response to natural language bug reports. However, this", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05372&hl=en&sa=X&d=17856431439942945890&ei=7wLhaMnKJcasieoP3am_iQM&scisig=AAZF9b9iNtxXJTJlEQXG_3JYQbs1&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Richard Fang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "TeTRIS: General-purpose Fuzzing for Translation Bugs in Source-to-Source Code Transpilers", "first_label": ["Fuzzing", "Code", "Bug"], "second_label": ["Generation"], "data": "Y Arafat, S Nagy - 2025\nThis paper focuses on the problem of multi-robot source-seeking, where a group of \nmobile sensors localizes and moves close to a single source using only local \nmeasurements. Drawing inspiration from the optimal sensor placement research, we", "link": "https://scholar.google.com/scholar_url?url=https://par.nsf.gov/biblio/10639405&hl=en&sa=X&d=7907468188891103628&ei=7wLhaMnKJcasieoP3am_iQM&scisig=AAZF9b-JjvHEqFSkoWR3imUFGdYu&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "GTVD: a multi-level aggregation vulnerability detection method based on full-dependency program graph", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "H He, S Li, Y Li, Y Li- Cluster Computing, 2025\nIn modern software development life cycles, proactive vulnerability discovery and \nremediation play crucial roles in ensuring application security. However, current \ndeep learning-based vulnerability detection methods frequently face limitations due", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10586-025-05506-7&hl=en&sa=X&d=9365356712912853263&ei=7wLhaMnKJcasieoP3am_iQM&scisig=AAZF9b_DdZ4fyL1mLj90wo4wpBRq&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Defeating Cerberus: Concept-Guided Privacy-Leakage Mitigation in Multimodal Language Models", "first_label": ["LLM"], "second_label": [], "data": "B Zhang, IE Akkus, R Chen, A Dethise, K Satzke- arXiv preprint arXiv, 2025\nMultimodal large language models (MLLMs) have demonstrated remarkable \ncapabilities in processing and reasoning over diverse modalities, but their advanced \nabilities also raise significant privacy concerns, particularly regarding Personally", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25525&hl=en&sa=X&d=188731358198544290&ei=7wLhaMTSAZ2N6rQP3enmuQg&scisig=AAZF9b_EU8J7u2BDblVrMgHsY-QG&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration", "first_label": ["LLM"], "second_label": ["Agent"], "data": "X Chen, J Zhao, Y Yuan, T Zhang, H Zhou, Z Zhu, P Hu- arXiv preprint arXiv, 2025\nExisting safety evaluation methods for large language models (LLMs) suffer from \ninherent limitations, including evaluator bias and detection failures arising from \nmodel homogeneity, which collectively undermine the robustness of risk evaluation", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25271&hl=en&sa=X&d=9498150266007123670&ei=7wLhaMTSAZ2N6rQP3enmuQg&scisig=AAZF9b_UXRq4nDsuky7i5vKaVskx&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Exploit Tool Invocation Prompt for Tool Behavior Hijacking in LLM-Based Agentic System", "first_label": ["LLM"], "second_label": ["Agent", "Exploit"], "data": "Y Liu, Y Xie, M Luo, Z Liu, Z Zhang, K Zhang, Z Li- arXiv preprint arXiv, 2025\nLLM-based agentic systems leverage large language models to handle user queries, \nmake decisions, and execute external tools for complex tasks across domains like \nchatbots, customer service, and software engineering. A critical component of these", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05755%3F&hl=en&sa=X&d=7380962265010499197&ei=7wLhaMTSAZ2N6rQP3enmuQg&scisig=AAZF9b_WNN5iEJzU4LQ3fLBGGpF6&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Paladin: Defending LLM-enabled Phishing Emails with a New Trigger-Tag Paradigm", "first_label": ["LLM"], "second_label": [], "data": "Y Pang, W Meng, X Liao, T Wang- arXiv preprint arXiv:2509.07287, 2025\nWith the rapid development of large language models, the potential threat of their \nmalicious use, particularly in generating phishing content, is becoming increasingly \nprevalent. Leveraging the capabilities of LLMs, malicious users can synthesize", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.07287&hl=en&sa=X&d=841142860163656335&ei=7wLhaMTSAZ2N6rQP3enmuQg&scisig=AAZF9b9zUiVve_NVtg5_7UjR-gXJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Leveraging CVAE Encoding for Backdoor Attacks in Few-Shot Learning with Prototypical Networks", "first_label": [], "second_label": [], "data": "Q Yan, S Liang, A Ullah- IEEE Transactions on Dependable and Secure, 2025\nFew-shot learning (FSL) has demonstrated tremendous potential when challenged \nwith limited training data, but the assessment of its vulnerability to backdoor attacks is \nstill at an early stage. However, recent research revealed this deep learning", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11152502/&hl=en&sa=X&d=6687930075784700670&ei=7wLhaMTSAZ2N6rQP3enmuQg&scisig=AAZF9b9ptsbEWBr80FGSyzcZR2Er&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Jailbreak Attack with Multimodal Virtual Scenario Hypnosis for Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "X Shi, S Chen, G Zhang, W Wei, Y Li, Z Fan, J Liu- Pattern Recognition, 2025\nDue to the inherent vulnerabilities of large Vision-Language Models (VLMs), security \ngovernance has emerged as a critical concern, particularly given the risks posed by \nnoisy and biased training data as well as adversarial attacks, including data", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0031320325010520&hl=en&sa=X&d=18404876866865125967&ei=7wLhaMTSAZ2N6rQP3enmuQg&scisig=AAZF9b9xJx3YOX0I9CBN24pCw_YG&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SWE-QA: Can Language Models Answer Repository-level Code Questions?", "first_label": ["LLM", "Code", "Repository-Level"], "second_label": [], "data": "W Peng, Y Shi, Y Wang, X Zhang, B Shen, X Gu- arXiv preprint arXiv:2509.14635, 2025\nUnderstanding and reasoning about entire software repositories is an essential \ncapability for intelligent software engineering tools. While existing benchmarks such \nas CoSQA and CodeQA have advanced the field, they predominantly focus on small", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.14635&hl=en&sa=X&d=15006803551698078506&ei=7wLhaMTSAZ2N6rQP3enmuQg&scisig=AAZF9b-gcqnrJWuOC2cDSJR6nYNt&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "ArcGen: Generalizing Neural Backdoor Detection Across Diverse Architectures", "first_label": [], "second_label": ["Detection"], "data": "Z Yang, C Luo, D He, Y Li, Y Li- IEEE Transactions on Information Forensics and, 2025\nBackdoor attacks pose a significant threat to the security and reliability of deep \nlearning models. To mitigate such attacks, one promising approach is to learn to \nextract features from the target model and use these features for backdoor detection", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11165475/&hl=en&sa=X&d=7195582352476832979&ei=7wLhaMTSAZ2N6rQP3enmuQg&scisig=AAZF9b8nLgHrtCNJPGLAFhh3jGYp&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "RANGER--Repository-Level Agent for Graph-Enhanced Retrieval", "first_label": ["Repository-Level"], "second_label": ["Agent", "Graph"], "data": "P Shah, R Ghosh, A Singhal, D Dutta- arXiv preprint arXiv:2509.25257, 2025\nGeneral-purpose automated software engineering (ASE) includes tasks such as \ncode completion, retrieval, repair, QA, and summarization. These tasks require a \ncode retrieval system that can handle specific queries about code entities, or code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25257&hl=en&sa=X&d=3054390226051185769&ei=7wLhaOn6Dc_O6rQP8eu_gAo&scisig=AAZF9b9Eew0DWviT3v-viFDU1IhW&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Reinforcement Learning-Guided Chain-of-Draft for Token-Efficient Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "X Tang, IE Olatunji, T Sun, J Klein, TF Bissyande- arXiv preprint arXiv:2509.25243, 2025\nLLMs demonstrate surface-level fluency in code generation but struggle with \nstructured reasoning tasks requiring correctness and semantic alignment. While \nChain-of-Thought (CoT) prompting enhances reasoning through intermediate steps\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25243&hl=en&sa=X&d=13341888933482322315&ei=7wLhaOn6Dc_O6rQP8eu_gAo&scisig=AAZF9b921Ipm0Cl6-LFEjKxPyIuq&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "JJ Li, J He, C Shang, D Kulshreshtha, X Xian, Y Zhang- arXiv preprint arXiv, 2025\nAs LLMs advance into autonomous agents with tool-use capabilities, they introduce \nsecurity challenges that extend beyond traditional content-based LLM safety \nconcerns. This paper introduces Sequential Tool Attack Chaining (STAC), a novel \nmulti-turn attack framework that exploits agent tool use. STAC chains together tool \ncalls that each appear harmless in isolation but, when combined, collectively enable \nharmful operations that only become apparent at the final execution step. We apply\nCites: Adaptive attacks break defenses against indirect prompt injection", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25624&hl=en&sa=X&d=5260927131714903741&ei=7ALhaNefKoSb6rQPt9iYgAM&scisig=AAZF9b-2X2MHEQe4edEMu7RoCaxC&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "SafeBehavior: Simulating Human-Like Multistage Reasoning to Mitigate Jailbreak Attacks in Large Language Models", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "Q Zhao, J Wang, Z Gao, Z Dou, B Abuhaija, K Huang- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have achieved impressive performance across \ndiverse natural language processing tasks, but their growing power also amplifies \npotential risks such as jailbreak attacks that circumvent built-in safety mechanisms. \nExisting defenses including input paraphrasing, multi step evaluation, and safety \nexpert models often suffer from high computational costs, limited generalization, or \nrigid workflows that fail to detect subtle malicious intent embedded in complex\nCites: Removing rlhf protections in gpt-4 via fine-tuning\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.26345&hl=en&sa=X&d=4186623186212525589&ei=7ALhaNefKoSb6rQPt9iYgAM&scisig=AAZF9b8kIJbFqgpfaFta6g2xMhdR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "What Do They Fix? LLM-Aided Categorization of Security Patches for Critical Memory Bugs", "first_label": ["LLM", "Bug"], "second_label": [], "data": "X Li, J Pu, Y Wu, X Zou, S Zhu, Q Wu, Z Zhang, J Hsu- arXiv preprint arXiv, 2025\nOpen-source software projects are foundational to modern software ecosystems, with \nthe Linux kernel standing out as a critical exemplar due to its ubiquity and \ncomplexity. Although security patches are continuously integrated into the Linux", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22796&hl=en&sa=X&d=5877456260761011502&ei=OWffaJLDHMnXieoP-o3JmQ0&scisig=AAZF9b_K5bVx20Ft-L-epPjLrGqv&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research", "David Lo - new related research", "Bach Le - new related research"]}
{"title": "Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "K Shehada, Y Wu, WD Feng, A Iyer, G Kumfert, Y Ding- NeurIPS 2025 Workshop on\nLarge Language Models (LLMs) have revolutionized automated program repair \n(APR) but current benchmarks like SWE-Bench predominantly focus on userspace \napplications and overlook the complexities of kernel-space debugging and repair", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DNY4wv5C39G&hl=en&sa=X&d=13284020585308537468&ei=OWffaJLDHMnXieoP-o3JmQ0&scisig=AAZF9b8qiQW2WOt5dhxoK0fl5lFh&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Abhik Roychoudhury - new related research", "Quang-Cuong Bui - new related research", "David Lo - new related research", "Bach Le - new related research"]}
{"title": "When Code Crosses Borders: A Security-Centric Evaluation of LLM-based Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "H Chang, G Meng, S Xiao, K Chen, K Sun, Y Li- arXiv preprint arXiv:2509.06504, 2025\nWith the growing demand for cross-language codebase migration, evaluating LLMs' \nsecurity implications in translation tasks has become critical. Existing evaluations \nprimarily focus on syntactic or functional correctness at the function level, neglecting", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.06504&hl=en&sa=X&d=15964686870607645440&ei=OWffaJLDHMnXieoP-o3JmQ0&scisig=AAZF9b9rJmR42d8IPErh15fFE3f8&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "DeepCodeProbe: Evaluating Code Representation Quality in Models Trained on Code", "first_label": ["Code"], "second_label": [], "data": "V Majdinasab, A Nikanjam, F Khomh- Empirical Software Engineering, 2025\nAbstract Machine Learning models trained on code and artifacts extracted from them \n(eg, version control histories, code differences, etc.), provide invaluable assistance \nfor software engineering tasks. Despite their good performance, there exists a lack of", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10731-0&hl=en&sa=X&d=4894546859526238222&ei=OWffaJLDHMnXieoP-o3JmQ0&scisig=AAZF9b9PrlAWMKjBTBOwWDVqSOtc&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "Bridging Developer Instructions and Code Completion Through Instruction-Aware Fill-in-the-Middle Paradigm", "first_label": ["Code"], "second_label": ["Generation"], "data": "Z Sun, C Yang, C Peng, P Gao, X Du, L Li, D Lo- arXiv preprint arXiv:2509.24637, 2025\nLarge Language Models (LLMs) have significantly advanced code completion, yet \nthey often fail when the developer's intent is underspecified in the code context. To \naddress this, developers usually add natural language instructions (eg, comments)", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24637&hl=en&sa=X&d=17305794744039020422&ei=OWffaJLDHMnXieoP-o3JmQ0&scisig=AAZF9b-qDU6QAC4PPz9qG-_owbNR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "From Cryptic to Clear-Training on LLM Explanations to Detect Smart Contract Vulnerabilities", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": [], "data": "Y Chen, Z Sun, G Wang, Q Liang, X Yu, D Hao- ACM Transactions on Software, 2025\nSmart contracts have revolutionized the way transactions are executed, offering \ndecentralized and immutable frameworks. The immutability of smart contracts poses \nsignificant risks when vulnerabilities exist in their code, leading to financial losses", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3765753&hl=en&sa=X&d=10696251976758637118&ei=OWffaJLDHMnXieoP-o3JmQ0&scisig=AAZF9b9ZBf4NQYTpgMU9yATSPdqf&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Improving the Efficiency of LLM Agent Systems through Trajectory Reduction", "first_label": ["LLM"], "second_label": ["Agent"], "data": "YA Xiao, P Gao, C Peng, Y Xiong- arXiv preprint arXiv:2509.23586, 2025\nMulti-turn agent systems based on Large Language Models (LLMs) have been \nincreasingly popular for software engineering tasks. While LLM agents show decent \neffectiveness, the high computational cost of input tokens due to the ever-growing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23586&hl=en&sa=X&d=12596444921036280365&ei=OWffaJLDHMnXieoP-o3JmQ0&scisig=AAZF9b-Nsxb9BzRYoIftNViBPFg1&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Abhik Roychoudhury - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research", "David Lo - new related research", "Bach Le - new related research", "4 new citations to articles by Xin ZHOU"]}
{"title": "Towards Human-interpretable Explanation in Code Clone Detection using LLM-based Post Hoc Explainer", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "T Racharak, C Ragkhitwetsagul, C Junplong- arXiv preprint arXiv, 2025\nRecent studies highlight various machine learning (ML)-based techniques for code \nclone detection, which can be integrated into developer tools such as static code \nanalysis. With the advancements brought by ML in code understanding, ML-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22978&hl=en&sa=X&d=13116222657243354012&ei=OWffaJLDHMnXieoP-o3JmQ0&scisig=AAZF9b-CrNTuw-vA-xt9R-PWj2rN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "TF-Bench: Evaluating Program Semantics Reasoning with Type Inference in System F", "first_label": [], "second_label": ["Reasoning"], "data": "Y He, L Yang, CCG Gonzalo, H Chen- arXiv preprint arXiv:2509.23686, 2025\nLarge Language Models (LLMs) are increasingly integrated into the software \nengineering ecosystem. Their test-time compute (TTC) reasoning capabilities show \nsignificant potential for understanding program logic and semantics beyond mere \ntoken recognition. However, current benchmarks for code reasoning lack a formal, \nprogram-centric deductive framework to ensure sound evaluation, and are incapable \nof assessing whether models genuinely reason about program semantics or merely\nCites: Can LLMs Reason About Program Semantics? A Comprehensive", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23686&hl=en&sa=X&d=7812027363893781818&ei=OGffaNCwHZycieoPgK6aoQo&scisig=AAZF9b921YNdLGMQG7M6UBXqYA2i&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 new citations to articles by Thanh Le-Cong", "6 new citations to articles by Bach Le"]}
{"title": "HFuzzer: Testing Large Language Models for Package Hallucinations via Phrase-based Fuzzing", "first_label": ["LLM", "Fuzzing", "Software Testing"], "second_label": [], "data": "Y Zhao, M Wu, X Hu, X Xia- arXiv preprint arXiv:2509.23835, 2025\nLarge Language Models (LLMs) are widely used for code generation, but they face \ncritical security risks when applied to practical production due to package \nhallucinations, in which LLMs recommend non-existent packages. These \nhallucinations can be exploited in software supply chain attacks, where malicious \nattackers exploit them to register harmful packages. It is critical to test LLMs for \npackage hallucinations to mitigate package hallucinations and defend against\nCites: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23835&hl=en&sa=X&d=16917587561815760773&ei=OGffaNCwHZycieoPgK6aoQo&scisig=AAZF9b8Mk-rnOTcKAAGqO9tIlO4J&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 new citations to articles by Thanh Le-Cong", "6 new citations to articles by Bach Le", "Abhik Roychoudhury - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research", "David Lo - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Automated Vulnerability Validation and Verification: A Large Language Model Approach", "first_label": ["Vulnerabilities", "Verification", "LLM"], "second_label": [], "data": "A Lotfi, C Katsis, E Bertino- arXiv preprint arXiv:2509.24037, 2025\nSoftware vulnerabilities remain a critical security challenge, providing entry points for \nattackers into enterprise networks. Despite advances in security practices, the lack of \nhigh-quality datasets capturing diverse exploit behavior limits effective vulnerability \nassessment and mitigation. This paper introduces an end-to-end multi-step pipeline \nleveraging generative AI, specifically large language models (LLMs), to address the \nchallenges of orchestrating and reproducing attacks to known software\nCites: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24037&hl=en&sa=X&d=7978409907240033186&ei=OGffaNCwHZycieoPgK6aoQo&scisig=AAZF9b8QoVaounWNCXofucwywvLP&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=2&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 new citations to articles by Thanh Le-Cong", "6 new citations to articles by Bach Le"]}
{"title": "Metamorphic Testing of Deep Code Models: A Systematic", "first_label": ["Code", "Software Testing"], "second_label": [], "data": "ALI ASGARI, M DE KONING, P DERAKHSHANFAR - 2025\nIn recent years, large language models for code (LLM4Code) have achieved \nremarkable performance across a range of software engineering tasks, reaching \naccuracy levels that make them increasingly viable for real-world adoption. These \ntasks include, but are not limited to, program repair [1], vulnerability detection [2, 3], \ncode completion [4, 5], and clone detection [6, 7], among others. However, the \npractical applicability of LLM4Code depends not only on their performance on\nCites: Evaluating program repair with semantic-preserving\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Annibale-Panichella/publication/395486459_Metamorphic_Testing_of_Deep_Code_Models_A_Systematic_Literature_Review/links/68d12186220a341aa14e4b74/Metamorphic-Testing-of-Deep-Code-Models-A-Systematic-Literature-Review.pdf&hl=en&sa=X&d=4283050785129156787&ei=OGffaNCwHZycieoPgK6aoQo&scisig=AAZF9b8CPVZTSsxHUaaieQPV0b6M&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=3&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 new citations to articles by Thanh Le-Cong", "6 new citations to articles by Bach Le", "David Lo - new related research", "7 new citations to articles by Hong Jin Kang", "4 new citations to articles by Xin ZHOU"]}
{"title": "Secure Motion Verification for Malicious Vehicles in Autonomous Driving", "first_label": ["Verification"], "second_label": [], "data": "W Yan, C Zhou, J Chen, Z Ning, Y Xie, N Yu- 2025 11th IEEE International, 2025\nIn autonomous driving and intelligent transportation systems, self-driving cars rely on \nmotion state information from surrounding vehicles for effective path planning. \nHowever, this reliance creates vulnerabilities, as malicious vehicles can inject false \ndata to compromise navigation and collision avoidance systems. To counter this \nthreat, we propose a holistic security framework that synergistically combines real-\ntime physical-layer verification with a long-term, decentralized reputation system built\nCites: Smart contract development: Challenges and opportunities", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/pcds/2025/774600a192/2aplMLyyDIc&hl=en&sa=X&d=2291248112185761117&ei=OmffaKXTA_iu6rQPlOqwiQY&scisig=AAZF9b_rQqrk_uJRyylGw5QsJnts&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=4&folt=cit", "author": ["Bach Le"], "ref": ["6 new citations to articles by Bach Le"]}
{"title": "KGCompass: Knowledge Graph Enhanced Repository-Level Software Repair", "first_label": ["Repository-Level"], "second_label": ["Repair", "Graph"], "data": "B YANG, J REN, S JIN, Y LIU, F LIU, B LE, H TIAN - 2025\nAuthors' Contact Information: Boyang Yang; Jiadong Ren; Shunfu Jin, Yanshan \nUniversity, China; Yang Liu, Nanyang Technological University, Singapore; Feng \nLiu; Bach Le, University of Melbourne, Australia; Haoye Tian, Aalto University, \nFinland.\nCites: A Survey of LLM-based Automated Program Repair: Taxonomies\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Boyang-Yang-2/publication/390247861_KGCompass_Knowledge_Graph_Enhanced_Repository-Level_Software_Repair/links/68cf54cc11d348252ba68e04/KGCompass-Knowledge-Graph-Enhanced-Repository-Level-Software-Repair.pdf&hl=en&sa=X&d=15376757677641919947&ei=OmffaKXTA_iu6rQPlOqwiQY&scisig=AAZF9b9PZD1aKGcwRv3HDINJO4vm&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=5&folt=cit", "author": ["Bach Le"], "ref": ["6 new citations to articles by Bach Le", "Bach Le - new articles", "7 new citations to articles by Hong Jin Kang", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents", "first_label": [], "second_label": ["Agent"], "data": "Z Yang, S Wang, K Fu, W He, W Xiong, Y Liu, Y Miao- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) are increasingly applied to software engineering \n(SWE), with SWE-bench as a key benchmark. Solutions are split into SWE-Agent \nframeworks with multi-turn interactions and workflow-based Agentless methods with", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23045&hl=en&sa=X&d=2319009272467082410&ei=O2ffaPPVFp6sieoP2PTggQg&scisig=AAZF9b9CT4ZER7as9GwLJ6RzCV2x&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Parallel Fuzzing based on Sub-tasks Scheduling", "first_label": ["Fuzzing"], "second_label": [], "data": "T Gu, T Wang, X Li, S Lu, Y Nie, Z Zhang, X Kuang- ACM Transactions on Software\nParallel fuzzing introduces two key steps: task division and task merging to improve \nefficiency and effectiveness. However, existing works lack effective analysis of task \nresults during task merging; they employ simple differential seed distribution", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3766542&hl=en&sa=X&d=2693574529684625139&ei=O2ffaPPVFp6sieoP2PTggQg&scisig=AAZF9b9aadL5OeSioZ8HLhUivWic&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "ReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory", "first_label": [], "second_label": ["Agent", "Reasoning"], "data": "S Ouyang, J Yan, I Hsu, Y Chen, K Jiang, Z Wang- arXiv preprint arXiv, 2025\nWith the growing adoption of large language model agents in persistent real-world \nroles, they naturally encounter continuous streams of tasks. A key limitation, \nhowever, is their failure to learn from the accumulated interaction history, forcing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25140&hl=en&sa=X&d=12867737869979691806&ei=O2ffaPPVFp6sieoP2PTggQg&scisig=AAZF9b-z7Jhe5lDHccQ4eyi-Wr3y&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FuzzRDUCC: Fuzzing with Reconstructed Def-Use Chain Coverage", "first_label": ["Fuzzing"], "second_label": [], "data": "K Feng, J Singer, AK Marnerides- arXiv preprint arXiv:2509.04967, 2025\nBinary-only fuzzing often struggles with achieving thorough code coverage and \nuncovering hidden vulnerabilities due to limited insight into a program's internal \ndataflows. Traditional grey-box fuzzers guide test case generation primarily using", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04967&hl=en&sa=X&d=12793668697793724612&ei=O2ffaPPVFp6sieoP2PTggQg&scisig=AAZF9b9DbASTknJLZ9Qw2muyThkA&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Fuzzing JavaScript JIT compilers with a high-quality differential test oracle", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "J Li, H Xu, Y Wang, Z Jiang, H Chun, P Xie, Y Chen- Computers & Security, 2025\nAbstract Modern JavaScript engines use Just-In-Time (JIT) compilers to convert \nfrequently executed code into machine instructions, boosting performance for web \napplications and cross-platform systems. However, the optimizations in JIT compilers", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825003499&hl=en&sa=X&d=7438620869129233397&ei=O2ffaPPVFp6sieoP2PTggQg&scisig=AAZF9b8tN2mMloCI7htWicorKtpq&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=6&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FuzzBox: Blending Fuzzing into Emulation for Binary-Only Embedded Targets", "first_label": ["Fuzzing"], "second_label": [], "data": "C Cesarano, R Natella- arXiv preprint arXiv:2509.05643, 2025\nCoverage-guided fuzzing has been widely applied to address zero-day \nvulnerabilities in general-purpose software and operating systems. This approach \nrelies on instrumenting the target code at compile time. However, applying it to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05643&hl=en&sa=X&d=4585422960426806286&ei=O2ffaPPVFp6sieoP2PTggQg&scisig=AAZF9b-p7mmDlvT3yh-ZhB_TgxIV&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=7&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "ChatInject: Abusing Chat Templates for Prompt Injection in LLM Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "H Chang, Y Jun, H Lee- arXiv preprint arXiv:2509.22830, 2025\nThe growing deployment of large language model (LLM) based agents that interact \nwith external environments has created new attack surfaces for adversarial \nmanipulation. One major threat is indirect prompt injection, where attackers embed \nmalicious instructions in external environment output, causing agents to interpret and \nexecute them as if they were legitimate prompts. While previous research has \nfocused primarily on plain-text injection attacks, we find a significant yet\nCites: Adaptive attacks break defenses against indirect prompt injection", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22830&hl=en&sa=X&d=2407502886914257722&ei=OWffaPemCZXP6rQP9ZK58Q0&scisig=AAZF9b_zGZ5UZWwrYdojCUU9qDJ3&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "Uncovering Vulnerabilities of LLM-Assisted Cyber Threat Intelligence", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "Y Meng, L Tang, F Yu, J Jia, G Yan, P Yang, Z Xi- arXiv preprint arXiv:2509.23573, 2025\nLarge Language Models (LLMs) are intensively used to assist security analysts in \ncounteracting the rapid exploitation of cyber threats, wherein LLMs offer cyber threat \nintelligence (CTI) to support vulnerability assessment and incident response. While \nrecent work has shown that LLMs can support a wide range of CTI tasks such as \nthreat analysis, vulnerability detection, and intrusion defense, significant \nperformance gaps persist in practical deployments. In this paper, we investigate the\nCites: Llm agents can autonomously exploit one-day vulnerabilities", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23573&hl=en&sa=X&d=1491611886356611360&ei=OWffaPemCZXP6rQP9ZK58Q0&scisig=AAZF9b8YCCxz0SFkvu5MTtMUUAKx&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "Defending MoE LLMs against Harmful Fine-Tuning via Safety Routing Alignment", "first_label": ["LLM"], "second_label": [], "data": "J Kim, M Song, S Shin, S Son- arXiv preprint arXiv:2509.22745, 2025\nRecent large language models (LLMs) have increasingly adopted the Mixture-of-\nExperts (MoE) architecture for efficiency. MoE-based LLMs heavily depend on a \nsuperficial safety mechanism in which harmful inputs are routed safety-critical \nexperts. However, our analysis reveals that routing decisions for harmful inputs drift \nsignificantly after fine-tuning, exposing a critical vulnerability to harmful fine-tuning \n(HFT) attacks. Existing defenses, primarily designed for monolithic LLMs, are less\nCites: Removing rlhf protections in gpt-4 via fine-tuning", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22745&hl=en&sa=X&d=11610053878383523095&ei=OWffaPemCZXP6rQP9ZK58Q0&scisig=AAZF9b9Ryy9lVeBzgEokbZ-QAxYp&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=2&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "Generalization of Variadic Structures with Binders: A Tool for Structural Code Comparison", "first_label": ["Code"], "second_label": [], "data": "A Baumgartner, T Kutsia- arXiv preprint arXiv:2509.25023, 2025\nThis paper introduces a novel anti-unification algorithm for the generalization of \nvariadic structures with binders, designed as a flexible tool for structural code \ncomparison. By combining nominal techniques for handling variable binding with \nsupport for variadic expressions (common in abstract syntax trees and programming \nlanguages), the approach addresses key challenges such as overemphasis on \nbound variable names and difficulty handling insertions or deletions in code\nCites: Vgx: Large-scale sample generation for boosting learning-based\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25023&hl=en&sa=X&d=11988250968567186176&ei=OWffaPemCZXP6rQP9ZK58Q0&scisig=AAZF9b8EJp72QJZ8HS6IBckT92RA&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=3&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "Q Wang, Z Sun, R Wang, T Huang, Z Jin, G Li, C Lyu- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) can translate natural language requirements into \ncode, yet empirical analyses of representative models reveal that semantic errors-\nprograms that compile but behave incorrectly-constitute the majority of observed", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24507&hl=en&sa=X&d=16752764936045731674&ei=PGffaKrdEMyR6rQP8M_xgAM&scisig=AAZF9b9KC1lKl2hTSKuhiiUc-Jar&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Brevity is the Soul of Wit: Condensing Code Changes to Improve Commit Message Generation", "first_label": ["Code", "Commit Message", "Code Change"], "second_label": ["Generation"], "data": "H Kuang, N Zhang, H Gao, X Zhou, WKG Assuno- arXiv preprint arXiv, 2025\nCommit messages are valuable resources for describing why code changes are \ncommitted to repositories in version control systems (eg, Git). They effectively help \ndevelopers understand code changes and better perform software maintenance", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.15567&hl=en&sa=X&d=3566966376596200560&ei=PGffaKrdEMyR6rQP8M_xgAM&scisig=AAZF9b-vZA0Uf808DqbPbNRX2qRx&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "SecureAgentBench: Benchmarking Secure Code Generation under Realistic Vulnerability Scenarios", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Generation", "Agent"], "data": "J Chen, H Huang, Y Lyu, J An, J Shi, C Yang, T Zhang- arXiv preprint arXiv, 2025\nLarge language model (LLM) powered code agents are rapidly transforming \nsoftware engineering by automating tasks such as testing, debugging, and repairing, \nyet the security risks of their generated code have become a critical concern. Existing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22097&hl=en&sa=X&d=17349871534881250756&ei=PGffaKrdEMyR6rQP8M_xgAM&scisig=AAZF9b8kYbQbluttLz4z1MJU_2OD&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=7&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "7 new citations to articles by Hong Jin Kang", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "ImportSnare: Directed\" Code Manual\" Hijacking in Retrieval-Augmented Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "K Ye, L Su, C Qian- arXiv preprint arXiv:2509.07941, 2025\nCode generation has emerged as a pivotal capability of Large Language Models \n(LLMs), revolutionizing development efficiency for programmers of all skill levels. \nHowever, the complexity of data structures and algorithmic logic often results in\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.07941%3F&hl=en&sa=X&d=12960283547209180326&ei=PGffaKrdEMyR6rQP8M_xgAM&scisig=AAZF9b-ZDtajHNi1jL3oUGb-sWCh&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=9&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "LLM-SZZ: Novel Vulnerability-Inducing Commit Identification Driven by Large Language Model and CVE Description", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "S Fan, X Liu, Y Zhang, Y Tan, L Yin, Z Chen, S Li\nThe SZZ method and its variants are widely employed to identify vulnerability-\naffected ranges by analyzing vulnerability-fixing commits to trace back vulnerability-\ninducing commits. However, these methods generally suffer from low precision due", "link": "https://scholar.google.com/scholar_url?url=https://songli.io/papers/LLM-SZZ.pdf&hl=en&sa=X&d=11360329303053337607&ei=PGffaOrUHZ2N6rQP3enmuQg&scisig=AAZF9b-llm-iUuaPic6SJcWwOQlc&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Enhancing Semantic Clone Detection with Siamese Bi-LSTM for Multi-Level Source Code Representations", "first_label": ["Code"], "second_label": ["Detection"], "data": "FHA Quradaa, S Shahzad, R Saeed, MH Al-Hakimi- Arabian Journal for Science and, 2025\nSource code clone detectors are fundamental techniques in Software Engineering. \nDespite significant research efforts in the last ten years, current methods still need to \nbe improved to detect semantic clones. The advancement of machine learning", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s13369-025-10675-z&hl=en&sa=X&d=7647209439385932584&ei=PGffaOrUHZ2N6rQP3enmuQg&scisig=AAZF9b8dwaU-JUy_Zn_LXzeDc-Vd&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Automated Repair of C Programs Using Large Language Models", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "M Farzandway, F Ghassemi- arXiv preprint arXiv:2509.01947, 2025\nThis study explores the potential of Large Language Models (LLMs) in automating \nthe repair of C programs. We present a framework that integrates spectrum-based \nfault localization (SBFL), runtime feedback, and Chain-of-Thought-structured", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01947&hl=en&sa=X&d=1317846922093490120&ei=PGffaOrUHZ2N6rQP3enmuQg&scisig=AAZF9b9xJ1n4DpSkY2MDDEUWo_Wk&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "D Liao, X Yin, S Pan, C Ni, Z Xing, X Sun- arXiv preprint arXiv:2509.23812, 2025\nUnit testing is essential for software quality assurance, yet writing and maintaining \ntests remains time-consuming and error-prone. To address this challenge, \nresearchers have proposed various techniques for automating unit test generation", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23812&hl=en&sa=X&d=17547399089676270182&ei=PGffaOrUHZ2N6rQP3enmuQg&scisig=AAZF9b_KQEA7UTv7yqv3sXHg6AI3&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "From Evaluation to Enhancement: Large Language Models for Zero-Knowledge Proof Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Z Xue, P Ma, Z Wang, S Wang- arXiv preprint arXiv:2509.11708, 2025\nZero-knowledge proofs (ZKPs) are increasingly deployed in domains such as privacy-\npreserving authentication, blockchain scalability, and secure finance. However, \nauthoring ZK programs remains challenging: unlike mainstream programming, ZK", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.11708&hl=en&sa=X&d=10349220616421543327&ei=PGffaOrUHZ2N6rQP3enmuQg&scisig=AAZF9b9VxdZ6a1w1kBGuJtv-cEtA&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Large Language Models for Software Testing: A Research Roadmap", "first_label": ["LLM", "Software Testing"], "second_label": ["Search"], "data": "C Augusto, A Bertolino, G De Angelis, F Lonetti- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) are starting to be profiled as one of the most \nsignificant disruptions in the Software Testing field. Specifically, they have been \nsuccessfully applied in software testing tasks such as generating test code, or", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25043&hl=en&sa=X&d=1208330022631398164&ei=OmffaIuYFZycieoPgK6aoQo&scisig=AAZF9b9b4upJnsQek3OFr6wbVQSd&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Binary Diff Summarization using Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "M Udeshi, VSC Putrevu, P Krishnamurthy- arXiv preprint arXiv, 2025\nSecurity of software supply chains is necessary to ensure that software updates do \nnot contain maliciously injected code or introduce vulnerabilities that may \ncompromise the integrity of critical infrastructure. Verifying the integrity of software", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23970&hl=en&sa=X&d=10519039045997772347&ei=OmffaIuYFZycieoPgK6aoQo&scisig=AAZF9b9YEARwInBvwF2248v01rbj&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Unveiling Many Faces of Surrogate Models for Configuration Tuning: A Fitness Landscape Analysis Perspective", "first_label": [], "second_label": [], "data": "P Chen, H Liang, T Chen- arXiv preprint arXiv:2509.21945, 2025\nTo efficiently tune configuration for better system performance (eg, latency), many \ntuners have leveraged a surrogate model to expedite the process instead of solely \nrelying on the profoundly expensive system measurement. As such, it is naturally \nbelieved that we need more accurate models. However, the fact of accuracy can lie-a \nsomewhat surprising finding from prior work-has left us many unanswered questions \nregarding what role the surrogate model plays in configuration tuning. This paper\nCites: Greening large language models of code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.21945&hl=en&sa=X&d=17783382616808622371&ei=OWffaJSAL63M6rQPuqaCiA0&scisig=AAZF9b9Ntb7LpDt7lJtxwzrDfIOk&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["7 new citations to articles by Hong Jin Kang"]}
{"title": "A Computational Perspective on NeuroAI and Synthetic Biological Intelligence", "first_label": [], "second_label": [], "data": "D Patel, MS Tanveer, J Gonzalez-Ferrer, A Loeffler- arXiv preprint arXiv, 2025\nNeuroAI is an emerging field at the intersection of neuroscience and artificial \nintelligence, where insights from brain function guide the design of intelligent \nsystems. A central area within this field is synthetic biological intelligence (SBI), \nwhich combines the adaptive learning properties of biological neural networks with \nengineered hardware and software. SBI systems provide a platform for modeling \nneural computation, developing biohybrid architectures, and enabling new forms of\nCites: Surveying neuro-symbolic approaches for reliable artificial", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23896&hl=en&sa=X&d=12339767377315408012&ei=OWffaJSAL63M6rQPuqaCiA0&scisig=AAZF9b-3yKT04XVUgn97AxgCGVSV&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["7 new citations to articles by Hong Jin Kang"]}
{"title": "Green Prompt Engineering: Investigating the Energy Impact of Prompt Design in Software Engineering", "first_label": [], "second_label": [], "data": "V De Martino, MA Zadenoori, X Franch, A Ferrari- arXiv preprint arXiv:2509.22320, 2025\nLanguage Models are increasingly applied in software engineering, yet their \ninference raises growing environmental concerns. Prior work has examined \nhardware choices and prompt length, but little attention has been paid to linguistic \ncomplexity as a sustainability factor. This paper introduces Green Prompt \nEngineering, framing linguistic complexity as a design dimension that can influence \nenergy consumption and performance. We conduct an empirical study on\nCites: Greening large language models of code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22320&hl=en&sa=X&d=1877254333866732556&ei=OWffaJSAL63M6rQPuqaCiA0&scisig=AAZF9b8K7TcENwRtapw434alUIMi&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=3&folt=cit", "author": ["Hong Jin Kang"], "ref": ["7 new citations to articles by Hong Jin Kang", "4 new citations to articles by Xin ZHOU"]}
{"title": "CCWise: CarbonCost Aware Regional LLM Orchestration for Next-Gen Sustainable AI", "first_label": ["LLM"], "second_label": [], "data": "RK Saha, D Chahal, R Singhal, M Nambiar- NeurIPS 2025 Workshop on Evaluating the\nThis paper presents a comprehensive orchestration for evaluating the sustainability \nof Large Language Models (LLMs) lifecycle by integrating carbon emissions, energy \nconsumption, and cost-efficiency metrics across diverse geographic regions. We \nintroduce two novel indicesCarbon-Cost Tradeoff Index (CCTI) and Green Cost \nEfficiency (GCE)to quantify the environmental and economic trade-offs inherent in \ntoken generation of LLM deployment. Through extensive experimental analysis\nCites: Greening large language models of code", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DVf4Gu3dtHC&hl=en&sa=X&d=9759993333755148706&ei=OWffaJSAL63M6rQPuqaCiA0&scisig=AAZF9b-jslubAsKcLm9kTJLUQZHj&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=4&folt=cit", "author": ["Hong Jin Kang"], "ref": ["7 new citations to articles by Hong Jin Kang"]}
{"title": "SoK: Potentials and Challenges of Large Language Models for Reverse Engineering", "first_label": ["LLM"], "second_label": [], "data": "X Hu, Z Fu, S Xie, SHH Ding, P Charland- arXiv preprint arXiv:2509.21821, 2025\nReverse Engineering (RE) is central to software security, enabling tasks such as \nvulnerability discovery and malware analysis, but it remains labor-intensive and \nrequires substantial expertise. Earlier advances in deep learning start to automate \nparts of RE, particularly for malware detection and vulnerability classification. More \nrecently, a rapidly growing body of work has applied Large Language Models (LLMs) \nto similar purposes. Their role compared to prior machine learning remains unclear\nCites: Large language model guided protocol fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.21821&hl=en&sa=X&d=14198233320746930427&ei=OmffaJO6NZycieoPgK6aoQo&scisig=AAZF9b8v8Q19cqHXP_WqEX1O7DfW&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "GUIFUZZ++: Unleashing Grey-box Fuzzing on Desktop Graphical User Interfacing Applications", "first_label": ["Fuzzing"], "second_label": ["Graph"], "data": "D Otto, T Rowlett, S Nagy\nDesktop applications represent one of today's largest software ecosystems, \naccounting for over 96% of workplace computing and supporting essential \noperations across critical sectors such as healthcare, commerce, industry, and \ngovernment. Though modern software is increasingly being vetted through fuzzing\nan automated testing technique for large-scale bug discoverya major component \nof desktop applications remains universally under-vetted: the Graphical User\nCites: Program Environment Fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://futures.cs.utah.edu/papers/25ASE.pdf&hl=en&sa=X&d=18087380470427803104&ei=OmffaJO6NZycieoPgK6aoQo&scisig=AAZF9b-vDiq1Xxp9P-WJQXt0xNy_&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning", "first_label": [], "second_label": ["Generation", "Agent"], "data": "Z Lu, H Ren, Y Yang, K Wang, Z Zong, J Pan, M Zhan- arXiv preprint arXiv, 2025\nAgent systems powered by large language models (LLMs) have demonstrated \nimpressive performance on repository-level code-generation tasks. However, for \ntasks such as website codebase generation, which depend heavily on visual effects \nand user-interaction feedback, current code agents rely only on simple code \nexecution for feedback and verification. This approach fails to capture the actual \nquality of the generated code. In this paper, we propose WebGen-Agent, a novel\nCites: Autocoderover: Autonomous program improvement, 2024", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22644&hl=en&sa=X&d=11672519558392686429&ei=OmffaJO6NZycieoPgK6aoQo&scisig=AAZF9b-ygX_LH_c9erux60Vcpblc&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Towards Reliable Generation of Executable Workflows by Foundation Models", "first_label": [], "second_label": ["Generation"], "data": "S Masoumzadeh, K Gallaba, D Lin, AE Hassan- arXiv preprint arXiv:2509.25117, 2025\nRecent advancements in Foundation Models (FMs) have demonstrated significant \nprogress in comprehending complex natural language to perform intricate tasks. \nSuccessfully executing these tasks often requires orchestrating calls to FMs \nalongside other software components. However, manually decomposing a task into a \ncoherent sequence of smaller, logically aggregated steps, commonly referred to as \nworkflows, demands considerable effort and specialized domain knowledge. While\nCites: SemFix: Program Repair via Semantic Analysis", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25117&hl=en&sa=X&d=12196803753268532282&ei=OmffaJO6NZycieoPgK6aoQo&scisig=AAZF9b9gpQwKrK9_-LvXOoBr77eH&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Metamorphic Testing for Audio Content Moderation Software", "first_label": ["Software Testing"], "second_label": [], "data": "W Wang, Y Wu, J Zhang, S Li, Y Peng, W Chen- arXiv preprint arXiv, 2025\nThe rapid growth of audio-centric platforms and applications such as WhatsApp and \nTwitter has transformed the way people communicate and share audio content in \nmodern society. However, these platforms are increasingly misused to disseminate \nharmful audio content, such as hate speech, deceptive advertisements, and explicit \nmaterial, which can have significant negative consequences (eg, detrimental effects \non mental health). In response, researchers and practitioners have been actively\nCites: Fuzz Testing based Data Augmentation to Improve Robustness of", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24215&hl=en&sa=X&d=7285678392934041559&ei=OmffaJO6NZycieoPgK6aoQo&scisig=AAZF9b8CrQWe7kLi42ILTluvuvkp&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Multifuzz: a Collaborative Fuzzing Framework Based on Concolic Execution", "first_label": ["Fuzzing"], "second_label": [], "data": "Z Sun, X Li, F He, D Yu, Y Zhang- 2025 11th IEEE International Conference on, 2025\nFuzzing is an efficient vulnerability discovery technique, but it has limitations in \nexploring the depth of program paths. Concolic Execution performs outstandingly in \npath coverage, yet its execution speed is relatively slow. Hybrid fuzzing combines the \nadvantages of both, improving the comprehensiveness and efficiency of testing. \nCollaborative fuzzing further enhances the testing effectiveness by integrating \nmultiple testing engines. This paper studies the impact of concolic execution on the\nCites: Coverage-based greybox fuzzing as markov chain", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/pcds/2025/774600a389/2aplMfRJflC&hl=en&sa=X&d=14208974081929903867&ei=OmffaJO6NZycieoPgK6aoQo&scisig=AAZF9b8CEUQNo3eDA7cUKfpOHM9m&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "LogicRepair: An Empirical Study on Automated Repair of Smart Contract Logic Vulnerabilities Based on Large Language Models", "first_label": ["Vulnerabilities", "Smart Contracts", "APR", "LLM"], "second_label": ["Repair"], "data": "M Ai, K Wang, H Wang, C Zheng, Y Zhang- on Privacy Computing and Data Security, 2025\nBlockchain technology has exploded in popularity, providing robust technical support \nfor decentralized finance (DeFi) and other domains. However, logical vulnerabilities \nin smart contracts can lead to serious security issues and economic losses. \nTraditional repair tools often fail to handle these logic flaws effectively. To address \nthis issue, our study proposes an automated repair framework for smart contract logic \nvulnerabilities, which takes advantage of large language models (LLM) to improve\nCites: Smart Contract Repair\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/pcds/2025/774600a261/2aplQRfplja&hl=en&sa=X&d=4220323208835090567&ei=OmffaJO6NZycieoPgK6aoQo&scisig=AAZF9b8NMXTGJp2wIoWlEe8SuIpe&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=9&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Formalization Driven LLM Prompt Jailbreaking via Reinforcement Learning", "first_label": ["LLM"], "second_label": [], "data": "Z Wang, D He, Z Zhang, X Li, L Zhu, M Li, J Liu- arXiv preprint arXiv:2509.23558, 2025\nLarge language models (LLMs) have demonstrated remarkable capabilities, yet they \nalso introduce novel security challenges. For instance, prompt jailbreaking attacks \ninvolve adversaries crafting sophisticated prompts to elicit responses from LLMs that", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23558&hl=en&sa=X&d=2749826917926664463&ei=PGffaLauA_iu6rQPlOqwiQY&scisig=AAZF9b8yPbrhQZJx7QFv8R1moIWX&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "HarmMetric Eval: Benchmarking Metrics and Judges for LLM Harmfulness Assessment", "first_label": ["LLM"], "second_label": [], "data": "L Yang, T Zheng, K Xiu, Y Chen, D Wang, P Zhao- arXiv preprint arXiv, 2025\nThe alignment of large language models (LLMs) with human values is critical for their \nsafe deployment, yet jailbreak attacks can subvert this alignment to elicit harmful \noutputs from LLMs. In recent years, a proliferation of jailbreak attacks has emerged", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24384&hl=en&sa=X&d=6954529287697046870&ei=PGffaLauA_iu6rQPlOqwiQY&scisig=AAZF9b9uM0TGT71bAeDSUUl5_-VC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Backdoor Attacks and Defenses in Computer Vision Domain: A Survey", "first_label": [], "second_label": [], "data": "BH Abbasi, Y Zhang, L Zhang, S Gao- arXiv preprint arXiv:2509.07504, 2025\nBackdoor (trojan) attacks embed hidden, controllable behaviors into machine-\nlearning models so that models behave normally on benign inputs but produce \nattacker-chosen outputs when a trigger is present. This survey reviews the rapidly", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.07504&hl=en&sa=X&d=3269854252125827141&ei=PGffaLauA_iu6rQPlOqwiQY&scisig=AAZF9b9hUL9vDNoEXnWcZIb5H3Bf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks", "first_label": ["LLM"], "second_label": ["Agent"], "data": "SM Hossain, RK Shayoni, MR Ameen, A Islam- arXiv preprint arXiv, 2025\nPrompt injection attacks represent a major vulnerability in Large Language Model \n(LLM) deployments, where malicious instructions embedded in user inputs can \noverride system prompts and induce unintended behaviors. This paper presents a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.14285&hl=en&sa=X&d=913307193832282926&ei=PGffaLauA_iu6rQPlOqwiQY&scisig=AAZF9b-cOLAwuLy9zQlk8KZ2kPLK&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Dual-Space Smoothness for Robust and Balanced LLM Unlearning", "first_label": ["LLM"], "second_label": [], "data": "H Yan, Z Liu, M Jiang- arXiv preprint arXiv:2509.23362, 2025\nWith the rapid advancement of large language models, Machine Unlearning has \nemerged to address growing concerns around user privacy, copyright infringement, \nand overall safety. Yet state-of-the-art (SOTA) unlearning methods often suffer from", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23362&hl=en&sa=X&d=1871730686130311929&ei=PGffaLauA_iu6rQPlOqwiQY&scisig=AAZF9b8As51yVW8jz__d_c1PoJ_F&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Backdoor Attribution: Elucidating and Controlling Backdoor in Language Models", "first_label": ["LLM"], "second_label": [], "data": "M Yu, Z Zhou, M Aloqaily, K Wang, B Huang, S Wang- arXiv preprint arXiv, 2025\nFine-tuned Large Language Models (LLMs) are vulnerable to backdoor attacks \nthrough data poisoning, yet the internal mechanisms governing these attacks remain \na black box. Previous research on interpretability for LLM safety tends to focus on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.21761&hl=en&sa=X&d=2109015168868723800&ei=PGffaLauA_iu6rQPlOqwiQY&scisig=AAZF9b8vuwf85b9luh6u5TdaGEpT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "You Can't Steal Nothing: Mitigating Prompt Leakages in LLMs via System Vectors", "first_label": ["LLM"], "second_label": [], "data": "B Cao, C Li, Y Cao, Y Ge, T Wang, J Chen- arXiv preprint arXiv:2509.21884, 2025\nLarge language models (LLMs) have been widely adopted across various \napplications, leveraging customized system prompts for diverse tasks. Facing \npotential system prompt leakage risks, model developers have implemented", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.21884&hl=en&sa=X&d=9049765669629367160&ei=PGffaLauA_iu6rQPlOqwiQY&scisig=AAZF9b-kaJvFCE65fBfFjzILwtIc&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "When Your Reviewer is an LLM: Biases, Divergence, and Prompt Injection Risks in Peer Review", "first_label": ["LLM"], "second_label": [], "data": "C Zhu, J Xiong, R Ma, Z Lu, Y Liu, L Li- arXiv preprint arXiv:2509.09912, 2025\nPeer review is the cornerstone of academic publishing, yet the process is \nincreasingly strained by rising submission volumes, reviewer overload, and expertise \nmismatches. Large language models (LLMs) are now being used as\" reviewer aids,\"", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.09912&hl=en&sa=X&d=559709989728729115&ei=PGffaLauA_iu6rQPlOqwiQY&scisig=AAZF9b_J-eLdccTA9UluyGqY5GIL&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A2D: Any-Order, Any-Step Safety Alignment for Diffusion Language Models", "first_label": ["LLM"], "second_label": [], "data": "W Jeung, S Yoon, Y Cho, D Jeon, S Shin, H Hong- arXiv preprint arXiv, 2025\nDiffusion large language models (dLLMs) enable any-order generation, but this \nflexibility enlarges the attack surface: harmful spans may appear at arbitrary \npositions, and template-based prefilling attacks such as DIJA bypass response-level", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23286&hl=en&sa=X&d=16977104919503302935&ei=PGffaLauA_iu6rQPlOqwiQY&scisig=AAZF9b-9ssXxkPlc54WBS9-P-Zx-&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Takedown: How It's Done in Modern Coding Agent Exploits", "first_label": [], "second_label": ["Agent", "Exploit"], "data": "E Lee, D Kim, W Kim, I Yun- arXiv preprint arXiv:2509.24240, 2025\nCoding agents, which are LLM-driven agents specialized in software development, \nhave become increasingly prevalent in modern programming environments. Unlike \ntraditional AI coding assistants, which offer simple code completion and suggestions\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24240&hl=en&sa=X&d=9106409834220255345&ei=PGffaLauA_iu6rQPlOqwiQY&scisig=AAZF9b8XIiHlvS0_WuiZZbFkX08R&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Interpretable Vulnerability Detection in LLMs: A BERT-Based Approach with SHAP Explanations", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "N Ahmad, C Zhang - 2025\nSource code vulnerabilities present significant security threats, necessitating \neffective detection techniques. Rigid rule-sets and pattern matching are the \nfoundation of traditional static analysis tools, which drown developers in false \npositives and miss context-sensitive vulnerabilities. Large Language Models (LLMs) \nlike BERT, in particular, are examples of artificial intelligence (AI) that exhibit promise \nbut frequently lack transparency. In order to overcome the issues with model\nCites: Large language model for vulnerability detection and repair", "link": "https://scholar.google.com/scholar_url?url=https://cdn.techscience.press/files/cmc/2025/TSP_CMC-85-2/TSP_CMC_67044/TSP_CMC_67044.pdf&hl=en&sa=X&d=1252818813327302141&ei=O2ffaJ-eM52qieoPz8OP6Qo&scisig=AAZF9b-4FiCmmcGvTLnyvFdif2Cb&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
