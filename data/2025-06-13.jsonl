{"title": "Language Models and Cybersecurity-Applications and Current Limits", "first_label": ["LLM"], "second_label": [], "data": "M Boffa - 2025\nThis thesis explores the intersection of AI and cybersecurity at a time of \nunprecedented technological acceleration. As AI reshapes expectations and \ncapabilities, cyberattacks are also becoming faster, more sophisticated, and \nwidespread. The risk of outpacing security experts is real and demands innovative \nsolutions. In this context, modern AI models, with Large Language Models (LLMs) \nspearheading, offer a promising path forward.\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://tesidottorato.depositolegale.it/bitstream/20.500.14242/210987/1/converted_final_version_thesis.pdf&hl=en&sa=X&d=6212026622236604058&ei=IJdKaPnQILXCieoP_vz9iAU&scisig=AAZF9b_lGqcZOdIDNXNhYPH6L38Z&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang"]}
{"title": "A Mining-Software-Repository study on deprecated API usages in open-source Java software applications", "first_label": [], "second_label": [], "data": "P Cassieri, S Romano, G Scanniello\\xc2\\xa0- Information and Software Technology, 2025\nAbstract Context: A deprecated API (Application Programming Interface) is an API \nthat its original developers no longer recommend using. Although deprecated APIs \n(ie, deprecated fields, methods, and classes) are still implemented, they are likely to \nbe removed in future implementations. Consequently, developers are advised \nagainst using deprecated APIs in newly written code and are encouraged to update \nexisting code to remove any deprecated API usage. Objective: We aimed to gather\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAndroEvolve: Automated Android API update with data flow\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925001211&hl=en&sa=X&d=1236854347499644314&ei=IJdKaNfrIeWs6rQPpf7X-Aw&scisig=AAZF9b_uqvwK9xd-zBoe5gmSzD10&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang"]}
{"title": "PatchScope\\xe2\\x80\\x93A Modular Tool for Annotating and Analyzing Contributions", "first_label": [], "second_label": [], "data": "J Nar\\xc4\\x99bski, M Fejzer, K Stencel, P Przymus\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nPatchScope is a modular framework for analyzing software contributions through \nautomatic code annotation, offering insights beyond traditional metrics. At its core, a \nflexible automatic code annotator labels source code lines based on customizable \nrules, categorizing changes such as documentation, testing, or code updates. \nLeveraging these annotations, PatchScope generates reports with actionable \ninsights for team evaluation and expertise identification. With applications in\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBugsinpy: a database of existing bugs in python programs to\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3713081.3731727&hl=en&sa=X&d=14958408935962562814&ei=IJdKaNfrIeWs6rQPpf7X-Aw&scisig=AAZF9b84KYorDxZvUqZZh6671UUK&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang"]}
{"title": "Can Large Language Models Verify System Software? A Case Study Using FSCQ as a Benchmark", "first_label": ["LLM"], "second_label": [], "data": "J Qin, A Du, D Zhang, M Lentz, D Zhuo\\xc2\\xa0- Proceedings of the 2025 Workshop on Hot\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have demonstrated remarkable coding capabilities. \nThey excel in code synthesis benchmarks across diverse domains and have become \nubiquitous in coding tools. Recently, they have also shown promise in generating\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713082.3730382&hl=en&sa=X&d=13785804118675261186&ei=IJdKaLyTKL_N6rQPzuHnkAg&scisig=AAZF9b8mi85OzbiS7sYulDU8fXJ3&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Xin ZHOU - new related research"]}
{"title": "Trailblazer: Practical End-to-end Web API Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "L Pan, S Cohney, T Murray, VT Pham\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThere are two key challenges in automatically testing web APIs:(a) determine where \nto send API requests and (b) identify how to make a valid payload for a given \nrequest. Both challenges are sometimes addressed by the presence of a machine\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3713081.3731717&hl=en&sa=X&d=13250706246401116236&ei=IJdKaLyTKL_N6rQPzuHnkAg&scisig=AAZF9b_zw8u8QNIWTDFuexbyX64v&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "10 new citations to articles by Abhik Roychoudhury", "Hong Jin Kang - new related research"]}
{"title": "On the Applicability of Benford's Law to Detect Saturation in Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "J Lee, H Lee, S Park, SK Cha\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nKnowing when a fuzzing campaign has reached saturation is crucial for practitioners \nto avoid unnecessarily lengthy campaigns without missing bugs within given \nresources. Unfortunately, existing solutions for determining the saturation point rely\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3713081.3731723&hl=en&sa=X&d=16464785359231774820&ei=IJdKaLyTKL_N6rQPzuHnkAg&scisig=AAZF9b8eVAPEPAehw4HTvQMR6bO8&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Personalized Fuzzing: A Case Study with the FANDANGO Fuzzer on a GNSS Module (Short Paper)", "first_label": ["Fuzzing"], "second_label": [], "data": "S Neuhaus, JAZ Amaya, A Zeller\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFuzzing is a widely used technique for uncovering vulnerabilities in software \nsystems, but traditional fuzzers often struggle with generating valid and meaningful \ntest cases for complex input formats. Grammar-based fuzzers address this issue by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3713081.3731722&hl=en&sa=X&d=5954195594365474187&ei=IJdKaLyTKL_N6rQPzuHnkAg&scisig=AAZF9b8Ap7FR5u6u22s4hMsvZiwq&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "10 new citations to articles by Abhik Roychoudhury", "Hong Jin Kang - new related research"]}
{"title": "KRAKEN: Program-Adaptive Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A ZHOU, H HUANG, C ZHANG - 2025\nDespite numerous advances, most existing fuzzers still require more than 24 hours to \nthoroughly test the target programs to achieve satisfactory code coverage or bug \ndetection results [7, 32, 42, 64]. Recently, as cloud-based computing and multicore\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://seviezhou.github.io/files/kraken.pdf&hl=en&sa=X&d=6944396394299119143&ei=IJdKaLyTKL_N6rQPzuHnkAg&scisig=AAZF9b9QILhkfV1b1x87AW8NkoEo&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FuseApplyBench: Multilingual Benchmark for Trustworthy Code Edit Applying Task", "first_label": ["Code"], "second_label": [], "data": "M Liang, Q Zhang, Z Zuo, S Zheng, D Chen, W Jiang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 34th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the rise of Language Models (LMs) and Large Language Models (LLMs), their \npotential for code editing (CE) has gained attention. An approach is to have LLMs \ngenerate draft code modifications, which are then refined by smaller LMs in further \nCode Editing Apply (CEA). However, CEA is error-prone, and existing benchmarks \ndo not systematically evaluate LLM performance in handling these issues. We \nintroduce FuseApplyBench, a benchmark designed to evaluate LLM performance\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3713081.3732929&hl=en&sa=X&d=7791836070318800823&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b9Diar8Ol3LPSrd8Qng2dXJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research", "Xin ZHOU - new related research"]}
{"title": "NexuSym: Marrying symbolic path finders with large language models", "first_label": ["LLM"], "second_label": [], "data": "J Wang, P Yu, Y Qin, Y Jiang, Y Yao, X Ma\\xc2\\xa0- Automated Software Engineering, 2025\nSymbolic execution is a powerful technique for automated test case generation, \nensuring comprehensive coverage of potential scenarios. However, it often struggles \nwith complex, deep paths due to path explosion. Conversely, large language models \n(LLMs) utilize vast training data to generate test cases that can uncover intricate \nprogram behaviors that symbolic execution might miss. Despite their complementary \nstrengths, integrating the systematic nature of symbolic execution with the creative\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00529-1&hl=en&sa=X&d=16869342251625094567&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b8d53DxM9ykrfgWfU25iopx&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "David Lo - new related research"]}
{"title": "The Havoc Paradox in Generator-Based Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A Li, M Huang, V Vikram, C Lemieux, R Padhye\\xc2\\xa0- ACM Transactions on Software\\xc2\\xa0\\xe2\\x80\\xa6\nParametric generators combine coverage-guided and generator-based fuzzing for \ntesting programs requiring structured inputs. They function as decoders that \ntransform arbitrary byte sequences into structured inputs, allowing mutations on byte \nsequences to map directly to mutations on structured inputs, without requiring \nspecialized mutators. However, this technique is prone to the havoc effect, where \nsmall mutations on the byte sequence cause large, destructive mutations to the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaExplainable fuzzer evaluation\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3742894&hl=en&sa=X&d=13479173031349752511&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b-pGEgKiMnReuBmCg6m-DNm&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Hong Jin Kang - new related research"]}
{"title": "\\xe7\\x89\\xa9\\xe8\\x81\\x94\\xe7\\xbd\\x91\\xe8\\xae\\xbe\\xe5\\xa4\\x87\\xe5\\x9b\\xba\\xe4\\xbb\\xb6\\xe8\\x87\\xaa\\xe5\\x8a\\xa8\\xe5\\x8c\\x96\\xe6\\xbc\\x8f\\xe6\\xb4\\x9e\\xe6\\x8c\\x96\\xe6\\x8e\\x98\\xe6\\x8a\\x80\\xe6\\x9c\\xaf\\xe7\\xa0\\x94\\xe7\\xa9\\xb6\\xe7\\xbb\\xbc\\xe8\\xbf\\xb0.", "first_label": [], "second_label": [], "data": "\\xe5\\x88\\x98\\xe8\\x88\\xaa\\xe5\\xa4\\xa9\\xef\\xbc\\x8c \\xe7\\x94\\x98\\xe6\\xb0\\xb4\\xe6\\xbb\\x94\\xef\\xbc\\x8c \\xe5\\xbc\\xa0\\xe8\\xb6\\x85\\xef\\xbc\\x8c \\xe5\\xbc\\xa0\\xe7\\xba\\xa2\\xe6\\x97\\x97\\xef\\xbc\\x8c \\xe5\\xad\\x99\\xe6\\x96\\x87\\xe5\\x8e\\x9a\\xef\\xbc\\x8c \\xe9\\xab\\x98\\xe5\\xad\\x90\\xe8\\x81\\xaa\\xef\\xbc\\x8c \\xe8\\xb5\\xb5\\xe6\\x95\\x8f\\xe2\\x80\\xa6\\xc2\\xa0- Chinese Journal of Network\\xc2\\xa0\\xe2\\x80\\xa6, 2025\n\\xe9\\x9a\\x8f\\xe7\\x9d\\x80\\xe7\\x89\\xa9\\xe8\\x81\\x94\\xe7\\xbd\\x91\\xe6\\x8a\\x80\\xe6\\x9c\\xaf\\xe7\\x9a\\x84\\xe5\\xb9\\xbf\\xe6\\xb3\\x9b\\xe5\\xba\\x94\\xe7\\x94\\xa8, \\xe7\\x89\\xa9\\xe8\\x81\\x94\\xe7\\xbd\\x91\\xe8\\xae\\xbe\\xe5\\xa4\\x87\\xe7\\x88\\x86\\xe7\\x82\\xb8\\xe5\\xbc\\x8f\\xe5\\xa2\\x9e\\xe9\\x95\\xbf. \\xe8\\xbf\\x91\\xe5\\xb9\\xb4\\xe6\\x9d\\xa5, \\xe7\\x89\\xa9\\xe8\\x81\\x94\\xe7\\xbd\\x91\\xe8\\xae\\xbe\\xe5\\xa4\\x87\\xe5\\xaf\\xbc\\xe8\\x87\\xb4\\xe7\\x9a\\x84\\xe5\\xae\\x89\\xe5\\x85\\xa8\n\\xe4\\xba\\x8b\\xe4\\xbb\\xb6\\xe9\\xa2\\x91\\xe5\\x8f\\x91, \\xe4\\xbd\\xbf\\xe5\\xbe\\x97\\xe7\\x89\\xa9\\xe8\\x81\\x94\\xe7\\xbd\\x91\\xe8\\xae\\xbe\\xe5\\xa4\\x87\\xe5\\xae\\x89\\xe5\\x85\\xa8\\xe7\\xa0\\x94\\xe7\\xa9\\xb6\\xe6\\x88\\x90\\xe4\\xb8\\xba\\xe7\\x83\\xad\\xe7\\x82\\xb9. \\xe9\\xa6\\x96\\xe5\\x85\\x88, \\xe5\\xaf\\xb9\\xe7\\x89\\xa9\\xe8\\x81\\x94\\xe7\\xbd\\x91\\xe8\\xae\\xbe\\xe5\\xa4\\x87\\xe5\\x9b\\xba\\xe4\\xbb\\xb6\\xe7\\x9a\\x84\\xe5\\xae\\x89\\xe5\\x85\\xa8\\xe7\\x89\\xb9\\xe6\\x80\\xa7(\\xe5\\x8c\\x85\\xe6\\x8b\\xac\n\\xe9\\xbb\\x91\\xe7\\x9b\\x92\\xe7\\x89\\xb9\\xe6\\x80\\xa7, \\xe7\\xbd\\x91\\xe7\\xbb\\x9c\\xe7\\x89\\xb9\\xe6\\x80\\xa7\\xe5\\x92\\x8c\\xe5\\xae\\x9a\\xe5\\x88\\xb6\\xe5\\x8c\\x96\\xe7\\x89\\xb9\\xe6\\x80\\xa7) \\xe8\\xbf\\x9b\\xe8\\xa1\\x8c\\xe4\\xba\\x86\\xe6\\xb7\\xb1\\xe5\\x85\\xa5\\xe5\\x89\\x96\\xe6\\x9e\\x90, \\xe8\\xbf\\x99\\xe4\\xba\\x9b\\xe7\\x89\\xb9\\xe6\\x80\\xa7\\xe7\\xbb\\x99\\xe8\\x87\\xaa\\xe5\\x8a\\xa8\\xe5\\x8c\\x96\\xe6\\xbc\\x8f\\xe6\\xb4\\x9e\\xe6\\x8c\\x96\\xe6\\x8e\\x98\\xe5\\xb8\\xa6\\xe6\\x9d\\xa5\\xe4\\xba\\x86\n\\xe6\\x96\\xb0\\xe7\\x9a\\x84\\xe6\\x8c\\x91\\xe6\\x88\\x98. \\xe5\\x9b\\xba\\xe4\\xbb\\xb6\\xe4\\xbb\\xa3\\xe7\\xa0\\x81\\xe9\\x97\\xad\\xe6\\xba\\x90, \\xe8\\xbf\\x90\\xe8\\xa1\\x8c\\xe7\\x8e\\xaf\\xe5\\xa2\\x83\\xe5\\xb0\\x81\\xe9\\x97\\xad, \\xe7\\xbd\\x91\\xe7\\xbb\\x9c\\xe4\\xba\\xa4\\xe4\\xba\\x92\\xe5\\xa4\\x8d\\xe6\\x9d\\x82, \\xe8\\xbd\\xaf\\xe7\\xa1\\xac\\xe4\\xbb\\xb6\\xe9\\xab\\x98\\xe5\\xba\\xa6\\xe5\\xae\\x9a\\xe5\\x88\\xb6\\xe5\\x8c\\x96, \n\\xe8\\xbf\\x99\\xe4\\xba\\x9b\\xe9\\x83\\xbd\\xe5\\xa2\\x9e\\xe5\\x8a\\xa0\\xe4\\xba\\x86\\xe5\\x9b\\xba\\xe4\\xbb\\xb6\\xe5\\xae\\x89\\xe5\\x85\\xa8\\xe5\\x88\\x86\\xe6\\x9e\\x90\\xe7\\x9a\\x84\\xe9\\x9a\\xbe\\xe5\\xba\\xa6. \\xe9\\x92\\x88\\xe5\\xaf\\xb9\\xe8\\xbf\\x99\\xe4\\xba\\x9b\\xe6\\x8c\\x91\\xe6\\x88\\x98, \\xe7\\xa0\\x94\\xe7\\xa9\\xb6\\xe4\\xba\\xba\\xe5\\x91\\x98\\xe7\\xa0\\x94\\xe5\\x8f\\x91\\xe4\\xba\\x86\\xe4\\xb8\\x80\\xe7\\xb3\\xbb\\xe5\\x88\\x97\\xe8\\xa7\\xa3\\xe5\\x86\\xb3\\xe6\\x96\\xb9\\xe6\\xa1\\x88. \n\\xe9\\x80\\x9a\\xe8\\xbf\\x87\\xe5\\xaf\\xb9\\xe7\\x8e\\xb0\\xe6\\x9c\\x89\\xe6\\x96\\x87\\xe7\\x8c\\xae\\xe8\\xbf\\x9b\\xe8\\xa1\\x8c\\xe7\\xbb\\xbc\\xe5\\x90\\x88\\xe5\\x88\\x86\\xe6\\x9e\\x90, \\xe4\\xbb\\x8e\\xe9\\xbb\\x91\\xe7\\x9b\\x92\\xe6\\xa8\\xa1\\xe7\\xb3\\x8a\\xe6\\xb5\\x8b\\xe8\\xaf\\x95, \\xe7\\x81\\xb0\\xe7\\x9b\\x92\\xe6\\xa8\\xa1\\xe7\\xb3\\x8a\\xe6\\xb5\\x8b\\xe8\\xaf\\x95, \\xe9\\x9d\\x99\\xe6\\x80\\x81\\xe7\\xa8\\x8b\\xe5\\xba\\x8f\\xe5\\x88\\x86\\xe6\\x9e\\x90\\xe5\\x92\\x8c\\xe5\\x9b\\xba\\xe4\\xbb\\xb6\\xe9\\x87\\x8d\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://search.ebscohost.com/login.aspx%3Fdirect%3Dtrue%26profile%3Dehost%26scope%3Dsite%26authtype%3Dcrawler%26jrnl%3D2096109X%26AN%3D185234143%26h%3D5HmMjO9hoXcpFWuC8jIFtTMXoM9wM8DrKwPiND9neg2rEtFq3daCsPzC6PvPi8AqJ95fvHEa3TGwTsFRFCCCoA%253D%253D%26crl%3Dc&hl=en&sa=X&d=15048786083317320872&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b9VnHuXL8dCmPQxjw_lYY87&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "High-Trigger Fuzz Testing for Microarchitectural Speculative Execution Vulnerability", "first_label": ["Vulnerabilities", "Fuzzing", "Software Testing"], "second_label": [], "data": "C Lu, S Luo, L Pan\\xc2\\xa0- Computers & Security, 2025\nMicroarchitectural speculative execution vulnerabilities can be utilized to steal \nprivate information and even bypass some defensive programming measures in the \ncode. The difficulty in detecting this vulnerability is ensuring a high triggering \nfrequency of speculative execution. However, existing methods randomly generate \ntest programs with high uncertainty, which lack dependencies relationship between \ncode lines required by speculative execution, resulting in low trigger rates of\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaoo7: Low-overhead defense against spectre attacks via program\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825002561&hl=en&sa=X&d=2804449662848039497&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b_p2fLZckYZuyuFUxzvXkCJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Behind the Hot Fix: Demystifying Hot Fixing Industrial Practices at Z\\xc3\\xbchlke and Beyond", "first_label": [], "second_label": [], "data": "C Hanna, D Elliman, W Emmerich, F Sarro, J Petke - 2025\nRushing a hot fix and having it fail can severely damage a software company's \nreputation, impacting user satisfaction and future business opportunities. Ensuring \nbest practices for emergency bug handling is critical, yet the process remains elusive \nin the industry. We are the first to conduct a study to gain insights on hot fixing \nindustrial practices. We surveyed 24 employees of Z\\xc3\\xbchlke, a midsized IT company \nspecializing in providing software engineering services to clients from different\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTrust Enhancement Issues in Program Repair\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://discovery.ucl.ac.uk/id/eprint/10209388/1/Industrial_Views_on_Hot_Fixing_Software__Open_Questionnaire.pdf&hl=en&sa=X&d=12216522735855445826&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b-I50VB1J436_apVfKuqu6G&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "ParRP: Enabling Space Isolation in Caches with Shared Data", "first_label": [], "second_label": [], "data": "X Wang, R Pellizzoni, H Patel\\xc2\\xa0- 2025 IEEE 31st Real-Time and Embedded\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis work presents an approach to isolate cache space while supporting shared \ndata. Enabling shared data caching is challenging because it causes interference \nmaking it unsuitable for real-time multicores. Unlike prior works, we aim to introduce \nisolation, but our approach enables caching of shared data, and promotes isolated \ncache analysis for individual cores. The crux behind our approach is that shared data \nisolation can be achieved by partitioning the replacement information instead of the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTiming analysis of concurrent programs running on shared cache\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11018778/&hl=en&sa=X&d=14127514159853511929&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b8DN3s9Xje00xC0bLTL0erl&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Exploring Prompt Patterns for Effective Vulnerability Repair in Real-World Code by Large Language Models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Repair"], "data": "Y Luo, B Li, A Singhal, P Tseng, L Zhang, Q Zou, X Sun\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 2025\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown promise in automating code \nvulnerability repair, but their effectiveness in handling real-world code remains \nlimited. This paper investigates the capability of LLMs, in repairing vulnerabilities and \nproposes a systematic approach to enhance their performance through specialized \nprompt engineering. Through extensive evaluation of 5,826 code samples, we found \nthat while LLMs successfully repair vulnerabilities in simple cases, they struggle with\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCodeflaws: a programming competition benchmark for evaluating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3716815.3729010&hl=en&sa=X&d=11942114562078715389&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b_IuH7nZURJP7EbJyXnPdcG&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=9&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "Generating Secure Artificial Intelligence Model Source Code: A Reinforcement Learning Approach", "first_label": ["Code"], "second_label": [], "data": "A Kathikar, B Lazarine, Y Gao, A Shah, S Samtani\\xc2\\xa0- 2025 IEEE Security and Privacy\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe increasing adoption of open-source AI models has introduced critical security \nrisks, as vulnerabilities in AI model source code propagate through the software \nsupply chain. This study presents a reinforcement learning (RL) based framework for\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/spw/2025/664300a265/27k6oIZ3FxC&hl=en&sa=X&d=10624097985797953024&ei=IJdKaNn7JM6r6rQP3rzY-QM&scisig=AAZF9b9DaVhE-p5iCpq9n7L8tTVj&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents", "first_label": ["LLM", "Code"], "second_label": ["Agent", "Reasoning"], "data": "K Hariharan, U Girit, A Wang, J Andreas\\xc2\\xa0- arXiv preprint arXiv:2506.00172, 2025\nBenchmarks for large language models (LLMs) have predominantly assessed short-\nhorizon, localized reasoning. Existing long-horizon suites (eg SWE-bench) rely on \nmanually curated issues, so expanding or tuning difficulty demands expensive\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00172&hl=en&sa=X&d=7723120566071680437&ei=IJdKaNn7JM6r6rQP3rzY-QM&scisig=AAZF9b-MEatAoZUO5Dw1f9NQmtaH&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "BECAAC: A Blockchain and Edge Computing-Assisted Access Control Scheme for Medical Data Sharing", "first_label": ["Blockchain"], "second_label": [], "data": "K Zhao, Z Bao, Y Zhang, H Lei\\xc2\\xa0- IEEE Internet of Things Journal, 2025\nSecuring the sharing of medical data has become a critical issue in the field of \nmedical informatics. Although existing IoMT-based medical data sharing systems \nprioritize data security, anonymity, and operational efficiency during transmission, \nthey still exhibit significant shortcomings in preventing unauthorized access and \nestablishing effective accountability mechanisms. Therefore, a solution is urgently \nneeded to ensure fine-grained access control and accountability during data sharing\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11025815/&hl=en&sa=X&d=8257800659657886567&ei=IJdKaJi7I72W6rQPjI6v-QY&scisig=AAZF9b-9SLHS5u1fhMXgsrtlpqb2&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["1 new citation to articles by Bach Le"]}
{"title": "Evaluatiing the efficacy of LLM Safety Solutions: The Palit Benchmark Dataset", "first_label": ["LLM"], "second_label": [], "data": "S Palit, D Woods\\xc2\\xa0- arXiv preprint arXiv:2505.13028, 2025\nLarge Language Models (LLMs) are increasingly integrated into critical systems in \nindustries like healthcare and finance. Users can often submit queries to LLM-\nenabled chatbots, some of which can enrich responses with information retrieved\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13028%3F&hl=en&sa=X&d=1273460049730580919&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b9ByON4eaZyjRTpM1-cA_zU&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Ip leakage attacks targeting llm-based multi-agent systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Wang, W Wang, S Wang, Z Li, Z Ji, Z Lyu, D Wu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Large Language Models (LLMs) has led to the \nemergence of Multi-Agent Systems (MAS) to perform complex tasks through \ncollaboration. However, the intricate nature of MAS, including their architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12442&hl=en&sa=X&d=8825331941370095164&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b_j6hKF2Zy8dNMOx-tobM6E&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning", "first_label": ["LLM"], "second_label": [], "data": "P Yang, Q Wang, Z Huang, T Liu, C Zhang, B Han\\xc2\\xa0- arXiv preprint arXiv:2505.11953, 2025\nLoss reweighting has shown significant benefits for machine unlearning with large \nlanguage models (LLMs). However, their exact functionalities are left unclear and the \noptimal strategy remains an open question, thus impeding the understanding and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11953%3F&hl=en&sa=X&d=10115741309441283535&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b_qGRbxQa3QaxEAOlNnGTTW&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Ripple Effect: On Unforeseen Complications of Backdoor Attacks", "first_label": [], "second_label": [], "data": "R Zhang, Y Shen, H Li, W Jiang, H Chen, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent research highlights concerns about the trustworthiness of third-party Pre-\nTrained Language Models (PTLMs) due to potential backdoor attacks. These \nbackdoored PTLMs, however, are effective only for specific pre-defined downstream\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11586&hl=en&sa=X&d=15157304470732077928&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b997v4XRj8-KVQslhBMZvqE&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "first_label": ["LLM"], "second_label": [], "data": "G Chen, F Song, Z Zhao, X Jia, Y Liu, Y Qiao, W Zhang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreak attacks to Large audio-language models (LALMs) are studied recently, but \nthey achieve suboptimal effectiveness, applicability, and practicability, particularly, \nassuming that the adversary can fully manipulate user prompts. In this work, we first\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14103&hl=en&sa=X&d=12355582258955555442&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b84twuHlVXU1hPFciKO3AfT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Securing AI Agents with Information-Flow Control", "first_label": [], "second_label": ["Agent"], "data": "M Costa, B K\\xc3\\xb6pf, A Kolluri, A Paverd, M Russinovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI agents become increasingly autonomous and capable, ensuring their security \nagainst vulnerabilities such as prompt injection becomes critical. This paper explores \nthe use of information-flow control (IFC) to provide security guarantees for AI agents\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23643%3F&hl=en&sa=X&d=4534448032257376326&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b-ruPZ7fbYUs0K6HirRZr2z&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "sudoLLM: On Multi-role Alignment of Language Models", "first_label": ["LLM"], "second_label": [], "data": "S Saha, A Chaturvedi, J Mahapatra, U Garain\\xc2\\xa0- arXiv preprint arXiv:2505.14607, 2025\nUser authorization-based access privileges are a key feature in many safety-critical \nsystems, but have thus far been absent from the large language model (LLM) realm. \nIn this work, drawing inspiration from such access control systems, we introduce\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14607&hl=en&sa=X&d=17656541914978309178&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b8_EqIyi95cbbheLEpLAFw7&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadDepth: Backdoor Attacks Against Monocular Depth Estimation in the Physical World", "first_label": [], "second_label": [], "data": "J Guo, L Zhou, Z Wang, J He, Q Song, A Chen, W Jiang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, deep learning-based Monocular Depth Estimation (MDE) models \nhave been widely applied in fields such as autonomous driving and robotics. \nHowever, their vulnerability to backdoor attacks remains unexplored. To fill the gap in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16154%3F&hl=en&sa=X&d=5415910119131408953&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b_P0jMEgHvYQo3O-kEno08o&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "P He, Y Xing, S Dong, J Li, Z Dai, X Tang, H Liu, H Xu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis paper argues that a comprehensive vulnerability analysis is essential for \nbuilding trustworthy Large Language Model-based Multi-Agent Systems (LLM-MAS). \nThese systems, which consist of multiple LLM-powered agents working\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.01245&hl=en&sa=X&d=2053462704520065028&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b_Rn4q6OeIutC2KAxU8lQwB&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Variance-Based Defense Against Blended Backdoor Attacks", "first_label": [], "second_label": [], "data": "S Aseervatham, A Kerzazi, Y Bennani\\xc2\\xa0- arXiv preprint arXiv:2506.01444, 2025\nBackdoor attacks represent a subtle yet effective class of cyberattacks targeting AI \nmodels, primarily due to their stealthy nature. The model behaves normally on clean \ndata but exhibits malicious behavior only when the attacker embeds a specific trigger\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.01444&hl=en&sa=X&d=9260748938123526683&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b9XaYcfgGaLkEqjewL_RjNC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
