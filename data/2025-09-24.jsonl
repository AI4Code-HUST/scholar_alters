{"title": "When Code Crosses Borders: A Security-Centric Evaluation of LLM-based Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "H Chang, G Meng, S Xiao, K Chen, K Sun, Y Li- arXiv preprint arXiv:2509.06504, 2025\nWith the growing demand for cross-language codebase migration, evaluating LLMs' \nsecurity implications in translation tasks has become critical. Existing evaluations \nprimarily focus on syntactic or functional correctness at the function level, neglecting\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.06504&hl=en&sa=X&d=15964686870607645440&ei=SkTUaKeYOKOj6rQPxs2duQU&scisig=AAZF9b9rJmR42d8IPErh15fFE3f8&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "PromeFuzz: A Knowledge-Driven Approach to Fuzzing Harness Generation with Large Language Models", "first_label": ["LLM", "Fuzzing"], "second_label": ["Generation"], "data": "Y Liu, J Deng, X Jia, Y Wang, M Wang, L Huang, T Wei\nFuzzing has long been recognized as an effective technique for uncovering security \nvulnerabilities by automatically generating and executing a diverse set of inputs [2, 3, \n6, 8, 14, 15, 18, 20, 24, 26, 30, 32, 34, 46, 52, 53, 55, 58]. Traditional fuzzing tools", "link": "https://scholar.google.com/scholar_url?url=https://pvz122.github.io/pdf/25-promefuzz.pdf&hl=en&sa=X&d=12396611312661296556&ei=S0TUaIjDDpXP6rQP5rHHiQo&scisig=AAZF9b-wSitwHBsEc3RIko2Rlc5c&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Fuzzing JavaScript Engines by Fusing JavaScript and WebAssembly", "first_label": ["Fuzzing"], "second_label": [], "data": "J Lin, C Luo, M Zhang, L Lin, P Li, C Qian - 2026\nJavaScript engines are a fundamental part of modern browsers, and many efforts \nhave been invested in testing them to enhance their security. However, the \nincorporation of WebAssembly into JavaScript engines introduces new attack\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://peng-hui.github.io/data/paper/icse26:mad-eye.pdf&hl=en&sa=X&d=7025301240690243176&ei=S0TUaIjDDpXP6rQP5rHHiQo&scisig=AAZF9b87H2l6opoFTjGi99T54n3u&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Enhancing Vulnerability-Fixing Commit Classification: The Synergy of User-Guided and LLM", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "Y Zheng, H Zhuang, D Wang, H Cao, C Qian\nWith the increasing complexity of software development environments, identifying \nand fixing vulnerabilities has become a key aspect of software maintenance. One \nway to improve the efficiency and effectiveness of vulnerability-fixing is to classify\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=http://poster-openaccess.com/files/ICIC2025/3920.pdf&hl=en&sa=X&d=4621968745240783450&ei=TETUaJfsBsmk6rQPxc_v6QY&scisig=AAZF9b8ft-6jddYIlsXjNrKNhV8T&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "1 new citation to articles by Hong Jin Kang", "1 new citation to articles by Thanh Le-Cong", "1 new citation to articles by Bach Le"]}
{"title": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution (arXiv version)", "first_label": ["LLM"], "second_label": [], "data": "K Even-Mendoza, A Brownlee, A Geiger, C Hanna - 2025\nGenetic Improvement (GI) of software automatically creates alternative software \nversions that are improved according to certain properties of interests (eg, running-\ntime). Search-based GI excels at navigating large program spaces, but operates\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://kclpure.kcl.ac.uk/portal/en/publications/llm-guided-genetic-improvement-envisioning-semantic-aware-automat&hl=en&sa=X&d=17522263310458421835&ei=TETUaKayF5u1ieoP1tDwoQs&scisig=AAZF9b9Mrgn6Wd2hitLrRWwo4Pj-&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "LLM as an Execution Estimator: Recovering Missing Dependency for Practical Time-travelling Debugging", "first_label": ["LLM", "Bug"], "second_label": [], "data": "Y Pei, H Wang, W Zhang, Y Lin, W Kong- arXiv preprint arXiv:2508.18721, 2025\nDynamic data dependency, answering\" why a variable has this value?\", is critical for \ndebugging. Given a program stepsreading a variablev, finding the dynamic definition \nofvis challenging. Traditional methods require either (1) exhaustive instrumentation", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.18721&hl=en&sa=X&d=9469297087740937979&ei=SkTUaM7fDuvD6rQP6euP0Ao&scisig=AAZF9b99kfXihCB2m5Hyo4na6QuH&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "MSFuzz: Directed Greybox Fuzzing Using Multi-Target Sensitivity-Based Energy Scheduling", "first_label": ["Fuzzing"], "second_label": [], "data": "C Qin, Z Ma\nDirected Greybox Fuzzing (DGF) effectively targets specific program locations for bug \ndiscovery, but existing tools face challenges in multi-target directed fuzzing due to \nstatic stage division and coarse energy scheduling. Key challenges include global \noptimization biases that overlook lower-priority targets, inadequate prioritization of \nseeds that reach multiple targets, and inflexible exploration-exploitation stage \nallocation. This paper presents adaptive strategies to tackle these issues: a multi\nCites: Directed greybox fuzzing\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=http://poster-openaccess.com/files/ICIC2025/3948.pdf&hl=en&sa=X&d=15747512734137565556&ei=SkTUaKqKJKDWieoPyfiAmA8&scisig=AAZF9b_R_IL7DL7ECBT5e3k37l6w&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["1 new citation to articles by Abhik Roychoudhury"]}
{"title": "Paladin: Defending LLM-enabled Phishing Emails with a New Trigger-Tag Paradigm", "first_label": ["LLM"], "second_label": [], "data": "Y Pang, W Meng, X Liao, T Wang- arXiv preprint arXiv:2509.07287, 2025\nWith the rapid development of large language models, the potential threat of their \nmalicious use, particularly in generating phishing content, is becoming increasingly \nprevalent. Leveraging the capabilities of LLMs, malicious users can synthesize", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.07287&hl=en&sa=X&d=841142860163656335&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b9zUiVve_NVtg5_7UjR-gXJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Backdoor Attacks and Defenses in Computer Vision Domain: A Survey", "first_label": [], "second_label": [], "data": "BH Abbasi, Y Zhang, L Zhang, S Gao- arXiv preprint arXiv:2509.07504, 2025\nBackdoor (trojan) attacks embed hidden, controllable behaviors into machine-\nlearning models so that models behave normally on benign inputs but produce \nattacker-chosen outputs when a trigger is present. This survey reviews the rapidly", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.07504&hl=en&sa=X&d=3269854252125827141&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b9hUL9vDNoEXnWcZIb5H3Bf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Leveraging CVAE Encoding for Backdoor Attacks in Few-Shot Learning with Prototypical Networks", "first_label": [], "second_label": [], "data": "Q Yan, S Liang, A Ullah- IEEE Transactions on Dependable and Secure, 2025\nFew-shot learning (FSL) has demonstrated tremendous potential when challenged \nwith limited training data, but the assessment of its vulnerability to backdoor attacks is \nstill at an early stage. However, recent research revealed this deep learning", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11152502/&hl=en&sa=X&d=6687930075784700670&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b9ptsbEWBr80FGSyzcZR2Er&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Prototype-Guided Robust Learning against Backdoor Attacks", "first_label": [], "second_label": [], "data": "W Guo, M Pintor, A Demontis, B Biggio- arXiv preprint arXiv:2509.08748, 2025\nBackdoor attacks poison the training data to embed a backdoor in the model, \ncausing it to behave normally on legitimate inputs but maliciously when specific \ntrigger signals appear. Training a benign model from a dataset poisoned by", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.08748&hl=en&sa=X&d=9079518275239981489&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b8nbcMJrz3EP9De5YM82FpF&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Exploit Tool Invocation Prompt for Tool Behavior Hijacking in LLM-Based Agentic System", "first_label": ["LLM"], "second_label": ["Agent", "Exploit"], "data": "Y Liu, Y Xie, M Luo, Z Liu, Z Zhang, K Zhang, Z Li- arXiv preprint arXiv, 2025\nLLM-based agentic systems leverage large language models to handle user queries, \nmake decisions, and execute external tools for complex tasks across domains like \nchatbots, customer service, and software engineering. A critical component of these", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05755%3F&hl=en&sa=X&d=7380962265010499197&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b_WNN5iEJzU4LQ3fLBGGpF6&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Prompt-in-Content Attacks: Exploiting Uploaded Inputs to Hijack LLM Behavior", "first_label": ["LLM"], "second_label": ["Exploit"], "data": "Z Lian, W Wang, Q Zeng, T Nakanishi, T Kitasuka, C Su- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) are widely deployed in applications that accept user-\nsubmitted content, such as uploaded documents or pasted text, for tasks like \nsummarization and question answering. In this paper, we identify a new class of", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.19287%3F&hl=en&sa=X&d=15365588001769154326&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b9rDXev84fKcPnDvE_cVDTn&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Oyster-I: Beyond Refusal--Constructive Safety Alignment for Responsible Language Models", "first_label": ["LLM"], "second_label": [], "data": "R Duan, J Liu, X Jia, S Zhao, R Cheng, F Wang, C Wei- arXiv preprint arXiv, 2025\nLarge language models (LLMs) typically deploy safety mechanisms to prevent \nharmful content generation. Most current approaches focus narrowly on risks posed \nby malicious actors, often framing risks as adversarial events and relying on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01909%3F&hl=en&sa=X&d=6590160868100905669&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b8p2pmNGwnqdehrNy547NkZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Jailbreak Attack with Multimodal Virtual Scenario Hypnosis for Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "X Shi, S Chen, G Zhang, W Wei, Y Li, Z Fan, J Liu- Pattern Recognition, 2025\nDue to the inherent vulnerabilities of large Vision-Language Models (VLMs), security \ngovernance has emerged as a critical concern, particularly given the risks posed by \nnoisy and biased training data as well as adversarial attacks, including data", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0031320325010520&hl=en&sa=X&d=18404876866865125967&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b9xJx3YOX0I9CBN24pCw_YG&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Backdoor defense based on adversarial prediction proximity and contrastive knowledge distillation", "first_label": [], "second_label": [], "data": "L Huang, LY Zhang, CC Chang, W Wang, C Qin- Pattern Recognition, 2025\nHighlightsWe propose a scheme that can realize backdoor detection and backdoor \npurification.Our scheme can defend against both visible and invisible backdoors.\nPoisoned labels can be detected without using the label-by-label way.Adversarial", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0031320325009975&hl=en&sa=X&d=16049830957057689748&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b9yG7oV3XS0gADdXNotiCMQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Why language models hallucinate", "first_label": ["LLM"], "second_label": [], "data": "AT Kalai, O Nachum, SS Vempala, E Zhang- arXiv preprint arXiv:2509.04664, 2025\nLike students facing hard exam questions, large language models sometimes guess \nwhen uncertain, producing plausible yet incorrect statements instead of admitting \nuncertainty. Such\" hallucinations\" persist even in state-of-the-art systems and\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04664&hl=en&sa=X&d=17470905045322269269&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b9-xvJdrsXYLi4Kkc78fX8P&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models", "first_label": ["LLM", "Bug", "Repository-Level"], "second_label": [], "data": "J Liu, Z Liu, Z Cheng, M He, X Shi, Y Guo, X Zhu, Y Guo- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have exhibited significant proficiency in code \ndebugging, especially in automatic program repair, which may substantially reduce \nthe time consumption of developers and enhance their efficiency. Significant\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04078%3F&hl=en&sa=X&d=12419661760319839544&ei=SUTUaMySBOvD6rQP6euP0Ao&scisig=AAZF9b8SHef7li0_lXitWcja8LI-&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "An Empirical Study of Exploring the Capabilities of Large Language Models in Code Learning", "first_label": ["LLM", "Code"], "second_label": [], "data": "S Liu, D Guo, J Zhang, W Ma, Y Li, Y Liu- IEEE Transactions on Software, 2025\nSince the advent of ChatGPT, large language models (LLMs) have attracted \nwidespread attention from academia and industry. They have also brought significant \nchanges to software engineering. However, until now, there has been a lack of", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11165494/&hl=en&sa=X&d=12085507997578536412&ei=8EzSaImaCZu1ieoP1tDwoQs&scisig=AAZF9b8QpfEvmwfa14Dvgemda9_a&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "3 new citations to articles by Xin ZHOU", "David Lo - new related research", "Thanh Le-Cong - new related research"]}
{"title": "PVDetector: Pretrained Vulnerability Detection on Vulnerability-enriched Code Semantic Graph", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection", "Graph"], "data": "J Li, L Cui, J Zhang, L Li, R Xi, H Zhu- ACM Transactions on Software Engineering, 2025\nAutomated vulnerability detection is a critical issue in software security. The advent of \ndeep learning (DL) has led to numerous studies employing DL to detect \nvulnerabilities in software source code. However, existing approaches still perform", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3768582&hl=en&sa=X&d=8582469852291084545&ei=8EzSaImaCZu1ieoP1tDwoQs&scisig=AAZF9b-KDpNTmZzjJ738P4MlJP3u&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research", "David Lo - new related research", "9 new citations to articles by Abhik Roychoudhury", "Quang-Cuong Bui - new related research", "Thanh Le-Cong - new related research"]}
{"title": "On the Effectiveness of Zero-shot and Few-shot Pretrained Language Models for Software Requirement Classification", "first_label": ["LLM"], "second_label": [], "data": "M Shafikuzzaman, MR Islam, S Zaman, A Ma, AI Sifat- IEEE Access, 2025\nAccurate classification of software requirements, particularly distinguishing between \nfunctional and non-functional requirements, is essential for enabling traceability, \nguiding system design, and ensuring project success. Traditional supervised", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/10820123/11153850.pdf&hl=en&sa=X&d=11947882102757591897&ei=8EzSaImaCZu1ieoP1tDwoQs&scisig=AAZF9b8nTkSrJUN-rA-zvTdkgh4M&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Bach Le - new related research", "Xin ZHOU - new related research", "Thanh Le-Cong - new related research"]}
{"title": "A Multi-agent LLM System for Automated Requirements Analysis: A Study on User Story Generation and Prioritization", "first_label": ["LLM"], "second_label": ["Generation", "Agent"], "data": "MA Sami, Z Zhang, M Waseem, KK Kemell, Z Rasheed- Euromicro Conference on, 2025\nManually specifying and prioritizing user stories in software projects is time-\nconsuming and prone to inconsistency. This paper investigates whether Large \nLanguage Models (LLMs) can support these activities through a role-based multi\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-04200-2_12&hl=en&sa=X&d=16294011070621165226&ei=8EzSaImaCZu1ieoP1tDwoQs&scisig=AAZF9b_xb3Ga6YXiFoi5pnMGkTkd&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Specification-Guided Repair of Arithmetic Errors in Dafny Programs using LLMs", "first_label": ["LLM"], "second_label": ["Repair"], "data": "A Abreu\nDebugging and repairing faults when programs fail to formally verify can be complex \nand time-consuming. Automated Program Repair (APR) can ease this burden by \nautomatically identifying and fixing faults. However, traditional APR techniques often\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://archimendes.com/publication/2025/sefm_repair/SEFM_Repair.pdf&hl=en&sa=X&d=10065646872316421301&ei=7UzSaOLpDqOj6rQPxs2duQU&scisig=AAZF9b8qzyPfd32OTsBcgYKa1xqs&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Automated vulnerability evaluation with large language models and vulnerability ontologies", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "R Ghosh, HM von Stockhausen, M Schmitt, GM Vasile- AI Magazine, 2025\nAbstract The National Vulnerability Database (NVD) publishes over a thousand new \nvulnerabilities monthly, with a projected 25 percent increase in 2024, highlighting the \ncrucial need for rapid vulnerability identification to mitigate cybersecurity attacks and \nsave costs and resources. In this work, we propose using large language models \n(LLMs) to learn vulnerability evaluation from historical assessments of medical \ndevice vulnerabilities in a single manufacturer's portfolio. We highlight the\nCites: Large language model for vulnerability detection and repair", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/pdf/10.1002/aaai.70031&hl=en&sa=X&d=14106213635778223781&ei=70zSaMHEH6Oj6rQPxs2duQU&scisig=AAZF9b_SqhJ1s0nxi-gs_ixWaICb&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["3 new citations to articles by Xin ZHOU"]}
{"title": "sBugChecker: A Systematic Framework for Detecting Solidity Compiler-Introduced Bugs", "first_label": ["Bug"], "second_label": ["Detection"], "data": "F Tong, Z Li, G Cheng, Y Zhang, H Li- IEEE Transactions on Information Forensics, 2025\nA compiler converts smart contract source code into bytecode, ensuring behavior \nconsistency between them. However, as compiler is also a program, it may contain \nbugs that disrupt this consistency, known as Compiler-Introduced Bugs (CIBs). Of the \nlatest 4,857 verified smart contracts coded in Solidity, approximately 58% still use \ncompilers that contain at least one CIB. These CIBs can be exploited by attackers to \nbypass security checks or inject malicious data, leading to significant security issues\nCites: Large language model for vulnerability detection: Emerging results\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11159069/&hl=en&sa=X&d=973917564340753579&ei=70zSaMHEH6Oj6rQPxs2duQU&scisig=AAZF9b9U6EYUWy1dQpWLOy1eKf7T&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["3 new citations to articles by Xin ZHOU"]}
{"title": "OpCodeBERT: A Method for Python Code Representation Learning by BERT with Opcode", "first_label": ["Code"], "second_label": [], "data": "C Qiu, J Liu, X Xiao, Y Xiao- IEEE Transactions on Software Engineering, 2025\nProgramming language pre-training models have made significant progress in code \nrepresentation learning in recent years. Although various methods, such as data flow \nand Abstract Syntax Tree (AST), have been widely applied to enhance code", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11169752/&hl=en&sa=X&d=1825874209020573091&ei=70zSaMfWOYjQ6rQP7MWZ4Ag&scisig=AAZF9b-cenZWTH8w2_NrvGDeuIZA&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "Trust Me, I Know This Function: Hijacking LLM Static Analysis using Bias", "first_label": ["LLM", "Static Analysis"], "second_label": [], "data": "S Bernstein, D Beste, D Ayzenshteyn, L Schonherr- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) are increasingly trusted to perform automated code \nreview and static analysis at scale, supporting tasks such as vulnerability detection, \nsummarization, and refactoring. In this paper, we identify and exploit a critical", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.17361&hl=en&sa=X&d=14936656878305558087&ei=70zSaMfWOYjQ6rQP7MWZ4Ag&scisig=AAZF9b-EYZLkXjUnKV9XPvZ59OSs&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Leveraging Large Language Models for Software Defect Detection", "first_label": ["LLM", "Software Defect"], "second_label": ["Detection"], "data": "E Wony, J Hryszko, A Roman- Euromicro Conference on Software Engineering and, 2025\nAbstract This paper evaluates Large Language Models (LLMs) for static code \nanalysis and defect detection across test sets of increasing complexity. Our findings \nshow LLMs excel with smaller code fragments but deteriorate with increasing\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-04200-2_9&hl=en&sa=X&d=12044849645783892459&ei=70zSaMfWOYjQ6rQP7MWZ4Ag&scisig=AAZF9b8_SzEL5yHzsqCjpZvxXfE8&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "The Journal of Systems & Software", "first_label": [], "second_label": [], "data": "A Eagal, KT Stolee, JP Ore\nThe ability to generate multiple equivalent versions of the same code segment \nacross different programming languages and within the same language is valuable \nfor code translation, language migration, and code comprehension in education", "link": "https://scholar.google.com/scholar_url?url=https://kstolee.github.io/assets/papers/2025JSS.pdf&hl=en&sa=X&d=3587664000965958368&ei=7kzSaOy1FMmk6rQPxc_v6QY&scisig=AAZF9b_g4Rbp0t3O7Dt6Cn42K7wt&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "An Attack Detection Mechanism in Smart Contracts Based on Deep Learning and Feature Fusion", "first_label": ["Smart Contracts"], "second_label": ["Detection"], "data": "P Li, G Wang, W Gu, X Li, X Liu, Y Zhang- Information Sciences, 2025\nThe rapid growth of Ethereum has spurred widespread adoption of smart contracts, \nenabling substantial financial transactions. Once deployed on the blockchain, smart \ncontracts are immutable, rendering them unmodifiable even if vulnerabilities are", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0020025525007789&hl=en&sa=X&d=4579278036844139192&ei=7kzSaOy1FMmk6rQPxc_v6QY&scisig=AAZF9b9gxKc_3n2nz2U4Us7cyQ0f&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "TypeNFuzz: Dynamic Type-aware Object Dependence Graph Guided Fuzzing for JavaScript Library Bug Discovery", "first_label": ["Fuzzing", "Bug"], "second_label": ["Graph"], "data": "Y Zeng, Y Wu, C Zhang- ACM Transactions on Software Engineering and\nNode. js owes much of its popularity to an enormous library ecosystem. While this \nabundance speeds development, widely varying code quality complicates efforts to \nassure robustness. Effective library testing is hard for two reasons:(1) dynamic typing", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3765760&hl=en&sa=X&d=5116157467151094045&ei=7kzSaOy1FMmk6rQPxc_v6QY&scisig=AAZF9b_fURRjvwZAmKpjZeYsQVaO&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Test Amplification for REST APIs via Single and Multi-agent LLM Systems", "first_label": ["LLM", "Software Testing"], "second_label": ["Agent"], "data": "S Demeyer- Testing Software and Systems\nREST APIs (Representational State Transfer Application Programming Interfaces) \nplay a vital role in modern cloud-native applications. As these APIs grow in \ncomplexity and scale, ensuring their correctness and robustness becomes", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/content/pdf/10.1007/978-3-032-05188-2.pdf%23page%3D171&hl=en&sa=X&d=15223294463602364426&ei=7kzSaOy1FMmk6rQPxc_v6QY&scisig=AAZF9b8SwIN3pZK4iTXpub_IkSvr&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "DiffGAN: A Test Generation Approach for Differential Testing of Deep Neural Networks for Image Analysis", "first_label": ["Software Testing"], "second_label": ["Generation"], "data": "Z Aghababaeyan, M Abdellatif, L Briand- IEEE Transactions on Software, 2025\nAbstract Deep Neural Networks (DNNs) are increasingly deployed across a wide \nrange of applications, from image classification to autonomous driving. However, \nensuring their reliability remains a challenge, and in many situations, alternative", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/journal/ts/5555/01/11173835/2a8P2CT7dq8&hl=en&sa=X&d=11527527068165018561&ei=7kzSaOy1FMmk6rQPxc_v6QY&scisig=AAZF9b8La2Ka594Yq-Q8MTYCSvUY&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Exploiting Contexts of LLM-based", "first_label": ["LLM"], "second_label": ["Exploit"], "data": "M Noppel, K Rubel, C Wressnegger- KI 2025: Advances in Artificial Intelligence: 48th, 2025\nCode assistants based on Large language models (LLMs) are built on massive \ndatasets, often sourced from untrusted GitHub repositories. Adversaries can poison \nthese sources so that the resulting models suggest insecure code. The\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DiJqCEQAAQBAJ%26oi%3Dfnd%26pg%3DPA298%26ots%3DF9z7W-8YPb%26sig%3DZ_qg3aC4Jv1hu2uRiL412geYjY8&hl=en&sa=X&d=11849080722612915147&ei=7kzSaOy1FMmk6rQPxc_v6QY&scisig=AAZF9b9n-mdQZq_y3Fr5E20CHAml&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "To Measure Is to Know, but Not in Software Engineering. A Call for Operational Definitions of Code Metrics", "first_label": ["Code"], "second_label": [], "data": "A Roman, M Mnich, J Hryszko- Euromicro Conference on Software Engineering and, 2025\nMeasurement is crucial in software engineering. Based on the results of \nmeasurement, critical software business decisions are made. Therefore, software \nmetrics should have precise operational definitions describing how the measurement \nshould be made. We examine this issue in the context of two well-known metrics, \nLOC and number of branches, as well as related test coverage metrics. We also \nshow significant differences in how measurement tools understand the same metrics\nCites: Does Going Beyond Branch Coverage Make Program Repair", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-04200-2_6&hl=en&sa=X&d=506954977415121341&ei=7kzSaPvSBJGG6rQPp77KgQ8&scisig=AAZF9b9iGkuOKtXEgVcaWLTvKyKy&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le"]}
{"title": "Copilot Tutor: Automated Software Engineering Practice Augmented with LLMs", "first_label": ["LLM"], "second_label": [], "data": "B Kong - 2025\nIn recent years, large language models (LLMs) have become more ubiquitous in the \nworkplace. In software engineering, they are often realized as copilots\" which \nproduce code given a prompt or existing code. Programmers using these tools to \nincrease their coding productivity need to be proficient in inspecting and in \nunderstanding these copilots' outputs. As engineers incorporate these tools to \naccelerate their workflows, they have a parallel opportunity to accelerate learning\nCites: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://dspace.mit.edu/bitstream/handle/1721.1/162750/kong-blisse-meng-eecs-2025-thesis.pdf%3Fsequence%3D1%26isAllowed%3Dy&hl=en&sa=X&d=13252524902133834568&ei=7kzSaPvSBJGG6rQPp77KgQ8&scisig=AAZF9b_KuxU3tz4tBk3WDV2luyOn&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le", "1 new citation to articles by Thanh Le-Cong"]}
{"title": "Blockchain Smart Contract Security: Threats and Mitigation Strategies in a Lifecycle Perspective", "first_label": ["Smart Contracts", "Blockchain"], "second_label": [], "data": "D Liu, J Zhang, Y Wang, H Shen, Z Zhang, T Ye- ACM Computing Surveys, 2025\nSmart contracts, as self-executing agreements on blockchain platforms, promise to \neliminate intermediaries and enhance transaction efficiency. However, their \nsusceptibility to security vulnerabilities not only poses risks of substantial financial \nlosses but also erodes trustworthiness in blockchain ecosystems, driving extensive \nresearch into enhancing both their security and trustworthiness. We provide a \ncomprehensive review of the current state of smart contract assurance, covering the\nCites: Smart contract development: Challenges and opportunities", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3769013&hl=en&sa=X&d=16417946769747450985&ei=7kzSaPvSBJGG6rQPp77KgQ8&scisig=AAZF9b-RAhc6b5rd7Pgu7ADbHvWl&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le", "9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Machine Learning for Triple-Entry Accounting: Enhancing Transparency and Oversight", "first_label": [], "second_label": [], "data": "AI Weinberg, A Faccia- Journal of Risk and Financial Management, 2025\nThis study develops a conceptual framework for integrating Triple-Entry (TE) \naccounting with machine learning (ML) to enhance transparency in financial \nreporting and auditing. TE extends the double-entry system by introducing a \ncryptographic third entry that captures contextual metadata and strengthens \nauditability. Existing research has discussed TE models and blockchain \nimplementations, yet there is limited exploration of how advanced analytics can\nCites: Smart contract development: Challenges and opportunities", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/1911-8074/18/9/525&hl=en&sa=X&d=3224295634474914379&ei=7kzSaPvSBJGG6rQPp77KgQ8&scisig=AAZF9b_z7ER2Pp9UT9MUeOcgazvH&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=3&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le"]}
{"title": "Towards Exploring Developers' Struggles in Developing Upgradeable Smart Contracts", "first_label": ["Smart Contracts"], "second_label": [], "data": "Z Zhong, J Chen, J Wang, Q Xue, J Wu, L Liu, X Ying- IEEE Transactions on, 2025\nImplementing upgradeable smart contracts (USCs) has become a trend in \nDecentralized applications. Due to blockchain immutability, ensuring the \nupgradeability of smart contracts requires specialized implementation strategies. A \nsystematic study of developers' concerns regarding USC development can provide \ninsights to reduce development costs and increase software robustness. In this work, \nwe propose the first empirical study on exploring developers' concerns over USCs\nCites: Smart contract development: Challenges and opportunities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11173264/&hl=en&sa=X&d=9843269027498256476&ei=7kzSaPvSBJGG6rQPp77KgQ8&scisig=AAZF9b9tXN-79yIlDw3hsG7M7EP-&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=4&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le"]}
{"title": "VPGFUZZ: Vulnerable Path-Guided Greybox Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "Z Lin, J Cao, X Wang, R Xie, Y Zhu, X Li, Q Li, Y Wang- IEEE Transactions on, 2025\nFuzzing is a prevalent technology for identifying software vulnerabilities. Existing \nfuzzing techniques predominantly focus on maximizing code coverage to unearth \npotential security issues. However, the mere expansion of explored code does not \nnecessarily correlate with an increased discovery of vulnerabilities. Additionally, \nexisting fuzzers often neglect comprehensive execution path information in code \nexploration. Consequently, potential vulnerabilities may be delayed or overlooked in\nCites: BLEEM: Packet Sequence Oriented Fuzzing for Protocol", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11153528/&hl=en&sa=X&d=2299234954927201608&ei=7kzSaLfbI_aT6rQP1-ijgAo&scisig=AAZF9b-dE3NYNukrDF3qy79FXAUB&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Performance of Test Generation Techniques on Property Checking: A Case Study", "first_label": ["Software Testing"], "second_label": ["Generation"], "data": "ZV Le, S Hong, Y Choi-  , 2025\nProperty verification plays a significant role in ensuring the functional correctness of \na system. This work presents a case study that explores the capability of various test \ngeneration techniques in identifying functional property violations. We empirically \nevaluated three representative tools from dominant domains: concolic testing \n(CRESTc), greybox fuzzing (AFL++), and stateful fuzzing (LTL-Fuzzer), measuring \ntheir detection ratio and detection time. The results indicate that these test generation\nCites: Linear-time Temporal Logic Guided Greybox Fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://www.dbpia.co.kr/Journal/articleDetail%3FnodeId%3DNODE12318178&hl=en&sa=X&d=7743493482519174611&ei=7kzSaLfbI_aT6rQP1-ijgAo&scisig=AAZF9b9mkr1UXL9ljNizUSqpcAjY&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Toward a Robust Ingress for Open-Sourced 5G Core Network", "first_label": [], "second_label": [], "data": "JW Hsu, XY Jiang, IW Chen, KJ Chen, C Ou-Yang- IEEE Transactions on, 2025\nThe security of 5G networks hinges on the robustness and reliability of their software \nimplementations from the core network infrastructure to end-user devices. Fortifying \nthese networks against emerging threats and vulnerabilities requires rigorous \ntesting. This article proposes a systematic approach for identifying flaws in 5G core \nnetwork implementations. Focusing on the attack surfaces at 5G core network entry \npoints, we identified flaws in handling the next-generation application protocol\nCites: AFLNet: a greybox fuzzer for network protocols", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11169296/&hl=en&sa=X&d=3739030609696673441&ei=7kzSaLfbI_aT6rQP1-ijgAo&scisig=AAZF9b8ckjIFSAYSrbEwsbON9VC5&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Distributed Critical Test Generation for Cyber-Physical Systems", "first_label": ["Software Testing"], "second_label": ["Generation"], "data": "A Kaya, I Porres- IFIP International Conference on Testing Software and, 2025\nWe present a family of distributed algorithms for Critical Test Generation (CTG). CTG \nsubsumes the problems of requirement falsification and scenario generation, two \nimportant methods for safety validation of cyber-physical systems. In this article, we \nexplore different strategies to parallelize and distribute a CTG algorithm based on \ngenerative models for test generation. By leveraging the sampling flexibility of \ngenerative models, our designs scale from synchronous to fully asynchronous\nCites: Coverage-based greybox fuzzing as markov chain", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-05188-2_8&hl=en&sa=X&d=7010854045471913033&ei=7kzSaLfbI_aT6rQP1-ijgAo&scisig=AAZF9b_LkeBBGVZ0Q-TbmcVtWRur&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "CoReX: Context-Aware Refinement-Based Slicing for Debugging Regression Failures", "first_label": ["Bug"], "second_label": [], "data": "S Badihi, J Rubin - 2026\nTroubleshooting regression failures is one of the most frequent yet time-consuming \ndevelopment tasks. To help with this task, numerous approaches aim to narrow down \ndevelopers' attention to the subset of code statements relevant to the failure. The \nmost prominent of these approaches are based on program slicing, as slicing not \nonly identifies a subset of relevant statements but also maintains the flow of \ninformation between these statements. By surveying more than 50 practitioners from\nCites: Darwin: An approach to debugging evolving programs", "link": "https://scholar.google.com/scholar_url?url=https://people.ece.ubc.ca/mjulia/publications/CoReX_ICSE2026.pdf&hl=en&sa=X&d=6186992737140311627&ei=7kzSaLfbI_aT6rQP1-ijgAo&scisig=AAZF9b82IYr22fx4tmdaOFV2Biyj&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Improving Vulnerability Discovery Tools and Training Through a Human Factors Lens", "first_label": ["Vulnerabilities"], "second_label": [], "data": "J Mattei - 2025\nAs technology continues to permeate daily life and critical infrastructure, the need for \nskilled practitioners to perform vulnerability discovery grows. Despite increased \ndemandexacerbated by rising cyberattacks and government calls to expand the \ncybersecurity workforcevulnerability discovery remains difficult, largely manual, \nand inaccessible to newcomers. Automated tools exist, but adoption is low; \nbeginners often face steep learning curves, leading to frustration and attrition.\nCites: Kleespectre: Detecting information leakage through speculative", "link": "https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/1ddf6dcca8b11ca215e73956fe5c6437/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=en&sa=X&d=12214694538292167265&ei=7kzSaLfbI_aT6rQP1-ijgAo&scisig=AAZF9b83myknTg2oBom_2bK72lHz&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "ZombieFuzz: Automatically Hijacking Encoded Messages for Network Protocol Fuzzing", "first_label": ["Fuzzing", "Code"], "second_label": [], "data": "N Grewal - 2025\nFuzzing is a widely-used technique for discovering bugs by randomly generating a \nlarge number of test cases. While fuzzing has proven effective for many applications, \nit remains difficult to apply fuzzing to stateful networked applications that use \ncryptography and/or compression. These mechanisms introduce input validation \nbarriers, causing most test cases to be rejected early on during decryption or \ndecompression. As such, conventional fuzzers fail to reach deep application logic\nCites: AFLNet: a greybox fuzzer for network protocols\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://security.csl.toronto.edu/wp-content/uploads/2025/08/ngrewal_msc_thesis_2025.pdf&hl=en&sa=X&d=5501172028455924305&ei=7kzSaLfbI_aT6rQP1-ijgAo&scisig=AAZF9b-RvMMVZQo2ouaevq01rFXy&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "LLM-Driven Adaptive SourceSink Identification and False Positive Mitigation for Static Analysis", "first_label": ["LLM", "Static Analysis"], "second_label": [], "data": "S Lin - 2025\nStatic analysis is effective for discovering software vulnerabilities but notoriously \nsuffers from incomplete sourcesink specifications and excessive false positives \n(FPs). We present ADATAINT, an LLM-driven taint analysis framework that adaptively \ninfers source/sink specifications and filters spurious alerts through neuro-symbolic \nreasoning. Unlike LLM-only detectors, ADATAINT grounds model suggestions in \nprogram facts and constraint validation, ensuring both adaptability and determinism\nCites: Detecting false alarms from automatic static analysis tools: How far\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.preprints.org/frontend/manuscript/bf8ba8d12f4182f7003df2d3a9a3ab36/download_pub&hl=en&sa=X&d=17506770233240427094&ei=7UzSaJSeMdHSieoPhLqokA4&scisig=AAZF9b979kmyD2LOgpSke9Vf17RK&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["1 new citation to articles by Hong Jin Kang"]}
{"title": "ExDoS: Expert-Guided Dual-Focus Cross-Modal Distillation for Smart Contract Vulnerability Detection", "first_label": ["Vulnerabilities", "Smart Contracts"], "second_label": ["Detection"], "data": "Y Jia, Y Tian, Y Wang, J Sun, H Xu- arXiv preprint arXiv:2509.10252, 2025\nThe success of smart contracts has made them a target for attacks, but their closed-\nsource nature often forces vulnerability detection to work on bytecode, which is \ninherently more challenging than source-code-based analysis. While recent studies", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.10252&hl=en&sa=X&d=8136317411742995021&ei=7UzSaN67IKDWieoPyfiAmA8&scisig=AAZF9b-H1kj3p4b3knTEUU2oHPBi&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "KG4VA: Constructing Vulnerability Knowledge Graph for Software Vulnerability Assessment", "first_label": ["Vulnerabilities"], "second_label": ["Graph"], "data": "Z Ye, X Sun, L Bo, S Cao, X Ren, L Qi, J Zhang- IEEE Transactions on Services, 2025\nSoftware vulnerabilities pose serious threats to software security. When faced with \nmultiple software vulnerabilities at the same time, it is urgent to determine whether \nthe vulnerabilities are high-risk. Existing vulnerability assessment approaches only\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11168463/&hl=en&sa=X&d=9875397822101594242&ei=7UzSaN67IKDWieoPyfiAmA8&scisig=AAZF9b8F4UfU_q2ktULWnlyDNb2z&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Unraveling LLM Jailbreaks Through Safety Knowledge Neurons", "first_label": ["LLM"], "second_label": [], "data": "C Zhao, K Huang- arXiv preprint arXiv:2509.01631, 2025\nLarge Language Models (LLMs) are increasingly attracting attention in various \napplications. Nonetheless, there is a growing concern as some users attempt to \nexploit these models for malicious purposes, including the synthesis of controlled", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01631&hl=en&sa=X&d=1514740733256060014&ei=70zSaIrdLMnXieoPztea-QE&scisig=AAZF9b9hCs1ysD6JyG0WYWiQsfvZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "first_label": ["LLM"], "second_label": ["Agent"], "data": "T Lindenbauer, I Slinko, L Felder, E Bogomolov- arXiv preprint arXiv, 2025\nLarge Language Model (LLM)-based agents solve complex tasks through iterative \nreasoning, exploration, and tool-use, a process that can result in long, expensive \ncontext histories. While state-of-the-art Software Engineering (SE) agents like", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21433&hl=en&sa=X&d=3778813371369713554&ei=70zSaIrdLMnXieoPztea-QE&scisig=AAZF9b8vjKgLLO8JtQg2HjxwaIIj&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "ArcGen: Generalizing Neural Backdoor Detection Across Diverse Architectures", "first_label": [], "second_label": ["Detection"], "data": "Z Yang, C Luo, D He, Y Li, Y Li- IEEE Transactions on Information Forensics and, 2025\nBackdoor attacks pose a significant threat to the security and reliability of deep \nlearning models. To mitigate such attacks, one promising approach is to learn to \nextract features from the target model and use these features for backdoor detection", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11165475/&hl=en&sa=X&d=7195582352476832979&ei=70zSaIrdLMnXieoPztea-QE&scisig=AAZF9b8nLgHrtCNJPGLAFhh3jGYp&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "STING: A Stealthy Backdoor Attack on GNN-Based Malicious Domain Detection via DNS Perturbations", "first_label": [], "second_label": ["Detection"], "data": "M Anan, M Nazzal, A Khreishah, I Khalil, NH Phan- IEEE Open Journal of the, 2025\nDetecting malicious Internet domains is essential for safeguarding against various \nonline threats. The current approach to detecting malicious domains (MDD) employs \na graph neural network (GNN) method, which uses DNS logs to construct", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/8782661/8901158/11165113.pdf&hl=en&sa=X&d=7155276764774839705&ei=70zSaIrdLMnXieoPztea-QE&scisig=AAZF9b_UhDaVT_j_RIbdLwdmME-T&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "IntentionReasoner: Facilitating Adaptive LLM Safeguards through Intent Reasoning and Selective Query Refinement", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "Y Shen, Z Huang, Z Guo, Y Liu, G Chen, R Yin- arXiv preprint arXiv, 2025\nThe rapid advancement of large language models (LLMs) has driven their adoption \nacross diverse domains, yet their ability to generate harmful content poses significant \nsafety challenges. While extensive research has focused on mitigating harmful", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.20151%3F&hl=en&sa=X&d=341990395345011620&ei=70zSaIrdLMnXieoPztea-QE&scisig=AAZF9b_-ms9316_TkF43ylzTeIAY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Improving Fisher Information Estimation and Efficiency for LoRA-based LLM Unlearning", "first_label": ["LLM"], "second_label": [], "data": "Y Kim, E Kim, B Chang, J Choe- arXiv preprint arXiv:2508.21300, 2025\nLLMs have demonstrated remarkable performance across various tasks but face \nchallenges related to unintentionally generating outputs containing sensitive \ninformation. A straightforward approach to address this issue is to retrain the model", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21300&hl=en&sa=X&d=18118274406447482310&ei=70zSaIrdLMnXieoPztea-QE&scisig=AAZF9b-Fkvoe-o37RUTmFYcxdzxr&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Dynamic Collaboration of Multi-Language Models based on Minimal Complete Semantic Units", "first_label": ["LLM"], "second_label": [], "data": "C Hao, Z Wang, Y Huang, R Xu, W Niu, X Liu, Z Yu- arXiv preprint arXiv:2508.18763, 2025\nThis paper investigates the enhancement of reasoning capabilities in language \nmodels through token-level multi-model collaboration. Our approach selects the \noptimal tokens from the next token distributions provided by multiple models to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.18763%3F&hl=en&sa=X&d=7978340676637382802&ei=70zSaIrdLMnXieoPztea-QE&scisig=AAZF9b-rc5S4wmmH_aQGW4hkQdKP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Standard vs. Modular Sampling: Best Practices for Reliable LLM Unlearning", "first_label": ["LLM"], "second_label": [], "data": "P Bushipaka, L Passaro, T Cucinotta- arXiv preprint arXiv:2509.05316, 2025\nA conventional LLM Unlearning setting consists of two subsets-\" forget\" and\" retain\", \nwith the objectives of removing the undesired knowledge from the forget set while \npreserving the remaining knowledge from the retain. In privacy-focused unlearning", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05316%3F&hl=en&sa=X&d=15276445221595613731&ei=70zSaIrdLMnXieoPztea-QE&scisig=AAZF9b_OE1DXKQI_RHcvSUGaI0fY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Revealing Potential Biases in LLM-Based Recommender Systems in the Cold Start Setting", "first_label": ["LLM"], "second_label": [], "data": "A Andre, G Roy, E Dyer, K Wang- arXiv preprint arXiv:2508.20401, 2025\nLarge Language Models (LLMs) are increasingly used for recommendation tasks \ndue to their general-purpose capabilities. While LLMs perform well in rich-context \nsettings, their behavior in cold-start scenarios, where only limited signals such as", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.20401%3F&hl=en&sa=X&d=14157156363092404303&ei=70zSaIrdLMnXieoPztea-QE&scisig=AAZF9b95JVATA_nzKnQYQUR0MKqQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Counterfactual Sensitivity for Faithful Reasoning in Language Models", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "IF Shihab, S Akter, A Sharma- arXiv preprint arXiv:2509.01544, 2025\nLarge language models (LLMs) often produce correct answers while relying on \nflawed or irrelevant reasoning traces, undermining their trustworthiness in high-\nstakes domains. We propose Counterfactual Sensitivity Regularization (CSR), a\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01544&hl=en&sa=X&d=16973430102837298098&ei=70zSaIrdLMnXieoPztea-QE&scisig=AAZF9b-nLRKB4WgajHq7UxZ_NYzW&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Conversational Automated Program Repair for ARM Assembly Code using LLMs", "first_label": ["APR", "LLM", "Code"], "second_label": ["Repair"], "data": "J Gomes, D Silveira, T Jorge\nThis paper explores the development of the Automated Program Repair (APR) field, \nwith a specific emphasis on the use of Large Language Models (LLMs) to tackle the \nchallenges of ARM assembly code in the AIR project, a joint initiative between GMV", "link": "https://scholar.google.com/scholar_url?url=https://www.horizon-schumann.eu/wp-content/uploads/2025/07/Conversational_Automated_Program_Repair_for_ARM_Assembly_Code_using_LLMs_final.pdf&hl=en&sa=X&d=4367788842176228212&ei=70zSaMWEBPKOieoP58qBqAc&scisig=AAZF9b_8xrU3osMG0qpQXxLpnrK7&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FuzzRDUCC: Fuzzing with Reconstructed Def-Use Chain Coverage", "first_label": ["Fuzzing"], "second_label": [], "data": "K Feng, J Singer, AK Marnerides- arXiv preprint arXiv:2509.04967, 2025\nBinary-only fuzzing often struggles with achieving thorough code coverage and \nuncovering hidden vulnerabilities due to limited insight into a program's internal \ndataflows. Traditional grey-box fuzzers guide test case generation primarily using", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04967&hl=en&sa=X&d=12793668697793724612&ei=70zSaMWEBPKOieoP58qBqAc&scisig=AAZF9b9DbASTknJLZ9Qw2muyThkA&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FuzzBox: Blending Fuzzing into Emulation for Binary-Only Embedded Targets", "first_label": ["Fuzzing"], "second_label": [], "data": "C Cesarano, R Natella- arXiv preprint arXiv:2509.05643, 2025\nCoverage-guided fuzzing has been widely applied to address zero-day \nvulnerabilities in general-purpose software and operating systems. This approach \nrelies on instrumenting the target code at compile time. However, applying it to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05643&hl=en&sa=X&d=4585422960426806286&ei=70zSaMWEBPKOieoP58qBqAc&scisig=AAZF9b-p7mmDlvT3yh-ZhB_TgxIV&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Leveraging SystemC-TLM-based Virtual Prototypes for Embedded Software Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "C Ghinami, J Winzer, N Bosbach, LM Reimann- arXiv preprint arXiv, 2025\nSystemC-based virtual prototypes have emerged as widely adopted tools to test \nsoftware ahead of hardware availability, reducing the time-to-market and improving \nsoftware reliability. Recently, fuzzing has become a popular method for automated", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01318&hl=en&sa=X&d=1341175212014518141&ei=70zSaMWEBPKOieoP58qBqAc&scisig=AAZF9b9xqbJnzFJ8oCl2uemQ46wF&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Syntactic multilingual probing of pre-trained language models of code", "first_label": ["LLM", "Code"], "second_label": [], "data": "JAH Lpez, M Weyssow, JS Cuadrado, H Sahraoui- Journal of Systems and, 2026\nPre-trained language models (PLMs) have demonstrated remarkable abilities in \ncoding tasks, establishing themselves as a state-of-the-art technique in machine \nlearning for code. However, due to their deep neural network-based structure, PLMs\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225002730&hl=en&sa=X&d=912414639058686127&ei=70zSaMWEBPKOieoP58qBqAc&scisig=AAZF9b_JpbZnEYTzTsY6dFTnCppp&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
