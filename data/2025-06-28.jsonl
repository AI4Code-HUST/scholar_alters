{"title": "May the Feedback Be with You! Unlocking the Power of Feedback-Driven Deep Learning Framework Fuzzing via LLMs", "first_label": ["LLM", "Fuzzing"], "second_label": [], "data": "S Yang, C Fang, H Lin, X Chen, Z Chen\\xc2\\xa0- arXiv preprint arXiv:2506.17642, 2025\nArtificial Intelligence (AI) Infrastructures, represented by Deep Learning (DL) \nframeworks, have served as fundamental DL systems over the last decade. However, \nthe bugs in DL frameworks could lead to catastrophic consequences in some critical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17642&hl=en&sa=X&d=11889850467341289951&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b91P2KqHxsqfRiaXkVsoi1_&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Enhancing Vulnerability Detection via Inter-procedural Semantic Completion", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Generation"], "data": "B Wu, C Liu, Z Li, Y Cao, J Sun, SW Lin\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInspired by advances in deep learning, numerous learning-based approaches for \nvulnerability detection have emerged, primarily operating at the function level for \nscalability. However, this design choice has a critical limitation: many vulnerabilities\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728912&hl=en&sa=X&d=8986759430451534011&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b9A33CcRPXunqP9s6dXKLU0&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research", "Xin ZHOU - new related research"]}
{"title": "CrossProbe: LLM-Empowered Cross-Project Bug Detection for Deep Learning Frameworks", "first_label": ["LLM", "Bug"], "second_label": ["Detection"], "data": "H Guan, G Bai, Y Liu\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nDeep Learning (DL) models may introduce reliability challenges in the underlying DL \nframeworks. These frameworks may be prone to bugs that can lead to crash or wrong \nresults, particularly when involving complex model architectures and substantial\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728984&hl=en&sa=X&d=1853826777394590417&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b94yhva0cu1ErAoxyUCC4C1&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Reassessing Code Authorship Attribution in the Era of Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "AK Dipongkor, Z Yao, K Moran\\xc2\\xa0- arXiv preprint arXiv:2506.17120, 2025\nThe study of Code Stylometry, and in particular Code Authorship Attribution (CAA), \naims to analyze coding styles to identify the authors of code samples. CAA is crucial \nin cybersecurity and software forensics for addressing, detecting plagiarism, and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17120&hl=en&sa=X&d=12069506939304281396&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b9OxubQtYi2lTNPr1YQmcjb&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research", "David Lo - new related research", "Bach Le - new related research", "Xin ZHOU - new related research"]}
{"title": "Dataflow-Guided Neuro-Symbolic Language Models for Type Inference", "first_label": ["LLM"], "second_label": [], "data": "G Li, Y Wan, H Zhang, Z Zhao, W Jiang, X Shi, H Jin\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nLanguage Models (LMs) are increasingly used for type inference, aiding in error \ndetection and software development. Some real-world deployments of LMs require \nthe model to run on local machines to safeguard the intellectual property of the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Do5D8i2zZ1l&hl=en&sa=X&d=18404508326142477871&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b9xjdjSj7gUqtAzIpU2LhAX&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Bach Le - new related research"]}
{"title": "Nemotron-CORTEXA: Enhancing LLM Agents for Software Engineering Tasks via Improved Localization and Solution Diversity", "first_label": ["LLM"], "second_label": ["Agent", "Localization"], "data": "A Sohrabizadeh, J Song, M Liu, R Roy, C Lee\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nLarge Language Models (LLMs) have demonstrated significant potential in code \ngeneration by following natural language instructions. Unfortunately, crucial real-\nworld software engineering tasks, such as debugging or repository-level feature\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dk6p8UKRdH7&hl=en&sa=X&d=951048739864022913&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b-H11fzuFCoL6Gk97_KnR7i&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "10 new citations to articles by Abhik Roychoudhury", "David Lo - new related research", "Bach Le - new related research", "Xin ZHOU - new related research"]}
{"title": "Call Me Maybe: Enhancing JavaScript Call Graph Construction using Graph Neural Networks", "first_label": ["Static Analysis"], "second_label": ["Graph"], "data": "MHM Bhuiyan, G De Stefano, G Pellegrino, CA Staicu\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nStatic analysis plays a key role in finding bugs, including security issues. A critical \nstep in static analysis is building accurate call graphs that model function calls in a \nprogram. However, due to hard-to-analyze language features, existing call graph\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18191&hl=en&sa=X&d=16428373106821087898&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b8B6-fht3Wn513mIkR_opua&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "7 new citations to articles by Thanh Le-Cong", "10 new citations to articles by Bach Le", "10 new citations to articles by Hong Jin Kang"]}
{"title": "Smart-LLaMA-DPO: Reinforced Large Language Model for Explainable Smart Contract Vulnerability Detection", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection"], "data": "L Yu, Z Huang, H Yuan, S Cheng, L Yang, F Zhang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSmart contract vulnerability detection is a critical challenge in the rapidly evolving \nblockchain landscape. Existing vulnerability detection methods face two main \nissues:(1) Existing datasets lack comprehensiveness and sufficient quality, with\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728878&hl=en&sa=X&d=2135693646383280550&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b-FHJ6rZDCUMR9iJ-6yMeNb&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "10 new citations to articles by Bach Le"]}
{"title": "FANDANGO: Evolving Language-Based Testing", "first_label": ["Software Testing"], "second_label": [], "data": "JA Zamudio Amaya, M Smytzek, A Zeller\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage-based fuzzers leverage formal input specifications (languages) to \ngenerate arbitrarily large and diverse sets of valid inputs for a program under test. \nModern language-based test generators combine grammars and constraints to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728915&hl=en&sa=X&d=13526184046567235231&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b9Ngi_JZAP5Qi9nTPmPtFJJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "TypyBench: Evaluating LLM Type Inference for Untyped Python Repositories", "first_label": ["LLM"], "second_label": [], "data": "H Dong, J Yang, X Deng, Y Jiang, G Pekhimenko\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nType inference for dynamic languages like Python is a persistent challenge in \nsoftware engineering. While large language models (LLMs) have shown promise in \ncode understanding, their type inference capabilities remain underexplored. We\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dxl9sv9vEDy&hl=en&sa=X&d=5590401666570182726&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b_1v2ZiYt35IkKDr0FkrnZ_&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Y Mao, T Cui, P Liu, D You, H Zhu\\xc2\\xa0- arXiv preprint arXiv:2506.15170, 2025\nLarge language models (LLMs) are rapidly evolving from single-modal systems to \nmultimodal LLMs and intelligent agents, significantly expanding their capabilities \nwhile introducing increasingly severe security risks. This paper presents a systematic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15170&hl=en&sa=X&d=16427093263132639213&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b-zqUEdPZ8IyWJxfUDycl5Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AdvAgent: Controllable Blackbox Red-teaming on Web Agents", "first_label": [], "second_label": ["Agent"], "data": "C Xu, M Kang, J Zhang, Z Liao, L Mo, M Yuan, H Sun\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nFoundation model-based agents are increasingly used to automate complex tasks, \nenhancing efficiency and productivity. However, their access to sensitive resources \nand autonomous decision-making also introduce significant security risks, where\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DbwidSkOyWF&hl=en&sa=X&d=9387054046201912213&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b_vl6xXIhUKB0x_dwYNdPRR&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Emoji attack: Enhancing jailbreak attacks against judge llm detection", "first_label": ["LLM"], "second_label": ["Detection"], "data": "Z Wei, Y Liu, NB Erichson\\xc2\\xa0- Forty-second International Conference on Machine\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreaking techniques trick Large Language Models (LLMs) into producing \nrestricted output, posing a potential threat. One line of defense is to use another LLM \nas a Judge to evaluate the harmfulness of generated text. However, we reveal that\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DQ0rKYiVEZq&hl=en&sa=X&d=17491126507172914063&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b_yTB1R20z-t6ApkecZnFST&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift", "first_label": ["LLM"], "second_label": [], "data": "S Liang, J Liang, T Pang, C Du, A Liu, M Zhu, X Cao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInstruction tuning enhances large vision-language models (LVLMs) but increases \ntheir vulnerability to backdoor attacks due to their open design. Unlike prior studies in \nstatic settings, this paper explores backdoor attacks in LVLM instruction tuning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=http://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.pdf&hl=en&sa=X&d=5142527777954789704&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b9_2Tz_lMykq3n8fQAVehJc&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, M Dras, U Naseem\\xc2\\xa0- arXiv preprint arXiv:2506.02442, 2025\nThis paper presents a systematic evaluation of Large Language Models'(LLMs) \nbehavior on long-tail distributed (encrypted) texts and their safety implications. We \nintroduce a two-dimensional framework for assessing LLM safety:(1) instruction\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02442&hl=en&sa=X&d=15102350404536711280&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b_4gGVOvmiHUrKGvn2E4Vhh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems", "first_label": ["LLM"], "second_label": ["Agent", "Search"], "data": "X Li, J Chen, X Fang, S Ding, H Duan, Q Liu, K Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown remarkable capabilities in solving \ndiverse tasks. However, their proficiency in iteratively optimizing complex solutions \nthrough learning from previous feedback remains insufficiently explored. To bridge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10764&hl=en&sa=X&d=1134890120116902745&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b8s_mGNSGwzfKFs6o2hgsbd&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "L Jiang, Z Zhang, Z Wang, X Sun, Z Li, L Zhen, X Xu\\xc2\\xa0- arXiv preprint arXiv:2506.16760, 2025\nLarge Vision-Language Models (LVLMs) demonstrate exceptional performance \nacross multimodal tasks, yet remain vulnerable to jailbreak attacks that bypass built-\nin safety mechanisms to elicit restricted content generation. Existing black-box\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16760&hl=en&sa=X&d=12136733750645262486&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b8NosIP6RI9jYFVbBgmH01C&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents", "first_label": ["LLM", "Code"], "second_label": ["Agent", "Reasoning"], "data": "K Hariharan, U Girit, A Wang, J Andreas\\xc2\\xa0- arXiv preprint arXiv:2506.00172, 2025\nBenchmarks for large language models (LLMs) have predominantly assessed short-\nhorizon, localized reasoning. Existing long-horizon suites (eg SWE-bench) rely on \nmanually curated issues, so expanding or tuning difficulty demands expensive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00172&hl=en&sa=X&d=7723120566071680437&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b-MEatAoZUO5Dw1f9NQmtaH&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "S-Eval: Towards Automated and Comprehensive Safety Evaluation for Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "X Yuan, J Li, D Wang, Y Chen, X Mao, L Huang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGenerative large language models (LLMs) have revolutionized natural language \nprocessing with their transformative and emergent capabilities. However, recent \nevidence indicates that LLMs can produce harmful content that violates social norms\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728971&hl=en&sa=X&d=8645951356678636667&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b8jZqhUmHLIf6ASSQvQ_7ot&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Yuan, Y Xu, J Shi, P Zhou, L Sun\\xc2\\xa0- arXiv preprint arXiv:2505.23561, 2025\nModel merging for Large Language Models (LLMs) directly fuses the parameters of \ndifferent models finetuned on various tasks, creating a unified model for multi-domain \ntasks. However, due to potential vulnerabilities in models available on open-source\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23561&hl=en&sa=X&d=6617189016454156514&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b-hKaNf3ql6GqPXtJeaxsCC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Fixing", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "K Huang, J Zhang, X Xie, C Chen\\xc2\\xa0- arXiv preprint arXiv:2506.16136, 2025\nLarge language model-(LLM) based automated program repair (APR) techniques \nhave shown promising results in resolving real-world GitHub issue tasks. Existing \nAPR systems are primarily evaluated in unimodal settings (eg, SWE-bench). \nHowever, these autonomous systems struggle to resolve multimodal problem \nscenarios (eg, SWE-bench M) due to limitations in interpreting and leveraging visual \ninformation. In multimodal scenarios, LLMs need to rely on visual information in the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Programming and Program Repair (Dagstuhl Seminar\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16136&hl=en&sa=X&d=11220685545668409026&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b9kYTbwxGsxJt9tRJbr87sr&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Thanh Le-Cong - new related research", "Bach Le - new related research"]}
{"title": "Quantum Optimization for Software Engineering: A Survey", "first_label": [], "second_label": [], "data": "M Zhang, Y Li, T Yue, KY Cai\\xc2\\xa0- arXiv preprint arXiv:2506.16878, 2025\nQuantum computing, particularly in the area of quantum optimization, is steadily \nprogressing toward practical applications, supported by an expanding range of \nhardware platforms and simulators. While Software Engineering (SE) optimization \nhas a strong foundation, which is exemplified by the active Search-Based Software \nEngineering (SBSE) community and numerous classical optimization methods, the \ngrowing complexity of modern software systems and their engineering processes\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaA 2030 Roadmap for Software Engineering\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16878&hl=en&sa=X&d=13495203515859157363&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b_ejlJTEJUIB_KsddWWyuBU&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "7 new citations to articles by Xin ZHOU"]}
{"title": "AdverIntent-Agent: Adversarial Reasoning for Repair Based on Inferred Program Intent", "first_label": [], "second_label": ["Repair", "Agent", "Reasoning"], "data": "H Ye, AZH Yang, C Hu, Y Wang, T Zhang, C Le Goues\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomated program repair (APR) has shown promising results, particularly with the \nuse of neural networks. Currently, most APR tools focus on code transformations \nspecified by test suites, rather than reasoning about the program's intent and the high-\nlevel bug specification. Without a proper understanding of program intent, these tools \ntend to generate patches that overfit incomplete test suites and fail to reflect the \ndeveloper's intentions. However, reasoning about program intent is challenging. In\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSpecRover: Code Intent Extraction via LLMs\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728939&hl=en&sa=X&d=338931335499312158&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b8rDbimJ50pvziYL6CPyglt&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research", "10 new citations to articles by Bach Le", "Xin ZHOU - new related research"]}
{"title": "Position: Future Research and Challenges Remain Towards AI for Software Engineering", "first_label": [], "second_label": ["Search"], "data": "A Gu, N Jain, WD Li, M Shetty, K Ellis, K Sen\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nAI for software engineering has made remarkable progress, becoming a notable \nsuccess within generative AI. Despite this, achieving fully automated software \nengineering is still a significant challenge, requiring research efforts across both \nacademia and industry. In this position paper, our goal is threefold. First, we provide \na taxonomy of measures and tasks to categorize work towards AI software \nengineering. Second, we outline the key bottlenecks permeating today's approaches\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAI software engineer: Programming with trust\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DRuLsq4LSZK&hl=en&sa=X&d=16570752453588002278&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b-3STm2owtN4TCxlRCJShpl&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "The Sustainability Face of Automated Program Repair Tools", "first_label": ["APR"], "second_label": ["Repair"], "data": "M Martinez, S Mart\\xc3\\xadnez-Fern\\xc3\\xa1ndez, X Franch\\xc2\\xa0- ACM Transactions on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomated program repair (APR) aims to automatize the process of repairing \nsoftware bugs in order to reduce the cost of maintaining software programs. While \nAPR accuracy has significantly improved in recent years, its energy impact remains \nunstudied. The field of green software research aims to measure the energy \nconsumption required to develop, maintain, and use software products. Our main \ngoal is to define the foundation for measuring the energy consumption of the APR\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3744900&hl=en&sa=X&d=4755253952998052333&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b_b2KUTH1ZpL1eFHeVxeyti&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Thanh Le-Cong - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research", "10 new citations to articles by Bach Le", "Xin ZHOU - new related research", "10 new citations to articles by Hong Jin Kang"]}
{"title": "Reinforcement Learning-Based Fuzz Testing for the Gazebo Robotic Simulator", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "Z Ren, Y Li, X Li, G Qi, J Xuan, H Jiang\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGazebo, being the most widely utilized simulator in robotics, plays a pivotal role in \ndeveloping and testing robotic systems. Given its impact on the safety and reliability \nof robotic operations, early bug detection is critical. However, due to the challenges \nof strict input structures and vast state space, it is not effective to directly use existing \nfuzz testing approach to Gazebo. In this paper, we present GzFuzz, the first fuzz \ntesting framework designed for Gazebo. GzFuzz addresses these challenges\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728942&hl=en&sa=X&d=3075738240390385607&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b8VXL9cL4H_XDpqotfpo8TD&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Program Feature-Based Benchmarking for Fuzz Testing", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "M Miao, S Kummita, E Bodden, S Wei\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFuzzing is a powerful software testing technique renowned for its effectiveness in \nidentifying software vulnerabilities. Traditional fuzzing evaluations typically focus on \noverall fuzzer performance across a set of target programs, yet few benchmarks \nconsider how fine-grained program features influence fuzzing effectiveness. To \nbridge this gap, we introduce FeatureBench, a novel benchmark designed to \ngenerate programs with configurable, fine-grained program features to enhance\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaExplainable fuzzer evaluation\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728899&hl=en&sa=X&d=17804857660489567580&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b-ycPYTcoj8tV5Ren2Yr_m3&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "PatchScope: LLM-Enhanced Fine-Grained Stable Patch Classification for Linux Kernel", "first_label": ["LLM"], "second_label": [], "data": "R Liu, H Shi, S Liu, C Hu, S Li, Y Shen, R Wang, X Shi\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nStable patch classification plays a crucial role in vulnerability management for the \nLinux kernel, significantly contributing to the stability and security of Long-term \nsupport (LTS) versions. Although existing tools have effectively assisted in assessing \nwhether patches should be merged into stable versions, they cannot determine \nwhich stable patches should be merged into which LTS versions. This process still \nrequires the maintainers of the distribution community to manually screen based on\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Patch Backporting in Linux (Experience Paper)\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728944&hl=en&sa=X&d=13842233969248958151&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b_UJL3j4gGFSExwdfzqcx38&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "PAGENT: Learning to Patch Software Engineering Agents", "first_label": [], "second_label": ["Agent"], "data": "H Xue, G Uddin, S Wang\\xc2\\xa0- arXiv preprint arXiv:2506.17772, 2025\nLLM Agents produce patches automatically to resolve an issue. However, they can \ngenerate inaccurate patches. Little is known about the root causes behind those \nfailed patches or how those could be fixed. This paper reports an empirical study of \nthe failed patches generated by seven top LLM code agents. We collected 114 \nissues from the SWE-bench Lite dataset that remained unresolved across the agents. \nThe seven agents produced a total of 769 failed patches for those issues, which we\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSemantic-guided Search for Efficient Program Repair with Large\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17772&hl=en&sa=X&d=9634659774701361862&ei=WnJeaJTyO7WP6rQP2a7yoQM&scisig=AAZF9b8M9wHuQ8oUIxiTKFTRdimk&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["7 new citations to articles by Thanh Le-Cong", "7 new citations to articles by Xin ZHOU", "10 new citations to articles by Bach Le"]}
{"title": "Towards Effective Complementary Security Analysis using Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "J Wagner, S M\\xc3\\xbcller, C N\\xc3\\xa4ther, JP Stegh\\xc3\\xb6fer, A Both\\xc2\\xa0- arXiv preprint arXiv:2506.16899, 2025\nA key challenge in security analysis is the manual evaluation of potential security \nweaknesses generated by static application security testing (SAST) tools. Numerous \nfalse positives (FPs) in these reports reduce the effectiveness of security analysis. \nWe propose using Large Language Models (LLMs) to improve the assessment of \nSAST findings. We investigate the ability of LLMs to reduce FPs while trying to \nmaintain a perfect true positive rate, using datasets extracted from the OWASP\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaComparison of static application security testing tools and large\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16899&hl=en&sa=X&d=338234354495058247&ei=WnJeaJTyO7WP6rQP2a7yoQM&scisig=AAZF9b9k578WYv6qBXDIR2_tDFZD&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["7 new citations to articles by Thanh Le-Cong", "7 new citations to articles by Xin ZHOU", "10 new citations to articles by Bach Le"]}
{"title": "Predictive Analytics for Collaborators Answers, Code Quality, and Dropout on Stack Overflow", "first_label": ["Code"], "second_label": [], "data": "E Zolduoarrati, SA Licorish, N Stanger\\xc2\\xa0- arXiv preprint arXiv:2506.18329, 2025\nPrevious studies that used data from Stack Overflow to develop predictive models \noften employed limited benchmarks of 3-5 models or adopted arbitrary selection \nmethods. Despite being insightful, their limited scope suggests the need to \nbenchmark more models to avoid overlooking untested algorithms. Our study \nevaluates 21 algorithms across three tasks: predicting the number of question a user \nis likely to answer, their code quality violations, and their dropout status. We\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaMulti-Granularity Detector for Vulnerability Fixes\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18329&hl=en&sa=X&d=7611469386357600639&ei=WnJeaJTyO7WP6rQP2a7yoQM&scisig=AAZF9b_9aCKiiObZde4sDQdrkYCS&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=3&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["7 new citations to articles by Thanh Le-Cong", "7 new citations to articles by Xin ZHOU", "10 new citations to articles by Bach Le", "10 new citations to articles by Hong Jin Kang"]}
{"title": "Recipe for Discovery: A Framework for Systematic Open Source Project Identification", "first_label": [], "second_label": [], "data": "J Gomez, E Lovell, S Lieggi, AA Cardenas, J Davis\\xc2\\xa0- arXiv preprint arXiv:2506.18359, 2025\nOpen source software development, particularly within institutions such as \nuniversities and research laboratories, is often decentralized and difficult to track. \nDespite producing highly impactful tools in science, these efforts often go \nunrecognized due to a lack of visibility and institutional awareness. This paper \naddresses the challenge of discovering, classifying, and analyzing open source \nsoftware projects developed across distributed institutional systems. We present a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTopic Recommendation for GitHub Repositories: How Far Can\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18359&hl=en&sa=X&d=4909976324713439627&ei=WnJeaJTyO7WP6rQP2a7yoQM&scisig=AAZF9b8joIL6Dmqc7i3wYZG9nx7K&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=4&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["7 new citations to articles by Thanh Le-Cong", "10 new citations to articles by Hong Jin Kang"]}
{"title": "When LLM-Generated Code Perpetuates User Interface Accessibility Barriers, How Can We Break the Cycle?", "first_label": ["LLM", "Code"], "second_label": [], "data": "AE Guri\\xc5\\xa3\\xc4\\x83, RD Vatavu - 2025\nAbstract The integration of Large Language Models (LLMs) into web development \nworkflows has the potential to revolutionize user interface design, yet their ability to \nproduce accessible interfaces still remains underexplored. In this paper, we present \nan evaluation of LLM-generated user interfaces against the accessibility criteria from \nthe Web Content Accessibility Guidelines (WCAG 2.1), comparing the output of \nChatGPT and Claude with two distinct prompt types\\xe2\\x80\\x94accessibility-agnostic and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaThanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://mintviz.usv.ro/publications/2025.W4A.3.pdf&hl=en&sa=X&d=9523739575333778085&ei=WnJeaJTyO7WP6rQP2a7yoQM&scisig=AAZF9b-YyI5rn7Fn1YbweubpkeNr&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=5&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["7 new citations to articles by Thanh Le-Cong", "10 new citations to articles by Bach Le"]}
{"title": "Adoption of AI tools in software development in Germany: curse or blessing for the SME sector?", "first_label": [], "second_label": [], "data": "R Blischke - 2025\nThis study investigated the adoption of Artificial Intelligence (AI) tools in Germany's \nsoftware development sector, focusing on small and medium-sized enterprises \n(SMEs). AI technologies are reshaping the industry, presenting opportunities and \nchallenges. Using a mixed-methods approach, including 14 expert interviews and a \nsurvey of 262 participants, the research identified key factors affected by AI adoption, \nsuch as efficiency gains, code quality, competitive pressure, security risks\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://repositorio.ucp.pt/bitstreams/798bec1a-ce1c-4920-94d9-48a2af77fcec/download&hl=en&sa=X&d=10961350433696587265&ei=WnJeaJTyO7WP6rQP2a7yoQM&scisig=AAZF9b_E19Obai84E6t8bDDqvOtz&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=6&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["7 new citations to articles by Thanh Le-Cong", "10 new citations to articles by Bach Le"]}
{"title": "Dissecting the SWE-Bench Leaderboards: Profiling Submitters and Architectures of LLM-and Agent-Based Repair Systems", "first_label": ["LLM"], "second_label": ["Repair", "Agent"], "data": "M Martinez, X Franch\\xc2\\xa0- arXiv preprint arXiv:2506.17208, 2025\nThe rapid progress in Automated Program Repair (APR) has been driven by \nadvances in AI, particularly large language models (LLMs) and agent-based \nsystems. SWE-Bench is a recent benchmark designed to evaluate LLM-based repair\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17208&hl=en&sa=X&d=4083813933118197972&ei=W3JeaL2XBczM6rQP1Iv48As&scisig=AAZF9b-dGmeF_-oVFNRpd5V_sd7Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research", "Bach Le - new related research"]}
{"title": "Tracing Errors, Constructing Fixes: Repository-Level Memory Error Repair via Typestate-Guided Context Retrieval", "first_label": ["Repository-Level"], "second_label": ["Repair"], "data": "X Cheng, Z Guo, H Huo, Y Sui\\xc2\\xa0- arXiv preprint arXiv:2506.18394, 2025\nMemory-related errors in C programming continue to pose significant challenges in \nsoftware development, primarily due to the complexities of manual memory \nmanagement inherent in the language. These errors frequently serve as vectors for\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18394&hl=en&sa=X&d=9210024111509700653&ei=W3JeaL2XBczM6rQP1Iv48As&scisig=AAZF9b-KQhWIdRXq44jekrEdQoui&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "ConTested: Consistency-Aided Tested Code Generation with LLM", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation"], "data": "J Dong, J Sun, W Zhang, JS Dong, D Hao\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent advancements in large language models (LLMs) have significantly improved \ncode generation, which generates code snippets automatically based on natural \nlanguage requirements. Despite achieving state-of-the-art performance, LLMs often\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728902&hl=en&sa=X&d=551936643568606765&ei=W3JeaL2XBczM6rQP1Iv48As&scisig=AAZF9b_BffNT3Tq28AAfyZzriimH&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "SemAgent: A Semantics Aware Program Repair Agent", "first_label": ["APR"], "second_label": ["Repair", "Agent"], "data": "A Pabba, A Mathai, A Chakraborty, B Ray\\xc2\\xa0- arXiv preprint arXiv:2506.16650, 2025\nLarge Language Models (LLMs) have shown impressive capabilities in downstream \nsoftware engineering tasks such as Automated Program Repair (APR). In particular, \nthere has been a lot of research on repository-level issue-resolution benchmarks\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16650&hl=en&sa=X&d=9444763424952485232&ei=W3JeaL2XBczM6rQP1Iv48As&scisig=AAZF9b8bAFz9tFwM1PpRte-a75b9&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research", "Abhik Roychoudhury - new related research", "Bach Le - new related research"]}
{"title": "Porting Software Libraries to OpenHarmony: Transitioning from TypeScript or JavaScript to ArkTS", "first_label": [], "second_label": [], "data": "B Zhou, J Shi, Y Wang, L Li, TO Li, H Yu, Z Zhu\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nOpenHarmony emerges as a potent force in the mobile app domain, poised to stand \nalongside established industry giants. ArkTS is its main language, enhancing \nTypeScript (TS) and JavaScript (JS) with strict typing for improved performance\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728941&hl=en&sa=X&d=13970335596822641006&ei=W3JeaL2XBczM6rQP1Iv48As&scisig=AAZF9b_QwQ4c8-BvXsYG1C-dI7ZY&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Bach Le - new related research"]}
{"title": "OJBench: A Competition Level Code Benchmark For Large Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "Z Wang, Y Liu, Y Wang, W He, B Gao, M Diao, Y Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent advancements in large language models (LLMs) have demonstrated \nsignificant progress in math and code reasoning capabilities. However, existing code \nbenchmark are limited in their ability to evaluate the full spectrum of these\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16395&hl=en&sa=X&d=3951203216320964809&ei=W3JeaOKQCqalieoPmtymiQ8&scisig=AAZF9b_bPDAjVh7ixiPmecwBliEw&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Improving Compiler Bug Isolation by Leveraging Large Language Models", "first_label": ["LLM", "Bug"], "second_label": [], "data": "Y Qi, J Jiang, F Li, B Chen, H Zhang, J Chen\\xc2\\xa0- arXiv preprint arXiv:2506.17647, 2025\nCompilers play a foundational role in building reliable software systems, and bugs \nwithin them can lead to catastrophic consequences. The compilation process \ntypically involves hundreds of files, making traditional automated bug isolation\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17647&hl=en&sa=X&d=15966502884654963985&ei=W3JeaOKQCqalieoPmtymiQ8&scisig=AAZF9b8HVK2FSOPtCH0zqcVktTCo&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Enhanced Prompting Framework for Code Summarization with Large Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "M Fang, X Yuan, Y Li, H Li, C Fang, J Du\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode summarization is essential for enhancing the efficiency of software \ndevelopment, enabling developers to swiftly comprehend and maintain software \nprojects. Recent efforts utilizing large language models for generating precise code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728949&hl=en&sa=X&d=14117780386321288734&ei=W3JeaOKQCqalieoPmtymiQ8&scisig=AAZF9b9gNpNnL3RU7XfwGlRRs4g_&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "A Conceptual Framework for AI Capability Evaluations", "first_label": [], "second_label": [], "data": "MV Carro, DA Mester, FG Selasco, LNF Gangi\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI systems advance and integrate into society, well-designed and transparent \nevaluations are becoming essential tools in AI governance, informing decisions by \nproviding evidence about system capabilities and risks. Yet there remains a lack of \nclarity on how to perform these assessments both comprehensively and reliably. To \naddress this gap, we propose a conceptual framework for analyzing AI capability \nevaluations, offering a structured, descriptive approach that systematizes the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLessLeak-Bench: A First Investigation of Data Leakage in LLMs\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18213&hl=en&sa=X&d=2185668946400310733&ei=W3JeaILHFMmQ6rQP85HVmAQ&scisig=AAZF9b8QpvCUs6-Ifqpwk6IvT11k&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["7 new citations to articles by Xin ZHOU"]}
{"title": "Is Your Automated Software Engineer Trustworthy?", "first_label": [], "second_label": [], "data": "NS Mathews, M Nagappan\\xc2\\xa0- arXiv preprint arXiv:2506.17812, 2025\nLarge Language Models (LLMs) are being increasingly used in software engineering \ntasks, with an increased focus on bug report resolution over the past year. However, \nmost proposed systems fail to properly handle uncertain or incorrect inputs and \noutputs. Existing LLM-based tools and coding agents respond to every issue and \ngenerate a patch for every case, even when the input is vague or their own output is \nincorrect. There are no mechanisms in place to abstain when confidence is low. This\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLessLeak-Bench: A First Investigation of Data Leakage in LLMs\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17812&hl=en&sa=X&d=6533195646356826131&ei=W3JeaILHFMmQ6rQP85HVmAQ&scisig=AAZF9b-ix22z26q2tseOa75uG-wk&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["7 new citations to articles by Xin ZHOU"]}
{"title": "Advanced time series modelling to address seasonal variability and extreme rainfall in Ghana", "first_label": [], "second_label": [], "data": "S Bosson-Amedenu, EM Baah, F Ayiah-Mensah\\xe2\\x80\\xa6\\xc2\\xa0- BMC Environmental\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRainfall forecasting is essential for environmental planning, disaster preparedness, \nand resource management. Accurate predictions enable better water resource \nmanagement, agricultural planning, and climate risk mitigation. However, forecasting \nextreme rainfall events remains a challenge due to their inherent unpredictability, \nnonlinearity, and sensitivity to seasonal and climatic variations. This study evaluates \nthe performance of various forecasting models\\xe2\\x80\\x94Facebook Prophet, Seasonal\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaPrioritizing speech test cases\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1186/s44329-025-00024-8&hl=en&sa=X&d=7308643962239435316&ei=W3JeaILHFMmQ6rQP85HVmAQ&scisig=AAZF9b_3U8FHvs12WGOrEHkWFk_n&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=6&folt=cit", "author": ["Xin ZHOU"], "ref": ["7 new citations to articles by Xin ZHOU"]}
{"title": "How Do Community Smells Influence Self-Admitted Technical Debt in Machine Learning Projects?", "first_label": [], "second_label": [], "data": "ST Cynthia, N Almarimi, B Roy\\xc2\\xa0- arXiv preprint arXiv:2506.15884, 2025\nCommunity smells reflect poor organizational practices that often lead to socio-\ntechnical issues and the accumulation of Self-Admitted Technical Debt (SATD). \nWhile prior studies have explored these problems in general software systems, their\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15884&hl=en&sa=X&d=4930810523598524491&ei=W3JeaM3kD66l6rQPjMWH6A8&scisig=AAZF9b9p78UQts06tLkLz3GRfYP7&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=4&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Recurring Vulnerability Detection: How Far Are We?", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "Y Cao, S Wu, R Wang, B Chen, Y Huang, C Lu, Z Zhou\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the rapid development of open-source software, code reuse has become a \ncommon practice to accelerate development. However, it leads to inheritance from \nthe original vulnerability, which recurs at the reusing projects, known as recurring\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728901&hl=en&sa=X&d=18169342812720045655&ei=W3JeaM3kD66l6rQPjMWH6A8&scisig=AAZF9b-tZjWk7-linGwbNJwyD3xN&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=7&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "SAVANT: Vulnerability Detection in Application Dependencies through Semantic-Guided Reachability Analysis", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "W Lingxiang, Q Fu, W Song, G Deng, Y Liu, D Williams\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe integration of open-source third-party library dependencies in Java development \nintroduces significant security risks when these libraries contain known \nvulnerabilities. Existing Software Composition Analysis (SCA) tools struggle to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17798&hl=en&sa=X&d=7380677225520193147&ei=W3JeaM3kD66l6rQPjMWH6A8&scisig=AAZF9b-ohwtk5qyThFSTpAAaGMIR&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=8&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "10 new citations to articles by Hong Jin Kang"]}
{"title": "Towards the Identification of Vulnerability-Fixing Code Lines in OSS Security Patches Using Lexical Code Segmentation and LLMs", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": [], "data": "RN Arakawa, Y Kanemoto, M Akiyama\\xc2\\xa0- IFIP Annual Conference on Data and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nReusing open-source software (OSS) code has become standard in software \ndevelopment. When vulnerabilities are discovered in reused code, maintainers \ntypically apply security patches. However, these patches often include non\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-96590-6_5&hl=en&sa=X&d=17465519127697819777&ei=W3JeaM3kD66l6rQPjMWH6A8&scisig=AAZF9b9GA1CSQxk-KAdJ_aEJwDYH&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=9&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Visualization Task Taxonomy to Understand the Fuzzing Internals", "first_label": ["Fuzzing"], "second_label": [], "data": "S Kummita, M Miao, E Bodden, S Wei\\xc2\\xa0- ACM Transactions on Software Engineering\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGreybox fuzzing is used extensively in research and practice. There are umpteen \npublications that improve greybox fuzzing. However, to what extent do these \nimprovements affect the internal components or internals of a given fuzzer is not yet\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3718346&hl=en&sa=X&d=6310038100822609560&ei=W3JeaNe2EbWP6rQP2a7yoQM&scisig=AAZF9b_Ue_jmzHRI425oDGHolQub&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Unlocking Low Frequency Syscalls in Kernel Fuzzing with Dependency-Based RAG", "first_label": ["Fuzzing"], "second_label": [], "data": "Z Zhang, L Li, R Liang, K Chen\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nMost coverage-guided kernel fuzzers test operating system kernels based on syscall \nsequence synthesis. However, there are still syscalls rarely or not covered (called \nlow frequency syscalls, LFS) in a period of fuzzing, meaning the relevant code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728913&hl=en&sa=X&d=16673182064331655227&ei=W3JeaNe2EbWP6rQP2a7yoQM&scisig=AAZF9b8RLECTw3pbQ9TEm3o8p8To&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "RIMFuzz: real-time impact-aware mutation for library API fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "X Wang, L Zhao\\xc2\\xa0- Journal of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs libraries merely expose APIs to developers rather than directly handling user \ninput, applying fuzzing to libraries requires fuzz drivers to help process fuzzer-\nprovided input and invoke APIs. To reduce manual effort and avoid reliance on\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00050-1&hl=en&sa=X&d=11566396351270247841&ei=W3JeaNe2EbWP6rQP2a7yoQM&scisig=AAZF9b9NzGapAGT-Gt26V3wejXNn&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Synthesizing Software Engineering Data in a Test-Driven Manner", "first_label": ["Software Testing"], "second_label": [], "data": "L Zhang, J Yang, M Yang, J Yang, M Chen, J Zhang\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nWe introduce** SWE-Flow**, a novel data synthesis framework grounded in Test-\nDriven Development (TDD). Unlike existing software engineering data that rely on \nhuman-submitted issues,** SWE-Flow** automatically infers incremental\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DP9DQ2IExgS&hl=en&sa=X&d=8547569170249215358&ei=W3JeaNe2EbWP6rQP2a7yoQM&scisig=AAZF9b8gNj1zFs_dhY5DtQxXJmJ1&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Trailblazer: Practical End-to-end Web API Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "L Pan, S Cohney, T Murray, VT Pham\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThere are two key challenges in automatically testing web APIs:(a) determine where \nto send API requests and (b) identify how to make a valid payload for a given \nrequest. Both challenges are sometimes addressed by the presence of a machine\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3731717&hl=en&sa=X&d=13250706246401116236&ei=W3JeaNe2EbWP6rQP2a7yoQM&scisig=AAZF9b-ohQDK3DHvGNmHJasK8R14&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "MQueez: Specification-Driven Fuzzing for MQTT Broker (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "X Liu, Q Wang, P Liu, W Wang, S Ji\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecently, the MQTT protocol, favored for its lightweight nature, has emerged as a \npreferred choice for IoT communications. However, MQTT brokers\\xe2\\x80\\x94the critical \ncomponents responsible for message routing\\xe2\\x80\\x94are vulnerable to memory corruption\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3713081.3731724&hl=en&sa=X&d=13307417480603544934&ei=W3JeaNe2EbWP6rQP2a7yoQM&scisig=AAZF9b_xE4_BGfVFrv02wDNdOemT&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=7&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "On the Applicability of Benford's Law to Detect Saturation in Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "J Lee, H Lee, S Park, SK Cha\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nKnowing when a fuzzing campaign has reached saturation is crucial for practitioners \nto avoid unnecessarily lengthy campaigns without missing bugs within given \nresources. Unfortunately, existing solutions for determining the saturation point rely\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3731723&hl=en&sa=X&d=16464785359231774820&ei=W3JeaNe2EbWP6rQP2a7yoQM&scisig=AAZF9b-hP7JkI_Vp2sP6UiYyub7W&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=8&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FreeWavm: Enhanced WebAssembly Runtime Fuzzing Guided by Parse Tree Mutation and Snapshot", "first_label": ["Fuzzing"], "second_label": [], "data": "P Qian, X Ying, J Wang, L Liu, L Zhang, J Chen, Q He\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWebAssembly, recognized as a low-level and portable language, has been widely \nembraced in areas as diverse as browsers and blockchains, emerging as a \nrevolutionary force for Internet evolution. Unfortunately, defects and flaws in\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728877&hl=en&sa=X&d=18038798613601042415&ei=W3JeaNe2EbWP6rQP2a7yoQM&scisig=AAZF9b_-nW9eZphbttu6zMA0Febg&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=9&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories", "first_label": [], "second_label": ["Agent"], "data": "I Bouzenia, M Pradel\\xc2\\xa0- arXiv preprint arXiv:2506.18824, 2025\nLarge Language Model (LLM)-based agents are increasingly employed to automate \ncomplex software engineering tasks such as program repair and issue resolution. \nThese agents operate by autonomously generating natural language thoughts\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18824&hl=en&sa=X&d=1052979868376128117&ei=W3JeaMTnAaKr6rQPu_PX8Ak&scisig=AAZF9b9RCRJ61JSO7LJ69UBWUCsj&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=7&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Use Property-Based Testing to Bridge LLM Code Generation and Validation", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation"], "data": "L He, Z Chen, Z Zhang, J Shao, X Gao, L Sheng\\xc2\\xa0- arXiv preprint arXiv:2506.18315, 2025\nLarge Language Models (LLMs) excel at code generation, but ensuring their outputs \nto be functionally correct, especially in complex programming tasks, is a persistent \nchallenge. While traditional Test-Driven Development (TDD) offers a path for code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18315&hl=en&sa=X&d=3101719763251668573&ei=W3JeaMTnAaKr6rQPu_PX8Ak&scisig=AAZF9b8VwRdS0BYT5dVQlhiDylYe&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=8&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "SWE-GPT: A Process-Centric Language Model for Automated Software Improvement", "first_label": ["LLM"], "second_label": [], "data": "Y Ma, R Cao, Y Cao, Y Zhang, J Chen, Y Liu, Y Liu\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have demonstrated remarkable performance in code \ngeneration, significantly enhancing the coding efficiency of developers. Recent \nadvancements in LLM-based agents have led to significant progress in end-to-end\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728981&hl=en&sa=X&d=16298319323825873072&ei=W3JeaMTnAaKr6rQPu_PX8Ak&scisig=AAZF9b8fbB6Sgf8veT0Tj0g5M6NA&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=9&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "VFArch\\\\= e: A Dual-Mode Framework for Locating Vulnerable Functions in Open-Source Software", "first_label": [], "second_label": [], "data": "L Zhang, J Zhang, K Li, C Wang, C Liu, J Wu, S Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware Composition Analysis (SCA) has become pivotal in addressing \nvulnerabilities inherent in software project dependencies. In particular, reachability \nanalysis is increasingly used in Open-Source Software (OSS) projects to identify \nreachable vulnerabilities (eg, CVEs) through call graphs, enabling a focus on \nexploitable risks. Performing reachability analysis typically requires the vulnerable \nfunction (VF) to track the call chains from downstream applications. However, such\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTest mimicry to assess the exploitability of library vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18050&hl=en&sa=X&d=12706225658298449789&ei=W3JeaIHBCM2l6rQP5MuimAI&scisig=AAZF9b-bn3YUCl4hnVomcS4ab3ua&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=4&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le", "10 new citations to articles by Hong Jin Kang"]}
{"title": "Probing the Robustness of Large Language Models Safety to Latent Perturbations", "first_label": ["LLM"], "second_label": [], "data": "T Gu, K Huang, Z Wang, Y Wang, J Li, Y Yao, Y Yao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSafety alignment is a key requirement for building reliable Artificial General \nIntelligence. Despite significant advances in safety alignment, we observe that minor \nlatent shifts can still trigger unsafe responses in aligned models. We argue that this \nstems from the shallow nature of existing alignment methods, which focus on surface-\nlevel refusal behaviors without sufficiently altering internal representations. \nConsequently, small shifts in hidden activations can re-trigger harmful behaviors\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16078&hl=en&sa=X&d=3967826748183267165&ei=W3JeaJbVA9zM6rQPjezbgAU&scisig=AAZF9b9UxxjGDnYxH7xpW52Wlueu&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["3 new citations to articles by Richard Fang"]}
{"title": "Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "Z Ji, D Wu, W Jiang, P Ma, Z Li, S Wang\\xc2\\xa0- arXiv preprint arXiv:2506.17644, 2025\nCapture-the-Flag (CTF) competitions are crucial for cybersecurity education and \ntraining. As large language models (LLMs) evolve, there is increasing interest in their \nability to automate CTF challenge solving. For example, DARPA has organized the \nAIxCC competition since 2023 to advance AI-powered automated offense and \ndefense. However, this demands a combination of multiple abilities, from knowledge \nto reasoning and further to actions. In this paper, we highlight the importance of\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTeams of llm agents can exploit zero-day vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17644&hl=en&sa=X&d=18039007939580853816&ei=W3JeaJbVA9zM6rQPjezbgAU&scisig=AAZF9b-ki8gDF4phocydM5b5FXR5&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["3 new citations to articles by Richard Fang"]}
{"title": "Fine-Tuning Lowers Safety and Disrupts Evaluation Consistency", "first_label": [], "second_label": [], "data": "KC Fraser, H Dawkins, I Nejadgholi, S Kiritchenko\\xc2\\xa0- arXiv preprint arXiv:2506.17209, 2025\nFine-tuning a general-purpose large language model (LLM) for a specific domain or \ntask has become a routine procedure for ordinary users. However, fine-tuning is \nknown to remove the safety alignment features of the model, even when the fine-\ntuning data does not contain any harmful content. We consider this to be a critical \nfailure mode of LLMs due to the widespread uptake of fine-tuning, combined with the \nbenign nature of the\" attack\". Most well-intentioned developers are likely unaware\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17209&hl=en&sa=X&d=3946927903142380014&ei=W3JeaJbVA9zM6rQPjezbgAU&scisig=AAZF9b_ZX2kkcXZnkIfmDHeOm3L6&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=2&folt=cit", "author": ["Richard Fang"], "ref": ["3 new citations to articles by Richard Fang"]}
{"title": "Teaching an Old LLM Secure Coding: Localized Preference Optimization on Distilled Preferences", "first_label": ["LLM"], "second_label": ["Localization"], "data": "M Saqib, S Chakraborty, S Karmaker\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM generated code often contains security issues. We address two key challenges \nin improving secure code generation. First, obtaining high quality training data \ncovering a broad set of security issues is critical. To address this, we introduce a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00419&hl=en&sa=X&d=3471320712326210844&ei=W3JeaM64HNzM6rQPjezbgAU&scisig=AAZF9b-zP6iuspafIpJ9gFQhBsZE&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Fuzzy-Assisted Contrastive Decoding Improving Code Generation of Large Language Models", "first_label": ["LLM", "Fuzzing", "Code"], "second_label": ["Generation"], "data": "S Wang, L Ding, Y Zhan, Y Luo, S Liu, W Ding\\xc2\\xa0- IEEE Transactions on Fuzzy Systems, 2025\nLarge Language Models (LLMs) play a crucial role in intelligent code generation \ntasks. Most existing work focuses on pre-training or fine-tuning specialized code \nLLMs, eg, CodeLlama. However, pre-training or fine-tuning a code LLM requires a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11018203/&hl=en&sa=X&d=14224229548332545185&ei=W3JeaM64HNzM6rQPjezbgAU&scisig=AAZF9b84Z_y_EtuSzqsfEfycTvKd&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Using Large Language Models for Aerospace Code Generation: Methods, Benchmarks, and Potential Values", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "R He, L Zhang, M Lyu, L Lyu, C Xue\\xc2\\xa0- Aerospace, 2025\nIn recent years, Large Language Models (LLMs) have witnessed rapid \nadvancements, revolutionizing various domains. Within the realm of software \ndevelopment, code generation technology powered by LLMs has emerged as a\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2226-4310/12/6/498&hl=en&sa=X&d=10774117724622108555&ei=W3JeaM64HNzM6rQPjezbgAU&scisig=AAZF9b_rdKO7Y_152Nx4dsGU87hA&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=9&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Hybrid Neuro-Symbolic Pipeline for Coreference Resolution and AMR-Based Semantic Parsing", "first_label": [], "second_label": [], "data": "C Papakostas, C Troussas, A Krouska\\xe2\\x80\\xa6\\xc2\\xa0- Information, 2025\nLarge Language Models (LLMs) have transformed Natural Language Processing \n(NLP), yet they continue to struggle with deep semantic understanding, particularly in \ntasks like coreference resolution and structured semantic inference. This study \npresents a hybrid neuro-symbolic pipeline that combines transformer-based \ncontextual encoding with symbolic coreference resolution and Abstract Meaning \nRepresentation (AMR) parsing to improve natural language understanding. The\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSurveying neuro-symbolic approaches for reliable artificial\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2078-2489/16/7/529&hl=en&sa=X&d=17750247940711752393&ei=W3JeaPH1BtSWieoP25n1uQQ&scisig=AAZF9b9LVDVTufrzdRQLqrDSlViu&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["10 new citations to articles by Hong Jin Kang"]}
{"title": "Regression Testing Optimization for ROS-based Autonomous Systems: A Comprehensive Review of Techniques", "first_label": ["Software Testing"], "second_label": [], "data": "Y Jiang, S Sun, X Zheng\\xc2\\xa0- arXiv preprint arXiv:2506.16101, 2025\nRegression testing plays a critical role in maintaining software reliability, particularly \nfor ROS-based autonomous systems (ROSAS), which frequently undergo continuous \nintegration and iterative development. However, conventional regression testing \ntechniques face significant challenges when applied to autonomous systems due to \ntheir dynamic and non-deterministic behaviors, complex multi-modal sensor data, \nasynchronous distributed architectures, and stringent safety and real-time\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSurveying neuro-symbolic approaches for reliable artificial\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16101&hl=en&sa=X&d=6869479742326984994&ei=W3JeaPH1BtSWieoP25n1uQQ&scisig=AAZF9b8PFz47rtLzzR2zc2iWry3S&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["10 new citations to articles by Hong Jin Kang"]}
{"title": "NADA: Neural Acceptance-Driven Approximate Specification Mining", "first_label": [], "second_label": [], "data": "W Luo, T Han, J Qiu, H Wan, J Du, B Peng, G Xiao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIt is hard to mine high-quality finite-state automata (FSAs) only from desired software \nbehaviors, ie, positive examples, because of a search space explosion and an \novergeneralization problem induced by a lack of undesired software behaviors, ie, \nnegative examples. To tackle the overgeneralization problem, we suggest modeling \nthe problem as searching for approximate FSAs from positive and negative examples \nwith noise, where the noise originates from synthetic negative examples used to\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAdversarial specification mining\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728956&hl=en&sa=X&d=13513417715284606276&ei=W3JeaPH1BtSWieoP25n1uQQ&scisig=AAZF9b_A5v9t1j8zI8Zqkh3kzBo_&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=8&folt=cit", "author": ["Hong Jin Kang"], "ref": ["10 new citations to articles by Hong Jin Kang"]}
{"title": "Identifying Multi-parameter Constraint Errors in Python Data Science Library API Documentation", "first_label": [], "second_label": ["Detection"], "data": "X Xu, F Xie, C Zhu, G Bai, S Khurshid, Y Li\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern AI-and Data-intensive software systems rely heavily on data science and \nmachine learning libraries that provide essential algorithmic implementations and \ncomputational frameworks. These libraries expose complex APIs whose correct \nusage has to follow constraints among multiple interdependent parameters. \nDevelopers using these APIs are expected to learn about the constraints through the \nprovided documentation and any discrepancy may lead to unexpected behaviors\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaActive learning of discriminative subgraph patterns for api misuse\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728945&hl=en&sa=X&d=1953829909907632975&ei=W3JeaPH1BtSWieoP25n1uQQ&scisig=AAZF9b9JTpkxHy0iFC3UWZsJGOrN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=9&folt=cit", "author": ["Hong Jin Kang"], "ref": ["10 new citations to articles by Hong Jin Kang"]}
{"title": "Your Agent Can Defend Itself against Backdoor Attacks", "first_label": [], "second_label": ["Agent"], "data": "L Changjiang, L Jiacheng, C Bochuan, C Jinghui\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite their growing adoption across domains, large language model (LLM)-\npowered agents face significant security risks from backdoor attacks during training \nand fine-tuning. These compromised agents can subsequently be manipulated to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08336&hl=en&sa=X&d=9281612337423238890&ei=FdpcaKDUB8zM6rQPxJ--yQI&scisig=AAZF9b8EnIakTDvZQGsyv1duPVA5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "System Prompt Extraction Attacks and Defenses in Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "BC Das, MH Amini, Y Wu\\xc2\\xa0- arXiv preprint arXiv:2505.23817, 2025\nThe system prompt in Large Language Models (LLMs) plays a pivotal role in guiding \nmodel behavior and response generation. Often containing private configuration \ndetails, user roles, and operational instructions, the system prompt has become an\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23817&hl=en&sa=X&d=8359490024520200495&ei=FdpcaKDUB8zM6rQPxJ--yQI&scisig=AAZF9b9kewGVoQUmVLeek21BFko2&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Adversarial Preference Learning for Robust LLM Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Wang, P Wang, C Xi, B Tang, J Zhu, W Wei, C Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern language models often rely on Reinforcement Learning from Human \nFeedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to \nadversarial attacks due to three key limitations:(1) the inefficiency and high cost of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24369%3F&hl=en&sa=X&d=11526575995055803369&ei=FdpcaKDUB8zM6rQPxJ--yQI&scisig=AAZF9b_ilBi9AMSJoKPXxHc_hWg5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SecurityLingua: Efficient Defense of LLM Jailbreak Attacks via Security-Aware Prompt Compression", "first_label": ["LLM"], "second_label": [], "data": "Y Li, S Ahn, H Jiang, AH Abdi, Y Yang, L Qiu\\xc2\\xa0- arXiv preprint arXiv:2506.12707, 2025\nLarge language models (LLMs) have achieved widespread adoption across \nnumerous applications. However, many LLMs are vulnerable to malicious attacks \neven after safety alignment. These attacks typically bypass LLMs' safety guardrails by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12707&hl=en&sa=X&d=8418273368991399970&ei=FdpcaKDUB8zM6rQPxJ--yQI&scisig=AAZF9b8AOJ5PQ2S2DYr5nVOYpqTl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge", "first_label": ["LLM"], "second_label": [], "data": "S Li, C Xu, J Wang, X Gong, C Chen, J Zhang, J Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable intelligence across \nvarious tasks, which has inspired the development and widespread adoption of LLM-\nas-a-Judge systems for automated model testing, such as red teaming and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09443&hl=en&sa=X&d=2052322274134661445&ei=FdpcaKDUB8zM6rQPxJ--yQI&scisig=AAZF9b9u9cyhYi06xXXt37CLZpdh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Syntactic paraphrase-based synthetic data generation for backdoor attacks against Chinese language models", "first_label": ["LLM"], "second_label": ["Generation"], "data": "M Hu, Y Yang, D Pan, Z Guo, L Xiao, D Lin, S Zhao\\xc2\\xa0- Information Fusion, 2025\nAbstract Language Models (LMs) have shown significant advancements in various \nNatural Language Processing (NLP) tasks. However, recent studies indicate that \nLMs are particularly susceptible to malicious backdoor attacks, where attackers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S156625352500449X&hl=en&sa=X&d=11939540759867308872&ei=FdpcaKDUB8zM6rQPxJ--yQI&scisig=AAZF9b_omHEFDqgnSwVne_pfKwnY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Through the Stealth Lens: Rethinking Attacks and Defenses in RAG", "first_label": [], "second_label": [], "data": "S Choudhary, N Palumbo, A Hooda, KD Dvijotham\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRetrieval-augmented generation (RAG) systems are vulnerable to attacks that inject \npoisoned passages into the retrieved set, even at low corruption rates. We show that \nexisting attacks are not designed to be stealthy, allowing reliable detection and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04390&hl=en&sa=X&d=15468735482968103516&ei=FdpcaKDUB8zM6rQPxJ--yQI&scisig=AAZF9b8u2OUJdUy7skXRySPRbZz3&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AsFT: Anchoring Safety During LLM Fine-Tuning Within Narrow Safety Basin", "first_label": ["LLM"], "second_label": [], "data": "S Yang, Q Zhang, Y Liu, Y Huang, X Jia, K Ning, J Yao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are vulnerable to safety risks during fine-tuning, \nwhere small amounts of malicious or harmless data can compromise safeguards. In \nthis paper, building on the concept of alignment direction--defined by the weight\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08473%3F&hl=en&sa=X&d=15059004078714992755&ei=FdpcaKDUB8zM6rQPxJ--yQI&scisig=AAZF9b-cmQJQ2nP1jAOJlM9iLuaf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Arms Race in Deep Learning: A Survey of Backdoor Defenses and Adaptive Attacks", "first_label": [], "second_label": [], "data": "X Mo, N Sun, LY Zhang, W Luo, S Gao, Y Xiang\\xc2\\xa0- Pacific-Asia Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeep neural networks (DNNs) face a growing threat from backdoor attacks, which \nembed hidden malicious functionalities triggered by specific inputs. This survey \nexamines the escalating arms race between backdoor defenses and increasingly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-96-8183-9_24&hl=en&sa=X&d=4258756518287065675&ei=FdpcaKDUB8zM6rQPxJ--yQI&scisig=AAZF9b80XRQuOtBuq86IspbsVv3h&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Cost of Dynamic Reasoning: Demystifying AI Agents and Test-Time Scaling from an AI Infrastructure Perspective", "first_label": ["Software Testing"], "second_label": ["Agent", "Reasoning"], "data": "J Kim, B Shin, J Chung, M Rhu\\xc2\\xa0- arXiv preprint arXiv:2506.04301, 2025\nLarge-language-model (LLM)-based AI agents have recently showcased impressive \nversatility by employing dynamic reasoning, an adaptive, multi-step process that \ncoordinates with external tools. This shift from static, single-turn inference to agentic\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04301&hl=en&sa=X&d=3072272730677106970&ei=FdpcaKDUB8zM6rQPxJ--yQI&scisig=AAZF9b-t8XUoljKdp6JjL-hJnilf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Efficient and Robust Security-Patch Localization for Disclosed OSS Vulnerabilities with Fine-Tuned LLMs in an Industrial Setting", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Localization"], "data": "D Ran, L Li, L Zhu, Y Cao, L Zhao, X Tan, G Liang\\xe2\\x80\\xa6 - 2025\nSecurity-patch localization, which links disclosed vulnerabilities in open-source \nsoftware (OSS) to corresponding patches, has become a practical technique to \nmitigate the risk of OSS vulnerabilities in a timely manner. While existing approaches \nextensively focus on estimating the correlation between individual patches and \nCommon Vulnerabilities and Exposures (CVEs), they often fail to address two major \nindustrial requirements that make a tool of security-patch localization desirable in\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaVulcurator: a vulnerability-fixing commit detector\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dezhi-ran.com/publication/fse25-taper/fse25-taper.pdf&hl=en&sa=X&d=6373928856750801940&ei=FNpcaN_TPLvM6rQP4I3MmQ4&scisig=AAZF9b8zgVXhveOMkc9bDSIkHaN0&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["1 new citation to articles by Bach Le", "David Lo - new related research", "1 new citation to articles by Thanh Le-Cong", "1 new citation to articles by Hong Jin Kang"]}
{"title": "Evaluating Large Language Models for Code Review", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "U Cihan, A \\xc4\\xb0\\xc3\\xa7\\xc3\\xb6z, V Haratian, E T\\xc3\\xbcz\\xc3\\xbcn\\xc2\\xa0- arXiv preprint arXiv:2505.20206, 2025\nContext: Code reviews are crucial for software quality. Recent AI advances have \nallowed large language models (LLMs) to review and fix code; now, there are tools \nthat perform these reviews. However, their reliability and accuracy have not yet been\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20206&hl=en&sa=X&d=15665831858314714693&ei=FNpcaN3VObXCieoPx6Gs6Q4&scisig=AAZF9b_nX5EjD1ohxo-XwLW6C4w4&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "A First Look at Bugs in LLM Inference Engines", "first_label": ["LLM", "Bug"], "second_label": [], "data": "M Liu, S Zhong, W Bi, Y Zhang, Z Chen, Z Chen, X Liu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language model-specific inference engines (in short as\\\\emph {LLM inference \nengines}) have become a fundamental component of modern AI infrastructure, \nenabling the deployment of LLM-powered applications (LLM apps) across cloud and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09713&hl=en&sa=X&d=1829118811417287869&ei=FNpcaN3VObXCieoPx6Gs6Q4&scisig=AAZF9b9PFvonW4DF-GngDik42RDE&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "EffiCoder: Enhancing Code Generation in Large Language Models through Efficiency-Aware Fine-tuning", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "D Huang, G Zeng, J Dai, M Luo, H Weng, Y Qing, H Cui\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nAs large language models (LLMs) play an increasingly important role in code \ngeneration, enhancing both correctness and efficiency has become crucial. Current \nmethods primarily focus on correctness, often overlooking efficiency. To address this\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D8bgaOg1TlZ&hl=en&sa=X&d=14915156030897718878&ei=FdpcaJrDCcy8ieoPq9flOA&scisig=AAZF9b9r-VHALFoUjA9M0GRk-50r&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Can Large Language Models Understand Intermediate Representations in Compilers?", "first_label": ["LLM"], "second_label": [], "data": "H Jiang, J Zhu, Y Wan, B Fang, H Zhang, R Jin, Q Guan\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nIntermediate Representations (IRs) play a critical role in compiler design and \nprogram analysis, yet their comprehension by* Large Language Models*(LLMs) \nremains underexplored. In this paper, we present an explorative empirical study\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DzDieh7VWfN&hl=en&sa=X&d=13871753026296865586&ei=FdpcaJrDCcy8ieoPq9flOA&scisig=AAZF9b_eyCuQfdrPuOD8zGlx9lsG&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Automatic Qiskit Code Refactoring Using Large Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "JM Su\\xc3\\xa1rez, LM Bibb\\xc3\\xb3, J Bogado, A Fernandez\\xc2\\xa0- arXiv preprint arXiv:2506.14535, 2025\nAs quantum software frameworks evolve, developers face increasing challenges in \nmaintaining compatibility with rapidly changing APIs. In this work, we present a novel \nmethodology for refactoring Qiskit code using large language models (LLMs). We\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.14535&hl=en&sa=X&d=4707492068215582196&ei=FdpcaJrDCcy8ieoPq9flOA&scisig=AAZF9b8ijIjD2XcJlduBt3t6lA4m&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Training Language Models to Generate Quality Code with Program Analysis Feedback", "first_label": ["LLM", "Code"], "second_label": [], "data": "F Yao, Z Wang, L Liu, J Cui, L Zhong, X Fu, H Mai\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode generation with large language models (LLMs), often termed vibe coding, is \nincreasingly adopted in production but fails to ensure code quality, particularly in \nsecurity (eg, SQL injection vulnerabilities) and maintainability (eg, missing type\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22704&hl=en&sa=X&d=13720297852295427429&ei=FNpcaLK0OJPN6rQPht3jyA8&scisig=AAZF9b9qU1hJff-ona5ynwmi0w3O&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Li, J Ding, C Peng, B Zhao, X Gao, H Gao, X Gu\\xc2\\xa0- arXiv preprint arXiv:2506.05692, 2025\nThe code generation capabilities of large language models (LLMs) have emerged as \na critical dimension in evaluating their overall performance. However, prior research \nhas largely overlooked the security risks inherent in the generated code. In this work\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05692%3F&hl=en&sa=X&d=5492650506064335063&ei=FNpcaLK0OJPN6rQPht3jyA8&scisig=AAZF9b_uwkPsOhWMHWjfdGwYFezG&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "KRAKEN: Program-Adaptive Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A ZHOU, H HUANG, C ZHANG - 2025\nDespite numerous advances, most existing fuzzers still require more than 24 hours to \nthoroughly test the target programs to achieve satisfactory code coverage or bug \ndetection results [7, 32, 42, 64]. Recently, as cloud-based computing and multicore\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://seviezhou.github.io/files/kraken.pdf&hl=en&sa=X&d=6944396394299119143&ei=FdpcaJSYBYOuieoPsICzsQc&scisig=AAZF9b9QILhkfV1b1x87AW8NkoEo&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "CODE-DITING: A Reasoning-Based Metric for Functional Alignment in Code Evaluation", "first_label": ["Code"], "second_label": ["Reasoning"], "data": "G Yang, Y Zhou, X Chen, W Zheng, X Hu, X Zhou, D Lo\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nTrustworthy evaluation methods for code snippets play a crucial role in neural code \ngeneration. Traditional methods, which either rely on reference solutions or require \nexecutable test cases, have inherent limitation in flexibility and scalability. The recent\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19502%3F&hl=en&sa=X&d=16683183957421599983&ei=FdpcaLq3ArWP6rQP6eGTwQY&scisig=AAZF9b-QxYjEGmNASUU4YZLrynZ2&oi=scholaralrt&hist=ylyK0_8AAAAJ:9162293956065397449:AAZF9b-XLYhOpfmwS_vhRk8lFc-r&html=&pos=0&folt=art", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new articles"]}
{"title": "An LLM-as-Judge Metric for Bridging the Gap with Human Evaluation in SE Tasks", "first_label": ["LLM"], "second_label": [], "data": "X Zhou, K Kim, T Zhang, M Weyssow, LF Gomes\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) and other automated techniques have been \nincreasingly used to support software developers by generating software artifacts \nsuch as code snippets, patches, and comments. However, accurately assessing the\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20854%3F&hl=en&sa=X&d=14069950555695470496&ei=FdpcaLq3ArWP6rQP6eGTwQY&scisig=AAZF9b_ITtaPav10Hi5bAp132EBc&oi=scholaralrt&hist=ylyK0_8AAAAJ:9162293956065397449:AAZF9b-XLYhOpfmwS_vhRk8lFc-r&html=&pos=1&folt=art", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new articles"]}
{"title": "Roz\\xc5\\xa1\\xc3\\xad\\xc5\\x99en\\xc3\\xad manu\\xc3\\xa1ln\\xc3\\xadho fuzz testov\\xc3\\xa1n\\xc3\\xad o minimalizaci fuzz test\\xc5\\xaf pro EVM chytr\\xc3\\xa9 kontrakty", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "Y Naoki - 2025\nTestov\\xc3\\xa1n\\xc3\\xad bezpe\\xc4\\x8dnosti smart kontrakt\\xc5\\xaf \\xc4\\x8del\\xc3\\xad zna\\xc4\\x8dn\\xc3\\xbdm v\\xc3\\xbdzv\\xc3\\xa1m p\\xc5\\x99i lad\\xc4\\x9bn\\xc3\\xad a anal\\xc3\\xbdze \nprobl\\xc3\\xa9m\\xc5\\xaf odhalen\\xc3\\xbdch p\\xc5\\x99i ru\\xc4\\x8dn\\xc4\\x9b \\xc5\\x99\\xc3\\xadzen\\xc3\\xa9m fuzzingu. Tento p\\xc5\\x99\\xc3\\xadstup k testov\\xc3\\xa1n\\xc3\\xad sice \n\\xc3\\xba\\xc4\\x8dinn\\xc4\\x9b vyhled\\xc3\\xa1v\\xc3\\xa1 zranitelnosti, ale v\\xc3\\xbdsledn\\xc3\\xa9 testovac\\xc3\\xad p\\xc5\\x99\\xc3\\xadpady \\xc4\\x8dasto obsahuj\\xc3\\xad stovky \nnebo tis\\xc3\\xadce krok\\xc5\\xaf, tak\\xc5\\xbee lad\\xc4\\x9bn\\xc3\\xad a anal\\xc3\\xbdza p\\xc5\\x99\\xc3\\xad\\xc4\\x8din jsou \\xc4\\x8dasov\\xc4\\x9b n\\xc3\\xa1ro\\xc4\\x8dn\\xc3\\xa9 a slo\\xc5\\xbeit\\xc3\\xa9. V t\\xc3\\xa9to \npr\\xc3\\xa1ci p\\xc5\\x99edstavujeme Fuzz Shrink v ru\\xc4\\x8dn\\xc4\\x9b \\xc5\\x99\\xc3\\xadzen\\xc3\\xa9m fuzzingu, nov\\xc3\\xbd p\\xc5\\x99\\xc3\\xadstup k \nautomatick\\xc3\\xa9 minimalizaci testovac\\xc3\\xadch p\\xc5\\x99\\xc3\\xadpad\\xc5\\xaf p\\xc5\\x99i zachov\\xc3\\xa1n\\xc3\\xad jejich schopnosti vyvolat\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaModel-based whitebox fuzzing for program binaries\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dspace.cvut.cz/bitstream/handle/10467/124063/F8-BP-2025-Yoshida-Naoki-yoshinao-thesis.pdf%3Fsequence%3D-1&hl=en&sa=X&d=14273270919586062683&ei=FdpcaPb3A8mQ6rQP97eusAo&scisig=AAZF9b9xCavycDMxlg9QZRdrmL0u&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["1 new citation to articles by Abhik Roychoudhury"]}
