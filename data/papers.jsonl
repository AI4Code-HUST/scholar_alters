{"title": "Identifying software vulnerabilities via code representation learning", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "B Wu - 2025\nIn the era of big code, the proliferation of software applications has led to a \ncorresponding increase in unidentified vulnerabilities, necessitating early detection \nduring development to avoid potential disruptions and security risks post\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dr.ntu.edu.sg/bitstream/10356/182636/2/thesis_wbz.pdf&hl=en&sa=X&d=9518447506841292613&ei=a9DQZ4KeL5uoieoPksjy2Ag&scisig=AFWwaeZFN8VED7Vhr_v-27_UY-sX&oi=scholaralrt&hist=apJ4fD8AAAAJ:6234092987365270793:AFWwaeZHIN6aK_iU38VPuuMoYcVu&html=&pos=0&folt=rel", "ref": ["Michael Fu - new related research"]}
{"title": "GPT-Based Automated Induction: Vulnerability Detection in Medical Software", "first_label": ["Vulnerabilities", "Large Language Models"], "second_label": ["Detection"], "data": "L Deng, H Lei, F Khan, G Srivastava, J Chen, M Haque\\xc2\\xa0- IEEE Journal of Biomedical\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIntegrating Natural Language Processing (NLP) with Generative Pre-trained \nTransformer (GPT) models plays a pivotal role in enhancing the accuracy and \nefficiency of healthcare software, which is essential for patient safety and providing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10899829/&hl=en&sa=X&d=4257828238536637457&ei=a9DQZ4KeL5uoieoPksjy2Ag&scisig=AFWwaebLUMgz30_kE6q-kcisdZTu&oi=scholaralrt&hist=apJ4fD8AAAAJ:6234092987365270793:AFWwaeZHIN6aK_iU38VPuuMoYcVu&html=&pos=1&folt=rel", "ref": ["Michael Fu - new related research"]}
{"title": "Mechanistic Understanding of Language Models in Syntactic Code Completion", "first_label": ["Code"], "second_label": ["Generation"], "data": "S Miller, D Rai, Z Yao\\xc2\\xa0- arXiv preprint arXiv:2502.18499, 2025\nRecently, language models (LMs) have shown impressive proficiency in code \ngeneration tasks, especially when fine-tuned on code-specific datasets, commonly \nknown as Code LMs. However, our understanding of the internal decision-making\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.18499&hl=en&sa=X&d=16766167717063467915&ei=a9DQZ4KeL5uoieoPksjy2Ag&scisig=AFWwaeZXFo3QPd08t686n6v36dI4&oi=scholaralrt&hist=apJ4fD8AAAAJ:6234092987365270793:AFWwaeZHIN6aK_iU38VPuuMoYcVu&html=&pos=2&folt=rel", "ref": ["Michael Fu - new related research", "Richard Fang - new related research", "Bach Le - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Bugfix: a standard language, database schema and repository for research on bugs and automatic program repair", "first_label": ["Automated Program Repair", "Bug"], "second_label": ["Repair"], "data": "V Kananchuk, I Mustafin, B Meyer\\xc2\\xa0- arXiv preprint arXiv:2502.15599, 2025\nAutomatic Program Repair (APR) is a brilliant idea: when detecting a bug, also \nprovide suggestions for correcting the program. Progress towards that goal is \nhindered by the absence of a common frame of reference for the multiplicity of APR\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nMichael Fu\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.15599&hl=en&sa=X&d=10642094292575353027&ei=a9DQZ4KeL5uoieoPksjy2Ag&scisig=AFWwaebYZkmLIso9Pt-1zoBNSzF7&oi=scholaralrt&hist=apJ4fD8AAAAJ:6234092987365270793:AFWwaeZHIN6aK_iU38VPuuMoYcVu&html=&pos=3&folt=rel", "ref": ["Michael Fu - new related research", "Bach Le - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Manual Prompt Engineering is Not Dead: A Case Study on Large Language Models for Code Vulnerability Detection with DSPy", "first_label": ["Vulnerabilities", "Large Language Models", "Code"], "second_label": ["Detection"], "data": "F Trad, A Chehab\\xc2\\xa0- 2025 8th International Conference on Data Science\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomated prompt engineering tools have recently emerged as a promising solution \nto simplify the traditional man-ual task of crafting prompts for large language models \n(LLMs). This study investigates whether such tools can fully replace manual prompt\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nTriet H. M. Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10908746/&hl=en&sa=X&d=5315185820890395558&ei=a9DQZ9ikNuehieoPw9e4wQE&scisig=AFWwaeb1X7i5BNQkTn_MCK7RZ9Ck&oi=scholaralrt&hist=apJ4fD8AAAAJ:15725322226479601129:AFWwaeYp-8wbw5OHTjoCHLP43E0V&html=&pos=0&folt=rel", "ref": ["Triet H. M. Le - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Unveiling Privacy Risks in LLM Agent Memory", "first_label": ["Large Language Models"], "second_label": ["Agent"], "data": "B Wang, W He, P He, S Zeng, Z Xiang, Y Xing, J Tang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Model (LLM) agents have become increasingly prevalent across \nvarious real-world applications. They enhance decision-making by storing private \nuser-agent interactions in the memory module for demonstrations, introducing new\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.13172&hl=en&sa=X&d=1205784360742732283&ei=a9DQZ-KmLNSyieoPy4i_oQo&scisig=AFWwaebxlZzBMwyVDWpxNWr57ygF&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=0&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "ELBA-Bench: An Efficient Learning Backdoor Attacks Benchmark for Large Language Models", "first_label": ["Large Language Models"], "second_label": [], "data": "X Liu, S Liang, M Han, Y Luo, A Liu, X Cai, Z He, D Tao\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGenerative large language models are crucial in natural language processing, but \nthey are vulnerable to backdoor attacks, where subtle triggers compromise their \nbehavior. Although backdoor attacks against LLMs are constantly emerging, existing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.18511&hl=en&sa=X&d=2326898847250844616&ei=a9DQZ-KmLNSyieoPy4i_oQo&scisig=AFWwaeYsxLaPZ35g7ZwCcXLowDSz&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=1&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Language Models Can See Better: Visual Contrastive Decoding For LLM Multimodal Reasoning", "first_label": ["Large Language Models"], "second_label": [], "data": "Y Pang, B Yang, H Tu, Y Cao, Z Zhang\\xc2\\xa0- \\xe2\\x80\\xa6\\xc2\\xa02025-2025 IEEE International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAlthough Large Language Models (LLMs) excel in reasoning and generation for \nlanguage tasks, they are not specifically designed for multimodal challenges. \nTraining Multimodal Large Language Models (MLLMs), however, is resource\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.11751&hl=en&sa=X&d=11065919914523651369&ei=a9DQZ-KmLNSyieoPy4i_oQo&scisig=AFWwaeafJ9hHibn9FVw6fdjz4t5T&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=2&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "LLM Compiler: Foundation Language Models for Compiler Optimization", "first_label": ["Large Language Models"], "second_label": [], "data": "C Cummins, V Seeker, D Grubisic, B Roziere\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 34th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable capabilities across \na variety of software engineering and coding tasks. However, their application in the \ndomain of code and compiler optimization remains underexplored. Training LLMs is\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3708493.3712691&hl=en&sa=X&d=15248179687375146706&ei=a9DQZ-KmLNSyieoPy4i_oQo&scisig=AFWwaeaQLmVGmhuYPirTSRdIm2C5&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=3&folt=rel", "ref": ["Richard Fang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "PersGuard: Preventing Malicious Personalization via Backdoor Attacks on Pre-trained Text-to-Image Diffusion Models", "first_label": [], "second_label": [], "data": "X Liu, X Jia, Y Xun, H Zhang, X Cao\\xc2\\xa0- arXiv preprint arXiv:2502.16167, 2025\nDiffusion models (DMs) have revolutionized data generation, particularly in text-to-\nimage (T2I) synthesis. However, the widespread use of personalized generative \nmodels raises significant concerns regarding privacy violations and copyright\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/abs/2502.16167&hl=en&sa=X&d=4329161943110226749&ei=a9DQZ-KmLNSyieoPy4i_oQo&scisig=AFWwaeafrJsvZfvDQ-TQGz6g7XVq&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=4&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Can LLMs Replace Human Evaluators? An Empirical Study of LLM-as-a-Judge in Software Engineering", "first_label": ["Large Language Models"], "second_label": [], "data": "R Wang, J Guo, C Gao, G Fan, CY Chong, X Xia\\xc2\\xa0- arXiv preprint arXiv:2502.06193, 2025\nRecently, large language models (LLMs) have been deployed to tackle various \nsoftware engineering (SE) tasks like code generation, significantly advancing the \nautomation of SE tasks. However, assessing the quality of these LLM-generated\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.06193&hl=en&sa=X&d=12339777162049768059&ei=a9DQZ-KmLNSyieoPy4i_oQo&scisig=AFWwaeYtNjr1mTkn28XzAtlnlVPu&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=6&folt=rel", "ref": ["Richard Fang - new related research", "Thanh Le-Cong - new related research", "Carlos E. Jimenez - new related research"]}
{"title": "Feature-Aware Malicious Output Detection and Mitigation", "first_label": [], "second_label": ["Detection"], "data": "W Dong, Y Tian, X Zeng, F Li, S Wang\\xc2\\xa0- AAAI 2025 Workshop on Preventing and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of large language models (LLMs) has brought significant \nbenefits to various domains while introducing substantial risks. Despite being fine-\ntuned through reinforcement learning, LLMs lack the capability to discern malicious\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DZ3tMPmEFD0&hl=en&sa=X&d=5955865318131764122&ei=a9DQZ-KmLNSyieoPy4i_oQo&scisig=AFWwaeaYhdFVqYvgVXzGKuam-hxh&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=7&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "LLM as a Broken Telephone: Iterative Generation Distorts Information", "first_label": ["Large Language Models"], "second_label": ["Generation"], "data": "A Mohamed, M Geng, M Vazirgiannis, G Shang\\xc2\\xa0- arXiv preprint arXiv:2502.20258, 2025\nAs large language models are increasingly responsible for online content, concerns \narise about the impact of repeatedly processing their own outputs. Inspired by the\" \nbroken telephone\" effect in chained human communication, this study investigates\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.20258&hl=en&sa=X&d=14349451129841775652&ei=a9DQZ-KmLNSyieoPy4i_oQo&scisig=AFWwaebOSUIQKcujWaLpJkKkqbje&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=8&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Class-Conditional Neural Polarizer: A Lightweight and Effective Backdoor Defense by Purifying Poisoned Features", "first_label": [], "second_label": [], "data": "M Zhu, S Wei, H Zha, B Wu\\xc2\\xa0- arXiv preprint arXiv:2502.18520, 2025\nRecent studies have highlighted the vulnerability of deep neural networks to \nbackdoor attacks, where models are manipulated to rely on embedded triggers \nwithin poisoned samples, despite the presence of both benign and trigger\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.18520&hl=en&sa=X&d=6105536655339044814&ei=a9DQZ-KmLNSyieoPy4i_oQo&scisig=AFWwaeYurmmbkgOuiDkmd6ofPMWA&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=9&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Effectively Detecting Software Vulnerabilities via Leveraging Features on Program Slices", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "X Zhang, H Guo, Z Zhang, G Tang, J Sun, Y Shen, J Ma\\xc2\\xa0- IEEE Internet of Things\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDetecting software vulnerabilities has become increasingly challenging with the \ngrowing size and complexity of modern software. Traditional static and dynamic \nanalysis methods often suffer from poor accuracy and reliance on expert knowledge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10884696/&hl=en&sa=X&d=12677073240774667567&ei=a9DQZ8POMMmpieoP4aW8iQ8&scisig=AFWwaea6FcI0bPWKCTkqRqPcGxwD&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=0&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "LLM-enhanced evolutionary test generation for untyped languages", "first_label": ["Large Language Models"], "second_label": ["Generation"], "data": "R Yang, X Xu, R Wang\\xc2\\xa0- Automated Software Engineering, 2025\nDynamic programming languages, such as Python, are widely used for their flexibility \nand support for rapid development. However, the absence of explicit parameter type \ndeclarations poses significant challenges in generating automated test cases. This\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00496-7&hl=en&sa=X&d=5209764566405071124&ei=a9DQZ8POMMmpieoP4aW8iQ8&scisig=AFWwaeZZcNNRu-1nh6WZ8bsL9w5L&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=2&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "An Empirical Study on the Relationship Between Defects and Source Code's Unnaturalness", "first_label": ["Code"], "second_label": [], "data": "Y Jiang, H Liu, J Liu, Y Zhang, W Ji, H Zhong, L Zhang\\xc2\\xa0- ACM Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nNatural languages are \\xe2\\x80\\x9cnatural\\xe2\\x80\\x9d in that texts in natural languages are repetitive and \npredictable. Recent research indicates that programming languages share similar \ncharacteristics (naturalness), with source code displaying patterns of repetition and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3718083&hl=en&sa=X&d=7306116860520413653&ei=a9DQZ8POMMmpieoP4aW8iQ8&scisig=AFWwaeYhQXymsslwMKE9PXdq4Ud6&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=3&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "FeedbackFuzz: Fuzzing Processors via Intricate Program Generation with Feedback Engine", "first_label": ["Fuzzing"], "second_label": ["Generation"], "data": "J Wang, B Cui, R Dong, R Zhai\\xc2\\xa0- ICASSP 2025-2025 IEEE International Conference\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs modern processor designs become increasingly complex, detecting hardware \nvulnerabilities has become more challenge. Recently, hardware fuzzing techniques \nhave shown promising results in generating complex programs for processor testing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10889404/&hl=en&sa=X&d=6605066460642033415&ei=a9DQZ8POMMmpieoP4aW8iQ8&scisig=AFWwaeYRRalM1Zf3FdGWcW9FhtBw&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=4&folt=rel", "ref": ["Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "From Large to Mammoth: A Comparative Evaluation of Large Language Models in Vulnerability Detection", "first_label": ["Vulnerabilities", "Large Language Models"], "second_label": ["Detection"], "data": "J Lin, D Mohaisen\nLarge Language Models (LLMs) have demonstrated strong potential in tasks such as \ncode understanding and generation. This study evaluates several advanced LLMs\\xe2\\x80\\x94\nsuch as LLaMA-2, CodeLLaMA, LLaMA-3, Mistral, Mixtral, Gemma, CodeGemma\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.ndss-symposium.org/wp-content/uploads/2025-1491-paper.pdf&hl=en&sa=X&d=4792361613594223308&ei=a9DQZ8POMMmpieoP4aW8iQ8&scisig=AFWwaeY2mHkuZqyAPpG8grIXpgws&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=5&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Design pattern recognition: a study of large language models", "first_label": ["Large Language Models"], "second_label": [], "data": "SK Pandey, S Chand, J Horkoff, M Staron, M Ochodek\\xe2\\x80\\xa6\\xc2\\xa0- Empirical Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAbstract Context As Software Engineering (SE) practices evolve due to extensive \nincreases in software size and complexity, the importance of tools to analyze and \nunderstand source code grows significantly. Objective This study aims to evaluate\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10625-1&hl=en&sa=X&d=8546412004218051293&ei=a9DQZ8POMMmpieoP4aW8iQ8&scisig=AFWwaealng_j1iX3a2iIiURF0bTp&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=6&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Large Language Models for In-File Vulnerability Localization Can Be\" Lost in the End\"", "first_label": ["Vulnerabilities", "Large Language Models"], "second_label": [], "data": "F Sovrano, A Bauer, A Bacchelli\\xc2\\xa0- arXiv preprint arXiv:2502.06898, 2025\nRecent advancements in artificial intelligence have enabled processing of larger \ninputs, leading everyday software developers to increasingly rely on chat-based \nlarge language models (LLMs) like GPT-3.5 and GPT-4 to detect vulnerabilities\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.06898&hl=en&sa=X&d=9797378383585173377&ei=a9DQZ8POMMmpieoP4aW8iQ8&scisig=AFWwaeYx0_9akMUZJd6BhXjqqVLp&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=7&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Exploring Depths of WebAudio: Advancing Greybox Fuzzing for Vulnerability Detection in Safari", "first_label": ["Vulnerabilities", "Fuzzing"], "second_label": ["Detection"], "data": "J Wang, J Wang, J Xie, Z Li, Y Chen, P Qian\nWebAudio is a widely used audio processing API in popular browsers, which \nprovides rich audio support for the exclusive browser Safari on macOS. Given its \nwidespread use, it is critical to thoroughly test WebAudio to ensure its reliability\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://users.cs.northwestern.edu/~ychen/Papers/WebAudio_APSEC.pdf&hl=en&sa=X&d=14421413917870641412&ei=a9DQZ8POMMmpieoP4aW8iQ8&scisig=AFWwaeaAZBPJhY_hEZJJoC6kkjo6&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=8&folt=rel", "ref": ["Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research", "2 new citations to articles by Abhik Roychoudhury"]}
{"title": "Ratte: Fuzzing for Miscompilations in Multi-Level Compilers Using Composable Semantics", "first_label": ["Fuzzing"], "second_label": [], "data": "P Yu, N Wu, AF Donaldson - 2025\nMulti-level intermediate representation (MLIR) is a rapidly growing compiler \nframework, with its defining feature being an ecosystem of modular language \nfragments called dialects. Specifying dialect semantics and validating dialect\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.doc.ic.ac.uk/~afd/papers/2025/ASPLOS-Ratte.pdf&hl=en&sa=X&d=2019974718744086328&ei=a9DQZ8POMMmpieoP4aW8iQ8&scisig=AFWwaeaxX8iJzmc1p4D9ISFbKJuw&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=9&folt=rel", "ref": ["Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Knowledge-Enhanced Program Repair for Data Science Code", "first_label": ["Automated Program Repair", "Code"], "second_label": ["Repair"], "data": "S Ouyang, JM Zhang, Z Sun, AM Penuela\\xc2\\xa0- arXiv preprint arXiv:2502.09771, 2025\nThis paper introduces DSrepair, a knowledge-enhanced program repair method \ndesigned to repair the buggy code generated by LLMs in the data science domain. \nDSrepair uses knowledge graph based RAG for API knowledge retrieval as well as\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.09771&hl=en&sa=X&d=3654048262265967&ei=a9DQZ66pMoC96rQP2s_YiAM&scisig=AFWwaea3b7K5alddz2-3Pw0svJ0R&oi=scholaralrt&hist=apJ4fD8AAAAJ:11137134570824175991:AFWwaeZJgvZkFmSwNlRigHvrI7d8&html=&pos=0&folt=rel", "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "ICSQuartz: Scan Cycle-Aware and Vendor-Agnostic Fuzzing for Industrial Control Systems", "first_label": ["Fuzzing"], "second_label": [], "data": "C Villa, C Doumanidis, H Lamri, PHN Rajput\\xe2\\x80\\xa6\nIndustrial Control Systems (ICS) ensure the automation and safe operation of critical \nindustry, energy, and commerce processes. Despite its importance, ICS code often \ncannot be evaluated as rigorously as software on traditional computing platforms, as\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.ndss-symposium.org/wp-content/uploads/2025-795-paper.pdf&hl=en&sa=X&d=10524862650214833634&ei=a9DQZ66pMoC96rQP2s_YiAM&scisig=AFWwaeZZ_2ARI6V22CenXEygxr-a&oi=scholaralrt&hist=apJ4fD8AAAAJ:11137134570824175991:AFWwaeZJgvZkFmSwNlRigHvrI7d8&html=&pos=1&folt=rel", "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "ROSA: Finding Backdoors with Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "D Kokkonis, M Marcozzi, E Decoux, S Zacchiroli\nA code-level backdoor is a hidden access, programmed and concealed within the \ncode of a program. For instance, hard-coded credentials planted in the code of a file \nserver application would enable maliciously logging into all deployed instances of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://binsec.github.io/assets/publications/papers/2025-icse.pdf&hl=en&sa=X&d=13531564943831013756&ei=a9DQZ66pMoC96rQP2s_YiAM&scisig=AFWwaeaGFFpUlOhEdz0gAvuIoA9h&oi=scholaralrt&hist=apJ4fD8AAAAJ:11137134570824175991:AFWwaeZJgvZkFmSwNlRigHvrI7d8&html=&pos=2&folt=rel", "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Snowplow: Effective Kernel Fuzzing with a Learned White-box Test Mutator", "first_label": ["Fuzzing"], "second_label": [], "data": "S Gong, R Wang, D Alt\\xc4\\xb1nb\\xc3\\xbcken, P Fonseca, P Maniatis - 2025\nKernel fuzzers rely heavily on program mutation to automatically generate new test \nprograms based on existing ones. In particular, program mutation can alter the test's \ncontrol and data flow inside the kernel by inserting new system calls, changing the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://sishuaigong.github.io/pdf/asplos25-snowplow.pdf&hl=en&sa=X&d=1525548876762051891&ei=a9DQZ66pMoC96rQP2s_YiAM&scisig=AFWwaeYhlLgOV_U4w2jfk052O3uX&oi=scholaralrt&hist=apJ4fD8AAAAJ:11137134570824175991:AFWwaeZJgvZkFmSwNlRigHvrI7d8&html=&pos=5&folt=rel", "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "SwFuzz: Structure-Sensitive WebAssembly Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "J Wang, Z Guo, X Ying, P Qian, Y Chen\nWebAssembly (WASM) has rapidly emerged as a ubiquitous target for web browsers, \nserver-side applications, and blockchain platforms, with promising performance and \nportability. As WASM grows in popularity, ensuring its security and resilience\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://users.cs.northwestern.edu/~ychen/Papers/SWFuzz_ASIA.pdf&hl=en&sa=X&d=3575353584380034570&ei=a9DQZ66pMoC96rQP2s_YiAM&scisig=AFWwaeZNlmOmuNwoN0uMt4pWuU0v&oi=scholaralrt&hist=apJ4fD8AAAAJ:11137134570824175991:AFWwaeZJgvZkFmSwNlRigHvrI7d8&html=&pos=6&folt=rel", "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "RefleXGen: The unexamined code is not worth using", "first_label": ["Code"], "second_label": [], "data": "B Wang, H Li, AF Liu, BT Yang, A Yang, YL Zhong\\xe2\\x80\\xa6\\xc2\\xa0- ICASSP 2025-2025 IEEE\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSecurity in code generation remains a pivotal challenge when applying large \nlanguage models (LLMs). This paper introduces RefleXGen, an innovative method \nthat significantly enhances code security by integrating Retrieval-Augmented\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10890824/&hl=vi&sa=X&d=11195540878604989715&ei=a9DQZ5PrM5m7ieoP1NrBiQU&scisig=AFWwaeafKI9AN2BOyhQ6uzYWLMEF&oi=scholaralrt&hist=apJ4fD8AAAAJ:11355862984917483435:AFWwaeZvT_NNWQMu4_zZrEW644gW&html=&pos=1&folt=rel", "ref": ["Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Contextual Augmented Multi-Model Programming (CAMP): A Local-Cloud Copilot Solution", "first_label": [], "second_label": [], "data": "Y Wang, S Guo, CW Tan\\xc2\\xa0- ICLR 2025 Third Workshop on Deep Learning for Code\nThe rapid advancement of cloud-based Large Language Models (LLMs) has \nrevolutionized AI-assisted programming, but their integration into local development \nenvironments faces trade-offs between performance and cost. Cloud LLMs deliver\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nGoogle Scholar g\\xe1\\xbb\\xadi th\\xc3\\xb4ng b\\xc3\\xa1o n\\xc3\\xa0y cho b\\xe1\\xba\\xa1n v\\xc3\\xac b\\xe1\\xba\\xa1n \\xc4\\x91ang theo d\\xc3\\xb5i nh\\xe1\\xbb\\xafng b\\xc3\\xa0i vi\\xe1\\xba\\xbft m\\xe1\\xbb\\x9bi li\\xc3\\xaan quan \\xc4\\x91\\xe1\\xba\\xbfn nghi\\xc3\\xaan c\\xe1\\xbb\\xa9u c\\xe1\\xbb\\xa7a \nXin ZHOU\n.\nLi\\xe1\\xbb\\x87t k\\xc3\\xaa c\\xe1\\xba\\xa3nh b\\xc3\\xa1o\nH\\xe1\\xbb\\xa7y th\\xc3\\xb4ng b\\xc3\\xa1o\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DzvkJHtEBUM&hl=vi&sa=X&d=12571089977382535116&ei=a9DQZ5PrM5m7ieoP1NrBiQU&scisig=AFWwaeaAPVXcqgVvjwKEKmvQIwi3&oi=scholaralrt&hist=apJ4fD8AAAAJ:11355862984917483435:AFWwaeZvT_NNWQMu4_zZrEW644gW&html=&pos=2&folt=rel", "ref": ["Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Large Language Models in Software Security: A Survey of Vulnerability Detection Techniques and Insights", "first_label": ["Vulnerabilities", "Large Language Models"], "second_label": ["Detection"], "data": "Z Sheng, Z Chen, S Gu, H Huang, G Gu, J Huang\\xc2\\xa0- arXiv preprint arXiv:2502.07049, 2025\nLarge Language Models (LLMs) are emerging as transformative tools for software \nvulnerability detection, addressing critical challenges in the security domain. \nTraditional methods, such as static and dynamic analysis, often falter due to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.07049&hl=en&sa=X&d=2363501710013147041&ei=a9DQZ9-CNbutieoP8ref4Qo&scisig=AFWwaeZdYD0r4U5a0brYKfAw5_To&oi=scholaralrt&hist=apJ4fD8AAAAJ:11631047573362457156:AFWwaeYhbBKL65h4pzyKCNru3s-R&html=&pos=0&folt=rel", "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Pragmatic Reasoning improves LLM Code Generation", "first_label": ["Large Language Models", "Code"], "second_label": ["Generation"], "data": "Z Cao, S Apel, A Singla, V Demberg\\xc2\\xa0- arXiv preprint arXiv:2502.15835, 2025\nLarge Language Models (LLMs) have demonstrated impressive potential in \ntranslating natural language (NL) instructions into program code. However, user \ninstructions often contain inherent ambiguities, making it challenging for LLMs to\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.15835&hl=en&sa=X&d=6927995321596801340&ei=a9DQZ9-CNbutieoP8ref4Qo&scisig=AFWwaebpCZ-l4eJjTQ3XaxQi2c08&oi=scholaralrt&hist=apJ4fD8AAAAJ:11631047573362457156:AFWwaeYhbBKL65h4pzyKCNru3s-R&html=&pos=4&folt=rel", "ref": ["Thanh Le-Cong - new related research"]}
{"title": "SVRM: Composing Various Network Service Fuzzing Corpus with One Single Model", "first_label": ["Fuzzing"], "second_label": [], "data": "W Lin, Z Jiang, F Xu, Y Su, Z Li, L Mao, C Tang\\xc2\\xa0- ICASSP 2025-2025 IEEE\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDiscovering vulnerabilities in network service is of great significance. Currently, \ncoverage-guided fuzzing (CGF) is widely regarded as the most effective method. \nHowever, the efficiency of CGF depends on the quality of initial corpus. The initial \ncorpus is a set of valid input examples used to initiate the fuzzing process. \nConstructing high-quality initial corpus typically requires manual efforts to \nunderstand the implementation details and corresponding protocol specifications\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaStateful Greybox Fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10888546/&hl=en&sa=X&d=9578137627106381686&ei=a9DQZ96HLsuZieoP9PnpkQc&scisig=AFWwaeZSYAXhEEcvA_a_EI6p2jEd&oi=scholaralrt&hist=apJ4fD8AAAAJ:5778505219825515303:AFWwaeaDDOggOneW-z6K3HLjAzuP&html=&pos=0&folt=cit", "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
{"title": "Reinforced Lifelong Editing for Language Models", "first_label": [], "second_label": [], "data": "Z Li, H Jiang, H Chen, B Bi, Z Zhou, F Sun, J Fang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) acquire information from pre-training corpora, but \ntheir stored knowledge can become inaccurate or outdated over time. Model editing \naddresses this challenge by modifying model parameters without retraining, and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.05759&hl=en&sa=X&d=16947591820930522598&ei=a9DQZ8bcKsCSieoPoa_pwQc&scisig=AFWwaeZSeCl4fgs2bqu21OUnEuxj&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=0&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "VLM-Guard: Safeguarding Vision-Language Models via Fulfilling Safety Alignment Gap", "first_label": [], "second_label": [], "data": "Q Liu, F Wang, C Xiao, M Chen\\xc2\\xa0- arXiv preprint arXiv:2502.10486, 2025\nThe emergence of vision language models (VLMs) comes with increased safety \nconcerns, as the incorporation of multiple modalities heightens vulnerability to \nattacks. Although VLMs can be built upon LLMs that have textual safety alignment, it\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.10486&hl=en&sa=X&d=11854639627530484779&ei=a9DQZ8bcKsCSieoPoa_pwQc&scisig=AFWwaea98Rw6lmSGwcIUp-ijLR2F&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=1&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "SafeChain: Safety of Language Models with Long Chain-of-Thought Reasoning Capabilities", "first_label": [], "second_label": [], "data": "F Jiang, Z Xu, Y Li, L Niu, Z Xiang, B Li, BY Lin\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nEmerging large reasoning models (LRMs), such as DeepSeek-R1 models, leverage \nlong chain-of-thought (CoT) reasoning to generate structured intermediate steps, \nenhancing their reasoning capabilities. However, long CoT does not inherently\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.12025%3F&hl=en&sa=X&d=11794055058332912936&ei=a9DQZ8bcKsCSieoPoa_pwQc&scisig=AFWwaeZIkep8RWr0oJ-gto7S9nZK&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=2&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "Adversary-Aware DPO: Enhancing Safety Alignment in Vision Language Models via Adversarial Training", "first_label": [], "second_label": [], "data": "F Weng, J Lou, J Feng, M Huang, W Wang\\xc2\\xa0- arXiv preprint arXiv:2502.11455, 2025\nSafety alignment is critical in pre-training large language models (LLMs) to generate \nresponses aligned with human values and refuse harmful queries. Unlike LLM, the \ncurrent safety alignment of VLMs is often achieved with post-hoc safety fine-tuning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.11455&hl=en&sa=X&d=14199852315052579694&ei=a9DQZ8bcKsCSieoPoa_pwQc&scisig=AFWwaeaQdgo38ob0HLeDPQrlflMZ&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=3&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "Following the Autoregressive Nature of LLM Embeddings via Compression and Alignment", "first_label": ["Large Language Models"], "second_label": [], "data": "J Deng, Z Jiang, L Pang, L Chen, K Xu, Z Wei, H Shen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nA new trend uses LLMs as dense text encoders via contrastive learning. However, \nsince LLM embeddings predict the probability distribution of the next token, they are \ninherently generative and distributive, conflicting with contrastive learning, which\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.11401&hl=en&sa=X&d=5106071575990121675&ei=a9DQZ8bcKsCSieoPoa_pwQc&scisig=AFWwaeZbBDaqVX9ZcIUYqZxcu6rk&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=4&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "EfficientLLM: Scalable Pruning-Aware Pretraining for Architecture-Agnostic Edge Language Models", "first_label": ["Large Language Models"], "second_label": [], "data": "X Xing, Z Liu, S Xiao, B Gao, Y Liang, W Zhang, H Lin\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern large language models (LLMs) driven by scaling laws, achieve intelligence \nemergency in large model sizes. Recently, the increasing concerns about cloud \ncosts, latency, and privacy make it an urgent requirement to develop compact edge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.06663&hl=en&sa=X&d=4201422002031415934&ei=a9DQZ8bcKsCSieoPoa_pwQc&scisig=AFWwaeY-Eig4oM44ld6QzAAHeJHJ&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=5&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "InfiR: Crafting Effective Small Language Models and Multimodal Small Language Models in Reasoning", "first_label": [], "second_label": [], "data": "C Xie, S Cai, W Wang, P Li, Z Sang, K Yang, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) and Multimodal Large Language Models (MLLMs) \nhave made significant advancements in reasoning capabilities. However, they still \nface challenges such as high computational demands and privacy concerns. This\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.11573&hl=en&sa=X&d=2040677933085995796&ei=a9DQZ8bcKsCSieoPoa_pwQc&scisig=AFWwaeZDYD_mnYjLxJYKHWP3K2QX&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=6&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "Towards Reasoning Ability of Small Language Models", "first_label": [], "second_label": [], "data": "G Srivastava, S Cao, X Wang\\xc2\\xa0- arXiv preprint arXiv:2502.11569, 2025\nReasoning has long been viewed as an emergent property of large language \nmodels (LLMs), appearing at or above a certain scale ($\\\\sim $100 B parameters). \nHowever, recent studies challenge this assumption, showing that small language\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.11569&hl=en&sa=X&d=9184148782116158442&ei=a9DQZ8bcKsCSieoPoa_pwQc&scisig=AFWwaeadOwkxcJuKXxo9ZaO0a4Zg&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=7&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems", "first_label": ["Large Language Models"], "second_label": ["Agent"], "data": "R Ye, S Tang, R Ge, Y Du, Z Yin, S Chen, J Shao\\xc2\\xa0- arXiv preprint arXiv:2503.03686, 2025\nLLM-based multi-agent systems (MAS) have shown significant potential in tackling \ndiverse tasks. However, to design effective MAS, existing approaches heavily rely on \nmanual configurations or multiple calls of advanced LLMs, resulting in inadaptability\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nCarlos E. Jimenez\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.03686&hl=en&sa=X&d=3100370313557490096&ei=a9DQZ8bcKsCSieoPoa_pwQc&scisig=AFWwaeZ387q4vTdA7oajqJeEL_yE&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=9&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
