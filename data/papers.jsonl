{"title": "An Empirical Study of Multi-Language Security Patches in Open Source Software", "first_label": [], "second_label": [], "data": "S Sun, Y Xing, G Zou, X Wang, K Sun\nVulnerabilities in software repositories written in multiple programming languages \npresent a major challenge to modern software quality assurance, especially those \nresulting from interactions between different languages. Existing static and dynamic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://yunlongxing.github.io/publications/dimva25_Empirical.pdf&hl=en&sa=X&d=10326866748066170289&ei=XAtAaJeYMsiE6rQP59uGiAk&scisig=AAZF9b-FrAQMzcNeCYBMoioph8Ze&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Rethinking Code Review Workflows with LLM Assistance: An Empirical Study", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "FS A\\xc3\\xb0alsteinsson, BB Magn\\xc3\\xbasson, M Milicevic\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode reviews are a critical yet time-consuming aspect of modern software \ndevelopment, increasingly challenged by growing system complexity and the \ndemand for faster delivery. This paper presents a study conducted at WirelessCar\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16339&hl=en&sa=X&d=775906120526056084&ei=XAtAaJeYMsiE6rQP59uGiAk&scisig=AAZF9b8cBmXiUvIKNiOXGDa3tGdK&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Evaluating Small-Scale Code Models for Code Clone Detection", "first_label": ["Code"], "second_label": ["Detection"], "data": "J Martinez-Gil - 2025\nDetecting code clones is relevant to software maintenance and code refactoring. This \nchallenge still presents unresolved cases, mainly when structural similarity does not \nreflect functional equivalence, though recent code models show promise. Therefore\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://hal.science/hal-05055646v1/file/small-code-models.pdf&hl=en&sa=X&d=2446613816357308363&ei=XAtAaJeYMsiE6rQP59uGiAk&scisig=AAZF9b8FyaOH5NsvjO7gTQbFjlr6&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Targeted Fuzzing for Unsafe Rust Code: Leveraging Selective Instrumentation", "first_label": ["Fuzzing", "Code"], "second_label": [], "data": "D Paa\\xc3\\x9fen, JR Giesen, L Davi\\xc2\\xa0- arXiv preprint arXiv:2505.02464, 2025\nRust is a promising programming language that focuses on concurrency, usability, \nand security. It is used in production code by major industry players and got \nrecommended by government bodies. Rust provides strong security guarantees\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.02464&hl=en&sa=X&d=17464682910892089266&ei=XAtAaK_wLLWv6rQPgJOzyAw&scisig=AAZF9b-bvKBMc2Po_9BYZAm8NsXQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "OmniGIRL: A Multilingual and Multimodal Benchmark for GitHub Issue Resolution", "first_label": ["GitHub Issue"], "second_label": [], "data": "L Guo, W Tao, R Jiang, Y Wang, J Chen, X Liu, Y Ma\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe GitHub issue resolution task aims to resolve issues reported in repositories \nautomatically. With advances in large language models (LLMs), this task has gained \nincreasing attention, and several benchmarks are proposed to evaluate the issue\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.04606&hl=en&sa=X&d=17721785651242552030&ei=XAtAaMzrKKKr6rQPiJHk4QU&scisig=AAZF9b9vdcHDALBkXHSBcEUw295J&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Adding Context to LLM-Guided Verilog Repair", "first_label": ["LLM"], "second_label": ["Repair"], "data": "A Elnaggar, B Tan\\xc2\\xa0- 2025 26th International Symposium on Quality\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRegister transfer level (RTL) bugs are critical issues that affect the functional \ncorrectness, security, and performance of systems-on-chip (SoC). Traditionally, \nrepairing these bugs is a time-consuming process that requires the expertise of \nexperienced engineers, leading to prolonged SoC development cycles and reduced \nvendor competitiveness. In this paper, we propose an automated framework that \nutilizes a Large Language Model (LLM) to repair RTL bugs. We investigate four\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11014472/&hl=en&sa=X&d=2409201528343540759&ei=XAtAaJbLK-SN6rQPzIKygQU&scisig=AAZF9b-R6QTYYOubdd15pBuoJogx&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["1 new citation to articles by Abhik Roychoudhury"]}
{"title": "Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack", "first_label": ["LLM"], "second_label": [], "data": "S Cappelletti, T Poppi, S Poppi, ZX Yong\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly evaluated on multiple-choice \nquestion answering (MCQA) tasks using* first-token probability*(FTP), which selects \nthe answer option whose initial token has the highest likelihood. While efficient, FTP\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15323%3F&hl=en&sa=X&d=5513891085179250670&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b8ts6vJnVnPKgZRZk2J59vT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Stealthy LLM-Driven Data Poisoning Attacks Against Embedding-Based Retrieval-Augmented Recommender Systems", "first_label": ["LLM"], "second_label": [], "data": "F Nazary, Y Deldjoo, T Di Noia, E Di Sciascio\\xc2\\xa0- arXiv preprint arXiv:2505.05196, 2025\nWe present a systematic study of provider-side data poisoning in retrieval-\naugmented recommender systems (RAG-based). By modifying only a small fraction \nof tokens within item descriptions--for instance, adding emotional keywords or\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.05196&hl=en&sa=X&d=7153996738322631678&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b9XYvMXz8xtJ6dU7EDwB2B7&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "PS Pandey, S Simko, K Pelrine, Z Jin\\xc2\\xa0- arXiv preprint arXiv:2505.16789, 2025\nAs large language models gain popularity, their vulnerability to adversarial attacks \nremains a primary concern. While fine-tuning models on domain-specific datasets is \noften employed to improve model performance, it can introduce vulnerabilities within\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16789%3F&hl=en&sa=X&d=9827187220639785834&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b-hRa3CIybDfceUhaRlecWD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution", "first_label": [], "second_label": [], "data": "J Guo, X Wen, W Jiang, C Huang, J Li, H Li\\xc2\\xa0- arXiv preprint arXiv:2505.15308, 2025\nWith the widespread application of super-resolution (SR) in various fields, \nresearchers have begun to investigate its security. Previous studies have \ndemonstrated that SR models can also be subjected to backdoor attacks through\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15308&hl=en&sa=X&d=13335437674086498390&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b8WmdvUXiuzvPutlRNCBmNP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "An Embarrassingly Simple Defense Against LLM Abliteration Attacks", "first_label": ["LLM"], "second_label": [], "data": "HA Shairah, HAAK Hammoud, B Ghanem, G Turkiyyah\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are typically aligned to comply with safety guidelines \nby refusing harmful instructions. A recent attack, termed abliteration, isolates and \nsuppresses the single latent direction most responsible for refusal behavior, enabling\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19056&hl=en&sa=X&d=3737202939224050048&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b8QKV5yRTnfm0WbZVG9RAGO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Poison in the Well: Feature Embedding Disruption in Backdoor Attacks", "first_label": [], "second_label": [], "data": "Z Feng, J Chen, C Zhou, Y Pu, Q Li, S Ji\\xc2\\xa0- arXiv preprint arXiv:2505.19821, 2025\nBackdoor attacks embed malicious triggers into training data, enabling attackers to \nmanipulate neural network behavior during inference while maintaining high \naccuracy on benign inputs. However, existing backdoor attacks face limitations\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19821&hl=en&sa=X&d=8217579378668490954&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b89XZjYdu_nSk8rXx0clM5e&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Advancing LLM Safe Alignment with Safety Representation Ranking", "first_label": ["LLM"], "second_label": [], "data": "T Du, Z Wei, Q Chen, C Zhang, Y Wang\\xc2\\xa0- arXiv preprint arXiv:2505.15710, 2025\nThe rapid advancement of large language models (LLMs) has demonstrated \nmilestone success in a variety of tasks, yet their potential for generating harmful \ncontent has raised significant safety concerns. Existing safety evaluation approaches\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15710%3F&hl=en&sa=X&d=9147050430051665415&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b_UrCXjo9qqEV1FKXREeILg&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses", "first_label": ["LLM"], "second_label": [], "data": "X Yang, B Stevanoski, M Meeus, YA de Montjoye\\xc2\\xa0- arXiv preprint arXiv:2505.15738, 2025\nLarge language models (LLMs) are rapidly deployed in real-world applications \nranging from chatbots to agentic systems. Alignment is one of the main approaches \nused to defend against attacks such as prompt injection and jailbreaks. Recent\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15738&hl=en&sa=X&d=15949587169759547530&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b9jW2tzEb1jjKg1wddBnl-L&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Llamafirewall: An open source guardrail system for building secure ai agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "S Chennabasappa, C Nikolaidis, D Song, D Molnar\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have evolved from simple chatbots into autonomous \nagents capable of performing complex tasks such as editing production code, \norchestrating workflows, and taking higher-stakes actions based on untrusted inputs\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.03574&hl=en&sa=X&d=4439105352924524607&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b9vbSaup9_At8OcInY6jBmA&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Unleashing the potential of prompt engineering for large language models", "first_label": ["LLM"], "second_label": [], "data": "B Chen, Z Zhang, N Langren\\xc3\\xa9, S Zhu\\xc2\\xa0- Patterns, 2025\nThis review explores the role of prompt engineering in unleashing the capabilities of \nlarge language models (LLMs). Prompt engineering is the process of structuring \ninputs, and it has emerged as a crucial technique for maximizing the utility and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.cell.com/patterns/fulltext/S2666-3899(25)00108-4&hl=en&sa=X&d=6676094083615587801&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b8tnw1APcMPz1M8W7CTpXY4&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Generative AI for Source Code Creation: Revolutionizing Cloud-Native Software Engineering", "first_label": ["Code"], "second_label": [], "data": "CVS Babu, KH Kishore\\xc2\\xa0- Artificial Intelligence for Cloud-Native Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis study explores the integration of Generative AI in cloud-native software \nengineering, aiming to enhance the efficiency and effectiveness of source code \ncreation. Targeting software developers, engineers, and organizations leveraging\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.igi-global.com/chapter/generative-ai-for-source-code-creation/378773&hl=en&sa=X&d=3868822976676006039&ei=XAtAaO-eKo-UywTXk47YAw&scisig=AAZF9b8Fu8sMrUJel-3NyAV4pq8w&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Implementation of Multi-Level RAG Model for Enhanced Synergistic Vulnerability Analysis", "first_label": ["Vulnerabilities"], "second_label": [], "data": "MJ Yoon, SM Yoo, JH Park, KW Park\\xc2\\xa0- 2025 1st International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nTraditional vulnerability analysis models often rely on a single data source, which \nlimits their ability to comprehensively detect and analyze vulnerabilities. In this study, \nwe propose a multi-level Retrieval-Augmented Generation (RAG) model that \nprogressively integrates multiple vulnerability databases to overcome these \nlimitations. By incorporating core and peripheral data sources at different levels, our \napproach aims to enhance the quality of vulnerability analysis. We integrate four\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection and repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11012876/&hl=en&sa=X&d=4531646570342184666&ei=XAtAaNefL_iJ6rQP4Lq-sAo&scisig=AAZF9b-YBT4_GKhWHSqOX9g18i9y&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["1 new citation to articles by Xin ZHOU"]}
{"title": "Structure-EnhancedPrompt Learning for Graph-Based Code Vulnerability Detection", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection", "Graph"], "data": "W Chang, C Ye, H Zhou\\xc2\\xa0- Applied Sciences, 2025\nRecent advances in prompt learning have opened new avenues for enhancing \nnatural language understanding in domain-specific tasks, including code \nvulnerability detection. Motivated by the limitations of conventional binary\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2076-3417/15/11/6128&hl=en&sa=X&d=14787634818984465351&ei=r4g-aJ7WNdOj6rQPzMDA4AM&scisig=AAZF9b8AbdZB3i79KkRKBO0madiQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Investigating Reproducibility Challenges in LLM Bugfixing on the HumanEvalFix Benchmark", "first_label": ["LLM", "Bug"], "second_label": [], "data": "B Szalontai, B M\\xc3\\xa1rton, B Pint\\xc3\\xa9r, T Gregorics - 2025\nBenchmark results for Large Language Models often show inconsistencies across \ndifferent studies. This paper investigates the challenges of reproducing these results \nin automatic bugfixing using LLMs, on the HumanEvalFix benchmark. To determine\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.preprints.org/frontend/manuscript/fb66f679111eaa15fc8e3c47e4f289e3/download_pub&hl=en&sa=X&d=5498677636109518696&ei=r4g-aJ7WNdOj6rQPzMDA4AM&scisig=AAZF9b_WTbrAan-CoxH3zpY3J3tj&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "1 new citation to articles by Hong Jin Kang", "Xin ZHOU - new related research"]}
{"title": "An empirical study on architectural smells through a pipeline for continuous technical debt assessment", "first_label": [], "second_label": [], "data": "M Bochicchio, D Sas, A Gilardi, FA Fontana\\xc2\\xa0- Information and Software Technology, 2025\nContext: Architectural smells, are a well-known indicator of architectural technical \ndebt, their presence could have a great impact on the maintainability and evolvability \nof a project. Hence, it is important to carefully study and monitor them. Objective: In\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925001223&hl=en&sa=X&d=12840437567590045959&ei=r4g-aJ7WNdOj6rQPzMDA4AM&scisig=AAZF9b85amGJ2QkpRdzBxsKM0zDQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Redefining Software Testing: How AI-Driven Automation Is Transforming Test Case Prioritization and Defect Prediction", "first_label": ["Software Testing", "Software Defect"], "second_label": [], "data": "E Oye - 2025\nThe landscape of software testing is undergoing a profound transformation driven by \nthe integration of Artificial Intelligence (AI) and automation technologies. This paper \nexplores how AI-driven automation is redefining essential aspects of software testing\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Emma-Oye/publication/392011768_Redefining_Software_Testing_How_AI-Driven_Automation_Is_Transforming_Test_Case_Prioritization_and_Defect_Prediction/links/683058dcbe1b507dce8ef446/Redefining-Software-Testing-How-AI-Driven-Automation-Is-Transforming-Test-Case-Prioritization-and-Defect-Prediction.pdf&hl=en&sa=X&d=8158512365196228399&ei=r4g-aJ7WNdOj6rQPzMDA4AM&scisig=AAZF9b_cWpchtUpewpXb0w4Q5FYx&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Improving prompt tuning-based software vulnerability assessment by fusing source code and vulnerability description", "first_label": ["Vulnerabilities", "Code"], "second_label": [], "data": "J Wang, X Chen, W Pei, S Yang\\xc2\\xa0- Automated Software Engineering, 2025\nTo effectively allocate resources for vulnerability remediation, it is crucial to prioritize \nvulnerability fixes based on vulnerability severity. With the increasingnumber of \nvulnerabilities in recent years, there is an urgent need for automated methods for\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00525-5&hl=en&sa=X&d=632305407775732564&ei=sIg-aNaSAuSN6rQPzIKygQU&scisig=AAZF9b9Mq4kj-GXYL15rG6YasTTq&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "MLIR-Smith: A Novel Random Program Generator for Evaluating Compiler Pipelines", "first_label": [], "second_label": [], "data": "B Ates, F Dobrosavljevi\\xc4\\x87, T Theodoridis, Z Su\nCompilers are essential for the performance and correct execution of software and \nhold universal relevance across various scientific disciplines. Despite this, there is a \nnotable lack of tools for testing and evaluating them, especially within the adaptable\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://filipdob.ro/papers/MLIR_Smith_Report.pdf&hl=en&sa=X&d=4663515892976989619&ei=sIg-aNaSAuSN6rQPzIKygQU&scisig=AAZF9b9F8m6qUmt2eAn_nfyYKk4S&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models", "first_label": ["APR"], "second_label": ["Repair"], "data": "FV Ruiz, M Hort, L Moonen\\xc2\\xa0- arXiv preprint arXiv:2505.02931, 2025\nAutomatic program repair (APR) aims to reduce the manual efforts required to \nidentify and fix errors in source code. Before the rise of LLM-based agents, a \ncommon strategy was to increase the number of generated patches, sometimes to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.02931%3F&hl=en&sa=X&d=16837479357373517474&ei=r4g-aKvgOYCt6rQP9sPUwAg&scisig=AAZF9b_WjCVulOfH0bpaSqZwLopC&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "CORECRISIS: Threat-Guided and Context-Aware Iterative Learning and Fuzzing of 5G Core Networks", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Dong, T Yang, A Al Ishtiaq, SMM Rashid, A Ranjbar\\xe2\\x80\\xa6\nWe develop CORECRISIS, a stateful black-box fuzz-testing framework for 5G core \nnetwork (5GC) implementations. Unlike previous stateful security analysis efforts of \ncellular networks which rely on manually-crafted, static test inputs and are limited to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.usenix.org/system/files/conference/usenixsecurity25/sec25cycle1-prepub-1292-dong-yilu.pdf&hl=en&sa=X&d=4291979592406815479&ei=r4g-aKvgOYCt6rQP9sPUwAg&scisig=AAZF9b8xMpoFy9xYsoZdVl1unvGx&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Fault localization of AI-enabled cyber-physical systems by exploiting temporal neuron activation", "first_label": ["Fault Localization"], "second_label": ["Exploit", "Localization"], "data": "D Lyu, Y Li, Z Zhang, P Arcaini, XY Zhang, F Ishikawa\\xe2\\x80\\xa6\\xc2\\xa0- Journal of Systems and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern cyber\\xe2\\x80\\x93physical systems (CPS) are evolving to integrate deep neural \nnetworks (DNNs) as controllers, leading to the emergence of AI-enabled CPSs. An \ninadequately trained DNN controller may produce incorrect control actions, exposing\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225001438&hl=en&sa=X&d=3286846770327067741&ei=r4g-aKvgOYCt6rQP9sPUwAg&scisig=AAZF9b-jUE3fT364wIMjAbdvLNMM&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Detection and Repair of Defects in Register Transfer Level Code Using Static Analysis and Generative AI", "first_label": ["Code", "Static Analysis", "Software Defect"], "second_label": ["Detection", "Repair"], "data": "B Ahmad - 2025\nThe detection and repair of hardware bugs have become increasingly important over \nthe past decade. In particular, security-related issues arising from these bugs have \nbeen the focus of significant academic and industrial efforts. It is crucial to detect \ndefects in hardware as early as possible to reduce costs, efforts, and damage to \nreputation down the line. Existing solutions rely on design-specific information, \nexpertise, and techniques. These constraints limit the generalizability of solutions\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefixar: Multi-version reasoning for automated repair of regression\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/5af68b8237bd46beda3e6c893d2c6788/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=en&sa=X&d=18433095172492645771&ei=r4g-aJ36M-SN6rQPzIKygQU&scisig=AAZF9b9nU-lZ___LvtULFZR6l21f&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["1 new citation to articles by Bach Le", "2 new citations to articles by Abhik Roychoudhury"]}
{"title": "Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based Backdoor Attacks for Jailbreaking Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "J Kong, H Fang, X Yang, K Gao, B Chen, ST Xia\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSupervised fine-tuning (SFT) aligns large language models (LLMs) with human \nintent by training them on labeled task-specific data. Recent studies have shown that \nmalicious attackers can inject backdoors into these models by embedding triggers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17601%3F&hl=en&sa=X&d=14932585774719166007&ei=r4g-aNucPMiE6rQP59uGiAk&scisig=AAZF9b-bRcbQ7r2VSTXuEVUTZE69&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Evaluatiing the efficacy of LLM Safety Solutions: The Palit Benchmark Dataset", "first_label": ["LLM"], "second_label": [], "data": "S Palit, D Woods\\xc2\\xa0- arXiv preprint arXiv:2505.13028, 2025\nLarge Language Models (LLMs) are increasingly integrated into critical systems in \nindustries like healthcare and finance. Users can often submit queries to LLM-\nenabled chatbots, some of which can enrich responses with information retrieved\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13028%3F&hl=en&sa=X&d=1273460049730580919&ei=r4g-aNucPMiE6rQP59uGiAk&scisig=AAZF9b9ByON4eaZyjRTpM1-cA_zU&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Wang, W Wang, S Wang, Z Li, Z Ji, Z Lyu, D Wu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Large Language Models (LLMs) has led to the \nemergence of Multi-Agent Systems (MAS) to perform complex tasks through \ncollaboration. However, the intricate nature of MAS, including their architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12442&hl=en&sa=X&d=8825331941370095164&ei=r4g-aNucPMiE6rQP59uGiAk&scisig=AAZF9b_j6hKF2Zy8dNMOx-tobM6E&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AgentXploit: End-to-End Redteaming of Black-Box AI Agents", "first_label": [], "second_label": ["Agent"], "data": "Z Wang, V Siu, Z Ye, T Shi, Y Nie, X Zhao, C Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe strong planning and reasoning capabilities of Large Language Models (LLMs) \nhave fostered the development of agent-based systems capable of leveraging \nexternal tools and interacting with increasingly complex environments. However\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.05849&hl=en&sa=X&d=13145039506086791936&ei=r4g-aNucPMiE6rQP59uGiAk&scisig=AAZF9b_5aWzkLQOK0HBWClMmbpt1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Ripple Effect: On Unforeseen Complications of Backdoor Attacks", "first_label": [], "second_label": [], "data": "R Zhang, Y Shen, H Li, W Jiang, H Chen, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent research highlights concerns about the trustworthiness of third-party Pre-\nTrained Language Models (PTLMs) due to potential backdoor attacks. These \nbackdoored PTLMs, however, are effective only for specific pre-defined downstream\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11586&hl=en&sa=X&d=15157304470732077928&ei=r4g-aNucPMiE6rQP59uGiAk&scisig=AAZF9b997v4XRj8-KVQslhBMZvqE&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadDepth: Backdoor Attacks Against Monocular Depth Estimation in the Physical World", "first_label": [], "second_label": [], "data": "J Guo, L Zhou, Z Wang, J He, Q Song, A Chen, W Jiang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, deep learning-based Monocular Depth Estimation (MDE) models \nhave been widely applied in fields such as autonomous driving and robotics. \nHowever, their vulnerability to backdoor attacks remains unexplored. To fill the gap in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16154%3F&hl=en&sa=X&d=5415910119131408953&ei=r4g-aNucPMiE6rQP59uGiAk&scisig=AAZF9b_P0jMEgHvYQo3O-kEno08o&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "first_label": ["LLM"], "second_label": [], "data": "G Chen, F Song, Z Zhao, X Jia, Y Liu, Y Qiao, W Zhang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreak attacks to Large audio-language models (LALMs) are studied recently, but \nthey achieve suboptimal effectiveness, applicability, and practicability, particularly, \nassuming that the adversary can fully manipulate user prompts. In this work, we first\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14103&hl=en&sa=X&d=12355582258955555442&ei=r4g-aNucPMiE6rQP59uGiAk&scisig=AAZF9b84twuHlVXU1hPFciKO3AfT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadLingual: A Novel Lingual-Backdoor Attack against Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Wang, H Li, R Zhang, W Jiang, K Chen, T Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn this paper, we present a new form of backdoor attack against Large Language \nModels (LLMs): lingual-backdoor attacks. The key novelty of lingual-backdoor attacks \nis that the language itself serves as the trigger to hijack the infected LLMs to generate\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.03501&hl=en&sa=X&d=15489349756851264058&ei=r4g-aNucPMiE6rQP59uGiAk&scisig=AAZF9b_j_X5MMHAf2tokb2xerP6r&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A4FL: Federated Adversarial Defense via Adversarial Training and Pruning Against Backdoor Attack", "first_label": [], "second_label": [], "data": "B Li, M Hamid, M Saleem, M Aman\\xc2\\xa0- IEEE Access, 2025\nBackdoor attacks threaten federated learning (FL) models, where malicious \nparticipants embed hidden triggers into local models during training. These triggers \ncan compromise crucial applications, such as autonomous systems, when they\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/10992684.pdf&hl=en&sa=X&d=4691259454218143835&ei=r4g-aNucPMiE6rQP59uGiAk&scisig=AAZF9b-NVXh_0LVfWkgmGPYIRTtu&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Bullying the Machine: How Personas Increase LLM Vulnerability", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "Z Xu, U Sanghi, M Kankanhalli\\xc2\\xa0- arXiv preprint arXiv:2505.12692, 2025\nLarge Language Models (LLMs) are increasingly deployed in interactions where \nthey are prompted to adopt personas. This paper investigates whether such persona \nconditioning affects model safety under bullying, an adversarial manipulation that\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12692%3F&hl=en&sa=X&d=3130006781540917286&ei=r4g-aNucPMiE6rQP59uGiAk&scisig=AAZF9b-r43I7NUbwAxgd2MM-t4Q_&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AnnCoder: A mti-Agent-Based Code Generation and Optimization Model", "first_label": ["Code"], "second_label": ["Generation", "Agent"], "data": "Z Zhang, J Wang, Z Li, Y Wang, J Zheng - 2025\nThe rapid progress of LLMs has greatly improved natural language tasks like code \ngeneration, boosting developer productivity. However, challenges persist. Generated \ncode often appears\" pseudocorrect\"\\xe2\\x80\\x94passing functional tests but plagued by \ninefficiency or redundant structures. Many models rely on outdated methods like \ngreedy selection, which trap them in local optima, limiting their ability to explore \nbetter solutions. We propose AnnCoder, a multi-agent framework that mimics the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.preprints.org/frontend/manuscript/59d3304520465f088e1d464fde951515/download_pub&hl=en&sa=X&d=6216303975224490934&ei=r4g-aJ2KN6uM6rQPsd_4QA&scisig=AAZF9b_CFpDRiIYOH7r3kCGBQ-OW&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
{"title": "Learning the fine-grained code representation for log-level prediction", "first_label": ["Code"], "second_label": [], "data": "Z Zhao, G Fan, J Li, M Zhu, H Zhang, H Su\\xc2\\xa0- \\xe2\\x80\\xa6\\xc2\\xa0of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLog levels are crucial to distinguish the severity of logs and directly reflecting the \nurgency of transactions in software systems. Automatically and efficiently determining \nlog levels is a crucial and challenging task in log management. Current log-level\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00064-9&hl=en&sa=X&d=2987968475870767202&ei=sIg-aKxgj5TLBNeTjtgD&scisig=AAZF9b-oMqC_G5jyOLyAbJstOPno&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
