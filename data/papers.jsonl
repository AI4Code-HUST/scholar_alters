{"title": "Unified Software Engineering agent as AI Software Engineer", "first_label": [], "second_label": ["Agent"], "data": "L Applis, Y Zhang, S Liang, N Jiang, L Tan\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe growth of Large Language Model (LLM) technology has raised expectations for \nautomated coding. However, software engineering is more than coding and is \nconcerned with activities including maintenance and evolution of a project. In this\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.14683&hl=en&sa=X&d=1343737154165269132&ei=OEhWaMCQH4OuieoPyIM7&scisig=AAZF9b8xZpv-JyJjXk2VF56_Q793&oi=scholaralrt&hist=ylyK0_8AAAAJ:17845465921536999430:AAZF9b8uxzftV24sircdvgSPVS-f&html=&pos=0&folt=art", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new articles", "Xin ZHOU - new related research", "Bach Le - new related research", "David Lo - new related research", "9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Empirical Evaluation of Large Language Models in Automated Program Repair", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "J Sun, F Li, X Qi, H Zhang, J Jiang\\xc2\\xa0- arXiv preprint arXiv:2506.13186, 2025\nThe increasing prevalence of software bugs has made automated program repair \n(APR) a key research focus. Large language models (LLMs) offer new opportunities \nfor APR, but existing studies mostly rely on smaller, earlier-generation models and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13186&hl=en&sa=X&d=14847840234469800688&ei=OEhWaLi_HdGM6rQPs-LTyAw&scisig=AAZF9b_y41VlOZ86kZEkYfQJ-XbI&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research", "8 new citations to articles by Bach Le", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "9 new citations to articles by Abhik Roychoudhury"]}
{"title": "From Empirical Evaluation to Context-Aware Enhancement: Repairing Regression Errors with LLMs", "first_label": ["LLM"], "second_label": ["Repair"], "data": "A Ho, T Le-Cong, B Le, C Rizkallah\\xc2\\xa0- arXiv preprint arXiv:2506.13182, 2025\n[...] Since then, various APR approaches, especially those leveraging the power of \nlarge language models (LLMs), have been rapidly developed to fix general software \nbugs. Unfortunately, the effectiveness of these advanced techniques in the context of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13182&hl=en&sa=X&d=16410952572033246035&ei=OEhWaLi_HdGM6rQPs-LTyAw&scisig=AAZF9b8A16cJdbkQ05iwE9pB-pF5&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "2 new citations to articles by Hong Jin Kang", "Thanh Le-Cong - new articles", "Bach Le - new articles", "4 new citations to articles by Thanh Le-Cong", "8 new citations to articles by Bach Le", "Quang-Cuong Bui - new related research", "9 new citations to articles by Abhik Roychoudhury"]}
{"title": "VulStamp: Vulnerability Assessment using Large Language Model", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "M Hu, X Xie, J Li, M Chen\\xc2\\xa0- arXiv preprint arXiv:2506.11484, 2025\nAlthough modern vulnerability detection tools enable developers to efficiently identify \nnumerous security flaws, indiscriminate remediation efforts often lead to superfluous \ndevelopment expenses. This is particularly true given that a substantial portion of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11484&hl=en&sa=X&d=10210371631874132603&ei=OEhWaLi_HdGM6rQPs-LTyAw&scisig=AAZF9b8D5-GPG5LVOP0Ejn5MaoBB&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "How Does LLM Reasoning Work for Code? A Survey and a Call to Action", "first_label": ["LLM", "Code"], "second_label": ["Reasoning"], "data": "I Ceka, S Pujar, I Manotas, G Kaiser, B Ray, S Ramji\\xc2\\xa0- arXiv preprint arXiv:2506.13932, 2025\nThe rise of large language models (LLMs) has led to dramatic improvements across \na wide range of natural language tasks. These advancements have extended into \nthe domain of code, facilitating complex tasks such as code generation, translation\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13932&hl=en&sa=X&d=2497012154074029495&ei=OEhWaLi_HdGM6rQPs-LTyAw&scisig=AAZF9b-zIykdYpRoGd_3N7etDyJQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Bach Le - new related research", "David Lo - new related research", "Hong Jin Kang - new related research", "9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Andromeda: Debugging Database Performance Issues with Retrieval-Augmented Large Language Models", "first_label": ["LLM", "Bug"], "second_label": [], "data": "P Wang, S Chen, J Fan, B Wu, N Tang, J Tan\\xc2\\xa0- Companion of the 2025 International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDebugging performance issues in a database management system (DBMS) is \ntedious and challenging, even for experienced database administrators (DBAs). \nThus, with the rapid advancement of large language models (LLMs), developing an\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3722212.3725080&hl=en&sa=X&d=11546786090620021914&ei=OEhWaLi_HdGM6rQPs-LTyAw&scisig=AAZF9b9ePwZ-JpKhnVkDq6wmWEpg&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Identifying Open-Source Threat Detection Resources on GitHub: A Scalable Machine Learning Approach", "first_label": [], "second_label": ["Detection"], "data": "M Kern, M Landauer, F Skopik, E Weippl\\xc2\\xa0- International Journal of Information\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMany businesses rely on open-source software modules to build their technology \nstacks. However, those who lack domain expertise may struggle to find the right \nsoftware due to unfamiliar terminology and specific names. As a consequence, \nsearch engines and other platforms often cannot be utilized effectively to discover \nappropriate solutions. There is thus a need for a more applicable approach to assist \nnon-domain experts in navigating the vastness of available repositories, enabling\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTopic Recommendation for GitHub Repositories: How Far Can\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10207-025-01069-1&hl=en&sa=X&d=5522668164929562503&ei=OEhWaJz5DLXCieoPsbu2sQ4&scisig=AAZF9b_4eNRxtIWbbSQ-wamWZZrj&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang", "David Lo - new related research", "4 new citations to articles by Thanh Le-Cong"]}
{"title": "Training Language Models to Generate Quality Code with Program Analysis Feedback", "first_label": ["LLM", "Code"], "second_label": [], "data": "F Yao, Z Wang, L Liu, J Cui, L Zhong, X Fu, H Mai\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode generation with large language models (LLMs), often termed vibe coding, is \nincreasingly adopted in production but fails to ensure code quality, particularly in \nsecurity (eg, SQL injection vulnerabilities) and maintainability (eg, missing type\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22704&hl=en&sa=X&d=13720297852295427429&ei=OEhWaNTwB9zM6rQPmJLS4Q8&scisig=AAZF9b9qU1hJff-ona5ynwmi0w3O&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution", "first_label": ["LLM"], "second_label": [], "data": "Y Wang, Z Peng, Y Wang, Z Wei, H Yu, Z Zhu\\xc2\\xa0- arXiv preprint arXiv:2506.12728, 2025\nLLMs demonstrate strong performance in auto-mated software engineering, \nparticularly for code generation and issue resolution. While proprietary models like \nGPT-4o achieve high benchmarks scores on SWE-bench, their API dependence\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12728&hl=en&sa=X&d=2604248405659445617&ei=OEhWaNTwB9zM6rQPmJLS4Q8&scisig=AAZF9b81DHSvOhQG3is-OJnqV2OF&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=3&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "David Lo - new related research", "4 new citations to articles by Xin ZHOU", "Abhik Roychoudhury - new related research"]}
{"title": "Reductive Analysis with Compiler-Guided Large Language Models for Input-Centric Code Optimizations", "first_label": ["LLM", "Code"], "second_label": [], "data": "X Wang, X Hui, C Liao, X Shen\\xc2\\xa0- Proceedings of the ACM on Programming\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInput-centric program optimization aims to optimize code by considering the relations \nbetween program inputs and program behaviors. Despite its promise, a long-\nstanding barrier for its adoption is the difficulty of automatically identifying critical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729282&hl=en&sa=X&d=4066048552262082451&ei=OEhWaKeTENzM6rQPmJLS4Q8&scisig=AAZF9b_cHHDNeP008iH4qW9Tn7JR&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "BugGen: A Self-Correcting Multi-Agent LLM Pipeline for Realistic RTL Bug Synthesis", "first_label": ["LLM", "Bug"], "second_label": ["Agent"], "data": "S Jasper, M Luu, E Pan, A Tyagi, M Quinn, J Hu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nHardware complexity continues to strain verification resources, motivating the \nadoption of machine learning (ML) methods to improve debug efficiency. However, \nML-assisted debugging critically depends on diverse and scalable bug datasets\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10501&hl=en&sa=X&d=18282061101799185605&ei=OEhWaKeTENzM6rQPmJLS4Q8&scisig=AAZF9b84MK6Vvw_jQZEsGjayFUqG&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "The Foundation Cracks: A Comprehensive Study on Bugs and Testing Practices in LLM Libraries", "first_label": ["LLM", "Bug", "Software Testing"], "second_label": [], "data": "W Jiang, X Zhang, X Xie, J Yu, Y Zhi, S Ma, C Shen\\xc2\\xa0- arXiv preprint arXiv:2506.12320, 2025\nLarge Language Model (LLM) libraries have emerged as the foundational \ninfrastructure powering today's AI revolution, serving as the backbone for LLM \ndeployment, inference optimization, fine-tuning, and production serving across\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12320&hl=en&sa=X&d=16202500750200898582&ei=OEhWaKeTENzM6rQPmJLS4Q8&scisig=AAZF9b--UIAtYzwloYca2LhAL11r&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "Automatic Qiskit Code Refactoring Using Large Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "JM Su\\xc3\\xa1rez, LM Bibb\\xc3\\xb3, J Bogado, A Fernandez\\xc2\\xa0- arXiv preprint arXiv:2506.14535, 2025\nAs quantum software frameworks evolve, developers face increasing challenges in \nmaintaining compatibility with rapidly changing APIs. In this work, we present a novel \nmethodology for refactoring Qiskit code using large language models (LLMs). We\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.14535&hl=en&sa=X&d=4707492068215582196&ei=OEhWaKeTENzM6rQPmJLS4Q8&scisig=AAZF9b8ijIjD2XcJlduBt3t6lA4m&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Incremental learning of code authors over time", "first_label": ["Code"], "second_label": [], "data": "S Gong, H Zhong\\xc2\\xa0- Journal of Systems and Software, 2025\nIdentifying code authors is essential in many research topics, and various \napproaches have been proposed. Recent studies show that the temporal effect can \nsignificantly affect existing approaches: their trained models rapidly become \noutdated and ineffective due to the evolution of code styles over time. To our \nknowledge, only a recent approach tries to alleviate the temporal effect. This \napproach treats the temporal effect problem as a cross-domain problem and uses\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaOn the Usage of Continual Learning for Out-of-Distribution\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225001955&hl=en&sa=X&d=6859829797092896473&ei=OEhWaJvZGaKr6rQP49vTsAY&scisig=AAZF9b9vU0kQT_Q4w4DcQMRitS09&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "VIS-Shepherd: Constructing Critic for LLM-based Data Visualization Generation", "first_label": ["LLM"], "second_label": ["Generation"], "data": "B Pan, Y Fu, K Wang, J Lu, L Pan, Z Qian, Y Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nData visualization generation using Large Language Models (LLMs) has shown \npromising results but often produces suboptimal visualizations that require human \nintervention for improvement. In this work, we introduce VIS-Shepherd, a specialized \nMultimodal Large Language Model (MLLM)-based critic to evaluate and provide \nfeedback for LLM-generated data visualizations. At the core of our approach is a \nframework to construct a high-quality visualization critique dataset, where we collect\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCodeultrafeedback: An llm-as-a-judge dataset for aligning large\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13326&hl=en&sa=X&d=3993740377334061467&ei=OEhWaJvZGaKr6rQP49vTsAY&scisig=AAZF9b8HSCvWaproKnemIEGbLJk1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "MalGuard: Towards Real-Time, Accurate, and Actionable Detection of Malicious Packages in PyPI Ecosystem", "first_label": [], "second_label": ["Detection"], "data": "X Gao, X Sun, S Cao, K Huang, D Wu, X Liu, X Lin\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMalicious package detection has become a critical task in ensuring the security and \nstability of the PyPI. Existing detection approaches have focused on advancing \nmodel selection, evolving from traditional machine learning (ML) models to large \nlanguage models (LLMs). However, as the complexity of the model increases, the \ntime consumption also increases, which raises the question of whether a lightweight \nmodel achieves effective detection. Through empirical research, we demonstrate that\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection and repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.14466&hl=en&sa=X&d=17613968064181352353&ei=OEhWaJvZGaKr6rQP49vTsAY&scisig=AAZF9b9f_Vwoe2-2WKWEQFGCqWDv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=3&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "Using LLMs for Security Advisory Investigations: How Far Are We?", "first_label": ["LLM"], "second_label": [], "data": "BF Abdullah, YS Nugroho, B Reid, RG Kula, K Shimari\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly used in software security, but their \ntrustworthiness in generating accurate vulnerability advisories remains uncertain. \nThis study investigates the ability of ChatGPT to (1) generate plausible security \nadvisories from CVE-IDs,(2) differentiate real from fake CVE-IDs, and (3) extract CVE-\nIDs from advisory descriptions. Using a curated dataset of 100 real and 100 fake \nCVE-IDs, we manually analyzed the credibility and consistency of the model's\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13161&hl=en&sa=X&d=14130687776360958501&ei=OEhWaMicBqu26rQPmuu-OA&scisig=AAZF9b8bF9Czw2J_XQJ4C7dB3TnU&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 new citations to articles by Thanh Le-Cong", "8 new citations to articles by Bach Le"]}
{"title": "Refactor Me If You Can: When AI Rewrites The Mess", "first_label": [], "second_label": [], "data": "E Neman, O Persson\\xc2\\xa0- LU-CS-EX, 2025\nMaintaining the quality of source code through refactoring is an important factor in \nachieving a sustainable software development process. Traditionally, refactoring has \nbeen a manual and time-consuming process, but Large Language Models (LLMs) \nhave shown promising capabilities in many software-related tasks, allowing \ndevelopers to use these models for automatic refactoring. Our research investigates \nthe code refactoring capabilities in improving the maintainability of a large, industrial\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaThanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://lup.lub.lu.se/luur/download%3Ffunc%3DdownloadFile%26recordOId%3D9200106%26fileOId%3D9200112&hl=en&sa=X&d=5695497971825654644&ei=OEhWaMicBqu26rQPmuu-OA&scisig=AAZF9b9a2ah-TzK0eiqGAJIgJAkm&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=2&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 new citations to articles by Thanh Le-Cong", "8 new citations to articles by Bach Le"]}
{"title": "A Framework for Blockchain-Based Secure Management of Mobile Healthcare (mHealth) Systems", "first_label": ["Blockchain"], "second_label": [], "data": "A Alkhalil, A Razzaq, A Ahmad, M Abdelrhman\\xe2\\x80\\xa6\\xc2\\xa0- Journal of Web Engineering, 2025\nIn recent years, several research and development initiatives have focused on \ndeveloping secure and trustworthy systems for the healthcare industry via pervasive \nand mobile healthcare (mHealth) solutions. State-of-the-art mHealth solutions \nprimarily rely on centralized storage, such as cloud computing servers, which may \nescalate the maintenance costs, require ever-increasing storage infrastructure, and \npose privacy and security risks to the health-critical data produced, consumed, and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/10243554/11037625/11037630.pdf&hl=en&sa=X&d=9468542096744583349&ei=OEhWaN3NDr2W6rQPs9Oj8A8&scisig=AAZF9b_hqimMR537VL3R1lifwp88&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=3&folt=cit", "author": ["Bach Le"], "ref": ["8 new citations to articles by Bach Le"]}
{"title": "Reusability in Blockchain", "first_label": ["Blockchain"], "second_label": [], "data": "M Ramachandran\\xc2\\xa0- Blockchain Engineering, 2025\nReusability in blockchain focuses on reusing pre-built components, such as smart \ncontracts, algorithms, and protocols, across multiple dApps. This reduces \ndevelopment time, cuts costs, and enhances system efficiency. The chapter \nintroduces Smart Contract as a Service (SCaaS), which provides reusable smart \ncontract templates to developers. Reusability aligns with blockchain sustainability by \nlowering energy consumption and promoting long-term system scalability. By\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-96-4360-8_6&hl=en&sa=X&d=169691411675943046&ei=OEhWaN3NDr2W6rQPs9Oj8A8&scisig=AAZF9b8gdEyXnNgDlZdiHIDoIcke&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=4&folt=cit", "author": ["Bach Le"], "ref": ["8 new citations to articles by Bach Le"]}
{"title": "The Socio-Economic Impact of Metaverse Technologies on Financial Institutions and Public Investments", "first_label": [], "second_label": [], "data": "AL Paul\nThe metaverse, an emerging digital frontier, is transforming how individuals, \nbusinesses, and governments interact in virtual environments. Envisioned as \ninterconnected immersive spaces enabled by technologies such as virtual reality \n(VR), augmented reality (AR), blockchain, and artificial intelligence (AI), the \nmetaverse is rapidly expanding beyond entertainment into sectors including finance \nand public governance. As financial institutions and public investors increasingly\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Anthony-Paul-2/publication/392704384_The_Socio-Economic_Impact_of_Metaverse_Technologies_on_Financial_Institutions_and_Public_Investments/links/684e6dc711be4823fbde7b68/The-Socio-Economic-Impact-of-Metaverse-Technologies-on-Financial-Institutions-and-Public-Investments.pdf&hl=en&sa=X&d=18375581120918309044&ei=OEhWaN3NDr2W6rQPs9Oj8A8&scisig=AAZF9b9BgvfNegcnMM0BIFEYKZN7&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=5&folt=cit", "author": ["Bach Le"], "ref": ["8 new citations to articles by Bach Le"]}
{"title": "Ethical Implications of AI-Driven Investment Tools in Public Sector Finance", "first_label": [], "second_label": [], "data": "R Ajax\nArtificial Intelligence (AI) is rapidly transforming public sector finance by enhancing \ninvestment analysis, improving resource allocation, and fostering data-driven \npolicymaking. However, the adoption of AI-driven investment tools also raises \npressing ethical concerns, particularly around algorithmic bias, transparency, \naccountability, data privacy, and public trust. As governments increasingly rely on AI \nto guide critical investment decisions, there is a growing need to scrutinize the ethical\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Raymond-Ajax/publication/392705933_Ethical_Implications_of_AI-Driven_Investment_Tools_in_Public_Sector_Finance/links/684e708e474abd185bd8e433/Ethical-Implications-of-AI-Driven-Investment-Tools-in-Public-Sector-Finance.pdf&hl=en&sa=X&d=10977577863542065423&ei=OEhWaN3NDr2W6rQPs9Oj8A8&scisig=AAZF9b9P-9xGKMtRMTb2FccLYqc6&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=6&folt=cit", "author": ["Bach Le"], "ref": ["8 new citations to articles by Bach Le"]}
{"title": "KRAKEN: Program-Adaptive Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A ZHOU, H HUANG, C ZHANG - 2025\nDespite numerous advances, most existing fuzzers still require more than 24 hours to \nthoroughly test the target programs to achieve satisfactory code coverage or bug \ndetection results [7, 32, 42, 64]. Recently, as cloud-based computing and multicore\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://seviezhou.github.io/files/kraken.pdf&hl=en&sa=X&d=6944396394299119143&ei=OEhWaNyHF-Ws6rQPkO7OyQk&scisig=AAZF9b9QILhkfV1b1x87AW8NkoEo&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Levels of Autonomy for AI Agents", "first_label": [], "second_label": ["Agent"], "data": "KJ Feng, DW McDonald, AX Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.12469, 2025\nAutonomy is a double-edged sword for AI agents, simultaneously unlocking \ntransformative possibilities and serious risks. How can agent developers calibrate \nthe appropriate levels of autonomy at which their agents should operate? We argue \nthat an agent's level of autonomy can be treated as a deliberate design decision, \nseparate from its capability and operational environment. In this work, we define five \nlevels of escalating agent autonomy, characterized by the roles a user can take when\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaVoice-Enabled AI Agents can Perform Common Scams\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12469&hl=en&sa=X&d=4354226690169182572&ei=OEhWaM_KCdGM6rQPs-LTyAw&scisig=AAZF9b-wYASRN4tKQ1VBXhiunkjk&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "SoK: The Privacy Paradox of Large Language Models: Advancements, Privacy Risks, and Mitigation", "first_label": ["LLM"], "second_label": [], "data": "Y Shanmugarasa, M Ding, MA Chamikara\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are sophisticated artificial intelligence systems that \nenable machines to generate human-like text with remarkable precision. While LLMs \noffer significant technological progress, their development using vast amounts of \nuser data scraped from the web and collected from extensive user interactions poses \nrisks of sensitive information leakage. Most existing surveys focus on the privacy \nimplications of the training data but tend to overlook privacy risks from user\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12699&hl=en&sa=X&d=11967645710981260650&ei=OEhWaM_KCdGM6rQPs-LTyAw&scisig=AAZF9b87RGce-US28ZZYdxSpzFit&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "From Promise to Peril: Rethinking Cybersecurity Red and Blue Teaming in the Age of LLMs", "first_label": ["LLM"], "second_label": [], "data": "A Abuadbba, C Hicks, K Moore, V Mavroudis\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are set to reshape cybersecurity by augmenting red \nand blue team operations. Red teams can exploit LLMs to plan attacks, craft phishing \ncontent, simulate adversaries, and generate exploit code. Conversely, blue teams \nmay deploy them for threat intelligence synthesis, root cause analysis, and \nstreamlined documentation. This dual capability introduces both transformative \npotential and serious risks. This position paper maps LLM applications across\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13434&hl=en&sa=X&d=2343985441905369680&ei=OEhWaM_KCdGM6rQPs-LTyAw&scisig=AAZF9b8oPWwA51ZflAK-U8wHonyY&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=2&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "AIRTBench: Measuring Autonomous AI Red Teaming Capabilities in Language Models", "first_label": ["LLM"], "second_label": [], "data": "A Dawson, R Mulla, N Landers, S Caldwell\\xc2\\xa0- arXiv preprint arXiv:2506.14682, 2025\nWe introduce AIRTBench, an AI red teaming benchmark for evaluating language \nmodels' ability to autonomously discover and exploit Artificial Intelligence and \nMachine Learning (AI/ML) security vulnerabilities. The benchmark consists of 70 \nrealistic black-box capture-the-flag (CTF) challenges from the Crucible challenge \nenvironment on the Dreadnode platform, requiring models to write python code to \ninteract with and compromise AI systems. Claude-3.7-Sonnet emerged as the clear\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites, 2024\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.14682&hl=en&sa=X&d=6408004129682148587&ei=OEhWaM_KCdGM6rQPs-LTyAw&scisig=AAZF9b8JqinYoexQ1D3nksq_I-Lu&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=3&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "VulBinLLM: LLM-powered Vulnerability Detection for Stripped Binaries", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "N Hussain, H Chen, C Tran, P Huang, Z Li, P Chugh\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecognizing vulnerabilities in stripped binary files presents a significant challenge in \nsoftware security. Although some progress has been made in generating human-\nreadable information from decompiled binary files with Large Language Models\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22010&hl=en&sa=X&d=10332909566617513173&ei=OEhWaKX4CuWs6rQPkO7OyQk&scisig=AAZF9b_uFh0VfBD1MzUN8jZA2T1m&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Rethinking the effects of data contamination in Code Intelligence", "first_label": ["Code"], "second_label": [], "data": "Z Yang, H Lin, Y He, J Xu, Z Sun, S Liu, P Wang, Z Yu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, code intelligence has gained increasing importance in the field of \nautomated software engineering. Meanwhile, the widespread adoption of Pretrained \nLanguage Models (PLMs) and Large Language Models (LLMs) has raised concerns\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02791&hl=en&sa=X&d=13914802631128746138&ei=OEhWaKX4CuWs6rQPkO7OyQk&scisig=AAZF9b9FbJDsSBQv15gRiA2JZNoe&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Anticipating Bugs: Ticket-Level Bug Prediction and Temporal Proximity Effects", "first_label": ["Bug"], "second_label": [], "data": "D La Prova, E Gentili, D Falessi\\xc2\\xa0- arXiv preprint arXiv:2506.14290, 2025\nThe primary goal of bug prediction is to optimize testing efforts by focusing on \nsoftware fragments, ie, classes, methods, commits (JIT), or lines of code, most likely \nto be buggy. However, these predicted fragments already contain bugs. Thus, the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.14290&hl=en&sa=X&d=7204056426952972327&ei=OEhWaKjnIPiJ6rQPh4zZ-Q8&scisig=AAZF9b-nd66JTlFIYlSHEhatnchG&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Quality Assessment of Python Tests Generated by Large Language Models", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "V Alves, C Bezerra, I Machado, L Rocha, T Virg\\xc3\\xadnio\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe manual generation of test scripts is a time-intensive, costly, and error-prone \nprocess, indicating the value of automated solutions. Large Language Models \n(LLMs) have shown great promise in this domain, leveraging their extensive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.14297&hl=en&sa=X&d=16755182731362667839&ei=OEhWaKjnIPiJ6rQPh4zZ-Q8&scisig=AAZF9b-bNUeNhFbiN2vZE3g48XeI&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Cloud Infrastructure Management in the Age of AI Agents", "first_label": [], "second_label": ["Agent"], "data": "Z Yang, A Bhatnagar, Y Qiu, T Miao, PTJ Kon, Y Xiao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCloud infrastructure is the cornerstone of the modern IT industry. However, managing \nthis infrastructure effectively requires considerable manual effort from the DevOps \nengineering team. We make a case for developing AI agents powered by large \nlanguage models (LLMs) to automate cloud infrastructure management tasks. In a \npreliminary study, we investigate the potential for AI agents to use different \ncloud/user interfaces such as software development kits (SDK), command line\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12270&hl=en&sa=X&d=14154561214130906357&ei=OEhWaO2EE6y16rQPzoCEgAc&scisig=AAZF9b_ifNq7e6gvpHIbtDlSaqx6&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Validating Interior Gateway Routing Protocols via Equivalent Topology Synthesis", "first_label": [], "second_label": [], "data": "B Shui, Y Zhou, J Wu, B Xu, Q Shi - 2025\nRouters, relying on routing protocols to determine how data packets travel across the \nInternet, serve as the backbone of modern networks. Vulnerable routing protocols \ncan lead to serious consequences, including data leaks and network congestion. \nThis work focuses on validating the implementation of a key class of routing protocols \nknown as Interior Gateway Protocols (IGPs). Unlike communication protocols such as \nTCP/IP, which define structured data packets and state machines to facilitate\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://qingkaishi.github.io/public_pdfs/CCS25.pdf&hl=en&sa=X&d=9088400310116954429&ei=OEhWaO2EE6y16rQPzoCEgAc&scisig=AAZF9b9Rkp6Qjekan02jkyADwsSr&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "SmartGuard: Making Prediction Verifiable through Transaction Sequences for Smart Contract Vulnerability Detection", "first_label": ["Vulnerabilities", "Smart Contracts"], "second_label": ["Detection"], "data": "J Chen, L Wang, H Zhu\\xc2\\xa0- IEEE Transactions on Information Forensics and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeep learning-based detectors have been widely proposed to predict vulnerabilities \nin smart contracts, yet their unreliable predictions pose severe security risks to \nfinancial transactions, making it critical to verify the reliability of vulnerability \npredictions. However, existing methods only produce prediction results, failing to \nprovide an evidence chain to check whether these predicted vulnerabilities \ngenuinely exist and deliver further guidance for fixing the vulnerabilities. Thus\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaNeuro-Symbolic Execution: Augmenting Symbolic Execution with\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11037432/&hl=en&sa=X&d=9556333083731351634&ei=OEhWaO2EE6y16rQPzoCEgAc&scisig=AAZF9b-YtrjQ3BDeJ28ZrSzr_tJq&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "INCOGNITOS: A Practical Unikernel Design for Full-System Obfuscation in Confidential Virtual Machines", "first_label": [], "second_label": [], "data": "KD Duy, J Kim, H Lim, H Lee\\xc2\\xa0- 2025 IEEE Symposium on Security and Privacy (SP), 2025\nRecent works have repeatedly proven the practicality of side-channel attacks in \nundermining the confidentiality guarantees of Trusted Execution Environments such \nas Intel SGX. Meanwhile, the trusted execution in the cloud is witnessing a trend shift \ntowards confidential virtual machines (CVMs). Unfortunately, several side-channel \nattacks have survived the shift and are feasible even for CVMs, along with the new \nattacks discovered on the CVM architectures. Previous works have explored\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBinary Rewriting without Control Flow Recovery\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11023442/&hl=en&sa=X&d=2075140509109417497&ei=OEhWaO2EE6y16rQPzoCEgAc&scisig=AAZF9b8N4mQwvAYfF5AA4TbHWwW0&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Variability Fault Localization by Abstract Interpretation and its Application to SPL Repair", "first_label": ["Fault Localization"], "second_label": ["Repair", "Localization"], "data": "AS Dimovski\\xc2\\xa0- Proceedings of the 18th ACM SIGPLAN International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFault localization is an important step in software debugging that aims to isolate and \nlocalize the bugs (errors) to a small part of the program. This becomes more \nchallenging in Software Product Lines (SPLs) due to the variable nature of bugs (so-\ncalled variability bugs). This paper introduces a novel variability fault localization \nalgorithm for SPLs. Moreover, we present its practical application for automatic repair \nof variability bugs in SPLs. Given a buggy SPL (program family) and an assertion to\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSemFix: Program Repair via Semantic Analysis\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3732771.3742722&hl=en&sa=X&d=16258344081663943125&ei=OEhWaO2EE6y16rQPzoCEgAc&scisig=AAZF9b9wdu8ALSmJOPUFmhWGRx81&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Your Agent Can Defend Itself against Backdoor Attacks", "first_label": [], "second_label": ["Agent"], "data": "L Changjiang, L Jiacheng, C Bochuan, C Jinghui\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite their growing adoption across domains, large language model (LLM)-\npowered agents face significant security risks from backdoor attacks during training \nand fine-tuning. These compromised agents can subsequently be manipulated to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08336&hl=en&sa=X&d=9281612337423238890&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b8EnIakTDvZQGsyv1duPVA5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Adversarial Preference Learning for Robust LLM Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Wang, P Wang, C Xi, B Tang, J Zhu, W Wei, C Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern language models often rely on Reinforcement Learning from Human \nFeedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to \nadversarial attacks due to three key limitations:(1) the inefficiency and high cost of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24369%3F&hl=en&sa=X&d=11526575995055803369&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b_ilBi9AMSJoKPXxHc_hWg5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SecurityLingua: Efficient Defense of LLM Jailbreak Attacks via Security-Aware Prompt Compression", "first_label": ["LLM"], "second_label": [], "data": "Y Li, S Ahn, H Jiang, AH Abdi, Y Yang, L Qiu\\xc2\\xa0- arXiv preprint arXiv:2506.12707, 2025\nLarge language models (LLMs) have achieved widespread adoption across \nnumerous applications. However, many LLMs are vulnerable to malicious attacks \neven after safety alignment. These attacks typically bypass LLMs' safety guardrails by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12707&hl=en&sa=X&d=8418273368991399970&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b8AOJ5PQ2S2DYr5nVOYpqTl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge", "first_label": ["LLM"], "second_label": [], "data": "S Li, C Xu, J Wang, X Gong, C Chen, J Zhang, J Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable intelligence across \nvarious tasks, which has inspired the development and widespread adoption of LLM-\nas-a-Judge systems for automated model testing, such as red teaming and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09443&hl=en&sa=X&d=2052322274134661445&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b9u9cyhYi06xXXt37CLZpdh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Syntactic paraphrase-based synthetic data generation for backdoor attacks against Chinese language models", "first_label": ["LLM"], "second_label": ["Generation"], "data": "M Hu, Y Yang, D Pan, Z Guo, L Xiao, D Lin, S Zhao\\xc2\\xa0- Information Fusion, 2025\nAbstract Language Models (LMs) have shown significant advancements in various \nNatural Language Processing (NLP) tasks. However, recent studies indicate that \nLMs are particularly susceptible to malicious backdoor attacks, where attackers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S156625352500449X&hl=en&sa=X&d=11939540759867308872&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b_omHEFDqgnSwVne_pfKwnY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Yuan, Y Xu, J Shi, P Zhou, L Sun\\xc2\\xa0- arXiv preprint arXiv:2505.23561, 2025\nModel merging for Large Language Models (LLMs) directly fuses the parameters of \ndifferent models finetuned on various tasks, creating a unified model for multi-domain \ntasks. However, due to potential vulnerabilities in models available on open-source\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23561&hl=en&sa=X&d=6617189016454156514&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b-hKaNf3ql6GqPXtJeaxsCC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Through the Stealth Lens: Rethinking Attacks and Defenses in RAG", "first_label": [], "second_label": [], "data": "S Choudhary, N Palumbo, A Hooda, KD Dvijotham\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRetrieval-augmented generation (RAG) systems are vulnerable to attacks that inject \npoisoned passages into the retrieved set, even at low corruption rates. We show that \nexisting attacks are not designed to be stealthy, allowing reliable detection and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04390&hl=en&sa=X&d=15468735482968103516&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b8u2OUJdUy7skXRySPRbZz3&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments", "first_label": [], "second_label": ["Agent"], "data": "X Wang, S Liang, Z Liu, Y Yu, Y Lu, X Cao, EC Chang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the growing integration of vision-language models (VLMs), mobile agents are \nnow widely used for tasks like UI automation and camera-based user assistance. \nThese agents are often fine-tuned on limited user-generated datasets, leaving them\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.13205&hl=en&sa=X&d=16051255714568695875&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b_TBjYkLf7UFyh9GNeX1Max&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Cost of Dynamic Reasoning: Demystifying AI Agents and Test-Time Scaling from an AI Infrastructure Perspective", "first_label": ["Software Testing"], "second_label": ["Agent", "Reasoning"], "data": "J Kim, B Shin, J Chung, M Rhu\\xc2\\xa0- arXiv preprint arXiv:2506.04301, 2025\nLarge-language-model (LLM)-based AI agents have recently showcased impressive \nversatility by employing dynamic reasoning, an adaptive, multi-step process that \ncoordinates with external tools. This shift from static, single-turn inference to agentic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04301&hl=en&sa=X&d=3072272730677106970&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b-t8XUoljKdp6JjL-hJnilf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SLADE: Shielding against Dual Exploits in Large Vision-Language Models", "first_label": ["LLM"], "second_label": ["Exploit"], "data": "MZ Hossain, A Imteaj\\xc2\\xa0- Proceedings of the Computer Vision and Pattern\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAbstract Large Vision-Language Models (LVLMs) have emerged as transformative \ntools in multimodal tasks, seamlessly integrating pretrained vision encoders to align \nvisual and textual modalities. Prior works have highlighted the susceptibility of\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/CVPR2025/papers/Hossain_SLADE_Shielding_against_Dual_Exploits_in_Large_Vision-Language_Models_CVPR_2025_paper.pdf&hl=en&sa=X&d=15365021744232455122&ei=OEhWaJKrG6u26rQPmuu-OA&scisig=AAZF9b_1fJe7OwiXTJjiVzlLPECb&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
