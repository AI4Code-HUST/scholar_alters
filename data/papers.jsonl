{"title": "Generating High-Quality Datasets for Code Editing via Open-Source Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "Z Zhang, M Liu, Z Chen, L Liang, Y Chen, G Ou- arXiv preprint arXiv, 2025\nCode editing plays a vital role in software engineering, requiring developers to adjust \nexisting code according to natural language instructions while keeping functionality \nintact and avoiding unnecessary modifications. However, commit-based datasets", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25203&hl=en&sa=X&d=16003307718581653243&ei=bmjzaKa5AoeVieoP9e_euQw&scisig=AAZF9b-WX82g5S_NgG548uiHBBUN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Hong Jin Kang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Diff-XYZ: A Benchmark for Evaluating Diff Understanding", "first_label": [], "second_label": [], "data": "E Glukhov, M Conti, E Bogomolov, Y Golubev- arXiv preprint arXiv, 2025\nReliable handling of code diffs is central to agents that edit and refactor repositories \nat scale. We introduce Diff-XYZ, a compact benchmark for code-diff understanding \nwith three supervised tasks: apply (old code $+ $ diff $\\rightarrow $ new code), anti", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12487&hl=en&sa=X&d=3268743020705423081&ei=bmjzaKa5AoeVieoP9e_euQw&scisig=AAZF9b-lJb8O-WEuxQCcZewfAK_v&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Multi Language Models for On-the-Fly Syntax Highlighting", "first_label": ["LLM"], "second_label": [], "data": "ME Palma, P Rani, HC Gall- arXiv preprint arXiv:2510.04166, 2025\nSyntax highlighting is a critical feature in modern software development \nenvironments, enhancing code readability and developer productivity. However, \ndelivering accurate highlighting in real time remains challenging for online and web", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04166&hl=en&sa=X&d=2254729212502568662&ei=bmjzaKa5AoeVieoP9e_euQw&scisig=AAZF9b-SZy6QCdbolKYgV0xZsjiV&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "What Do They Fix? LLM-Aided Categorization of Security Patches for Critical Memory Bugs", "first_label": ["LLM", "Bug"], "second_label": [], "data": "X Li, J Pu, Y Wu, X Zou, S Zhu, Q Wu, Z Zhang, J Hsu- arXiv preprint arXiv, 2025\nOpen-source software projects are foundational to modern software ecosystems, with \nthe Linux kernel standing out as a critical exemplar due to its ubiquity and \ncomplexity. Although security patches are continuously integrated into the Linux\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22796&hl=en&sa=X&d=5877456260761011502&ei=bmjzaKa5AoeVieoP9e_euQw&scisig=AAZF9b_K5bVx20Ft-L-epPjLrGqv&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=3&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "From Defender to Devil? Unintended Risk Interactions Induced by LLM Defenses", "first_label": ["LLM"], "second_label": [], "data": "X Meng, T Cong, L Wang, W Chen, Z Li, S Guo- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have shown remarkable performance across \nvarious applications, but their deployment in sensitive domains raises significant \nconcerns. To mitigate these risks, numerous defense strategies have been proposed", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07968&hl=en&sa=X&d=16628375445005170696&ei=cGjzaNywK52k6rQPiNutyQc&scisig=AAZF9b-769OFYdciBP8asq-WL4LX&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "HarmMetric Eval: Benchmarking Metrics and Judges for LLM Harmfulness Assessment", "first_label": ["LLM"], "second_label": [], "data": "L Yang, T Zheng, K Xiu, Y Chen, D Wang, P Zhao- arXiv preprint arXiv, 2025\nThe alignment of large language models (LLMs) with human values is critical for their \nsafe deployment, yet jailbreak attacks can subvert this alignment to elicit harmful \noutputs from LLMs. In recent years, a proliferation of jailbreak attacks has emerged", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24384%3F&hl=en&sa=X&d=6954529287697046870&ei=cGjzaNywK52k6rQPiNutyQc&scisig=AAZF9b9dFauzR9dpBNzzfY8bDWby&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration", "first_label": ["LLM"], "second_label": ["Agent"], "data": "X Chen, J Zhao, Y Yuan, T Zhang, H Zhou, Z Zhu, P Hu- arXiv preprint arXiv, 2025\nExisting safety evaluation methods for large language models (LLMs) suffer from \ninherent limitations, including evaluator bias and detection failures arising from \nmodel homogeneity, which collectively undermine the robustness of risk evaluation", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25271%3F&hl=en&sa=X&d=9498150266007123670&ei=cGjzaNywK52k6rQPiNutyQc&scisig=AAZF9b95zCxcGgN2hu1swbKS_h_V&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Formalization Driven LLM Prompt Jailbreaking via Reinforcement Learning", "first_label": ["LLM"], "second_label": [], "data": "Z Wang, D He, Z Zhang, X Li, L Zhu, M Li, J Liu- arXiv preprint arXiv:2509.23558, 2025\nLarge language models (LLMs) have demonstrated remarkable capabilities, yet they \nalso introduce novel security challenges. For instance, prompt jailbreaking attacks \ninvolve adversaries crafting sophisticated prompts to elicit responses from LLMs that", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23558%3F&hl=en&sa=X&d=2749826917926664463&ei=cGjzaNywK52k6rQPiNutyQc&scisig=AAZF9b9socy1uU0idrQjXea7u6Gn&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Defeating Cerberus: Concept-Guided Privacy-Leakage Mitigation in Multimodal Language Models", "first_label": ["LLM"], "second_label": [], "data": "B Zhang, IE Akkus, R Chen, A Dethise, K Satzke- arXiv preprint arXiv, 2025\nMultimodal large language models (MLLMs) have demonstrated remarkable \ncapabilities in processing and reasoning over diverse modalities, but their advanced \nabilities also raise significant privacy concerns, particularly regarding Personally", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25525%3F&hl=en&sa=X&d=188731358198544290&ei=cGjzaNywK52k6rQPiNutyQc&scisig=AAZF9b83Zm3Lci4vXc2-RuCtKxTZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Proactive defense against LLM Jailbreak", "first_label": ["LLM"], "second_label": [], "data": "W Zhao, J Peng, D Ben-Levi, Z Yu, J Yang- arXiv preprint arXiv:2510.05052, 2025\nThe proliferation of powerful large language models (LLMs) has necessitated robust \nsafety alignment, yet these models remain vulnerable to evolving adversarial attacks, \nincluding multi-turn jailbreaks that iteratively search for successful queries. Current", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05052&hl=en&sa=X&d=12643963361954479351&ei=cGjzaNywK52k6rQPiNutyQc&scisig=AAZF9b8Coa_W30rxK1WFNlFrrWpl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Microsaccade-Inspired Probing: Positional Encoding Perturbations Reveal LLM Misbehaviours", "first_label": ["LLM"], "second_label": [], "data": "R Melo, R Abreu, CS Pasareanu- arXiv preprint arXiv:2510.01288, 2025\nWe draw inspiration from microsaccades, tiny involuntary eye movements that reveal \nhidden dynamics of human perception, to propose an analogous probing method for \nlarge language models (LLMs). Just as microsaccades expose subtle but informative", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01288&hl=en&sa=X&d=4079834350174690212&ei=cGjzaNywK52k6rQPiNutyQc&scisig=AAZF9b8rbcS03ioCYUn4xb7F5XTc&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM Unlearning Under the Microscope: A Full-Stack View on Methods and Metrics", "first_label": ["LLM"], "second_label": [], "data": "C Fan, C Wang, Y Huang, S Pal, S Liu- arXiv preprint arXiv:2510.07626, 2025\nMachine unlearning for large language models (LLMs) aims to remove undesired \ndata, knowledge, and behaviors (eg, for safety, privacy, or copyright) while \npreserving useful model capabilities. Despite rapid progress over the past two years", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07626&hl=en&sa=X&d=2219175947074663426&ei=cGjzaNywK52k6rQPiNutyQc&scisig=AAZF9b8K58fohUV3HCgE5BozXqN8&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SWE-QA: Can Language Models Answer Repository-level Code Questions?", "first_label": ["LLM", "Code", "Repository-Level"], "second_label": [], "data": "W Peng, Y Shi, Y Wang, X Zhang, B Shen, X Gu- arXiv preprint arXiv:2509.14635, 2025\nUnderstanding and reasoning about entire software repositories is an essential \ncapability for intelligent software engineering tools. While existing benchmarks such \nas CoSQA and CodeQA have advanced the field, they predominantly focus on small", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.14635&hl=en&sa=X&d=15006803551698078506&ei=cGjzaNywK52k6rQPiNutyQc&scisig=AAZF9b-gcqnrJWuOC2cDSJR6nYNt&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research", "Bach Le - new related research"]}
{"title": "A2D: Any-Order, Any-Step Safety Alignment for Diffusion Language Models", "first_label": ["LLM"], "second_label": [], "data": "W Jeung, S Yoon, Y Cho, D Jeon, S Shin, H Hong- arXiv preprint arXiv, 2025\nDiffusion large language models (dLLMs) enable any-order generation, but this \nflexibility enlarges the attack surface: harmful spans may appear at arbitrary \npositions, and template-based prefilling attacks such as DIJA bypass response-level\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23286&hl=en&sa=X&d=16977104919503302935&ei=cGjzaNywK52k6rQPiNutyQc&scisig=AAZF9b-9ssXxkPlc54WBS9-P-Zx-&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Semantic-Aware Fuzzing: An Empirical Framework for LLM-Guided, Reasoning-Driven Input Mutation", "first_label": ["LLM", "Fuzzing"], "second_label": ["Reasoning"], "data": "M Lu, S Ding, F Alaca, P Charland- arXiv preprint arXiv:2509.19533, 2025\nSecurity vulnerabilities in Internet-of-Things devices, mobile platforms, and \nautonomous systems remain critical. Traditional mutation-based fuzzers--while \neffectively explore code paths--primarily perform byte-or bit-level edits without", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19533%3F&hl=en&sa=X&d=537743905954534716&ei=cGjzaPKJBO2ZieoP7ueJyQk&scisig=AAZF9b_eToZ4RmutapvruNcVtSkV&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "MALF: A Multi-Agent LLM Framework for Intelligent Fuzzing of Industrial Control Protocols", "first_label": ["LLM", "Fuzzing"], "second_label": ["Agent"], "data": "B Ning, X Zong, K He- arXiv preprint arXiv:2510.02694, 2025\nIndustrial control systems (ICS) are vital to modern infrastructure but increasingly \nvulnerable to cybersecurity threats, particularly through weaknesses in their \ncommunication protocols. This paper presents MALF (Multi-Agent LLM Fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02694&hl=en&sa=X&d=17402884467768873558&ei=cGjzaPKJBO2ZieoP7ueJyQk&scisig=AAZF9b-gbdcp8la6VIQjpMAaZGFm&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "STAFF: Stateful Taint-Assisted Full-system Firmware Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A Izzillo, R Lazzeretti, E Coppa- arXiv preprint arXiv:2509.18039, 2025\nModern embedded Linux devices, such as routers, IP cameras, and IoT gateways, \nrely on complex software stacks where numerous daemons interact to provide \nservices. Testing these devices is crucial from a security perspective since vendors", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18039&hl=en&sa=X&d=14471577617811823956&ei=cGjzaPKJBO2ZieoP7ueJyQk&scisig=AAZF9b8iiNsdPIPeQqPwlBXEq_w5&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Minoris: Practical Out-of-Emulator Kernel Module Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Xiang, F Wang, Y Chen, Q Liu, H Wang, J Wang- IEEE Transactions on, 2025\nVulnerabilities in the Linux kernel can be exploited to perform privilege escalation \nand take over the whole system. Fuzzing has been leveraged to detect Linux kernel \nvulnerabilities during the last decade. However, existing kernel fuzzing techniques", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11186228/&hl=en&sa=X&d=4018952161547770155&ei=cGjzaPKJBO2ZieoP7ueJyQk&scisig=AAZF9b_CC9xKPQgXt0Ya_fO_Yt6g&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Evaluating the Effectiveness of Coverage-Guided Fuzzing for Testing Deep Learning Library APIs", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "F Qin, MM Naziri, H Ai, S Dutta, M d'Amorim- arXiv preprint arXiv:2509.14626, 2025\nDeep Learning (DL) libraries such as PyTorch provide the core components to build \nmajor AI-enabled applications. Finding bugs in these libraries is important and \nchallenging. Prior approaches have tackled this by performing either API-level", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.14626&hl=en&sa=X&d=11350896954294303435&ei=cGjzaPKJBO2ZieoP7ueJyQk&scisig=AAZF9b_GT4mzQ2w1NTOQ8RIfpK9G&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "David Lo - new related research"]}
{"title": "Extraction and Mutation at a High Level: Template-Based Fuzzing for JavaScript Engines", "first_label": ["Fuzzing"], "second_label": [], "data": "WK Wong, D Xiao, CT Lai, Y Peng, D Wu, S Wang- Proceedings of the ACM on, 2025\nJavaScript (JS) engines implement complex language semantics and optimization \nstrategies to support the dynamic nature of JS, making them difficult to test thoroughly \nand prone to subtle, security-critical bugs. Existing fuzzers often struggle to generate", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3763154&hl=en&sa=X&d=604366854830515299&ei=cGjzaPKJBO2ZieoP7ueJyQk&scisig=AAZF9b-zybHDhCRxUx1hTq5-Uny_&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "R1-Fuzz: Specializing Language Models for Textual Fuzzing via Reinforcement Learning", "first_label": ["LLM", "Fuzzing"], "second_label": [], "data": "J Lin, L Su, J Li, C Qian- arXiv preprint arXiv:2509.20384, 2025\nFuzzing is effective for vulnerability discovery but struggles with complex targets such \nas compilers, interpreters, and database engines, which accept textual input that \nmust satisfy intricate syntactic and semantic constraints. Although language models", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.20384&hl=en&sa=X&d=1649136629077213896&ei=cGjzaPKJBO2ZieoP7ueJyQk&scisig=AAZF9b9A_fC3MFUyhQ5sK9VXroDy&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=6&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "E-FuzzEdge: Optimizing Embedded Device Security with Scalable In-Place Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "D Rusconi, O Yousef, M Picca, F Toffalini, A Lanzi- arXiv preprint arXiv:2510.01393, 2025\nIn this paper we show E-FuzzEdge, a novel fuzzing architecture targeted towards \nimproving the throughput of fuzzing campaigns in contexts where scalability is \nunavailable. E-FuzzEdge addresses the inefficiencies of hardware-in-the-loop", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01393&hl=en&sa=X&d=876126288656849057&ei=cGjzaPKJBO2ZieoP7ueJyQk&scisig=AAZF9b8HafEkkmQjPmdiYY4QT43e&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=7&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Clutch Control: An Attention-based Combinatorial Bandit for Efficient Mutation in JavaScript Engine Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "M Foley, S Maffeis, MF Rozi, T Takahashi- arXiv preprint arXiv:2510.12732, 2025\nJavaScript engines are widely used in web browsers, PDF readers, and server-side \napplications. The rise in concern over their security has led to the development of \nseveral targeted fuzzing techniques. However, existing approaches use random", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12732&hl=en&sa=X&d=1368299778829400409&ei=cGjzaPKJBO2ZieoP7ueJyQk&scisig=AAZF9b-4A-Be966_j6dsNuC_iOPC&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=8&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "6 new citations to articles by Abhik Roychoudhury", "2 new citations to articles by Hong Jin Kang"]}
{"title": "DFAFUZZ: Fuzzing for Embedded JavaScript Virtual Machines with Type-Directed DFA", "first_label": ["Fuzzing"], "second_label": [], "data": "H Lai, B Hua\nJavaScript is rapidly being deployed in securitycritical embedded domains, including \nIoT devices, edge computing, and smart automotive applications. Embedded \nJavaScript virtual machines (VMs) are critical in powering such deployments, which\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://csslab-ustc.github.io/publications/2025/js-vm-bugs.pdf&hl=en&sa=X&d=14086662969394613156&ei=cGjzaPKJBO2ZieoP7ueJyQk&scisig=AAZF9b_N79M1UHX5bgLAcXN1CDD7&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=9&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "6 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Survey of Vibe Coding with Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Y Ge, L Mei, Z Duan, T Li, Y Zheng, Y Wang, L Wang- arXiv preprint arXiv, 2025\nThe advancement of large language models (LLMs) has catalyzed a paradigm shift \nfrom code generation assistance to autonomous coding agents, enabling a novel \ndevelopment methodology termed\" Vibe Coding\" where developers validate AI", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12399&hl=en&sa=X&d=1219463424960778158&ei=b2jzaMCuFoOAieoPtpDVoA0&scisig=AAZF9b99VNSZwjrivbFRYGvFXvzo&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "2 new citations to articles by Xin ZHOU", "4 new citations to articles by Richard Fang", "6 new citations to articles by Abhik Roychoudhury"]}
{"title": "RelRepair: Enhancing Automated Program Repair by Retrieving Relevant Code", "first_label": ["APR", "Code"], "second_label": ["Repair"], "data": "S Liu, G Bai, M Utting, G Yang- arXiv preprint arXiv:2509.16701, 2025\nAutomated Program Repair (APR) has emerged as a promising paradigm for \nreducing debugging time and improving the overall efficiency of software \ndevelopment. Recent advances in Large Language Models (LLMs) have", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.16701&hl=en&sa=X&d=15347269361517940440&ei=b2jzaMCuFoOAieoPtpDVoA0&scisig=AAZF9b8vu1eZydL8Y3sfpnI8ZfQS&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "AgentPack: A Dataset of Code Changes, Co-Authored by Agents and Humans", "first_label": ["Code", "Code Change"], "second_label": ["Agent"], "data": "Y Zi, Z Wu, A Boruch-Gruszecki, J Bell, A Guha- arXiv preprint arXiv:2509.21891, 2025\nFine-tuning large language models for code editing has typically relied on mining \ncommits and pull requests. The working hypothesis has been that commit messages \ndescribe human intent in natural language, and patches to code describe the\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.21891&hl=en&sa=X&d=8401534489153068556&ei=b2jzaMCuFoOAieoPtpDVoA0&scisig=AAZF9b8yVBL1R6bjr0bbMiiuPEz9&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "iCodeReviewer: Improving Secure Code Review with Mixture of Prompts", "first_label": ["Code Review", "Code"], "second_label": [], "data": "Y Peng, K Kim, L Meng, K Liu- arXiv preprint arXiv:2510.12186, 2025\nCode review is an essential process to ensure the quality of software that identifies \npotential software issues at an early stage of software development. Among all \nsoftware issues, security issues are the most important to identify, as they can easily \nlead to severe software crashes and service disruptions. Recent research efforts \nhave been devoted to automated approaches to reduce the manual efforts required \nin the secure code review process. Despite the progress, current automated\nCites: Large language model for vulnerability detection: Emerging results\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12186&hl=en&sa=X&d=16943958283747804862&ei=cGjzaKvZHoOAieoPtpDVoA0&scisig=AAZF9b9S2MNTvT1URne-Tk9VsXJi&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU", "4 new citations to articles by Bach Le", "3 new citations to articles by Thanh Le-Cong"]}
{"title": "GJALLARHORN: A framework for vulnerability detection via electromagnetic side-channel analysis in embedded systems", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "J Barredo, M Eceiza, JL Flores, M Iturbe- Computers & Security, 2025\nThe proliferation of embedded systems within the Internet of Things (IoT) has \nheightened the difficulty of detecting vulnerabilities due to their inherent resource \nconstraints. This paper introduces GJALLARHORN, a framework extending", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825003815&hl=en&sa=X&d=5152757559966511413&ei=b2jzaMGTM4TN6rQPq8fVkQs&scisig=AAZF9b-JMllkIBW-QBwgGgbOqHIN&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Automated Code Repair for C/C++ Static Analysis", "first_label": ["Code", "Static Analysis"], "second_label": ["Repair"], "data": "D Svoboda, L Flynn, W Klieber, M Duggan, N Reimer - 2025\nStatic analysis (SA) tools produce many diagnostic alerts indicating that source code \nin C or C++ may be defective and potentially vulnerable to security exploits. Many of \nthese alerts are false positives. Identifying the true positive alerts and repairing the\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sei.cmu.edu/documents/6362/Automated_Code_Repair_for_CC_Static_Analysis.pdf&hl=en&sa=X&d=11380272638430810579&ei=b2jzaMGTM4TN6rQPq8fVkQs&scisig=AAZF9b-WwVU0dqeLObAUtq1za6iz&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=1&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Enhancing Neural Code Representation with Additional Context", "first_label": ["Code"], "second_label": [], "data": "H Nguyen, C Treude, P Thongtanunam- arXiv preprint arXiv:2510.12082, 2025\nAutomated program comprehension underpins many software engineering tasks, \nfrom code summarisation to clone detection. Recent deep learning models achieve \nstrong results but typically rely on source code alone, overlooking contextual \ninformation such as version history or structural relationships. This limits their ability \nto capture how code evolves and operates. We conduct an empirical study on how \nenriching code representations with such contextual signals affects neural model\nCites: Can LLMs Reason About Program Semantics? A Comprehensive", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12082&hl=en&sa=X&d=14155260986105681472&ei=b2jzaPWKB9yOieoP1t-zoQM&scisig=AAZF9b_QiKC8VYZH5z-10UhDW2e5&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["4 new citations to articles by Bach Le", "Xin ZHOU - new related research", "3 new citations to articles by Thanh Le-Cong", "2 new citations to articles by Hong Jin Kang"]}
{"title": "Lingxi: Repository-Level Issue Resolution Framework Enhanced by Procedural Knowledge Guided Scaling", "first_label": ["Repository-Level"], "second_label": [], "data": "X Yang, J Zhou, M Pacheco, W Zhu, P He, S Wang- arXiv preprint arXiv, 2025\nDriven by the advancements of Large Language Models (LLMs), LLM-powered \nagents are making significant improvements in software engineering tasks, yet \nstruggle with complex, repository-level issue resolution. Existing agent-based \nmethods have two key limitations. First, they lack of procedural knowledge (ie, how \nan issue is fixed step-by-step and rationales behind it) to learn and leverage for issue \nresolution. Second, they rely on massive computational power to blindly explore the\nCites: Enhancing repository-level software repair via repository-aware", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.11838&hl=en&sa=X&d=7427407364105775832&ei=b2jzaPWKB9yOieoP1t-zoQM&scisig=AAZF9b-0-2q0pXf9eVNYy8WX-m_W&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["4 new citations to articles by Bach Le", "6 new citations to articles by Abhik Roychoudhury"]}
{"title": "RefactorGPT: a ChatGPT-based multi-agent framework for automated code refactoring", "first_label": ["LLM", "Code"], "second_label": ["Agent"], "data": "MA Karabiyik- PeerJ Computer Science, 2025\nThe rise of large language models has redefined what is computationally possible in \ncode generation, yet their potential in systematic software refactoring remains largely \nuntapped. This article introduces RefactorGPT, a ChatGPT-augmented sequential \nmulti-agent framework that transforms refactoring from a monolithic, opaque process \ninto a modular, explainable, and scalable workflow. The system orchestrates four \nspecialized agents, Analyzer, Refactor, Refine, and Fixer, to sequentially analyse\nCites: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://peerj.com/articles/cs-3257/&hl=en&sa=X&d=8103968893034925928&ei=b2jzaPWKB9yOieoP1t-zoQM&scisig=AAZF9b8NOtKE3gngPl7mquXRlBaZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=3&folt=cit", "author": ["Bach Le"], "ref": ["4 new citations to articles by Bach Le", "3 new citations to articles by Thanh Le-Cong"]}
{"title": "Vdexplainer: Sequential decision-making and probability sampling guided statement-level explanation for vulnerability detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "W Zheng, X Su, Y Jiang, H Wei, W Tao- Computers & Security, 2025\nMost existing deep learning (DL) based vulnerability detection methods, including \npre-trained models, are coarse-grained binary classification methods that lack the \ninterpretability for detection results. Although the explanation of deep learning has", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825003591&hl=en&sa=X&d=1218753570899613844&ei=bmjzaOuyJJ2k6rQPiNutyQc&scisig=AAZF9b-Gvd82yXjuXXps0NDpxzwO&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "MAVUL: Multi-Agent Vulnerability Detection via Contextual Reasoning and Interactive Refinement", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Agent", "Reasoning"], "data": "Y Li, K Joshi, X Wang, E Wong- arXiv preprint arXiv:2510.00317, 2025\nThe widespread adoption of open-source software (OSS) necessitates the mitigation \nof vulnerability risks. Most vulnerability detection (VD) methods are limited by \ninadequate contextual understanding, restrictive single-round interactions, and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.00317&hl=en&sa=X&d=577185325914480253&ei=bmjzaOuyJJ2k6rQPiNutyQc&scisig=AAZF9b9zhj17R2ND7E9Z8TAf0EMX&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "A Scalable Vulnerability Detection System with Multi-View Graph Representations", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "S Dou, H Zheng, J Shan, Y Wu, D Zou, X Huang, Y Liu- ACM Transactions on, 2025\nDeep learning (DL) has been extensively utilized in source code vulnerability \ndetection due to its robust automatic feature extraction capabilities. To achieve \nscalable vulnerability scanning, some prior studies intend to process the source code", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3770075&hl=en&sa=X&d=14953216934661661615&ei=bmjzaOuyJJ2k6rQPiNutyQc&scisig=AAZF9b-mdJedTULsxLZv6yXH09xW&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Enhancing Domain-Specific Code Completion via Collaborative Inference with Large and Small Language Models", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Yu, Z Gao, L Bao, Z Liu- ACM Transactions on Software Engineering and, 2025\nLarge language model-based code completion has demonstrated excellent \nperformance, but still encounters challenges in capturing domain-specific knowledge \nfor more precise completion within specific domains, ie, domain-specific code", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3770748&hl=en&sa=X&d=2019769577165862416&ei=bmjzaOuyJJ2k6rQPiNutyQc&scisig=AAZF9b_nxigUKpDd0h7u_giae804&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language", "first_label": ["LLM", "Software Testing"], "second_label": ["Agent"], "data": "S Salva, R Taguelmimt- arXiv preprint arXiv:2509.19136, 2025\nThe use of natural language (NL) test cases for validating graphical user interface \n(GUI) applications is emerging as a promising direction to manually written \nexecutable test scripts, which are costly to develop and difficult to maintain. Recent", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19136&hl=en&sa=X&d=14763218273592887225&ei=bmjzaOuyJJ2k6rQPiNutyQc&scisig=AAZF9b-UHW8cguy7BjMGIC6z7CK9&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Bach Le - new related research"]}
{"title": "ALMAS: an autonomous llm-based multi-agent software engineering framework", "first_label": ["LLM"], "second_label": ["Agent"], "data": "V Tawosi, K Ramani, S Alamir, X Liu- arXiv preprint arXiv:2510.03463, 2025\nMulti-agent Large Language Model (LLM) systems have been leading the way in \napplied LLM research across a number of fields. One notable area is software \ndevelopment, where researchers have advanced the automation of code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03463&hl=en&sa=X&d=6189494284468520954&ei=bmjzaOuyJJ2k6rQPiNutyQc&scisig=AAZF9b8zKTPWNRtbnL5YxBMg92_V&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Towards Human-interpretable Explanation in Code Clone Detection using LLM-based Post Hoc Explainer", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "T Racharak, C Ragkhitwetsagul, C Junplong- arXiv preprint arXiv, 2025\nRecent studies highlight various machine learning (ML)-based techniques for code \nclone detection, which can be integrated into developer tools such as static code \nanalysis. With the advancements brought by ML in code understanding, ML-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22978&hl=en&sa=X&d=13116222657243354012&ei=bmjzaOuyJJ2k6rQPiNutyQc&scisig=AAZF9b-CrNTuw-vA-xt9R-PWj2rN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Local Agentic RAG-Based Information System Development for Intelligent Analysis of GitHub Code Repositories in Computer Science Education", "first_label": ["Code"], "second_label": ["Agent"], "data": "Z Hu, MM Paprotskyi, V Vysotska, L Chyrun, Y Ushenko\nThis study presents the development and evaluation of a local agent-based Retrieval-\nAugmented Generation (Agentic RAG) system designed for the intelligent analysis of \nGitHub repositories in computer science education and IT practice. The novelty of\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.mecs-press.org/ijmecs/ijmecs-v17-n5/IJMECS-V17-N5-7.pdf&hl=en&sa=X&d=15899062735032558573&ei=bmjzaOuyJJ2k6rQPiNutyQc&scisig=AAZF9b9zpITZz-kJHGT1UMgEWtn4&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research"]}
{"title": "Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning", "first_label": ["LLM", "Code"], "second_label": [], "data": "Z Chu, Y Wan, Z Zhang, D Wang, Z Yang, H Zhang- arXiv preprint arXiv, 2025\nWhile Code Language Models (CLMs) have demonstrated superior performance in \nsoftware engineering tasks such as code generation and summarization, recent \nempirical studies reveal a critical privacy vulnerability: these models exhibit", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.13755&hl=en&sa=X&d=15695711709507586926&ei=cGjzaMn9N4ePieoPtcvwuAc&scisig=AAZF9b-GbF4lUDy44GMQdWyqOkv7&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Integrating Large Language Models into Automated Software Testing", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "YS Iznaga, L Rato, P Salgueiro, JL Len- environments, 2025\nThis work investigates the use of LLMs to enhance automation in software testing, \nwith a particular focus on generating high-quality, context-aware test scripts from \nnatural language descriptions, while addressing both text-to-code and text+ code-to", "link": "https://scholar.google.com/scholar_url?url=https://www.preprints.org/frontend/manuscript/6dce9a44c01bba11d8679b804f89ffe3/download_pub&hl=en&sa=X&d=5631235108066530487&ei=cGjzaMn9N4ePieoPtcvwuAc&scisig=AAZF9b8frdiwv1HUKakv2-IdeP9i&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "The Question Neighbourhood Approach for Systematic Evaluation of Code-Generating LLMs", "first_label": ["LLM", "Code"], "second_label": [], "data": "S Honarvar, M Rei, A Donaldson- IEEE Transactions on Software Engineering, 2025\nWe present the concept of a question neighbourhood for systematically evaluating \ninstruction-tuned large language models (LLMs) for code generation via a new \nbenchmark, Turbulence. Turbulence consists of a large set of natural language", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11175086/&hl=en&sa=X&d=12331338329639325411&ei=cGjzaMn9N4ePieoPtcvwuAc&scisig=AAZF9b8Ies8RuQhW4d_WHfainK40&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Do Large Language Models Respect Contracts? Evaluating and Enforcing Contract-Adherence in Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "S Lim, J Hahn, H Park, SK Ko, YS Han- arXiv preprint arXiv:2510.12047, 2025\nPrevailing code generation benchmarks, such as HumanEval+ and MBPP+, primarily \nevaluate large language models (LLMs) with pass@ k on functional correctness \nusing well-formed inputs. However, they ignore a crucial aspect of real-world", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12047&hl=en&sa=X&d=2889880949652380666&ei=cGjzaMn9N4ePieoPtcvwuAc&scisig=AAZF9b9FPoWujYYX-jHRvrHaUI6M&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "CLMTracing: Black-box User-level Watermarking for Code Language Model Tracing", "first_label": ["LLM", "Code"], "second_label": [], "data": "B Zhang, P He, T Du, X Zhang, L Yun, K Chow, J Yin- arXiv preprint arXiv, 2025\nWith the widespread adoption of open-source code language models (code LMs), \nintellectual property (IP) protection has become an increasingly critical concern. \nWhile current watermarking techniques have the potential to identify the code LM to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.13982&hl=en&sa=X&d=14851863240844447268&ei=cGjzaMn9N4ePieoPtcvwuAc&scisig=AAZF9b9MnsfxxD6KbVrkei3eB0d6&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=7&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Beyond Language Barriers: Multi-Agent Coordination for Multi-Language Code Generation", "first_label": ["Code"], "second_label": ["Generation", "Agent"], "data": "MB Moumoula, SL Nikiema, AE Djire, AK Kabore- arXiv preprint arXiv, 2025\nProducing high-quality code across multiple programming languages is increasingly \nimportant as today's software systems are built on heterogeneous stacks. Large \nlanguage models (LLMs) have advanced the state of automated programming, yet", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19918&hl=en&sa=X&d=14811258885698436173&ei=cGjzaMn9N4ePieoPtcvwuAc&scisig=AAZF9b8x1dDUh0eB-LPirrM3oNjg&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=8&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "SolContractEval: A Benchmark for Evaluating Contract-Level Solidity Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "Z Ye, J Chen, Z Shao, L Bao, X Yang, Z Liu- arXiv preprint arXiv:2509.23824, 2025\nThe rise of blockchain has brought smart contracts into mainstream use, creating a \ndemand for smart contract generation tools. While large language models (LLMs) \nexcel at generating code in general-purpose languages, their effectiveness on\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23824&hl=en&sa=X&d=16647490109124805642&ei=cGjzaMn9N4ePieoPtcvwuAc&scisig=AAZF9b8b5b5lGM3HNy8KdJKV_KDL&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=9&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "CTIArena: Benchmarking LLM Knowledge and Reasoning Across Heterogeneous Cyber Threat Intelligence", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "Y Cheng, Y Liu, C Li, D Song, P Gao- arXiv preprint arXiv:2510.11974, 2025\nCyber threat intelligence (CTI) is central to modern cybersecurity, providing critical \ninsights for detecting and mitigating evolving threats. With the natural language \nunderstanding and reasoning capabilities of large language models (LLMs), there is \nincreasing interest in applying them to CTI, which calls for benchmarks that can \nrigorously evaluate their performance. Several early efforts have studied LLMs on \nsome CTI tasks but remain limited:(i) they adopt only closed-book settings, relying on\nCites: Llm agents can autonomously exploit one-day vulnerabilities", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.11974&hl=en&sa=X&d=10681635986323189181&ei=bmjzaLfYE4TN6rQPq8fVkQs&scisig=AAZF9b8dfRE3yjlSwwhzCotTjpLz&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang", "6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Generative AI for web application pentesting", "first_label": ["Software Testing"], "second_label": [], "data": "R Diaz-Parra- Issues in Information Systems, 2025\nThe integration of Generative AI into cybersecurity practices has opened new \npossibilities for automating and enhancing offensive security operations. This study \nexplores the application of ShellGPT in the context of web application penetration \ntesting using the OWASP Web Security Testing Guide (WSTG) as the methodological \nframework. The experiment targeted a vulnerable application and systematically \nprogressed through reconnaissance, enumeration, and exploitation phases. Notably\nCites: Teams of llm agents can exploit zero-day vulnerabilities", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Raul-Diaz-Parra/publication/396476730_Generative_AI_for_Web_Application_Pentesting/links/68ee8b75e7f5f867e6dfa91b/Generative-AI-for-Web-Application-Pentesting.pdf&hl=en&sa=X&d=13025652940846298039&ei=bmjzaLfYE4TN6rQPq8fVkQs&scisig=AAZF9b8Uon09cCZAM-yxdRIRaM2l&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=2&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "Holistic Agent Leaderboard: The Missing Infrastructure for AI Agent Evaluation", "first_label": [], "second_label": ["Agent"], "data": "S Kapoor, B Stroebl, P Kirgis, N Nadgir, ZS Siegel- arXiv preprint arXiv, 2025\nAI agents have been developed for complex real-world tasks from coding to \ncustomer service. But AI agent evaluations suffer from many challenges that \nundermine our understanding of how well agents really work. We introduce the \nHolistic Agent Leaderboard (HAL) to address these challenges. We make three main \ncontributions. First, we provide a standardized evaluation harness that orchestrates \nparallel evaluations across hundreds of VMs, reducing evaluation time from weeks to\nCites: CVE-Bench: A benchmark for AI agents ability to exploit real-world\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.11977&hl=en&sa=X&d=6432919180068206060&ei=bmjzaLfYE4TN6rQPq8fVkQs&scisig=AAZF9b_ZHJum1rtpeAU54_-AAyla&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=3&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "CNCFuzzer: Directed Blackbox Fuzzing of Computer Numerical Control System Based on Message Behaviour Guidance", "first_label": ["Fuzzing"], "second_label": [], "data": "Z Li, D Fang, Y Chen, S Li, J Peng, Z Song, S Lv, L Sun- ACM Transactions on Software\nIn the era of the Industrial Internet of Things, Computer Numerical Control (CNC) \nSystems are confronted with a pervasive threat from attackers. Uncovering their \nsecurity vulnerabilities before being exploited becomes imperative. Enterprise-level \nCNC devices often pose significant challenges in obtaining firmware, limiting \nvulnerability analysis to black-box fuzzing. However, the communication protocols \nused by CNC devices are characterized by heterogeneity, complexity, and\nCites: Large language model guided protocol fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3771764&hl=en&sa=X&d=4976772631307591836&ei=b2jzaOfzJJ2k6rQPiNutyQc&scisig=AAZF9b9j79dN34fDJGAEhCcU7VBX&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Data-Model Co-Evolution: Growing Test Sets to Refine LLM Behavior", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "M Lee, M Kahng- arXiv preprint arXiv:2510.12728, 2025\nA long-standing challenge in machine learning has been the rigid separation \nbetween data work and model refinement, enforced by slow fine-tuning cycles. The \nrise of Large Language Models (LLMs) overcomes this historical barrier, allowing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12728&hl=en&sa=X&d=16810793366910306367&ei=cWjzaL2CB4m16rQPu6Ol8AM&scisig=AAZF9b_FuRVHYIKleSD8po8xmUWI&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Brevity is the Soul of Wit: Condensing Code Changes to Improve Commit Message Generation", "first_label": ["Code", "Commit Message", "Code Change"], "second_label": ["Generation"], "data": "H Kuang, N Zhang, H Gao, X Zhou, WKG Assuno- arXiv preprint arXiv, 2025\nCommit messages are valuable resources for describing why code changes are \ncommitted to repositories in version control systems (eg, Git). They effectively help \ndevelopers understand code changes and better perform software maintenance", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.15567&hl=en&sa=X&d=3566966376596200560&ei=cWjzaL2CB4m16rQPu6Ol8AM&scisig=AAZF9b-vZA0Uf808DqbPbNRX2qRx&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Balancing Validity and Vulnerability: Knowledge-Driven Seed Generation via LLMs for Deep Learning Library Fuzzing", "first_label": ["Vulnerabilities", "LLM", "Fuzzing"], "second_label": ["Generation"], "data": "R Liao, X Yan, Z Pang, K Zhu- Applied Sciences, 2025\nFuzzing deep learning (DL) libraries is essential for uncovering security \nvulnerabilities in AI systems. Existing approaches enhance large language models \n(LLMs) with external knowledge such as bug reports to improve the quality of", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2076-3417/15/19/10396&hl=en&sa=X&d=9374413942225787882&ei=cWjzaL2CB4m16rQPu6Ol8AM&scisig=AAZF9b_coV2M25K3l6JkCX-ZdrMr&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "PIONEER: improving the robustness of student models when compressing pre-trained models of code", "first_label": ["Code"], "second_label": [], "data": "X Liu, X Liu, L Bo, X Wu, Y Yang, X Sun, F Zhou- Automated Software Engineering, 2026\nPre-trained models of code have shown significant effectiveness in a variety of \nsoftware engineering tasks, but they are difficult for local deployment due to their \nlarge size. Existing works mainly focus on compressing these large models into small", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00560-2&hl=en&sa=X&d=17836676178374949159&ei=cWjzaL2CB4m16rQPu6Ol8AM&scisig=AAZF9b_ryg7uDpBLUFYEs8zWj5qt&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Assertion Messages with Large Language Models (LLMs) for Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "A Aljohani, AH Mollah, H Do- arXiv preprint arXiv:2509.19673, 2025\nAssertion messages significantly enhance unit tests by clearly explaining the \nreasons behind test failures, yet they are frequently omitted by developers and \nautomated test-generation tools. Despite recent advancements, Large Language", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19673&hl=en&sa=X&d=7084463702742822906&ei=cWjzaL2CB4m16rQPu6Ol8AM&scisig=AAZF9b93i6m23y0xnjeM1zyUGkQc&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "BloomAPR: A Bloom's Taxonomy-based Framework for Assessing the Capabilities of LLM-Powered APR Solutions", "first_label": ["LLM"], "second_label": [], "data": "Y Ma, J Shin, L Da Silva, Z Ming, S Wang, F Khomh- arXiv preprint arXiv, 2025\nRecent advances in large language models (LLMs) have accelerated the \ndevelopment of AI-driven automated program repair (APR) solutions. However, these \nsolutions are typically evaluated using static benchmarks such as Defects4J and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25465&hl=en&sa=X&d=11066311399156471814&ei=cWjzaL2CB4m16rQPu6Ol8AM&scisig=AAZF9b8-WlUSvsvzUFkBWMfotWY9&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Improving the Efficiency of LLM Agent Systems through Trajectory Reduction", "first_label": ["LLM"], "second_label": ["Agent"], "data": "YA Xiao, P Gao, C Peng, Y Xiong- arXiv preprint arXiv:2509.23586, 2025\nMulti-turn agent systems based on Large Language Models (LLMs) have been \nincreasingly popular for software engineering tasks. While LLM agents show decent \neffectiveness, the high computational cost of input tokens due to the ever-growing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23586%3F&hl=en&sa=X&d=12596444921036280365&ei=cWjzaL2CB4m16rQPu6Ol8AM&scisig=AAZF9b-zx_eKF_ZSiOU7-hQKM67w&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Beyond Postconditions: Can Large Language Models infer Formal Contracts for Automatic Software Verification?", "first_label": ["Verification", "LLM"], "second_label": [], "data": "C Richter, H Wehrheim- arXiv preprint arXiv:2510.12702, 2025\nAutomatic software verifiers have become increasingly effective at the task of \nchecking software against (formal) specifications. Yet, their adoption in practice has \nbeen hampered by the lack of such specifications in real world code. Large\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12702&hl=en&sa=X&d=17536797185387086304&ei=cWjzaL2CB4m16rQPu6Ol8AM&scisig=AAZF9b9WQGM9dEkPoKp7WqDL-4OI&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Llama-Based Source Code Vulnerability Detection: Prompt Engineering vs Fine Tuning", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "DS Ouchebara, S Dupont- European Symposium on Research in Computer, 2025\nThe significant increase in software production, driven by the acceleration of \ndevelopment cycles over the past two decades, has led to a steady rise in software \nvulnerabilities, as shown by statistics published yearly by the CVE program. The \nautomation of the source code vulnerability detection (CVD) process has thus \nbecome essential, and several methods have been proposed ranging from the well \nestablished program analysis techniques to the more recent AI-based methods. Our\nCites: Large language model for vulnerability detection and repair", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-07884-1_15&hl=en&sa=X&d=16960497214690829179&ei=c-PxaKaAGoGpieoP2uHr6Ac&scisig=AAZF9b-UNFhJHUBNG5l-ec_dQkkA&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU", "David Lo - new related research", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "A Systematic Study on Generating Web Vulnerability Proof-of-Concepts Using Large Language Models", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "M Zhao, K Li, L Zhang, W Dang, C Ding, S Chen, Z Liu- arXiv preprint arXiv, 2025\nRecent advances in Large Language Models (LLMs) have brought remarkable \nprogress in code understanding and reasoning, creating new opportunities and \nraising new concerns for software security. Among many downstream tasks, \ngenerating Proof-of-Concept (PoC) exploits plays a central role in vulnerability \nreproduction, comprehension, and mitigation. While previous research has focused \nprimarily on zero-day exploitation, the growing availability of rich public information\nCites: Large language model for vulnerability detection: Emerging results\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10148&hl=en&sa=X&d=10273041275718330713&ei=c-PxaKaAGoGpieoP2uHr6Ac&scisig=AAZF9b9SkXW6HTBfjp5jEa9aG9jR&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU", "5 new citations to articles by Richard Fang"]}
{"title": "The Attacker Moves Second: Stronger Adaptive Attacks Bypass Defenses Against Llm Jailbreaks and Prompt Injections", "first_label": ["LLM"], "second_label": [], "data": "M Nasr, N Carlini, C Sitawarin, SV Schulhoff, J Hayes- arXiv preprint arXiv, 2025\nHow should we evaluate the robustness of language model defenses? Current \ndefenses against jailbreaks and prompt injections (which aim to prevent an attacker \nfrom eliciting harmful knowledge or remotely triggering malicious actions, \nrespectively) are typically evaluated either against a static set of harmful attack \nstrings, or against computationally weak optimization methods that were not \ndesigned with the defense in mind. We argue that this evaluation process is flawed\nCites: Adaptive attacks break defenses against indirect prompt injection", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.09023&hl=en&sa=X&d=7729878491841817349&ei=cOPxaP-BMJOJ6rQPlJbh-Qc&scisig=AAZF9b9PYzy3TWxvre7GOJLf-CYd&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["5 new citations to articles by Richard Fang", "Richard Fang - new related research"]}
{"title": "Webcloak: Characterizing and mitigating the threats of llm-driven web agents as intelligent scrapers", "first_label": ["LLM"], "second_label": ["Agent"], "data": "X Li, T Qiu, Y Jin, L Wang, H Guo, X Jia, X Wang- Proceedings of the 2026, 2026\nThe rise of web agents powered by large language models (LLMs) is reshaping the \nlandscape of human-computer interaction, enabling users to automate complex web \ntasks with natural language commands. However, this progress introduces serious, \nyet largely unexplored security concerns: adversaries can easily employ such web \nagents to conduct advanced web scraping, particularly of rich visual content. This \npaper presents the first systematic characterization of the danger represented by\nCites: Llm agents can autonomously hack websites", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Xinfeng-Li-7/publication/396418425_WebCloak_Characterizing_and_Mitigating_Threats_from_LLM-Driven_Web_Agents_as_Intelligent_Scrapers/links/68ea2bc4f3032e2b4be84935/WebCloak-Characterizing-and-Mitigating-Threats-from-LLM-Driven-Web-Agents-as-Intelligent-Scrapers.pdf&hl=en&sa=X&d=11222165444201781035&ei=cOPxaP-BMJOJ6rQPlJbh-Qc&scisig=AAZF9b_YUPVueXaKg_vffu8We5ja&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["5 new citations to articles by Richard Fang", "Richard Fang - new related research"]}
{"title": "Countering Jailbreak Attacks with Two-Axis Pre-detection and Conditional Warning Wrappers", "first_label": [], "second_label": ["Detection"], "data": "H Na, H Kim, D Yoon, D Choi- European Symposium on Research in Computer, 2025\nEnsuring the security and ethical alignment of large language models (LLMs) is \ncritical as adversarial attacks, such as prompt injections and jailbreak exploits, \ncontinue to evolve. Pre-detection mechanisms have emerged as a promising \ndefense, filtering adversarial prompts before they reach the LLM. However, existing \npre-detectors exhibit limitations in distinguishing genuinely harmful queries from \nlegitimate prompts that resemble adversarial inputs, leading to high false positive\nCites: Removing rlhf protections in gpt-4 via fine-tuning", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-07884-1_13&hl=en&sa=X&d=11255779199620420292&ei=cOPxaP-BMJOJ6rQPlJbh-Qc&scisig=AAZF9b9rX6lNB4aMdumlmqZhc79y&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=3&folt=cit", "author": ["Richard Fang"], "ref": ["5 new citations to articles by Richard Fang"]}
{"title": "PACEbench: A Framework for Evaluating Practical AI Cyber-Exploitation Capabilities", "first_label": [], "second_label": ["Exploit"], "data": "Z Liu, L Huang, J Zhang, D Liu, Y Tian, J Shao- arXiv preprint arXiv:2510.11688, 2025\nThe increasing autonomy of Large Language Models (LLMs) necessitates a rigorous \nevaluation of their potential to aid in cyber offense. Existing benchmarks often lack \nreal-world complexity and are thus unable to accurately assess LLMs' cybersecurity \ncapabilities. To address this gap, we introduce PACEbench, a practical AI cyber-\nexploitation benchmark built on the principles of realistic vulnerability difficulty, \nenvironmental complexity, and cyber defenses. Specifically, PACEbench comprises\nCites: Llm agents can autonomously hack websites, 2024\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.11688&hl=en&sa=X&d=15034103702715491295&ei=cOPxaP-BMJOJ6rQPlJbh-Qc&scisig=AAZF9b-Y_HUMbtycunOemcR67jX2&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=4&folt=cit", "author": ["Richard Fang"], "ref": ["5 new citations to articles by Richard Fang"]}
{"title": "Bridging Semantics & Structure for Software Vulnerability Detection using Hybrid Network Models", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "J Gajjar, K Ranaware, K Subramaniakuppusamy- arXiv preprint arXiv:2510.10321, 2025\nSoftware vulnerabilities remain a persistent risk, yet static and dynamic analyses \noften overlook structural dependencies that shape insecure behaviors. Viewing \nprograms as heterogeneous graphs, we capture control-and data-flow relations as \ncomplex interaction networks. Our hybrid framework combines these graph \nrepresentations with light-weight (< 4B) local LLMs, uniting topological features with \nsemantic reasoning while avoiding the cost and privacy concerns of large cloud\nCites: Vul4j: A dataset of reproducible java vulnerabilities geared towards\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10321&hl=en&sa=X&d=10226567657462591767&ei=cePxaPiJOtyOieoPsYjeCQ&scisig=AAZF9b9oNhPXdR_nhfKyXSDZlgF5&oi=scholaralrt&hist=ylyK0_8AAAAJ:5615766320347152220:AAZF9b9Qy0LEut_atU8F20t2CTM_&html=&pos=0&folt=cit", "author": ["Quang-Cuong Bui"], "ref": ["1 new citation to articles by Quang-Cuong Bui"]}
{"title": "Evaluating Line-level Localization Ability of Learning-based Code Vulnerability Detection Models", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection", "Localization"], "data": "M Pintore, G Piras, A Sotgiu, M Pintor, B Biggio- arXiv preprint arXiv:2510.11202, 2025\nTo address the extremely concerning problem of software vulnerability, system \nsecurity is often entrusted to Machine Learning (ML) algorithms. Despite their now \nestablished detection capabilities, such models are limited by design to flagging the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.11202&hl=en&sa=X&d=9055377727216407082&ei=cuPxaL-jDdqI6rQPwYiV4AI&scisig=AAZF9b8xbm1Du6lgyxc1WTrkXNTp&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Quang-Cuong Bui - new related research", "Xin ZHOU - new related research"]}
{"title": "A Study on Thinking Patterns of Large Reasoning Models in Code Generation", "first_label": ["Code"], "second_label": ["Generation", "Reasoning"], "data": "K Halim, SG Teo, R Feng, Z Chen, Y Gu, C Wang, Y Liu- arXiv preprint arXiv, 2025\nCurrently, many large language models (LLMs) are utilized for software engineering \ntasks such as code generation. The emergence of more advanced models known as \nlarge reasoning models (LRMs), such as OpenAI's o3, DeepSeek R1, and Qwen3", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.13758&hl=en&sa=X&d=2224436918693180739&ei=cuPxaL-jDdqI6rQPwYiV4AI&scisig=AAZF9b8PXkuQShZa8PJmAUV09aCI&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "LLMs are All You Need? Improving Fuzz Testing for MOJO with Large Language Models", "first_label": ["LLM", "Fuzzing", "Software Testing"], "second_label": [], "data": "L Huang, P Zhao, H Chen- arXiv preprint arXiv:2510.10179, 2025\nThe rapid development of large language models (LLMs) has revolutionized \nsoftware testing, particularly fuzz testing, by automating the generation of diverse and \neffective test inputs. This advancement holds great promise for improving software", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10179&hl=en&sa=X&d=1799101126036134381&ei=cuPxaL-jDdqI6rQPwYiV4AI&scisig=AAZF9b81rAe6qhsRipbAgfYJBzD0&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "10 new citations to articles by Abhik Roychoudhury", "Hong Jin Kang - new related research"]}
{"title": "Automating Code Generation for Semiconductor Equipment Control from Developer Utterances with LLMs", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Y Kim, S Park, M Kim, G Yoon, E Lee, SS Woo- arXiv preprint arXiv:2509.13055, 2025\nSemiconductors form the backbone of modern electronics, with their manufacturing \nand testing relying on highly specialized equipment and domain-specific \nprogramming languages. Equipment languages such as the Algorithmic Pattern", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.13055&hl=en&sa=X&d=8083439099579672792&ei=cuPxaL-jDdqI6rQPwYiV4AI&scisig=AAZF9b_6B1-ggVyk13BUPke_jxTs&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Relative Positioning Based Code Chunking Method For Rich Context Retrieval In Repository Level Code Completion Task With Code Language Model", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "I Rahman, MR Rahman- arXiv preprint arXiv:2510.08610, 2025\nCode completion can help developers improve efficiency and ease the development \nlifecycle. Although code completion is available in modern integrated development \nenvironments (IDEs), research lacks in determining what makes a good context for", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.08610&hl=en&sa=X&d=2303000934938645600&ei=cuPxaL-jDdqI6rQPwYiV4AI&scisig=AAZF9b8YqAS_lxGgGujfimOUg3Ye&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "TIT: A Tree-Structured Instruction Tuning Approach for LLM-Based Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "H Jiang, Y Wang, H Lin, P Zou, Z Zhou, A Jia, X Li- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have shown strong performance in automated \nsource-to-target code translation through pretraining on extensive code corpora. \nHowever, mainstream LLM-based code translation methods suffer from two critical", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.09400&hl=en&sa=X&d=13736189209612319180&ei=cuPxaL-jDdqI6rQPwYiV4AI&scisig=AAZF9b8BgaCRZ98gjqOLuA3yWzr7&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "Project-Level C-to-Rust Translation via Synergistic Integration of Knowledge Graphs and Large Language Models", "first_label": ["LLM"], "second_label": ["Generation", "Graph"], "data": "Z Yuan, W Mao, Z Chen, X Shang, C Wang, Y Lou- arXiv preprint arXiv, 2025\nTranslating C code into safe Rust is an effective way to ensure its memory safety. \nCompared to rule-based translation which produces Rust code that remains largely \nunsafe, LLM-based methods can generate more idiomatic and safer Rust code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10956&hl=en&sa=X&d=2267252876492551064&ei=cuPxaL-jDdqI6rQPwYiV4AI&scisig=AAZF9b-L3WHUJKU3RlplwlZN3OmP&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "RepoSummary: Feature-Oriented Summarization and Documentation Generation for Code Repositories", "first_label": ["Code"], "second_label": ["Generation"], "data": "Y Zhu, X Zhao, X Li, Y Zou, H Yuan, Y Wang, B Xie- arXiv preprint arXiv:2510.11039, 2025\nRepository summarization is a crucial research question in development and \nmaintenance for software engineering. Existing repository summarization techniques \nprimarily focus on summarizing code according to the directory tree, which is\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.11039&hl=en&sa=X&d=1535321579264936728&ei=cuPxaL-jDdqI6rQPwYiV4AI&scisig=AAZF9b8ILiPteblPIuCcixyJUcPL&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Advances in AI-Driven Biomass Processing: A Review of Conversion Technologies, Optimization Strategies, and Smart Energy Integration", "first_label": [], "second_label": [], "data": "R Garg, P Rajput, J Vibhandik, A Ali, I Abrar- ACS Omega, 2025\nThe present paper explores the revolutionary potential of artificial intelligence (AI) in \ndeveloping fuel efficiency and biomass conversion technologies to power the \nsustainable energy system. In light of growing concerns about environmental \ndegradation and dependency on fossil fuels, AI models such as support vector \nmachines and neural networks optimize fuel performance and modify energy \ndynamics in various disciplines, from fuel cells to biomass systems. This article\nCites: Surveying neuro-symbolic approaches for reliable artificial", "link": "https://scholar.google.com/scholar_url?url=https://pubs.acs.org/doi/full/10.1021/acsomega.5c05427&hl=en&sa=X&d=8448256697217404129&ei=cePxaJ_2F7eO6rQPjrOG8Qc&scisig=AAZF9b8fUyCPLdV6mrYbbQBFcb4t&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang"]}
{"title": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs", "first_label": ["LLM", "Bug", "Software Defect"], "second_label": ["Repair"], "data": "J Wang, X Xie, Q Hu, S Liu, J Yu, J Klong, Y Li- arXiv preprint arXiv:2510.11059, 2025\nAutomated Program Repair (APR) plays a critical role in enhancing the quality and \nreliability of software systems. While substantial progress has been made in Java-\nbased APR, largely facilitated by benchmarks like Defects4J, there remains a \nsignificant gap in research on C/C++ program repair, despite the widespread use of \nC/C++ and the prevalence of associated vulnerabilities. This gap is primarily due to \nthe lack of high-quality, open-source benchmarks tailored for C/C++. To address this\nCites: Bugsinpy: a database of existing bugs in python programs to\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.11059&hl=en&sa=X&d=18114606130303362985&ei=cePxaJ_2F7eO6rQPjrOG8Qc&scisig=AAZF9b98C3oJprE4TsnYPaw7JACP&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang", "3 new citations to articles by Bach Le", "10 new citations to articles by Abhik Roychoudhury", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "Detection of ethereum smart contract vulnerabilities using weighted control flow graphs", "first_label": ["Vulnerabilities", "Smart Contracts", "Ethereum", "Static Analysis"], "second_label": ["Detection", "Graph"], "data": "YY Cheong, RY Choi, J Ahn, T Kim, DH Im- Applied Intelligence, 2025\nSmart contracts are self-executing programs deployed on the blockchain to handle \ncomplex business logic. Due to the immutable nature of blockchain, once deployed, \nsmart contracts cannot be modified, making them vulnerable to malicious exploitation \nif they contain programming flaws. Such vulnerabilities pose significant risks to the \nsecurity and reliability of blockchain systems. Existing approaches typically rely on \nfixed, manually defined rules or target single vulnerabilities, limiting scalability as the\nCites: Smart contract development: Challenges and opportunities", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10489-025-06915-2&hl=en&sa=X&d=17520089520681804530&ei=cePxaOOlKY3WieoP9f3a2QY&scisig=AAZF9b8un7iCNA7qt2kDu7U01O--&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Design Pattern Development for Online Labor Platforms: Addressing Certificate Forgery Through Blockchain-Based Solutions", "first_label": ["Blockchain"], "second_label": [], "data": "AL Hupe, U Bretschneider - 2025\nOutsourcing tasks via online labor platforms (OLPs) has become a widely adopted \nstrategy for companies to delegate activities beyond their core competencies to \nexternal gig workers, enabling rapid and cost-effective task execution. Increasing \ntask complexity and required expertise lead to higher payment, incentivizing gig \nworkers to exaggerate their qualifications and engage in certificate forgery. Such \nmisrepresentations often result in inadequate task outcomes. Existing approaches\nCites: Smart contract development: Challenges and opportunities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://aisel.aisnet.org/icis2025/sharing_econ/sharing_econ/14/&hl=en&sa=X&d=10700170445617501004&ei=cePxaOOlKY3WieoP9f3a2QY&scisig=AAZF9b_LfORHizn-RrTRS0WbhMFc&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System", "first_label": ["LLM"], "second_label": ["Agent"], "data": "J Guo, S Huang, M Li, D Huang, X Chen, R Zhang- arXiv preprint arXiv, 2025\nThe integration of LLMs into software engineering has catalyzed a paradigm shift \nfrom traditional rule-based systems to sophisticated agentic systems capable of \nautonomous problem-solving. Despite this transformation, the field lacks a \ncomprehensive understanding of how benchmarks and solutions interconnect, \nhindering systematic progress and evaluation. This survey presents the first holistic \nanalysis of LLM-empowered software engineering, bridging the critical gap between\nCites: AutoCodeRover: Autonomous program improvement", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.09721&hl=en&sa=X&d=7629575093655778225&ei=cuPxaK7vHNyOieoPsYjeCQ&scisig=AAZF9b9V63ASc13sZHKI073UXwRv&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Comprehensive Survey on LLMBased Network Management and Operations", "first_label": ["LLM"], "second_label": [], "data": "J Hong, NV Tu, JWK Hong- International Journal of Network Management, 2025\nThe growing demands for network capacity and the increasing complexities of \nmodern network environments pose significant challenges for effective network \nmanagement and operations. In response, network operators and administrators are \nmoving beyond traditional manual and rulebased methods, adopting advanced \nartificial intelligence (AI)driven paradigms (eg, selfdriving networks, autonomous \nnetworks, network automation). Recently, large language models (LLMs) have\nCites: Large language model guided protocol fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/pdf/10.1002/nem.70029&hl=en&sa=X&d=9425036470997377820&ei=cuPxaK7vHNyOieoPsYjeCQ&scisig=AAZF9b8z_NH3pBWsQ3TX2GtPPkbR&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Hound: Relation-First Knowledge Graphs for Complex-System Reasoning in Security Audits", "first_label": [], "second_label": ["Reasoning", "Graph"], "data": "B Mueller- arXiv preprint arXiv:2510.09633, 2025\nHound introduces a relation-first graph engine that improves system-level reasoning \nacross interrelated components in complex codebases. The agent designs flexible, \nanalyst-defined views with compact annotations (eg, monetary/value flows, \nauthentication/authorization roles, call graphs, protocol invariants) and uses them to \nanchor exact retrieval: for any question, it loads precisely the code that matters (often \nacross components) so it can zoom out to system structure and zoom in to the\nCites: AutoCodeRover: Autonomous program improvement", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.09633&hl=en&sa=X&d=5199970391130033131&ei=cuPxaK7vHNyOieoPsYjeCQ&scisig=AAZF9b-vGgdqZCNCce6SbntlOvsQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "(Dis) Proving Spectre Security with Speculation-Passing Style", "first_label": [], "second_label": [], "data": "S Arranz-Olmos, G Barthe, L Blatter, X Xie, Z Zhang- arXiv preprint arXiv:2510.11573, 2025\nConstant-time (CT) verification tools are commonly used for detecting potential side-\nchannel vulnerabilities in cryptographic libraries. Recently, a new class of tools, \ncalled speculative constant-time (SCT) tools, has also been used for detecting \npotential Spectre vulnerabilities. In many cases, these SCT tools have emerged as \nliftings of CT tools. However, these liftings are seldom defined precisely and are \nalmost never analyzed formally. The goal of this paper is to address this gap, by\nCites: oo7: Low-overhead defense against spectre attacks via program", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.11573&hl=en&sa=X&d=14810075995319052396&ei=cuPxaK7vHNyOieoPsYjeCQ&scisig=AAZF9b_CMNYbJ7kdg0y_5e4yembw&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Testing and Enhancing Multi-Agent Systems for Robust Code Generation", "first_label": ["Code", "Software Testing"], "second_label": ["Generation", "Agent"], "data": "Z Lyu, S Chen, Z Ji, L Wang, S Wang, D Wu, W Wang- arXiv preprint arXiv, 2025\nMulti-agent systems (MASs) have emerged as a promising paradigm for automated \ncode generation, demonstrating impressive performance on established benchmarks \nby decomposing complex coding tasks across specialized agents with different roles. \nDespite their prosperous development and adoption, their robustness remains \npressingly under-explored, raising critical concerns for real-world deployment. This \npaper presents the first comprehensive study examining the robustness of MASs for\nCites: Coverage-based greybox fuzzing as markov chain", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10460&hl=en&sa=X&d=630507134168963513&ei=cuPxaK7vHNyOieoPsYjeCQ&scisig=AAZF9b9KyrQgaoF0-kmqHw52LU7_&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Survey for MQTT Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "SY Chowdhury, R Sun, B Dudley- Proceedings of the 2025 Workshop on Re-design, 2025\nMessage Queuing Telemetry Transport (MQTT) has emerged as a promising \ncommunication protocol for Internet of Things (IoT) ecosystems, enabling lightweight, \nscalable publish-subscribe messaging across resource-constrained devices. As \nMQTT adoption accelerates across critical domains from smart cities to industrial \nautomation, ensuring protocol security through rigorous testing has become crucial. \nThis paper presents a comprehensive comparative analysis of MQTT fuzzing\nCites: Directed greybox fuzzing\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3733823.3764515&hl=en&sa=X&d=13012329971672204999&ei=cuPxaK7vHNyOieoPsYjeCQ&scisig=AAZF9b8vgf7FG03SkoQTaHno7c8H&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=9&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Abhik Roychoudhury - new related research"]}
{"title": "Backdoor-Powered Prompt Injection Attacks Nullify Defense Methods", "first_label": [], "second_label": [], "data": "Y Chen, H Li, Y Sui, Y Song, B Hooi- arXiv preprint arXiv:2510.03705, 2025\nWith the development of technology, large language models (LLMs) have dominated \nthe downstream natural language processing (NLP) tasks. However, because of the \nLLMs' instruction-following abilities and inability to distinguish the instructions in the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03705&hl=en&sa=X&d=9793005798347645046&ei=c-PxaKqxJ7eO6rQPjrOG8Qc&scisig=AAZF9b_HnZpDS0idSVQ9IazqK7ZK&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Poisoned to Aware: Fostering Backdoor Self-Awareness in LLMs", "first_label": ["LLM"], "second_label": [], "data": "G Shen, S Cheng, X Xu, Y Zhou, H Guo, Z Zhang- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) can acquire deceptive behaviors through backdoor \nattacks, where the model executes prohibited actions whenever secret triggers \nappear in the input. Existing safety training methods largely fail to address this", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05169&hl=en&sa=X&d=9405091671790165810&ei=c-PxaKqxJ7eO6rQPjrOG8Qc&scisig=AAZF9b8o4jJRSuUiMq-cqxdu42gl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Q Wei, T Yang, Y Wang, X Li, L Li, Z Yin, Y Zhan, T Holz- arXiv preprint arXiv, 2025\nLarge Language Model (LLM) agents use memory to learn from past interactions, \nenabling autonomous planning and decision-making in complex environments. \nHowever, this reliance on memory introduces a critical security risk: an adversary can", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02373%3F&hl=en&sa=X&d=4598414696562770679&ei=c-PxaKqxJ7eO6rQPjrOG8Qc&scisig=AAZF9b81TzOjaUWLDsP44BPpjuXB&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Dual-Space Smoothness for Robust and Balanced LLM Unlearning", "first_label": ["LLM"], "second_label": [], "data": "H Yan, Z Liu, M Jiang- arXiv preprint arXiv:2509.23362, 2025\nWith the rapid advancement of large language models, Machine Unlearning has \nemerged to address growing concerns around user privacy, copyright infringement, \nand overall safety. Yet state-of-the-art (SOTA) unlearning methods often suffer from", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23362&hl=en&sa=X&d=1871730686130311929&ei=c-PxaKqxJ7eO6rQPjrOG8Qc&scisig=AAZF9b8As51yVW8jz__d_c1PoJ_F&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "MetaBreak: Jailbreaking Online LLM Services via Special Token Manipulation", "first_label": ["LLM"], "second_label": [], "data": "W Zhu, Z Xiang, W Niu, L Guan- arXiv preprint arXiv:2510.10271, 2025\nUnlike regular tokens derived from existing text corpora, special tokens are artificially \ncreated to annotate structured conversations during the fine-tuning process of Large \nLanguage Models (LLMs). Serving as metadata of training data, these tokens play a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10271&hl=en&sa=X&d=10904776402205985786&ei=c-PxaKqxJ7eO6rQPjrOG8Qc&scisig=AAZF9b_F0Cun6iwf_kcQRFluBJsN&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Misactivation-Aware Stealthy Backdoor Attacks on Neural Code Understanding Models", "first_label": ["Code"], "second_label": [], "data": "X Sun, Y Xiao, L Bo, W Sun, X Liu, B Li, J Zhang- IEEE Transactions on Software, 2025\nNeural code models (NCMs) play a crucial role in helping developers solve code \nunderstanding tasks. Recent studies have exposed that NCMs are vulnerable to \nseveral security threats, among which backdoor attack is one of the toughest. It is", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11181191/&hl=en&sa=X&d=1845847614155086033&ei=c-PxaKqxJ7eO6rQPjrOG8Qc&scisig=AAZF9b9cJUSS-tJDGaC1EhJgMR6O&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "TokenSwap: Backdoor Attack on the Compositional Understanding of Large Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Zhang, Q Tao, J Lv, N Zhao, L Feng, JT Zhou- arXiv preprint arXiv:2509.24566, 2025\nLarge vision-language models (LVLMs) have achieved impressive performance \nacross a wide range of vision-language tasks, while they remain vulnerable to \nbackdoor attacks. Existing backdoor attacks on LVLMs aim to force the victim model", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24566&hl=en&sa=X&d=14209309214606815133&ei=c-PxaKqxJ7eO6rQPjrOG8Qc&scisig=AAZF9b8EZ5L_oQZac8jX4YZetjCL&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "C Ziakas, N Loo, N Jain, A Russo- arXiv preprint arXiv:2510.07239, 2025\nAutomated red-teaming has emerged as a scalable approach for auditing Large \nLanguage Models (LLMs) prior to deployment, yet existing approaches lack \nmechanisms to efficiently adapt to model-specific vulnerabilities at inference. We\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07239%3F&hl=en&sa=X&d=7730973334197366962&ei=c-PxaKqxJ7eO6rQPjrOG8Qc&scisig=AAZF9b_6OS1meKBJ_r2Js8UAke4U&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "PVDetector: Pretrained Vulnerability Detection on Vulnerability-enriched Code Semantic Graph", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection", "Graph"], "data": "J Li, L Cui, J Zhang, L Li, R Xi, H Zhu- ACM Transactions on Software Engineering, 2025\nAutomated vulnerability detection is a critical issue in software security. The advent of \ndeep learning (DL) has led to numerous studies employing DL to detect \nvulnerabilities in software source code. However, existing approaches still perform", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3768582&hl=en&sa=X&d=8582469852291084545&ei=dOPxaO2zBJ2k6rQP94Xs2QI&scisig=AAZF9b-KDpNTmZzjJ738P4MlJP3u&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "On the Use of Imbalanced Datasets for Learning-Based Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "RZL Foulefack, A Marchetto- IFIP International Conference on Testing Software and, 2025\nStatic code analysis conducted by means of learning-based methods is an essential \npart of Security Testing. Effective learning algorithms are crucial for training reliable \nmodels that can accurately detect weaknesses and vulnerabilities. During models'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-05188-2_20&hl=en&sa=X&d=7711185064955775681&ei=dOPxaO2zBJ2k6rQP94Xs2QI&scisig=AAZF9b89r6zwK8DmhfjAM2OZUwge&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "K Shehada, Y Wu, WD Feng, A Iyer, G Kumfert, Y Ding- NeurIPS 2025 Workshop on\nLarge Language Models (LLMs) have revolutionized automated program repair \n(APR) but current benchmarks like SWE-Bench predominantly focus on userspace \napplications and overlook the complexities of kernel-space debugging and repair", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DNY4wv5C39G&hl=en&sa=X&d=13284020585308537468&ei=cOPxaOucHN_N6rQPqOmrqQ4&scisig=AAZF9b8qiQW2WOt5dhxoK0fl5lFh&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation", "first_label": ["LLM", "Fault Localization"], "second_label": ["Localization"], "data": "F Liu, T Wang, L Zhang, Z Yang, J Jiang, Z Sun- arXiv preprint arXiv:2509.25676, 2025\nProviding timely and personalized guidance for students' programming assignments, \noffers significant practical value for helping students complete assignments and \nenhance their learning. In recent years, various automated Fault Localization (FL)", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25676&hl=en&sa=X&d=16831300563596066577&ei=cOPxaOucHN_N6rQPqOmrqQ4&scisig=AAZF9b8KiRs4870r1KbKTYTF0UyR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "InsightQL: Advancing Human-Assisted Fuzzing with a Unified Code Database and Parameterized Query Interface", "first_label": ["Fuzzing", "Code"], "second_label": [], "data": "W Gao, R Borovica-Gajic, SK Cha, T Qiu, VT Pham- arXiv preprint arXiv:2510.04835, 2025\nFuzzing is a highly effective automated testing method for uncovering software \nvulnerabilities. Despite advances in fuzzing techniques, such as coverage-guided \ngreybox fuzzing, many fuzzers struggle with coverage plateaus caused by fuzz", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04835&hl=en&sa=X&d=7721758508651636625&ei=cuPxaITvOpOJ6rQPlJbh-Qc&scisig=AAZF9b9S6TLnsxYfSiDSKvyS6fS2&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "MOSAIC: Multi-agent Orchestration for Task-Intelligent Scientific Coding", "first_label": [], "second_label": ["Agent"], "data": "S Raghavan, T Mallick- arXiv preprint arXiv:2510.08804, 2025\nWe present MOSAIC, a multi-agent Large Language Model (LLM) framework for \nsolving challenging scientific coding tasks. Unlike general-purpose coding, scientific \nworkflows require algorithms that are rigorous, interconnected with deep domain", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.08804&hl=en&sa=X&d=10022260456277741818&ei=cuPxaITvOpOJ6rQPlJbh-Qc&scisig=AAZF9b9SDv8T5--427oUuSMW7pYh&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "DynamiQ: Unlocking the Potential of Dynamic Task Allocation in Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "W Yan, T Murray, B Rubinstein, VT Pham- arXiv preprint arXiv:2510.04469, 2025\nWe present DynamiQ, a full-fledged and optimized successor to AFLTeam that \nsupports dynamic and adaptive parallel fuzzing. Unlike most existing approaches \nthat treat individual seeds as tasks, DynamiQ leverages structural information from", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04469&hl=en&sa=X&d=10962816615102660239&ei=cuPxaITvOpOJ6rQPlJbh-Qc&scisig=AAZF9b_5VltWA46OsWSnq5GXtqKm&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing", "first_label": ["LLM", "Fuzzing", "Bug"], "second_label": [], "data": "S Ou, Y Li, L Yu, C Wei, T Wen, Q Chen, Y Chen- IEEE Transactions on, 2025\nDeep learning (DL) frameworks serve as the backbone for a wide range of artificial \nintelligence applications. However, bugs within DL frameworks can cascade into \ncritical issues in higher-level applications, jeopardizing reliability and security. While", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/32/4359463/11201027.pdf&hl=en&sa=X&d=1422528139240657868&ei=cuPxaITvOpOJ6rQPlJbh-Qc&scisig=AAZF9b899-spy-aa2AQhyA9vfr3w&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Function Clustering-Based Fuzzing Termination: Toward Smarter Early Stopping", "first_label": ["Fuzzing"], "second_label": [], "data": "L Ding, W Yang, Y Xue\nFuzzing is a testing technique that generates a large number of inputs to cause \nprogram crashes. As software development accelerates and projects scale, the \ndemand for fuzz testing in software assurance has increased. Performing", "link": "https://scholar.google.com/scholar_url?url=https://wzyang.cn/files/FuzzingTermination.pdf&hl=en&sa=X&d=16741608997780760317&ei=cuPxaITvOpOJ6rQPlJbh-Qc&scisig=AAZF9b8PamUxP4hadUhNaXUhRS_c&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=6&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "CG-Bench: Can Language Models Assist Call Graph Construction in the Real World?", "first_label": ["LLM", "Static Analysis"], "second_label": ["Graph"], "data": "T Yuan, W Zhang, D Chen, J Wang- Proceedings of the 1st ACM SIGPLAN, 2025\nLanguage models for coding are shifting their focus from function-level to repository-\nlevel, with complex function invocations. We introduce CG-Bench, the first manually \nconstructed benchmark that measures the ability to understand call graphs for\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3759425.3763379&hl=en&sa=X&d=11570618845570061776&ei=cuPxaITvOpOJ6rQPlJbh-Qc&scisig=AAZF9b8qflr4UNBQdgiN0mJqf1U8&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=8&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Search-based Hyperparameter Tuning for Python Unit Test Generation", "first_label": ["Software Testing"], "second_label": ["Generation", "Search"], "data": "S Lukasczyk, G Fraser- arXiv preprint arXiv:2510.08716, 2025\nSearch-based test-generation algorithms have countless configuration options. \nUsers rarely adjust these options and usually stick to the default values, which may \nnot lead to the best possible results. Tuning an algorithm's hyperparameters is a\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.08716&hl=en&sa=X&d=261527645054763210&ei=cuPxaNiRLJm96rQPkKyjqAI&scisig=AAZF9b-5rMU4beHJbtfRJF32MhYG&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=3&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "MC-LRNN: A logic-based neural network for multi-class software vulnerability prediction", "first_label": ["Vulnerabilities"], "second_label": [], "data": "Y Shang, S Liu- Journal of Systems and Software, 2025\nSoftware vulnerabilities are a major threat to information systems. Detecting them \nearly and accurately is critical. Software metrics are commonly used in vulnerability \nprediction, but choosing the most relevant features remains a major challenge. In this", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225002961&hl=en&sa=X&d=8570138772226985730&ei=cePxaLvxBZ2k6rQP94Xs2QI&scisig=AAZF9b84q-crm5S0aBJ7OE9mFpMl&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "The Richer Representation Fallacy: Are We Just Adding Noise to LLM-based Software Vulnerability Detectors?", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "H Hanif, S Maffeis, NB Anuar\nLarge Language Models (LLMs) have established strong baselines for software \nvulnerability detection, leading to a common assumption that their performance can \nbe enhanced by augmenting them with supplementary information such as Abstract", "link": "https://scholar.google.com/scholar_url?url=https://www.doc.ic.ac.uk/~maffeis/papers/icoco25.pdf&hl=en&sa=X&d=9374945953362351896&ei=cePxaLvxBZ2k6rQP94Xs2QI&scisig=AAZF9b8kuDDgBtCLNX4BQ9S00QXz&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Fortifying LLM-Based Code Generation with Graph-Based Reasoning on Secure Coding Practices", "first_label": ["LLM", "Code"], "second_label": ["Generation", "Reasoning", "Graph"], "data": "R Patir, K Guo, H Cai, H Hu- arXiv preprint arXiv:2510.09682, 2025\nThe code generation capabilities of Large Language Models (LLMs) have \ntransformed the field of software development. However, this advancement also \npresents significant security challenges, as LLM-generated code often contains", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.09682&hl=en&sa=X&d=6457581180391498391&ei=cePxaLvxBZ2k6rQP94Xs2QI&scisig=AAZF9b9UJfYG6I1hC7QL_1Z9x7IQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "GramTrans: A Better Code Representation Approach in Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "Z Zhang, Q Liang, Z Sun, Y Chen, G Wang, Y Sun- arXiv preprint arXiv, 2025\nCode generation has shown great promise in assisting software development. A \nfundamental yet underexplored question is how the choice of code representation \naffects model performance. While existing studies employ various representations", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02887&hl=en&sa=X&d=4294784226274265196&ei=cePxaLvxBZ2k6rQP94Xs2QI&scisig=AAZF9b8oYU_W4aCctz4kLZN8XYHr&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "for Learning-Based Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "RZL Foulefack, A Marchetto- Testing Software and Systems: 37th IFIP WG 6.1\nStatic code analysis conducted by means of learning-based methods is an essential \npart of Security Testing. Effective learning algo-rithms are crucial for training reliable \nmodels that can accurately detect weaknesses and vulnerabilities. During models'\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DHQuHEQAAQBAJ%26oi%3Dfnd%26pg%3DPA307%26ots%3DdVPsdrYowq%26sig%3Diwmjwx7b1UIoZdYyrINHEjHbUQg&hl=en&sa=X&d=879843498815082224&ei=cePxaLvxBZ2k6rQP94Xs2QI&scisig=AAZF9b9GE7IRjO0oX45CzVJrQ4rM&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "OpCodeBERT: A Method for Python Code Representation Learning by BERT with Opcode", "first_label": ["Code"], "second_label": [], "data": "C Qiu, J Liu, X Xiao, Y Xiao- IEEE Transactions on Software Engineering, 2025\nProgramming language pre-training models have made significant progress in code \nrepresentation learning in recent years. Although various methods, such as data flow \nand Abstract Syntax Tree (AST), have been widely applied to enhance code", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11169752/&hl=en&sa=X&d=1825874209020573091&ei=c-PxaK3INNqI6rQPwYiV4AI&scisig=AAZF9b-cenZWTH8w2_NrvGDeuIZA&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Enhanced Architecture of Structure Semantics for SyntaxAware Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "C Zhou, Z Li, H Huang, Y Xiang, F Liu, Z Hao- Software: Practice and Experience, 2025\nObjective The task of code generation aims to transform natural language \ndescriptions into corresponding target code. Among the various approaches, syntax\naware code generation has emerged as a significant approach that strives to", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.70025&hl=en&sa=X&d=17163292334780918507&ei=c-PxaK3INNqI6rQPwYiV4AI&scisig=AAZF9b8XJeITFf1Q_L-Ts39FDVK3&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Systematic Evaluation of Parameter-Efficient Fine-Tuning Methods for the Security of Code LLMs", "first_label": ["LLM", "Code"], "second_label": [], "data": "K Lee, J Kim, D Kim, H Kim- arXiv preprint arXiv:2509.12649, 2025\nCode-generating Large Language Models (LLMs) significantly accelerate software \ndevelopment. However, their frequent generation of insecure code presents serious \nrisks. We present a comprehensive evaluation of seven parameter-efficient fine", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.12649&hl=en&sa=X&d=7696794774262272409&ei=c-PxaK3INNqI6rQPwYiV4AI&scisig=AAZF9b91MaqL-Oau2ztvPU9w1eiz&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution", "first_label": ["Code"], "second_label": ["Generation"], "data": "TY Zhuo, X Jin, H Liu, J Jiang, T Liu, C Gong, B Bishnoi- arXiv preprint arXiv, 2025\nCrowdsourced model evaluation platforms, such as Chatbot Arena, enable real-time \nevaluation from human perspectives to assess the quality of model responses. In the \ncoding domain, manually examining the quality of LLM-generated content is", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.08697&hl=en&sa=X&d=3424101587674263597&ei=c-PxaK3INNqI6rQPwYiV4AI&scisig=AAZF9b8_Uu4XqC-JnTRQryaVcRNg&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=8&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
