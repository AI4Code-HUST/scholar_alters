{"title": "Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Zheng, X Qian, H Zhou, S Yang, Y He, S Jana\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models (LMs) show promise for vulnerability detection but struggle with \nlong, real-world code due to sparse and uncertain vulnerability locations. These \nissues, exacerbated by token limits, often cause models to miss vulnerability-related\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17460&hl=en&sa=X&d=9334848497739178959&ei=OXw4aJa0D4qIieoPj_7kqQE&scisig=AAZF9b_EDz61GJXVBfE-c2mGro5g&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research", "1 new citation to articles by Thanh Le-Cong", "Bach Le - new related research", "2 new citations to articles by Hong Jin Kang", "Richard Fang - new related research", "David Lo - new related research", "2 new citations to articles by Bach Le", "Abhik Roychoudhury - new related research", "Xin ZHOU - new related research"]}
{"title": "Gradient-Based Program Repair: Fixing Bugs in Continuous Program Spaces", "first_label": ["APR", "Bug"], "second_label": ["Repair"], "data": "A Silva, G Thor\\xc3\\xa9n, M Monperrus\\xc2\\xa0- arXiv preprint arXiv:2505.17703, 2025\nAutomatic program repair seeks to generate correct code from buggy programs, with \nmost approaches searching the correct program in a discrete, symbolic space of \nsource code tokens. This symbolic search is fundamentally limited by its inability to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17703&hl=en&sa=X&d=16474865879424877259&ei=OXw4aJa0D4qIieoPj_7kqQE&scisig=AAZF9b_Nk8nyD3YHpgwp8sahtoaV&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research", "Hong Jin Kang - new related research"]}
{"title": "Leveraging Open-Source LLMs for Zero-Shot Vulnerability Detection: A Comparative Analysis", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "N Capuano, V Carletti, P Foggia, G Parrella, M Vento\\xc2\\xa0- International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid expansion of the Internet of Things (IoT) has brought significant security \nchallenges, primarily due to vulnerabilities in the firmware of IoT and network \ndevices, which is predominantly written in low-level programming languages such as\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-87775-9_2&hl=en&sa=X&d=8724089268434184607&ei=OXw4aJa0D4qIieoPj_7kqQE&scisig=AAZF9b-ahkowI222f9SeGE9jq2lb&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "HouseFuzz: Service-Aware Grey-Box Fuzzing for Vulnerability Detection in Linux-Based Firmware", "first_label": ["Vulnerabilities", "Fuzzing"], "second_label": ["Detection"], "data": "H Xiao, Z Wei, J Dai, B Li, Y Zhang, M Yang\\xc2\\xa0- 2025 IEEE Symposium on Security and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nTo date, grey-box fuzzing has become an essential technique to detect \nvulnerabilities implied in Linuxbased firmware. However, existing fuzzing \napproaches commonly encounter three overlooked obstacles stemming from\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://yuanxzhang.github.io/paper/housefuzz-oakland25.pdf&hl=en&sa=X&d=2985212275357273259&ei=OXw4aKOkFuWBieoP0PLYiAU&scisig=AAZF9b-79MvgylM8QDOXkXYrQWz8&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "David Lo - new related research"]}
{"title": "Identifying Root Cause of bugs by Capturing Changed Code Lines with Relational Graph Neural Networks", "first_label": ["Code", "Bug"], "second_label": ["Detection", "Graph"], "data": "J Zhang, S Guo, H Li, C Li, Y Chai, R Chen\\xc2\\xa0- arXiv preprint arXiv:2505.00990, 2025\nThe Just-In-Time defect prediction model helps development teams improve software \nquality and efficiency by assessing whether code changes submitted by developers \nare likely to introduce defects in real-time, allowing timely identification of potential\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.00990&hl=en&sa=X&d=17996198631274398381&ei=OXw4aMnrIIOuieoP-ZTn2Aw&scisig=AAZF9b_S66ntoRzUw7soStgrJChb&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "CRAKEN: Cybersecurity LLM Agent with Knowledge-Based Execution", "first_label": ["LLM"], "second_label": ["Agent"], "data": "M Shao, H Xi, N Rani, M Udeshi, VSC Putrevu, K Milner\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Model (LLM) agents can automate cybersecurity tasks and can \nadapt to the evolving cybersecurity landscape without re-engineering. While LLM \nagents have demonstrated cybersecurity capabilities on Capture-The-Flag (CTF)\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17107&hl=en&sa=X&d=15972287277060203373&ei=OXw4aMnrIIOuieoP-ZTn2Aw&scisig=AAZF9b9ztm3EoTSFCd4yC4zLZwar&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Towards Practical Defect-Focused Automated Code Review", "first_label": ["Code Review", "Code", "Software Defect"], "second_label": [], "data": "J Lu, L Jiang, X Li, J Fang, F Zhang, L Yang, C Zuo\\xc2\\xa0- arXiv preprint arXiv:2505.17928, 2025\nThe complexity of code reviews has driven efforts to automate review comments, but \nprior approaches oversimplify this task by treating it as snippet-level code-to-text \ngeneration and relying on text similarity metrics like BLEU for evaluation. These\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17928&hl=en&sa=X&d=12067756449610676850&ei=OXw4aMnrIIOuieoP-ZTn2Aw&scisig=AAZF9b_qGcuYwPmk8Xhnck7wk9eC&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Detecting Taint-Style Vulnerabilities in Microservice-Structured Web Applications", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "F Liu, Y Zhang, T Chen, Y Shi, G Yang, Z Lin, M Yang\\xe2\\x80\\xa6\\xc2\\xa0- 2025 IEEE Symposium on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMicroservice architecture has been becoming increasingly popular for building \nscalable and maintainable applications. A microservice-structured web application \n(shortened to microservice application) enhances security by providing a loose-\ncoupling design and enforcing the security isolation between different microservices. \nHowever, in this paper, our study shows microservice applications still suffer from \ntaintstyle vulnerability, one of the most serious vulnerabilities. We propose a novel\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection: Emerging results\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://yuanxzhang.github.io/paper/mscan-oakland25.pdf&hl=en&sa=X&d=18396175674193620539&ei=OXw4aLubHJ-mieoPoOrjuQU&scisig=AAZF9b8eUIifMEfDqb7jf0bqc780&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["1 new citation to articles by Xin ZHOU"]}
{"title": "Guided Search Strategies in Non-Serializable Environments with Applications to Software Engineering Agents", "first_label": [], "second_label": ["Agent", "Search"], "data": "K Zainullina, A Golubev, M Trofimova, S Polezhaev\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have recently achieved remarkable results in \ncomplex multi-step tasks, such as mathematical reasoning and agentic software \nengineering. However, they often struggle to maintain consistent performance across\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13652%3F&hl=en&sa=X&d=16639264652215845731&ei=OXw4aJPqDZ-mieoPoOrjuQU&scisig=AAZF9b8trwPKX9QyV63_k_pzmKHD&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Enhancing line-level defect prediction using bilinear attention fusion and ranking optimization", "first_label": ["Software Defect"], "second_label": [], "data": "S Qiu, H Huang, Y Kuang, H Luo, X Liu\\xc2\\xa0- Empirical Software Engineering, 2025\nThe aim of software defect prediction is to identify defect-prone code segments, \nthereby facilitating the optimal allocation of testing resources by the quality \nassurance team. Previous defect prediction models have primarily concentrated on a \ncoarse-grained file-level defect prediction, which frequently lacks the necessary \nprecision for defect localization. In response, recent advancements in the field have \nseen the emergence of fine-grained line-level defect prediction methods\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCc2vec: Distributed representations of code changes\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10674-6&hl=en&sa=X&d=16103404085638523760&ei=OXw4aIroEIOuieoP-ZTn2Aw&scisig=AAZF9b_SGOXJDhMOe4gCrJwiQLYc&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang"]}
{"title": "PandaGuard: Systematic Evaluation of LLM Safety in the Era of Jailbreaking Attacks", "first_label": ["LLM"], "second_label": [], "data": "G Shen, D Zhao, L Feng, X He, J Wang, S Shen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have achieved remarkable capabilities but remain \nvulnerable to adversarial prompts known as jailbreaks, which can bypass safety \nalignment and elicit harmful outputs. Despite growing efforts in LLM safety research\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13862&hl=en&sa=X&d=7957433049052051517&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b8uuohndjng7lcz2CFokw4p&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based Backdoor Attacks for Jailbreaking Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "J Kong, H Fang, X Yang, K Gao, B Chen, ST Xia\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSupervised fine-tuning (SFT) aligns large language models (LLMs) with human \nintent by training them on labeled task-specific data. Recent studies have shown that \nmalicious attackers can inject backdoors into these models by embedding triggers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17601&hl=en&sa=X&d=14932585774719166007&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b9Mpttr2wQUEHafuYZfV36C&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Automating Safety Enhancement for LLM-based Agents with Synthetic Risk Scenarios", "first_label": ["LLM"], "second_label": ["Agent"], "data": "X Zhou, W Wang, L Lu, J Shi, G Tie, Y Xu, L Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Model (LLM)-based agents are increasingly deployed in real-world \napplications such as\" digital assistants, autonomous customer service, and decision-\nsupport systems\", where their ability to\" interact in multi-turn, tool-augmented\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17735&hl=en&sa=X&d=12532090448198307722&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b9bre4aTPQdE8jg7Mn1R_NE&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Wang, W Wang, S Wang, Z Li, Z Ji, Z Lyu, D Wu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Large Language Models (LLMs) has led to the \nemergence of Multi-Agent Systems (MAS) to perform complex tasks through \ncollaboration. However, the intricate nature of MAS, including their architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12442&hl=en&sa=X&d=8825331941370095164&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b_j6hKF2Zy8dNMOx-tobM6E&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution", "first_label": [], "second_label": [], "data": "J Guo, X Wen, W Jiang, C Huang, J Li, H Li\\xc2\\xa0- arXiv preprint arXiv:2505.15308, 2025\nWith the widespread application of super-resolution (SR) in various fields, \nresearchers have begun to investigate its security. Previous studies have \ndemonstrated that SR models can also be subjected to backdoor attacks through\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15308&hl=en&sa=X&d=13335437674086498390&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b8WmdvUXiuzvPutlRNCBmNP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Ripple Effect: On Unforeseen Complications of Backdoor Attacks", "first_label": [], "second_label": [], "data": "R Zhang, Y Shen, H Li, W Jiang, H Chen, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent research highlights concerns about the trustworthiness of third-party Pre-\nTrained Language Models (PTLMs) due to potential backdoor attacks. These \nbackdoored PTLMs, however, are effective only for specific pre-defined downstream\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11586&hl=en&sa=X&d=15157304470732077928&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b997v4XRj8-KVQslhBMZvqE&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AgentXploit: End-to-End Redteaming of Black-Box AI Agents", "first_label": [], "second_label": ["Agent"], "data": "Z Wang, V Siu, Z Ye, T Shi, Y Nie, X Zhao, C Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe strong planning and reasoning capabilities of Large Language Models (LLMs) \nhave fostered the development of agent-based systems capable of leveraging \nexternal tools and interacting with increasingly complex environments. However\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.05849&hl=en&sa=X&d=13145039506086791936&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b_5aWzkLQOK0HBWClMmbpt1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Safety Alignment Can Be Not Superficial With Explicit Safety Signals", "first_label": [], "second_label": [], "data": "J Li, JE Kim\\xc2\\xa0- arXiv preprint arXiv:2505.17072, 2025\nRecent studies on the safety alignment of large language models (LLMs) have \nrevealed that existing approaches often operate superficially, leaving models \nvulnerable to various adversarial attacks. Despite their significance, these studies\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17072&hl=en&sa=X&d=3884119238907864380&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b_-WQPT8NKA4EMeavI8x-X5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A4FL: Federated Adversarial Defense via Adversarial Training and Pruning Against Backdoor Attack", "first_label": [], "second_label": [], "data": "B Li, M Hamid, M Saleem, M Aman\\xc2\\xa0- IEEE Access, 2025\nBackdoor attacks threaten federated learning (FL) models, where malicious \nparticipants embed hidden triggers into local models during training. These triggers \ncan compromise crucial applications, such as autonomous systems, when they\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/10992684.pdf&hl=en&sa=X&d=4691259454218143835&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b-NVXh_0LVfWkgmGPYIRTtu&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM-BSCVM: An LLM-Based Blockchain Smart Contract Vulnerability Management Framework", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM", "Blockchain"], "second_label": [], "data": "Y Jin, C Li, P Fan, P Liu, X Li, C Liu, W Qiu\\xc2\\xa0- arXiv preprint arXiv:2505.17416, 2025\nSmart contracts are a key component of the Web 3.0 ecosystem, widely applied in \nblockchain services and decentralized applications. However, the automated \nexecution feature of smart contracts makes them vulnerable to potential attacks due\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17416&hl=en&sa=X&d=10855861846148419865&ei=OXw4aKvLE8y8ieoPz-jf4A8&scisig=AAZF9b_mYzDvvJxBEB76yl3JeJnw&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Adaptive Plan-Execute Framework for Smart Contract Security Auditing", "first_label": ["Smart Contracts"], "second_label": [], "data": "Z Wei, J Sun, Z Zhang, Z Hou, Z Zhao\\xc2\\xa0- arXiv preprint arXiv:2505.15242, 2025\nLarge Language Models (LLMs) have shown great promise in code analysis and \nauditing; however, they still struggle with hallucinations and limited context-aware \nreasoning. We introduce SmartAuditFlow, a novel Plan-Execute framework that\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15242%3F&hl=en&sa=X&d=12215254457367510356&ei=OXw4aKvLE8y8ieoPz-jf4A8&scisig=AAZF9b947-Kg9JIl0flSbUcHwrKi&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "SmartNote: An LLM-Powered, Personalised Release Note Generator That Just Works", "first_label": ["LLM"], "second_label": [], "data": "F Daneshyan, R He, J Wu, M Zhou\\xc2\\xa0- arXiv preprint arXiv:2505.17977, 2025\nThe release note is a crucial document outlining changes in new software versions. \nYet, many developers view the process of writing software release notes as a tedious \nand dreadful task. Consequently, numerous tools have been developed by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17977&hl=en&sa=X&d=9800160746809662848&ei=OXw4aKvLE8y8ieoPz-jf4A8&scisig=AAZF9b_GgqDLYefmItqDOvP0zOfL&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "AUTOMATIC GENERATION OF ETHEREUM-BASED SMART CONTRACTS FOR AGRI-FOOD TRACEABILITY SYSTEM", "first_label": ["Smart Contracts", "Ethereum"], "second_label": ["Generation"], "data": "P KATHIRESAN, TK SELVI\nThere is a growing demand for transparency along the agri-food chain, both from \ncustomers and governments. The adoption of block chain technology to enable \nsecure traceability for the management of the agri-food chain, provide information \nsuch as the provenance of a food product and prevent food fraud, is emerging \nrapidly, due to the inherent trust and inalterability provided by this technology. \nHowever, developing the right smart contracts for these use cases is even more of a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://erode-sengunthar.ac.in/wp-content/uploads/2025/05/15.-IJCRT2304284.pdf&hl=en&sa=X&d=10559769453103330358&ei=OXw4aPerEvel6rQP6dvK4Ao&scisig=AAZF9b-yaYonZYR24dyIBCf7azkj&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le"]}
{"title": "The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models", "first_label": ["APR"], "second_label": ["Repair"], "data": "FV Ruiz, M Hort, L Moonen\\xc2\\xa0- arXiv preprint arXiv:2505.02931, 2025\nAutomatic program repair (APR) aims to reduce the manual efforts required to \nidentify and fix errors in source code. Before the rise of LLM-based agents, a \ncommon strategy was to increase the number of generated patches, sometimes to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.02931%3F&hl=en&sa=X&d=16837479357373517474&ei=OXw4aMvlGeSN6rQPzIKygQU&scisig=AAZF9b_WjCVulOfH0bpaSqZwLopC&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "CORECRISIS: Threat-Guided and Context-Aware Iterative Learning and Fuzzing of 5G Core Networks", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Dong, T Yang, A Al Ishtiaq, SMM Rashid, A Ranjbar\\xe2\\x80\\xa6\nWe develop CORECRISIS, a stateful black-box fuzz-testing framework for 5G core \nnetwork (5GC) implementations. Unlike previous stateful security analysis efforts of \ncellular networks which rely on manually-crafted, static test inputs and are limited to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.usenix.org/system/files/conference/usenixsecurity25/sec25cycle1-prepub-1292-dong-yilu.pdf&hl=en&sa=X&d=4291979592406815479&ei=OXw4aMvlGeSN6rQPzIKygQU&scisig=AAZF9b8xMpoFy9xYsoZdVl1unvGx&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "WildSync: Automated Fuzzing Harness Synthesis via Wild API Usage Recovery", "first_label": ["Fuzzing"], "second_label": [], "data": "WEIC WU, S NAGY, C HAUSER - 2025\nAuthors' Contact Information: Wei-Cheng Wu, Dartmouth College, Hanover, USA, wei-\ncheng. wu. gr@ dartmouth. edu; Stefan Nagy, University of Utah, Salt Lake City, USA, \nstefan. nagy@ utah. edu; Christophe Hauser, Dartmouth College, Hanover, USA\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://users.cs.utah.edu/~snagy/papers/25ISSTA.pdf&hl=en&sa=X&d=3125007074729669279&ei=OXw4aMvlGeSN6rQPzIKygQU&scisig=AAZF9b8Pijs9BnZif9GfvBHcFCPy&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Fault localization of AI-enabled cyber-physical systems by exploiting temporal neuron activation", "first_label": ["Fault Localization"], "second_label": ["Exploit", "Localization"], "data": "D Lyu, Y Li, Z Zhang, P Arcaini, XY Zhang, F Ishikawa\\xe2\\x80\\xa6\\xc2\\xa0- Journal of Systems and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern cyber\\xe2\\x80\\x93physical systems (CPS) are evolving to integrate deep neural \nnetworks (DNNs) as controllers, leading to the emergence of AI-enabled CPSs. An \ninadequately trained DNN controller may produce incorrect control actions, exposing\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225001438&hl=en&sa=X&d=3286846770327067741&ei=OXw4aMvlGeSN6rQPzIKygQU&scisig=AAZF9b-jUE3fT364wIMjAbdvLNMM&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Programming Models for Correct and Modular Distributed Systems", "first_label": [], "second_label": [], "data": "S Laddad - 2025\nWriting distributed software is hard. Distributed systems are the backbone of the \nmodern Internet, involved in every website load, button click, and data transaction. \nBut these systems face complex correctness challenges. Concurrency, network \ndelays, and machine failures all lead to bugs with brutal consequences: data loss, \nsecurity vulnerabilities, and denial of service. Distributed systems are hard because \nthey have implicit non-determinism. In sequential programs, the order of operations\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaGreybox fuzzing of distributed systems\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-85.pdf&hl=en&sa=X&d=14972060672026920479&ei=OXw4aPKDFaalieoP5f2nkAE&scisig=AAZF9b-s2lffO8y1tMklDVka1rr7&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
{"title": "The state of hybrid artificial intelligence for interstellar missions", "first_label": [], "second_label": [], "data": "A Ellery\\xc2\\xa0- Progress in Aerospace Sciences, 2025\nInterstellar missions will require a high degree of autonomy mediated through \nartificial intelligence (AI). All interstellar missions are characterised by 50-100-year \ntransits to extrasolar systems. High system availability demands that interstellar \nspacecraft are self-repairable imposing significant demands on onboard intelligence. \nWe review the current status of artificial intelligence to assess its capabilities in \nproviding such autonomy. In particular, we focus on hybrid AI methods as these\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Program Repair\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0376042125000260&hl=en&sa=X&d=353621729800259380&ei=OXw4aPKDFaalieoP5f2nkAE&scisig=AAZF9b-Tz9nbgrTgCe-Bce_SiBUH&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
{"title": "Learning code better through structural information of data flow", "first_label": ["Code", "Static Analysis"], "second_label": [], "data": "Z Zhang, Y Chen, T Jiao, L Bai, C Guo, J Song\\xc2\\xa0- The Journal of Supercomputing, 2025\nCode representation aims to transform source code into mathematical or vector forms \nto support models in processing and analyzing code. The data flow in code \nrepresents the information about how variables are passed and manipulated within\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11227-025-07348-x&hl=en&sa=X&d=4688121816012655931&ei=h_02aK_tDcmx6rQP-rCh4AE&scisig=AAZF9b8nFdzNPfGMCwf17Erquei3&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Are requirements really all you need? A case study of LLM-driven configuration code generation for automotive simulations", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "K Lebioda, N Petrovic, F Pan, V Zolfaghari\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are taking many industries by storm. They possess \nimpressive reasoning capabilities and are capable of handling complex problems, as \nshown by their steadily improving scores on coding and mathematical benchmarks\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13263&hl=en&sa=X&d=8142159630564180976&ei=h_02aK_tDcmx6rQP-rCh4AE&scisig=AAZF9b8JjDXL2WTWCxGT05T_vG1H&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Retrieval Augmented Generation Fine-Tuned LLM Model for Code Recommendations to Mitigate Lock Contention", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "A Shawon, R Liscano, A Azim, V Sundaresan\\xe2\\x80\\xa6\\xc2\\xa0- Companion of the 16th ACM\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLock contention performance faults can lead to degradation in the performance of \nsoftware applications. Unlike software bugs, per-formance faults do not lead to \nfailures and application crashes but surface as a degradation in the response and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3680256.3721324&hl=en&sa=X&d=9066686008189024422&ei=h_02aJWzBoCt6rQP9sPUwAg&scisig=AAZF9b_z8isVs0s9J_P2VPM3lUR4&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "How Developers Make Decisions When Choosing Issues and Reviewing Code: An Eye Tracking GitHub Study", "first_label": ["Code"], "second_label": [], "data": "IS Wiese, J Boyer, E Rasgorshek, G Pinto, M Gerosa\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 2025\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe paper presents a pilot eye-tracking study on how developers choose what \nissues to work on and how they perform code-reviewing tasks within the GitHub \necosystem. In this study, we recorded the eye movements of thirteen developers to\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3715669.3723108&hl=en&sa=X&d=348434684063622474&ei=h_02aMbwB6m7ieoP1JuLsA8&scisig=AAZF9b-EDLXrAhddxUATQ0V97r4L&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Targeted Fuzzing for Unsafe Rust Code: Leveraging Selective Instrumentation", "first_label": ["Fuzzing", "Code"], "second_label": [], "data": "D Paa\\xc3\\x9fen, JR Giesen, L Davi\\xc2\\xa0- arXiv preprint arXiv:2505.02464, 2025\nRust is a promising programming language that focuses on concurrency, usability, \nand security. It is used in production code by major industry players and got \nrecommended by government bodies. Rust provides strong security guarantees\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.02464&hl=en&sa=X&d=17464682910892089266&ei=h_02aMatCbeC6rQP9sj2mQ8&scisig=AAZF9b-bvKBMc2Po_9BYZAm8NsXQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Stateful Analysis and Fuzzing of Commercial Baseband Firmware", "first_label": ["Fuzzing"], "second_label": [], "data": "A Ranjbar, T Yang, K Tu, S Khalilollahi, SR Hussain\\xc2\\xa0- 2025 IEEE Symposium on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBaseband firmware plays a critical role in cellular communication, yet its proprietary, \nclosed-source nature and complex, stateful processing logic make systematic \nsecurity testing challenging. Existing methods often fail to account for the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://syed-rafiul-hussain.github.io/wp-content/uploads/2025/05/Loris_baseband_fuzzing_sp25.pdf&hl=en&sa=X&d=12942867024371270911&ei=h_02aMatCbeC6rQP9sj2mQ8&scisig=AAZF9b-Ze-vPOALeUo-ikpj0sFws&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Systematic exploration of fuzzing in IoT: techniques, vulnerabilities, and open challenges", "first_label": ["Vulnerabilities", "Fuzzing"], "second_label": [], "data": "A Touqir, F Iradat, W Iqbal, A Rakib, N Taskin\\xe2\\x80\\xa6\\xc2\\xa0- The Journal of\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs our dependence on the internet and digital platforms grows, the risk of cyber \nthreats rises, making it essential to implement effective measures to safeguard \nsensitive information through cybersecurity, ensure system integrity, and prevent\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11227-025-07371-y&hl=en&sa=X&d=6083537071761720509&ei=h_02aMatCbeC6rQP9sj2mQ8&scisig=AAZF9b9_2tGbhprfWVgY0gWilcYB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Revisiting Defects4J for Fault Localization in Diverse Development Scenarios", "first_label": ["Fault Localization", "Software Defect"], "second_label": ["Localization"], "data": "MN Rafi, AR Chen, THP Chen, S Wang\nDefects4J stands out as a leading benchmark dataset for software testing research, \nproviding a controlled environment to study real bugs from prominent open-source \nsystems. While Defects4J provides a clean and valuable dataset, we aim to explore\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://petertsehsun.github.io/papers/MSR25_Defects4j.pdf&hl=en&sa=X&d=17769356187159404178&ei=h_02aMatCbeC6rQP9sj2mQ8&scisig=AAZF9b9Jow3u953pAdt-vrSlDqrb&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "StatePre: A Large Language Model-Based State-Handling Method for Network Protocol Fuzzing", "first_label": ["LLM", "Fuzzing"], "second_label": [], "data": "Y Zhang, K Zhu, J Peng, Y Lu, Q Chen, Z Li\\xc2\\xa0- Electronics, 2025\nAs essential components for communication, network protocol programs are highly \nsecurity-critical, making it crucial to identify their vulnerabilities. Fuzzing is one of the \nmost popular software vulnerability discovery techniques, being highly efficient and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2079-9292/14/10/1931&hl=en&sa=X&d=627385219736855262&ei=h_02aJLPD4-UywTXk47YAw&scisig=AAZF9b8UGqCLjsKWT4IzOOpbHV9F&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "R-Bench: Graduate-level Multi-disciplinary Benchmarks for LLM & MLLM Complex Reasoning Evaluation", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "MH Guo, J Xu, Y Zhang, J Song, H Peng, YX Deng\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nReasoning stands as a cornerstone of intelligence, enabling the synthesis of existing \nknowledge to solve complex problems. Despite remarkable progress, existing \nreasoning benchmarks often fail to rigorously evaluate the nuanced reasoning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.02018%3F&hl=en&sa=X&d=8843826795691330105&ei=h_02aKSFDJ-mieoPoOrjuQU&scisig=AAZF9b8oZTpHhJulcZKPuCXTowVa&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Transferable Adversarial Attacks on Black-Box Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "K Hu, W Yu, L Zhang, A Robey, A Zou, C Xu, H Hu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nVision Large Language Models (VLLMs) are increasingly deployed to offer \nadvanced capabilities on inputs comprising both text and images. While prior \nresearch has shown that adversarial attacks can transfer from open-source to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.01050&hl=en&sa=X&d=34750902821152867&ei=h_02aKSFDJ-mieoPoOrjuQU&scisig=AAZF9b9lHgWBmRQgOUsWiSdzwfqQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "FFCBA: Feature-based Full-target Clean-label Backdoor Attacks", "first_label": [], "second_label": [], "data": "Y Yin, H Chen, Y Gao, P Sun, L Wu, Z Li, W Liu\\xc2\\xa0- arXiv preprint arXiv:2504.21054, 2025\nBackdoor attacks pose a significant threat to deep neural networks, as backdoored \nmodels would misclassify poisoned samples with specific triggers into target classes \nwhile maintaining normal performance on clean samples. Among these, multi-target\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.21054&hl=en&sa=X&d=11764564091838188098&ei=h_02aKSFDJ-mieoPoOrjuQU&scisig=AAZF9b9SdO4MnuUOO575ZCPWE7mf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SFIBA: Spatial-based Full-target Invisible Backdoor Attacks", "first_label": [], "second_label": [], "data": "Y Yin, H Chen, Y Gao, P Sun, Z Li, W Liu\\xc2\\xa0- arXiv preprint arXiv:2504.21052, 2025\nMulti-target backdoor attacks pose significant security threats to deep neural \nnetworks, as they can preset multiple target classes through a single backdoor \ninjection. This allows attackers to control the model to misclassify poisoned samples\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.21052&hl=en&sa=X&d=5761980514706203657&ei=h_02aKSFDJ-mieoPoOrjuQU&scisig=AAZF9b_W6N6zXzE0bD6783lkFzLc&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "ACE: A Security Architecture for LLM-Integrated App Systems", "first_label": ["LLM"], "second_label": [], "data": "E Li, T Mallick, E Rose, W Robertson, A Oprea\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM-integrated app systems extend the utility of Large Language Models (LLMs) \nwith third-party apps that are invoked by a system LLM using interleaved planning \nand execution phases to answer user queries. These systems introduce new attack\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.20984&hl=en&sa=X&d=3998395298276971569&ei=h_02aKSFDJ-mieoPoOrjuQU&scisig=AAZF9b9c-SzDc9aTwMz6OjIT80SJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "$\\\\texttt {SAGE} $: A Generic Framework for LLM Safety Evaluation", "first_label": ["LLM"], "second_label": [], "data": "M Jindal, H Shrawgi, P Agrawal, S Dandapat\\xc2\\xa0- arXiv preprint arXiv:2504.19674, 2025\nSafety evaluation of Large Language Models (LLMs) has made progress and \nattracted academic interest, but it remains challenging to keep pace with the rapid \nintegration of LLMs across diverse applications. Different applications expose users\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.19674&hl=en&sa=X&d=13515953365107310793&ei=h_02aKSFDJ-mieoPoOrjuQU&scisig=AAZF9b8I6Tao4xVmOMNkh4fRFyk2&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Summary the Savior: Harmful Keyword and Query-based Summarization for LLM Jailbreak Defense", "first_label": ["LLM"], "second_label": [], "data": "S Rahman, I Harris\\xc2\\xa0- Proceedings of the 5th Workshop on Trustworthy NLP\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAbstract Large Language Models (LLMs) are widely used for their capabilities, but \nface threats from jailbreak attacks, which exploit LLMs to generate inappropriate \ninformation and bypass their defense system. Existing defenses are often specific to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.trustnlp-main.17.pdf&hl=en&sa=X&d=14170740403670373463&ei=h_02aKSFDJ-mieoPoOrjuQU&scisig=AAZF9b8DP8uiyb5TC-J1nixhoFBT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LlamaFirewall: An open source guardrail system for building secure AI agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "S Chennabasappa, C Nikolaidis, D Song, D Molnar\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have evolved from simple chatbots into autonomous \nagents capable of performing complex tasks such as editing production code, \norchestrating workflows, and taking higher-stakes actions based on untrusted inputs\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.03574&hl=en&sa=X&d=4439105352924524607&ei=h_02aKSFDJ-mieoPoOrjuQU&scisig=AAZF9b9vbSaup9_At8OcInY6jBmA&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "F Aguilera-Mart\\xc3\\xadnez, F Berzal\\xc2\\xa0- arXiv preprint arXiv:2505.01177, 2025\nAs large language models (LLMs) continue to evolve, it is critical to assess the \nsecurity threats and vulnerabilities that may arise both during their training phase \nand after models have been deployed. This survey seeks to define and categorize\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.01177&hl=en&sa=X&d=7671221624049003302&ei=h_02aKSFDJ-mieoPoOrjuQU&scisig=AAZF9b9G2hD-1XbRFK3ie2HSPQEM&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Protecting Privacy against Membership Inference Attack with LLM Fine-tuning through Flatness", "first_label": ["LLM"], "second_label": [], "data": "T Chen, L Da, H Zhou, P Li, K Zhou, T Chen, H Wei\\xc2\\xa0- Proceedings of the 2025 SIAM\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe privacy concerns associated with the use of Large Language Models (LLMs) \nhave grown dramatically with the development of pioneer LLMs such as ChatGPT. \nDifferential Privacy (DP) techniques that utilize DP-SGD are explored in existing work\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://epubs.siam.org/doi/pdf/10.1137/1.9781611978520.41&hl=en&sa=X&d=17254526290774706544&ei=h_02aKSFDJ-mieoPoOrjuQU&scisig=AAZF9b9QKrfqxl5MqrtGoHHu2KtO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
