{"title": "AI-Driven Autonomous Vulnerability Detection and Remediation Method for Network-Disconnected Cloud Environments", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "F Bi\\xc2\\xa0- 2025 8th International Conference on Advanced\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nUnder military requirements, cloud platforms are often deployed in network-free \nenvironments, rendering traditional vulnerability detection and remediation methods \ndifficult to apply. Particularly in the absence of real-time network support, manual \nrepairs exhibit low efficiency and high error rates. To address this challenge, this \nstudy proposes a vulnerability detection and repair method based on a locally \ndeployed large-scale deep learning model. Leveraging the model's zero-shot\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11042782/&hl=en&sa=X&d=6955648240487334598&ei=U8piaNHeK7vM6rQPzp2XwQQ&scisig=AAZF9b_hOzHNknvMrcom1nuZuSL1&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang"]}
{"title": "From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Y Mao, T Cui, P Liu, D You, H Zhu\\xc2\\xa0- arXiv preprint arXiv:2506.15170, 2025\nLarge language models (LLMs) are rapidly evolving from single-modal systems to \nmultimodal LLMs and intelligent agents, significantly expanding their capabilities \nwhile introducing increasingly severe security risks. This paper presents a systematic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15170&hl=en&sa=X&d=16427093263132639213&ei=VMpiaMInzMzqtA-G16fABQ&scisig=AAZF9b-zqUEdPZ8IyWJxfUDycl5Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Emoji attack: Enhancing jailbreak attacks against judge llm detection", "first_label": ["LLM"], "second_label": ["Detection"], "data": "Z Wei, Y Liu, NB Erichson\\xc2\\xa0- Forty-second International Conference on Machine\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreaking techniques trick Large Language Models (LLMs) into producing \nrestricted output, posing a potential threat. One line of defense is to use another LLM \nas a Judge to evaluate the harmfulness of generated text. However, we reveal that\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DQ0rKYiVEZq&hl=en&sa=X&d=17491126507172914063&ei=VMpiaMInzMzqtA-G16fABQ&scisig=AAZF9b_yTB1R20z-t6ApkecZnFST&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift", "first_label": ["LLM"], "second_label": [], "data": "S Liang, J Liang, T Pang, C Du, A Liu, M Zhu, X Cao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInstruction tuning enhances large vision-language models (LVLMs) but increases \ntheir vulnerability to backdoor attacks due to their open design. Unlike prior studies in \nstatic settings, this paper explores backdoor attacks in LVLM instruction tuning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=http://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.pdf&hl=en&sa=X&d=5142527777954789704&ei=VMpiaMInzMzqtA-G16fABQ&scisig=AAZF9b9_2Tz_lMykq3n8fQAVehJc&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, M Dras, U Naseem\\xc2\\xa0- arXiv preprint arXiv:2506.02442, 2025\nThis paper presents a systematic evaluation of Large Language Models'(LLMs) \nbehavior on long-tail distributed (encrypted) texts and their safety implications. We \nintroduce a two-dimensional framework for assessing LLM safety:(1) instruction\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02442&hl=en&sa=X&d=15102350404536711280&ei=VMpiaMInzMzqtA-G16fABQ&scisig=AAZF9b_4gGVOvmiHUrKGvn2E4Vhh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems", "first_label": ["LLM"], "second_label": ["Agent", "Search"], "data": "X Li, J Chen, X Fang, S Ding, H Duan, Q Liu, K Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown remarkable capabilities in solving \ndiverse tasks. However, their proficiency in iteratively optimizing complex solutions \nthrough learning from previous feedback remains insufficiently explored. To bridge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10764&hl=en&sa=X&d=1134890120116902745&ei=VMpiaMInzMzqtA-G16fABQ&scisig=AAZF9b8s_mGNSGwzfKFs6o2hgsbd&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "L Jiang, Z Zhang, Z Wang, X Sun, Z Li, L Zhen, X Xu\\xc2\\xa0- arXiv preprint arXiv:2506.16760, 2025\nLarge Vision-Language Models (LVLMs) demonstrate exceptional performance \nacross multimodal tasks, yet remain vulnerable to jailbreak attacks that bypass built-\nin safety mechanisms to elicit restricted content generation. Existing black-box\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16760&hl=en&sa=X&d=12136733750645262486&ei=VMpiaMInzMzqtA-G16fABQ&scisig=AAZF9b8NosIP6RI9jYFVbBgmH01C&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring", "first_label": ["LLM"], "second_label": [], "data": "Y Li, Q Sheng, Y Yang, X Zhang, J Cao\\xc2\\xa0- arXiv preprint arXiv:2506.09996, 2025\nThough safety alignment has been applied to most large language models (LLMs), \nLLM service providers generally deploy a subsequent moderation as the external \nsafety guardrail in real-world products. Existing moderators mainly practice a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09996&hl=en&sa=X&d=8967671192696781749&ei=VMpiaMInzMzqtA-G16fABQ&scisig=AAZF9b-I099JquXawda445fWweEs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM Jailbreak Oracle", "first_label": ["LLM"], "second_label": [], "data": "S Lin, A Suri, A Oprea, C Tan\\xc2\\xa0- arXiv preprint arXiv:2506.17299, 2025\nAs large language models (LLMs) become increasingly deployed in safety-critical \napplications, the lack of systematic methods to assess their vulnerability to jailbreak \nattacks presents a critical security gap. We introduce the jailbreak oracle problem\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17299&hl=en&sa=X&d=13276394224623482198&ei=VMpiaMInzMzqtA-G16fABQ&scisig=AAZF9b9_2v0eFVwHwueuxrSl-vyP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Use Property-Based Testing to Bridge LLM Code Generation and Validation", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation"], "data": "L He, Z Chen, Z Zhang, J Shao, X Gao, L Sheng\\xc2\\xa0- arXiv preprint arXiv:2506.18315, 2025\nLarge Language Models (LLMs) excel at code generation, but ensuring their outputs \nto be functionally correct, especially in complex programming tasks, is a persistent \nchallenge. While traditional Test-Driven Development (TDD) offers a path for code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18315&hl=en&sa=X&d=3101719763251668573&ei=VMpiaMInzMzqtA-G16fABQ&scisig=AAZF9b8VwRdS0BYT5dVQlhiDylYe&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning", "first_label": ["LLM"], "second_label": [], "data": "GJ Perin, R Chen, X Chen, NST Hirata, Z Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have become indispensable in real-world \napplications. However, their widespread adoption raises significant safety concerns, \nparticularly in responding to socially harmful questions. Despite substantial efforts to\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15606&hl=en&sa=X&d=5494164285246185827&ei=VMpiaMInzMzqtA-G16fABQ&scisig=AAZF9b83jkzg6GWJfE0yBor7b9qA&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Smart Cuts: Enhance Active Learning for Vulnerability Detection by Pruning Bad Seeds", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "X Lan, T Menzies, B Xu\\xc2\\xa0- arXiv preprint arXiv:2506.20444, 2025\nVulnerability detection is crucial for identifying security weaknesses in software \nsystems. However, the effectiveness of machine learning models in this domain is \noften hindered by low-quality training datasets, which contain noisy, mislabeled, or\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.20444&hl=en&sa=X&d=10183691335888321487&ei=U8piaN2BMLWP6rQP0NbM6AY&scisig=AAZF9b8H0DjqIEGUL5Bu5B5aKxhR&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "3 new citations to articles by Xin ZHOU", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Evaluating the Test Adequacy of Benchmarks for LLMs on Code Generation", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation"], "data": "X Liu, X Sun, L Bo, Y Hu, X Liu, Z Ye\\xc2\\xa0- Journal of Software: Evolution and Process, 2025\nCode generation for users' intent has become increasingly prevalent with the large \nlanguage models (LLMs). To automatically evaluate the effectiveness of these \nmodels, multiple execution\\xe2\\x80\\x90based benchmarks are proposed, including specially\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.70034&hl=en&sa=X&d=12854615194772568307&ei=U8piaN2BMLWP6rQP0NbM6AY&scisig=AAZF9b8MDs-1Yrosy2y_whx6JbZA&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "EffiCoder: Enhancing Code Generation in Large Language Models through Efficiency-Aware Fine-tuning", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "D Huang, G Zeng, J Dai, M Luo, H Weng, Y Qing, H Cui\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nAs large language models (LLMs) play an increasingly important role in code \ngeneration, enhancing both correctness and efficiency has become crucial. Current \nmethods primarily focus on correctness, often overlooking efficiency. To address this\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D8bgaOg1TlZ&hl=en&sa=X&d=14915156030897718878&ei=U8piaN2BMLWP6rQP0NbM6AY&scisig=AAZF9b9r-VHALFoUjA9M0GRk-50r&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Retrieval-Augmented Code Review Comment Generation", "first_label": ["Code Review", "Code"], "second_label": ["Generation"], "data": "H Hong, J Baik\\xc2\\xa0- arXiv preprint arXiv:2506.11591, 2025\nAutomated code review comment generation (RCG) aims to assist developers by \nautomatically producing natural language feedback for code changes. Existing \napproaches are primarily either generation-based, using pretrained language\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11591&hl=en&sa=X&d=15885059784306332833&ei=U8piaN2BMLWP6rQP0NbM6AY&scisig=AAZF9b-1WT7RGxAC1bABTNtyDxhD&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "HPCTransCompile: An AI Compiler Generated Dataset for High-Performance CUDA Transpilation and LLM Preliminary Exploration", "first_label": ["LLM"], "second_label": [], "data": "J Lv, X He, Y Liu, X Dai, Y Hu, S Yin\\xc2\\xa0- arXiv preprint arXiv:2506.10401, 2025\nThe rapid growth of deep learning has driven exponential increases in model \nparameters and computational demands. NVIDIA GPUs and their CUDA-based \nsoftware ecosystem provide robust support for parallel computing, significantly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10401&hl=en&sa=X&d=14309937792901999617&ei=U8piaN2BMLWP6rQP0NbM6AY&scisig=AAZF9b_LyVd5W0C0U28-mRiJrH9j&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Synthesizing Software Engineering Data in a Test-Driven Manner", "first_label": ["Software Testing"], "second_label": [], "data": "L Zhang, J Yang, M Yang, J Yang, M Chen, J Zhang\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nWe introduce** SWE-Flow**, a novel data synthesis framework grounded in Test-\nDriven Development (TDD). Unlike existing software engineering data that rely on \nhuman-submitted issues,** SWE-Flow** automatically infers incremental\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DP9DQ2IExgS&hl=en&sa=X&d=8547569170249215358&ei=U8piaN2BMLWP6rQP0NbM6AY&scisig=AAZF9b8gNj1zFs_dhY5DtQxXJmJ1&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Towards More Effective Fault Detection in LLM-Based Unit Test Generation", "first_label": ["LLM", "Software Testing"], "second_label": ["Detection", "Generation"], "data": "G Wang, Q Xu, LC Briand, K Liu\\xc2\\xa0- arXiv preprint arXiv:2506.02954, 2025\nUnit tests play a vital role in uncovering potential faults in software. While tools like \nEvoSuite focus on maximizing code coverage, recent advances in large language \nmodels (LLMs) have shifted attention toward LLM-based test generation. However\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02954&hl=en&sa=X&d=5602972151000617790&ei=U8piaN2BMLWP6rQP0NbM6AY&scisig=AAZF9b-teZsjTIJdP31OgBwjNz0D&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Reductive Analysis with Compiler-Guided Large Language Models for Input-Centric Code Optimizations", "first_label": ["LLM", "Code"], "second_label": [], "data": "X Wang, X Hui, C Liao, X Shen\\xc2\\xa0- Proceedings of the ACM on Programming\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInput-centric program optimization aims to optimize code by considering the relations \nbetween program inputs and program behaviors. Despite its promise, a long-\nstanding barrier for its adoption is the difficulty of automatically identifying critical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729282&hl=en&sa=X&d=4066048552262082451&ei=U8piaN2BMLWP6rQP0NbM6AY&scisig=AAZF9b_cHHDNeP008iH4qW9Tn7JR&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "A First Look at Bugs in LLM Inference Engines", "first_label": ["LLM", "Bug"], "second_label": [], "data": "M Liu, S Zhong, W Bi, Y Zhang, Z Chen, Z Chen, X Liu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language model-specific inference engines (in short as\\\\emph {LLM inference \nengines}) have become a fundamental component of modern AI infrastructure, \nenabling the deployment of LLM-powered applications (LLM apps) across cloud and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09713&hl=en&sa=X&d=1829118811417287869&ei=U8piaN2BMLWP6rQP0NbM6AY&scisig=AAZF9b9PFvonW4DF-GngDik42RDE&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Pcebench: A multi-dimensional benchmark for evaluating large language models in parallel code generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "NA Le Chen, M Capota, T Hasabnis, N Hasabnis\\xe2\\x80\\xa6\\xc2\\xa0- Parallel code generation\\xc2\\xa0\\xe2\\x80\\xa6, 2025\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar?cluster=5646112575563555284&hl=en&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Automated Vulnerability Repair Based on Retrieval-Augmented Generation", "first_label": ["Vulnerabilities"], "second_label": ["Repair", "Generation"], "data": "S Cheng, Q Yu, Y Zhu, Z Huang\\xc2\\xa0- 2025 7th International Conference on Information\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs software scale continues to grow and complexity increases, vulnerabilities have \nbecome a significant issue affecting system security and stability. In recent years, \nadvancements in machine learning and natural language processing technologies \nhave made automated vulnerability repair an increasingly effective solution to this \nproblem. However, existing automated vulnerability repair methods often lack a \nsufficient understanding of code context, making it difficult to handle complex\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaVul4J: a dataset of reproducible Java vulnerabilities geared\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11041756/&hl=en&sa=X&d=5349250528594061207&ei=U8piaMrDLvuvieoPupH_2Ak&scisig=AAZF9b_aE4ks8JAMexncOwfU9qNE&oi=scholaralrt&hist=ylyK0_8AAAAJ:5615766320347152220:AAZF9b9Qy0LEut_atU8F20t2CTM_&html=&pos=0&folt=cit", "author": ["Quang-Cuong Bui"], "ref": ["1 new citation to articles by Quang-Cuong Bui", "3 new citations to articles by Xin ZHOU", "4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Estimating Uncertainty in Line-Level Defect Prediction via Perceptual Borderline Oversampling", "first_label": ["Software Defect"], "second_label": [], "data": "C Wu, S Guo, H Li, C Li, R Chen\\xc2\\xa0- ACM Transactions on Software Engineering and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware defect prediction aims to identify potentially defective software modules \nusing various techniques, while fine-grained line-level defect prediction can pinpoint \ndefective lines of code. This helps developers promptly discover and fix errors, \nthereby enhancing the efficiency of testing and code review. However, previous \nstudies often overlook the impact of characterizing noise and the skewed distribution \nof defect knowledge in software projects, making it difficult for current methods to\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDexBERT: Effective, Task-Agnostic and Fine-grained\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3746225&hl=en&sa=X&d=2221243845085863102&ei=U8piaNzkO8mQ6rQPpLDpqQo&scisig=AAZF9b-VIwEYT-j-T0ExR8Vf-0Dv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["3 new citations to articles by Xin ZHOU"]}
{"title": "Teaching an Old LLM Secure Coding: Localized Preference Optimization on Distilled Preferences", "first_label": ["LLM"], "second_label": ["Localization"], "data": "M Saqib, S Chakraborty, S Karmaker\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM generated code often contains security issues. We address two key challenges \nin improving secure code generation. First, obtaining high quality training data \ncovering a broad set of security issues is critical. To address this, we introduce a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00419&hl=en&sa=X&d=3471320712326210844&ei=VMpiaMnrAdSWieoP7PPKiQQ&scisig=AAZF9b-zP6iuspafIpJ9gFQhBsZE&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "UCP: a unified framework for code generation with pseudocode-based multi-task learning and reinforcement alignment", "first_label": ["Code"], "second_label": ["Generation"], "data": "Y Wen, Z Cui, Y Liu, Z Zhang, J Zhou, L Tang\\xc2\\xa0- The Journal of Supercomputing, 2025\nPre-trained large language models (LLMs) have been widely applied to natural \nlanguage-based code generation. However, because code generation tasks are \nhighly sensitive to structured information and exhibit diverse logical forms, directly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11227-025-07487-1&hl=en&sa=X&d=264978427275781755&ei=VMpiaMnrAdSWieoP7PPKiQQ&scisig=AAZF9b8HnhQLRB1NFzaWU0iyGBfI&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Mapping NVD Records to Their VFCs: How Hard is it?", "first_label": [], "second_label": [], "data": "HH Nguyen, DM Tran, Y Cheng, T Le-Cong, HJ Kang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMapping National Vulnerability Database (NVD) records to vulnerability-fixing \ncommits (VFCs) is crucial for vulnerability analysis but challenging due to sparse \nexplicit links in NVD references. This study explores this mapping's feasibility through\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09702&hl=en&sa=X&d=17350753801902205444&ei=VMpiaMnrAdSWieoP7PPKiQQ&scisig=AAZF9b9GdE1B-xLLhUOLme72JT4D&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Using Large Language Models for Aerospace Code Generation: Methods, Benchmarks, and Potential Values", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "R He, L Zhang, M Lyu, L Lyu, C Xue\\xc2\\xa0- Aerospace, 2025\nIn recent years, Large Language Models (LLMs) have witnessed rapid \nadvancements, revolutionizing various domains. Within the realm of software \ndevelopment, code generation technology powered by LLMs has emerged as a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2226-4310/12/6/498&hl=en&sa=X&d=10774117724622108555&ei=VMpiaMnrAdSWieoP7PPKiQQ&scisig=AAZF9b_rdKO7Y_152Nx4dsGU87hA&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "CCISolver: End-to-End Detection and Repair of Method-Level Code-Comment Inconsistency", "first_label": ["Code"], "second_label": ["Detection", "Repair"], "data": "R Zhong, Y Huo, W Gu, J Kuang, Z Jiang, G Yu, Y Li\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nComments within code serve as a crucial foundation for software documentation, \nfacilitating developers to communicate and understand the code effectively. \nHowever, code-comment inconsistency (CCI) can negatively affect software\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.20558&hl=en&sa=X&d=1752298852314553626&ei=VMpiaMnrAdSWieoP7PPKiQQ&scisig=AAZF9b9YMWbRb4xFMGmfFS3MTewM&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Adversarial Attack Classification and Robustness Testing for Large Language Models for Code", "first_label": ["LLM", "Code", "Software Testing"], "second_label": [], "data": "Y Liu, A Foundjem, F Khomh, H Li\\xc2\\xa0- arXiv preprint arXiv:2506.07942, 2025\nLarge Language Models (LLMs) have become vital tools in software development \ntasks such as code generation, completion, and analysis. As their integration into \nworkflows deepens, ensuring robustness against vulnerabilities especially those\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07942&hl=en&sa=X&d=10411796502631711196&ei=VMpiaMnrAdSWieoP7PPKiQQ&scisig=AAZF9b-eMQpfZUdxJwBqS5XD673H&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=7&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Towards Automating Domain-Specific Data Generation for Text-to-SQL: A Comprehensive Approach", "first_label": [], "second_label": ["Generation"], "data": "S Chafik, S Ezzini, I Berrada\\xc2\\xa0- ACM Transactions on Software Engineering and\\xc2\\xa0\\xe2\\x80\\xa6\nAs software systems increasingly rely on natural language interfaces, ensuring the \nreliability of these systems is crucial. One critical component is the ability to \naccurately translate natural language queries into corresponding SQL queries, a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3746226&hl=en&sa=X&d=16563225255177221814&ei=VMpiaMnrAdSWieoP7PPKiQQ&scisig=AAZF9b9xTgA9UDFaYcuj4K_SJBZr&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=8&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Intent-driven Web UI Tests Repair with LLM", "first_label": ["LLM", "Software Testing"], "second_label": ["Repair"], "data": "Y Tao, W Wang, J Guo\\xc2\\xa0- 2025 8th International Conference on Advanced\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs web applications are frequently updated, changes may introduce to web elements \nin new versions, causing test cases to fail. Consequently, automatic web test repair \ntechniques are proposed to reduce the cost of regression testing. Most existing \nmethods focus on finding the correct candidate elements or related attributes to fix \nthe broken test case. However, when test case failures are caused by test flow \nchanges or propagated breakages, those methods that focus solely on matching the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11042761/&hl=en&sa=X&d=14403944987015828325&ei=U8piaMjAMaKr6rQPxKWDUA&scisig=AAZF9b-QhxIYUCZrUfoyDCSsnVPs&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "HCC: A Language-Independent Hardening Contract Compiler for Smart Contracts", "first_label": ["Smart Contracts"], "second_label": [], "data": "JR Giesen, S Andreina, M Rodler, G Karame, L Davi\\xc2\\xa0- International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeveloping secure smart contracts remains a challenging task. Existing approaches \nare either impractical or leave the burden to developers for fixing bugs. In this paper, \nwe propose the first practical smart contract compiler, called hcc, which automatically \ninserts security hardening checks at the source-code level based on a novel and \nlanguage-independent code property graph (CPG) notation. The high \nexpressiveness of our developed CPG allows us to mitigate all of the most common\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart Contract Repair\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-95761-1_5&hl=en&sa=X&d=18240499024450880428&ei=U8piaMjAMaKr6rQPxKWDUA&scisig=AAZF9b_5sxQR9yzYs_jTFBkdhlqi&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "TypyBench: Evaluating LLM Type Inference for Untyped Python Repositories", "first_label": ["LLM"], "second_label": [], "data": "H Dong, J Yang, X Deng, Y Jiang, G Pekhimenko\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nType inference for dynamic languages like Python is a persistent challenge in \nsoftware engineering. While large language models (LLMs) have shown promise in \ncode understanding, their type inference capabilities remain underexplored. We\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dxl9sv9vEDy&hl=en&sa=X&d=5590401666570182726&ei=U8piaJeSLe2rieoPqNCcqA8&scisig=AAZF9b_1v2ZiYt35IkKDr0FkrnZ_&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Li, J Ding, C Peng, B Zhao, X Gao, H Gao, X Gu\\xc2\\xa0- arXiv preprint arXiv:2506.05692, 2025\nThe code generation capabilities of large language models (LLMs) have emerged as \na critical dimension in evaluating their overall performance. However, prior research \nhas largely overlooked the security risks inherent in the generated code. In this work\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05692%3F&hl=en&sa=X&d=5492650506064335063&ei=U8piaJeSLe2rieoPqNCcqA8&scisig=AAZF9b_uwkPsOhWMHWjfdGwYFezG&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "The Struggles of LLMs in Cross-Lingual Code Clone Detection", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "MB Moumoula, AK Kabor\\xc3\\xa9, J Klein, TF Bissyand\\xc3\\xa9\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the involvement of multiple programming languages in modern software \ndevelopment, cross-lingual code clone detection has gained traction within the \nsoftware engineering community. Numerous studies have explored this topic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715764&hl=en&sa=X&d=13415771137676208664&ei=U8piaJeSLe2rieoPqNCcqA8&scisig=AAZF9b94b9bfALws5oAEMt0gH9Lv&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Nemotron-CORTEXA: Enhancing LLM Agents for Software Engineering Tasks via Improved Localization and Solution Diversity", "first_label": ["LLM"], "second_label": ["Agent", "Localization"], "data": "A Sohrabizadeh, J Song, M Liu, R Roy, C Lee\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nLarge Language Models (LLMs) have demonstrated significant potential in code \ngeneration by following natural language instructions. Unfortunately, crucial real-\nworld software engineering tasks, such as debugging or repository-level feature\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dk6p8UKRdH7&hl=en&sa=X&d=951048739864022913&ei=U8piaJeSLe2rieoPqNCcqA8&scisig=AAZF9b-H11fzuFCoL6Gk97_KnR7i&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "AdaptiveLLM: A Framework for Selecting Optimal Cost-Efficient LLM for Code-Generation Based on CoT Length", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Cheng, F Liu, C Wu, L Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.10525, 2025\nWhile Large Language Models (LLMs) have significantly advanced code generation \nefficiency, they face inherent challenges in balancing performance and inference \ncosts across diverse programming tasks. Dynamically selecting the optimal LLM\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10525&hl=en&sa=X&d=12946040656504681529&ei=VMpiaI3LA6alieoP0qP0qQs&scisig=AAZF9b8m2TloB0C3Hd11YMxRGFIR&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "ZTaint-Havoc: From Havoc Mode to Zero-Execution Fuzzing-Driven Taint Inference", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Xie, W Zhang, D She\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nFuzzing is a popular software testing technique for discovering vulnerabilities. A \ncentral problem in fuzzing is identifying hot bytes that can influence program \nbehavior. Taint analysis can track the data flow of hot bytes in a white-box fashion\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728916&hl=en&sa=X&d=11807420278266769302&ei=VMpiaI3LA6alieoP0qP0qQs&scisig=AAZF9b8qJKOy3h08rQgyQ5y4FnqB&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Not One to Rule Them All: Mining Meaningful Code Review Orders From GitHub", "first_label": ["Code Review", "Code"], "second_label": [], "data": "A Bouraffa, C Brandt, A Zaidmann, W Maalej\\xc2\\xa0- arXiv preprint arXiv:2506.10654, 2025\nDevelopers use tools such as GitHub pull requests to review code, discuss proposed \nchanges, and request modifications. While changed files are commonly presented in \nalphabetical order, this does not necessarily coincide with the reviewer's preferred\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10654&hl=en&sa=X&d=3992668249292818405&ei=VMpiaI3LA6alieoP0qP0qQs&scisig=AAZF9b9_WwY7lVF-4S1NfuqiNPEi&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "AI-Enhanced Static Analysis: Reducing False Alarms Using Large Language Models", "first_label": ["LLM", "Static Analysis"], "second_label": [], "data": "GD Apostolidis, I Kalouptsoglou, M Siavvas\\xe2\\x80\\xa6\nIn modern software systems, the early and accurate detection of vulnerabilities is \ncritical from a security viewpoint. Traditional Static Analysis Tools (SATs) highlight \npotential security issues, providing fine-grained information including specific lines of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/George-Apostolidis/publication/392424588_AI-Enhanced_Static_Analysis_Reducing_False_Alarms_Using_Large_Language_Models/links/68415b128a76251f22ebacdb/AI-Enhanced-Static-Analysis-Reducing-False-Alarms-Using-Large-Language-Models.pdf&hl=en&sa=X&d=2853376939638096529&ei=VMpiaI3LA6alieoP0qP0qQs&scisig=AAZF9b_6Tc1rXYm7WUXzpijlYeBM&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "RIMFuzz: real-time impact-aware mutation for library API fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "X Wang, L Zhao\\xc2\\xa0- Journal of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs libraries merely expose APIs to developers rather than directly handling user \ninput, applying fuzzing to libraries requires fuzz drivers to help process fuzzer-\nprovided input and invoke APIs. To reduce manual effort and avoid reliance on\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00050-1&hl=en&sa=X&d=11566396351270247841&ei=U8piaIvuN_fWieoPvsyt2AE&scisig=AAZF9b9NzGapAGT-Gt26V3wejXNn&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Trailblazer: Practical End-to-end Web API Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "L Pan, S Cohney, T Murray, VT Pham\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThere are two key challenges in automatically testing web APIs:(a) determine where \nto send API requests and (b) identify how to make a valid payload for a given \nrequest. Both challenges are sometimes addressed by the presence of a machine\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3731717&hl=en&sa=X&d=13250706246401116236&ei=U8piaIvuN_fWieoPvsyt2AE&scisig=AAZF9b-ohQDK3DHvGNmHJasK8R14&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "LLM-powered test case generation for detecting bugs in plausible programs", "first_label": ["LLM", "Bug", "Software Testing"], "second_label": ["Detection", "Generation"], "data": "K Liu, Z Chen, Y Liu, JM Zhang, M Harman, Y Han\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 63rd\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDetecting tricky bugs in plausible programs, those that pass existing test suites yet \nstill contain bugs, remains a significant challenge in software testing. To address this \nproblem, we propose TrickCatcher, an LLM-powered approach to generating test\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://chenzhenpeng18.github.io/papers/ACL25_AID.pdf&hl=en&sa=X&d=1138877347567479720&ei=U8piaIvuN_fWieoPvsyt2AE&scisig=AAZF9b9cIXBHNvROwFBS9vlx4ynw&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "On the Applicability of Benford's Law to Detect Saturation in Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "J Lee, H Lee, S Park, SK Cha\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nKnowing when a fuzzing campaign has reached saturation is crucial for practitioners \nto avoid unnecessarily lengthy campaigns without missing bugs within given \nresources. Unfortunately, existing solutions for determining the saturation point rely\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3731723&hl=en&sa=X&d=16464785359231774820&ei=U8piaIvuN_fWieoPvsyt2AE&scisig=AAZF9b-hP7JkI_Vp2sP6UiYyub7W&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Leveraging activation and optimisation layers as dynamic strategies in the multi-task fuzzing scheme", "first_label": ["Fuzzing"], "second_label": [], "data": "S Bamohabbat Chafjiri, P Legg, MA Tsompanas\\xe2\\x80\\xa6 - 2025\nFuzzing is a common technique for identifying vulnerabilities in software. Recent \napproaches, like She et al.'s Multi-Task Fuzzing (MTFuzz), use neural networks to \nimprove fuzzing efficiency. However, key elements like network architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1016/j.csi.2025.104011&hl=en&sa=X&d=18210490462320417689&ei=U8piaIvuN_fWieoPvsyt2AE&scisig=AAZF9b-SniAFgKPoPY_eeSgA0SFX&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization", "first_label": ["Code"], "second_label": ["Localization"], "data": "D Gupta, GG Lakshmy, Y Xie\\xc2\\xa0- arXiv preprint arXiv:2506.20081, 2025\nRetrieval-Augmented Code Generation (RACG) is a critical technique for enhancing \ncode generation by retrieving relevant information. In this work, we conduct an in-\ndepth analysis of code retrieval by systematically masking specific features while\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.20081&hl=en&sa=X&d=12775045762874034763&ei=U8piaIvuN_fWieoPvsyt2AE&scisig=AAZF9b9ov4403FQkw-WjBazX_yPT&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
