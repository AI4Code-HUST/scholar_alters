{"title": "Privacy in Action: Towards Realistic Privacy Mitigation and Evaluation for LLM-Powered Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "S Wang, F Yu, X Liu, X Qin, J Zhang, Q Lin, D Zhang- arXiv preprint arXiv, 2025\nThe increasing autonomy of LLM agents in handling sensitive communications, \naccelerated by Model Context Protocol (MCP) and Agent-to-Agent (A2A) frameworks, \ncreates urgent privacy challenges. While recent work reveals significant gaps \nbetween LLMs' privacy Q&A performance and their agent behavior, existing \nbenchmarks remain limited to static, simplified scenarios. We present \nPrivacyChecker, a model-agnostic, contextual integrity based mitigation approach\nCites: Adaptive attacks break defenses against indirect prompt injection", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.17488&hl=en&sa=X&d=312274391396841502&ei=a9jVaPnkCsasieoPpPjngQI&scisig=AAZF9b9K3ap6j8j5OGZL-e49vsq7&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "SecureFixAgent: A Hybrid LLM Agent for Automated Python Static Vulnerability Repair", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Repair", "Agent"], "data": "J Gajjar, K Subramaniakuppusamy, R Puthal- arXiv preprint arXiv, 2025\nModern software development pipelines face growing challenges in securing large \ncodebases with extensive dependencies. Static analysis tools like Bandit are \neffective at vulnerability detection but suffer from high false positives and lack repair \ncapabilities. Large Language Models (LLMs), in contrast, can suggest fixes but often \nhallucinate changes and lack self-validation. We present SecureFixAgent, a hybrid \nrepair framework integrating Bandit with lightweight local LLMs (< 8B parameters) in\nCites: CVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.16275&hl=en&sa=X&d=4326118608227598374&ei=a9jVaPnkCsasieoPpPjngQI&scisig=AAZF9b_ygYc5Zk_yHyWWgFq9I7JR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang", "6 new citations to articles by Xin ZHOU"]}
{"title": "SABER: Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection", "first_label": ["Vulnerabilities"], "second_label": [], "data": "M Joshi, P Nandi, T Chakraborty- arXiv preprint arXiv:2509.16060, 2025\nLarge Language Models (LLMs) with safe-alignment training are powerful \ninstruments with robust language comprehension capabilities. These models \ntypically undergo meticulous alignment procedures involving human feedback to \nensure the acceptance of safe inputs while rejecting harmful or unsafe ones. \nHowever, despite their massive scale and alignment efforts, LLMs remain vulnerable \nto jailbreak attacks, where malicious users manipulate the model to produce harmful\nCites: Removing rlhf protections in gpt-4 via fine-tuning", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.16060&hl=en&sa=X&d=17261609647161767724&ei=a9jVaPnkCsasieoPpPjngQI&scisig=AAZF9b_SyebUxLZ6r0XGU8SWdNUO&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=2&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "Evaluating LLM Generated Detection Rules in Cybersecurity", "first_label": ["LLM"], "second_label": ["Detection"], "data": "A Bertiger, B Filar, A Luthra, S Meschiari, A Mitchell- arXiv preprint arXiv, 2025\nLLMs are increasingly pervasive in the security environment, with limited measures \nof their effectiveness, which limits trust and usefulness to security practitioners. Here, \nwe present an open-source evaluation framework and benchmark metrics for \nevaluating LLM-generated cybersecurity rules. The benchmark employs a holdout \nset-based methodology to measure the effectiveness of LLM-generated security \nrules in comparison to a human-generated corpus of rules. It provides three key\nCites: Llm agents can autonomously hack websites\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.16749&hl=en&sa=X&d=10597955481111603530&ei=a9jVaPnkCsasieoPpPjngQI&scisig=AAZF9b8O-vWxOyeTp_s2ah7AOHCp&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=3&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing", "first_label": ["LLM", "Fuzzing", "Software Testing"], "second_label": [], "data": "M Xiao, Y Xiao, S Ji, J Tu, P Zhang- arXiv preprint arXiv:2509.17335, 2025\nFuzzing has shown great success in evaluating the robustness of intelligent natural \nlanguage processing (NLP) software. As large language model (LLM)-based NLP \nsoftware is widely deployed in critical industries, existing methods still face two main \nchallenges: 1 testing methods are insufficiently coupled with the behavioral patterns \nof LLM-based NLP software; 2 fuzzing capability for the testing scenario of natural \nlanguage generation (NLG) generally degrades. To address these issues, we\nCites: Towards Reliable Evaluation of Neural Program Repair with", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.17335&hl=en&sa=X&d=5561943593931128081&ei=atjVaLDJIY6IieoPlO6dwA8&scisig=AAZF9b_pb5_048PeH6ooKSBjSJ82&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 new citations to articles by Thanh Le-Cong", "5 new citations to articles by Bach Le", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "How Far Are We? An Empirical Analysis of Current Vulnerability Localization Approaches", "first_label": ["Vulnerabilities"], "second_label": ["Localization"], "data": "H Xu, Z Chen, J Han, X Zhao, J Yin, S Deng- arXiv preprint arXiv:2509.15777, 2025\nOpen-source software vulnerability patch detection is a critical component for \nmaintaining software security and ensuring software supply chain integrity. \nTraditional manual detection methods face significant scalability challenges when \nprocessing large volumes of commit histories, while being prone to human errors \nand omissions. Existing automated approaches, including heuristic-based methods \nand pre-trained model solutions, suffer from limited accuracy, poor generalization\nCites: VulCurator: A Vulnerability-Fixing Commit Detector\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.15777&hl=en&sa=X&d=9112354886256225119&ei=atjVaLDJIY6IieoPlO6dwA8&scisig=AAZF9b_Y4gjtUlQar3-i9os54Gf1&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 new citations to articles by Thanh Le-Cong", "5 new citations to articles by Bach Le", "5 new citations to articles by Hong Jin Kang"]}
{"title": "RelRepair: Enhancing Automated Program Repair by Retrieving Relevant Code", "first_label": ["APR", "Code"], "second_label": ["Repair"], "data": "S Liu, G Bai, M Utting, G Yang- arXiv preprint arXiv:2509.16701, 2025\nAutomated Program Repair (APR) has emerged as a promising paradigm for \nreducing debugging time and improving the overall efficiency of software \ndevelopment. Recent advances in Large Language Models (LLMs) have \ndemonstrated their potential for automated bug fixing and other software engineering \ntasks. Nevertheless, the general-purpose nature of LLM pre-training means these \nmodels often lack the capacity to perform project-specific repairs, which require\nCites: S3: Syntax- and Semantic-Guided Repair Synthesis via", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.16701&hl=en&sa=X&d=15347269361517940440&ei=bNjVaNjKAY6IieoPlO6dwA8&scisig=AAZF9b8vu1eZydL8Y3sfpnI8ZfQS&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le", "Thanh Le-Cong - new related research", "10 new citations to articles by Abhik Roychoudhury", "David Lo - new related research", "Quang-Cuong Bui - new related research", "Xin ZHOU - new related research"]}
{"title": "Blockchain-Based Efficient Cross-Domain Access Control System for Autonomous Vehicle Data Sharing", "first_label": ["Blockchain"], "second_label": [], "data": "Y Li, Y Yin, H Gao, H Lei, Z Li, Y Li- ACM Transactions on Autonomous and Adaptive\nAutonomous driving requires the cooperation between vehicles and vehicle to \ninfrastructures, a substantial amount of data is continuously being generated and \nshared to support intelligent transportation. It is necessary to apply strict and flexible \naccess control mechanisms to protect data privacy in such complex scenarios. \nHowever, traditional centralized architecture cannot efficiently handle the usage and \nauthorization of autonomous vehicle data. To prioritize the data sharing among\nCites: Smart contract development: Challenges and opportunities", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769004&hl=en&sa=X&d=15729025039417514504&ei=bNjVaNjKAY6IieoPlO6dwA8&scisig=AAZF9b8-OkgBH3J8hAOdHVFB-Zhe&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=3&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le"]}
{"title": "Automated Facility Enumeration for Building Compliance Checking using Door Detection and Large Language Models", "first_label": ["LLM"], "second_label": ["Detection"], "data": "L Zhan, B Le, N Akhtar, T Ngo- arXiv preprint arXiv:2509.17283, 2025\nBuilding compliance checking (BCC) is a critical process for ensuring that \nconstructed facilities meet regulatory standards. A core component of BCC is the \naccurate enumeration of facility types and their spatial distribution. Despite its \nimportance, this problem has been largely overlooked in the literature, posing a \nsignificant challenge for BCC and leaving a critical gap in existing workflows. \nPerforming this task manually is time-consuming and labor-intensive. Recent\nCites: DoorDet: Semi-Automated Multi-Class Door Detection Dataset via\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.17283&hl=en&sa=X&d=14912654334653900535&ei=bNjVaNjKAY6IieoPlO6dwA8&scisig=AAZF9b9T3nFHucQLT4t3gijVdMLe&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=4&folt=cit", "author": ["Bach Le"], "ref": ["5 new citations to articles by Bach Le", "Bach Le - new articles"]}
{"title": "AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software", "first_label": ["LLM"], "second_label": [], "data": "R Yang, M Fu, C Tantithamthavorn, C Arora- arXiv preprint arXiv, 2025\nGuardrails are critical for the safe deployment of Large Language Models (LLMs)-\npowered software. Unlike traditional rule-based systems with limited, predefined \ninput-output spaces that inherently constrain unsafe behavior, LLMs enable open", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.16861&hl=en&sa=X&d=12778847261423124364&ei=bdjVaKn4N_iu6rQPoL_hyQw&scisig=AAZF9b_riHTMgcRy1SDsppcvpig1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Unraveling LLM Jailbreaks Through Safety Knowledge Neurons", "first_label": ["LLM"], "second_label": [], "data": "C Zhao, K Huang- arXiv preprint arXiv:2509.01631, 2025\nLarge Language Models (LLMs) are increasingly attracting attention in various \napplications. Nonetheless, there is a growing concern as some users attempt to \nexploit these models for malicious purposes, including the synthesis of controlled", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01631&hl=en&sa=X&d=1514740733256060014&ei=bdjVaKn4N_iu6rQPoL_hyQw&scisig=AAZF9b9hCs1ysD6JyG0WYWiQsfvZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "first_label": ["LLM"], "second_label": ["Agent"], "data": "T Lindenbauer, I Slinko, L Felder, E Bogomolov- arXiv preprint arXiv, 2025\nLarge Language Model (LLM)-based agents solve complex tasks through iterative \nreasoning, exploration, and tool-use, a process that can result in long, expensive \ncontext histories. While state-of-the-art Software Engineering (SE) agents like", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21433&hl=en&sa=X&d=3778813371369713554&ei=bdjVaKn4N_iu6rQPoL_hyQw&scisig=AAZF9b8vjKgLLO8JtQg2HjxwaIIj&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "DecipherGuard: Understanding and Deciphering Jailbreak Prompts for a Safer Deployment of Intelligent Software Systems", "first_label": [], "second_label": [], "data": "R Yang, M Fu, C Tantithamthavorn, C Arora- arXiv preprint arXiv, 2025\nIntelligent software systems powered by Large Language Models (LLMs) are \nincreasingly deployed in critical sectors, raising concerns about their safety during \nruntime. Through an industry-academic collaboration when deploying an LLM", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.16870&hl=en&sa=X&d=14786970252072141331&ei=bdjVaKn4N_iu6rQPoL_hyQw&scisig=AAZF9b_-6BD7dCVb_QOltOw2qmG8&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?", "first_label": [], "second_label": ["Agent"], "data": "X Deng, J Da, E Pan, YY He, C Ide, K Garg, N Lauffer- arXiv preprint arXiv, 2025\nWe introduce SWE-Bench Pro, a substantially more challenging benchmark that \nbuilds upon the best practices of SWE-BENCH [25], but is explicitly designed to \ncapture realistic, complex, enterprise-level problems beyond the scope of SWE", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.16941&hl=en&sa=X&d=16612405126166951427&ei=bdjVaKn4N_iu6rQPoL_hyQw&scisig=AAZF9b_Sny1WEMFE1cCFOEYpk5pL&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research", "10 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research", "David Lo - new related research"]}
{"title": "Strategic Dishonesty Can Undermine AI Safety Evaluations of Frontier LLM", "first_label": ["LLM"], "second_label": [], "data": "A Panfilov, E Kortukov, K Nikoli, M Bethge- arXiv preprint arXiv, 2025\nLarge language model (LLM) developers aim for their models to be honest, helpful, \nand harmless. However, when faced with malicious requests, models are trained to \nrefuse, sacrificing helpfulness. We show that frontier LLMs can develop a preference", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18058&hl=en&sa=X&d=5974652715231715788&ei=bdjVaKn4N_iu6rQPoL_hyQw&scisig=AAZF9b8FI8DpRTgWQLXJy9_20zE-&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "IntentionReasoner: Facilitating Adaptive LLM Safeguards through Intent Reasoning and Selective Query Refinement", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "Y Shen, Z Huang, Z Guo, Y Liu, G Chen, R Yin- arXiv preprint arXiv, 2025\nThe rapid advancement of large language models (LLMs) has driven their adoption \nacross diverse domains, yet their ability to generate harmful content poses significant \nsafety challenges. While extensive research has focused on mitigating harmful", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.20151%3F&hl=en&sa=X&d=341990395345011620&ei=bdjVaKn4N_iu6rQPoL_hyQw&scisig=AAZF9b_-ms9316_TkF43ylzTeIAY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Towards Transparent and Incentive-Compatible Collaboration in Decentralized LLM Multi-Agent Systems: A Blockchain-Driven Approach", "first_label": ["LLM", "Blockchain"], "second_label": ["Agent"], "data": "M Qi, T Zhu, L Zhang, N Li, W Zhou- arXiv preprint arXiv:2509.16736, 2025\nLarge Language Models (LLMs) have enabled the emergence of autonomous \nagents capable of complex reasoning, planning, and interaction. However, \ncoordinating such agents at scale remains a fundamental challenge, particularly in", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.16736&hl=en&sa=X&d=112890382982507064&ei=bdjVaKn4N_iu6rQPoL_hyQw&scisig=AAZF9b_AMXEORqN1k0Q4rb8JNgqy&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The fire tries gold: Evaluating pre-trained language models for multi-label vulnerability detection in ethereum smart contracts", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM", "Ethereum"], "second_label": ["Detection"], "data": "TK Luu, DM Trung, TD Tran, PT Duy, VH Pham- Journal of Systems and Software, 2025\nSmart contracts are integral components of blockchain ecosystems, yet they remain \nhighly susceptible to security vulnerabilities that can lead to severe financial and \noperational consequences. To address this, a range of vulnerability detection", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225003115&hl=en&sa=X&d=4615522462473200335&ei=bdjVaKn4N_iu6rQPoL_hyQw&scisig=AAZF9b8mF4aV7z3AbrLjb4NhA9PS&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Backdoor Mitigation via Invertible Pruning Masks", "first_label": [], "second_label": [], "data": "K Dunnett, R Arablouei, D Miller, V Dedeoglu, R Jurdak- arXiv preprint arXiv, 2025\nModel pruning has gained traction as a promising defense strategy against backdoor \nattacks in deep learning. However, existing pruning-based approaches often fall \nshort in accurately identifying and removing the specific parameters responsible for\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.15497&hl=en&sa=X&d=17839695143460234014&ei=bdjVaKn4N_iu6rQPoL_hyQw&scisig=AAZF9b-G5DBnxkb-uS_NiR4CAZw_&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LoCaL: Countering Surface Bias in Code Evaluation Metrics", "first_label": ["Code"], "second_label": [], "data": "SB Dristi, MB Dwyer- arXiv preprint arXiv:2509.15397, 2025\nWith the increasing popularity of large language models (LLMs) and LLM-based \nagents, reliable and effective code evaluation metrics (CEMs) have become crucial \nfor progress across several software engineering tasks. While popular benchmarks \noften provide test cases to assess the correctness of generated code, crafting and \nexecuting test cases is expensive. Reference-based CEMs provide a cheaper \nalternative by scoring a candidate program based on its functional similarity to a\nCites: CODE-DITING: A Reasoning-Based Metric for Functional", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.15397&hl=en&sa=X&d=13533776935078327992&ei=bdjVaLnlKsmk6rQPwcXzuAc&scisig=AAZF9b-edmzNnUbIc_nipIUm5Bnk&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["6 new citations to articles by Xin ZHOU"]}
{"title": "Brevity is the Soul of Wit: Condensing Code Changes to Improve Commit Message Generation", "first_label": ["Code", "Commit Message", "Code Change"], "second_label": ["Generation"], "data": "H Kuang, N Zhang, H Gao, X Zhou, WKG Assuno- arXiv preprint arXiv, 2025\nCommit messages are valuable resources for describing why code changes are \ncommitted to repositories in version control systems (eg, Git). They effectively help \ndevelopers understand code changes and better perform software maintenance \ntasks. Unfortunately, developers often neglect to write high-quality commit messages \nin practice. Therefore, a growing body of work is proposed to generate commit \nmessages automatically. These works all demonstrated that how to organize and\nCites: Exploring Parameter-Efficient Fine-Tuning Techniques for Code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.15567&hl=en&sa=X&d=3566966376596200560&ei=bdjVaLnlKsmk6rQPwcXzuAc&scisig=AAZF9b-vZA0Uf808DqbPbNRX2qRx&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["6 new citations to articles by Xin ZHOU", "David Lo - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research", "5 new citations to articles by Hong Jin Kang"]}
{"title": "BRMDS: an LLM-based multi-dimensional summary generation approach for bug reports", "first_label": ["LLM", "Bug"], "second_label": ["Generation"], "data": "Y Zhang, Y Li, M Fang, X Yuan, J Du- Automated Software Engineering, 2026\nBug report summarization aims to generate concise and accurate descriptions to \nhelp developers understand and maintain. The existing methodologies prioritize \nsimplifying reporting content but fail to provide a structured and well-rounded \ndescription of bugs, limiting developers' understanding efficiency. In this paper, we \nleverage large language models (LLMs) to generate detailed, multi-dimensional \nsummaries. Our intuition is based on the following facts:(1) LLMs establish robust\nCites: Out of Sight, Out of Mind: Better Automatic Vulnerability Repair by", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00553-1&hl=en&sa=X&d=174928423074309735&ei=bdjVaLnlKsmk6rQPwcXzuAc&scisig=AAZF9b89CRQCerlxBjA7m40lB3zT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=3&folt=cit", "author": ["Xin ZHOU"], "ref": ["6 new citations to articles by Xin ZHOU"]}
{"title": "AEAS: Actionable Exploit Assessment System", "first_label": [], "second_label": ["Exploit"], "data": "X Shen, W Cheng, Y Chen, Z Li, Y Gu, L Wang, W Zhao- arXiv preprint arXiv, 2025\nSecurity practitioners face growing challenges in exploit assessment, as public \nvulnerability repositories are increasingly populated with inconsistent and low-quality \nexploit artifacts. Existing scoring systems, such as CVSS and EPSS, offer limited \nsupport for this task. They either rely on theoretical metrics or produce opaque \nprobability estimates without assessing whether usable exploit code exists. In \npractice, security teams often resort to manual triage of exploit repositories, which is\nCites: Large language model for vulnerability detection: Emerging results", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.17832&hl=en&sa=X&d=17970522990433135486&ei=bdjVaLnlKsmk6rQPwcXzuAc&scisig=AAZF9b-U540RmgNBVcFVNoM_pQ7f&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=4&folt=cit", "author": ["Xin ZHOU"], "ref": ["6 new citations to articles by Xin ZHOU"]}
{"title": "Evaluating the Capability of Prompted LLMs to Recommend NFR from User Stories: A Preliminary Study", "first_label": ["LLM"], "second_label": [], "data": "JRA Pereira, M Perkusich, FBA Ramos- Simpsio Brasileiro de, 2025\nResumo [Context] Non-functional requirements (NFRs) are critical to software quality \nbut are often underspecified in agile projects. Previous work proposed NFRec, a k-\nnearest neighbors (kNN) recommender system, to support NFR elicitation based on \nstructured User Story metadata.[Objective] This study investigates whether Large \nLanguage Models (LLMs), when prompted with structured representations of User \nStories, can generate relevant NFRs comparable to those recommended by\nCites: Representation Learning for Stack Overflow Posts: How Far are We?\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/sbes/article/download/37045/36830/&hl=en&sa=X&d=9241788750515447533&ei=bdjVaLnlKsmk6rQPwcXzuAc&scisig=AAZF9b8jgZj_g8OnPfu6TNPNbzqC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=5&folt=cit", "author": ["Xin ZHOU"], "ref": ["6 new citations to articles by Xin ZHOU"]}
{"title": "404: Civility Not Found? Evaluating the Effectiveness of Small Language Models in Detecting Incivility in GitHub Conversations", "first_label": ["LLM"], "second_label": ["Detection"], "data": "M Patrcio, S Eufrsio, A Ucha, LS Rocha, D Coutinho- Simpsio Brasileiro de, 2025\nContext: Incivility in open-source software (OSS) platforms like GitHub can harm \ncollaboration, discourage contributor participation, and impact code quality. Although \ncurrent moderation tools based on Machine Learning (ML) and Natural Language", "link": "https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/sbes/article/download/37008/36793/&hl=en&sa=X&d=8286556912583976160&ei=a9jVaIqqHJXP6rQPo4LniQU&scisig=AAZF9b_jlkuJK4BY40jB1qNnC7OY&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Bach Le - new related research", "David Lo - new related research", "Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "On the Use of Imbalanced Datasets for Learning-Based Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "RZL Foulefack, A Marchetto- IFIP International Conference on Testing Software and, 2025\nStatic code analysis conducted by means of learning-based methods is an essential \npart of Security Testing. Effective learning algorithms are crucial for training reliable \nmodels that can accurately detect weaknesses and vulnerabilities. During models'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-05188-2_20&hl=en&sa=X&d=7711185064955775681&ei=a9jVaIqqHJXP6rQPo4LniQU&scisig=AAZF9b89r6zwK8DmhfjAM2OZUwge&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "SIExVulTS: Sensitive Information Exposure Vulnerability Detection System using Transformer Models and Static Analysis", "first_label": ["Vulnerabilities", "Static Analysis"], "second_label": ["Detection"], "data": "K Katz, S Moshtari, I Mujhid, M Mirakhorli, D Garcia- arXiv preprint arXiv:2508.19472, 2025\nSensitive Information Exposure (SIEx) vulnerabilities (CWE-200) remain a persistent \nand under-addressed threat across software systems, often leading to serious \nsecurity breaches. Existing detection tools rarely target the diverse subcategories of", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.19472&hl=en&sa=X&d=7796505405812517065&ei=a9jVaIqqHJXP6rQPo4LniQU&scisig=AAZF9b_N_o9MHRnErNEAJe_2k9p9&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "PeacemakerBot: A LLM-Powered Bot for Identifying and Reducing Signs of Incivility in GitHub Conversations", "first_label": ["LLM"], "second_label": ["Detection"], "data": "A Gomes, E Mesquita, E vila, C Jeft, A Mesquita- Simpsio Brasileiro de, 2025\nContext: Developers' interactions on collaborative software development platforms \nlike GitHub are key to maintaining technical alignment and community engagement. \nHowever, uncivil behaviors such as disrespectful, sarcastic, or offensive comments", "link": "https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/sbes/article/download/37072/36857/&hl=en&sa=X&d=10125934674601119665&ei=a9jVaIqqHJXP6rQPo4LniQU&scisig=AAZF9b8Pw9rHvLiGUIjd8lt4clD_&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "PIONEER: improving the robustness of student models when compressing pre-trained models of code", "first_label": ["Code"], "second_label": [], "data": "X Liu, X Liu, L Bo, X Wu, Y Yang, X Sun, F Zhou- Automated Software Engineering, 2026\nPre-trained models of code have shown significant effectiveness in a variety of \nsoftware engineering tasks, but they are difficult for local deployment due to their \nlarge size. Existing works mainly focus on compressing these large models into small\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00560-2&hl=en&sa=X&d=17836676178374949159&ei=a9jVaIqqHJXP6rQPo4LniQU&scisig=AAZF9b_ryg7uDpBLUFYEs8zWj5qt&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research", "5 new citations to articles by Hong Jin Kang"]}
{"title": "MatchFixAgent: Language-Agnostic Autonomous Repository-Level Code Translation Validation and Repair", "first_label": ["Code", "Repository-Level"], "second_label": ["Repair", "Generation", "Agent"], "data": "AR Ibrahimzada, B Paulsen, R Jabbarvand, J Dodds- arXiv preprint arXiv, 2025\nCode translation transforms source code from one programming language (PL) to \nanother. Validating the functional equivalence of translation and repairing, if \nnecessary, are critical steps in code translation. Existing automated validation and \nrepair approaches struggle to generalize to many PLs due to high engineering \noverhead, and they rely on existing and often inadequate test suites, which results in \nfalse claims of equivalence and ineffective translation repair. We develop\nCites: SpecRover: Code Intent Extraction via LLMs", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.16187&hl=en&sa=X&d=15628138488713843815&ei=bNjVaO6bMI6IieoPlO6dwA8&scisig=AAZF9b-c2sVrXLcJ4bl0xnIBxQHf&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research"]}
{"title": "Clotho: Measuring Task-Specific Pre-Generation Test Adequacy for LLM Inputs", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "J Yoon, S Kim, R Feldt, S Yoo- arXiv preprint arXiv:2509.17314, 2025\nSoftware increasingly relies on the emergent capabilities of Large Language Models \n(LLMs), from natural language understanding to program analysis and generation. \nYet testing them on specific tasks remains difficult and costly: many prompts lack \nground truth, forcing reliance on human judgment, while existing uncertainty and \nadequacy measures typically require full inference. A key challenge is to assess \ninput adequacy in a way that reflects the demands of the task, ideally before even\nCites: AutoCodeRover: Autonomous program improvement", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.17314&hl=en&sa=X&d=10179268634339549149&ei=bNjVaO6bMI6IieoPlO6dwA8&scisig=AAZF9b_3T5WqADXJjf3fi2G4Mqaf&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Enhancing Fuzz Testing Efficiency through Automated Fuzz Target Generation", "first_label": ["Fuzzing", "Software Testing"], "second_label": ["Generation"], "data": "TC Thien- Programming and Computer Software, 2025\nFuzzing remains to be the most effective method for identifying security \nvulnerabilities in software. In the context of fuzz testing, the fuzzer supplies varied \ninputs to fuzz targets, which are designed to comprehensively exercise critical \nsections of the client code. Various studies have focused on optimizing and \ndeveloping advanced fuzzers, such as AFL++, libFuzzer, Honggfuzz, syzkaller, ISP-\nFuzzer, which have substantially enhanced vulnerability detection in widely used\nCites: Fuzzing: Challenges and Reflections", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1134/S0361768825700227&hl=en&sa=X&d=11041934952071996068&ei=bNjVaO6bMI6IieoPlO6dwA8&scisig=AAZF9b9Vnf-xSeq5WrZELopRVRdV&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "STAFF: Stateful Taint-Assisted Full-system Firmware Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A Izzillo, R Lazzeretti, E Coppa- arXiv preprint arXiv:2509.18039, 2025\nModern embedded Linux devices, such as routers, IP cameras, and IoT gateways, \nrely on complex software stacks where numerous daemons interact to provide \nservices. Testing these devices is crucial from a security perspective since vendors \noften use custom closed-or open-source software without documenting releases and \npatches. Recent coverage-guided fuzzing solutions primarily test individual \nprocesses, ignoring deep dependencies between daemons and their persistent\nCites: AFLNet: a greybox fuzzer for network protocols", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18039&hl=en&sa=X&d=14471577617811823956&ei=bNjVaO6bMI6IieoPlO6dwA8&scisig=AAZF9b8iiNsdPIPeQqPwlBXEq_w5&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Certified Implementability of Global Multiparty Protocols", "first_label": [], "second_label": [], "data": "E Li, T Wies- 16th International Conference on Interactive Theorem, 2025\nImplementability is the decision problem at the heart of top-down approaches to \nprotocol verification. In this paper, we present a mechanization of a recently \nproposed precise implementability characterization by Li et al. for a large class of \nprotocols that subsumes many existing formalisms in the literature. Our protocols and \nimplementations model asynchronous commmunication, and can exhibit infinite \nbehavior. We improve upon their pen-and-paper results by unifying distinct\nCites: Symbolic message sequence charts", "link": "https://scholar.google.com/scholar_url?url=https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ITP.2025.15&hl=en&sa=X&d=9064981023453248096&ei=bNjVaO6bMI6IieoPlO6dwA8&scisig=AAZF9b_prdb_5KX3eTtCfDk_beGs&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "DIFFuzzer: Detecting File System Errors with Differential Grey-box Fuzzing", "first_label": ["Fuzzing"], "second_label": ["Detection"], "data": "VM Kovalevsky, VV Kechin, VM Itsykson-   , 2025\nFile systems are a crucial component of any modern operating system, whether it is a \ngeneral-purpose computing system or a specialized data storage system. The cost of \na file system error is very high; consequently, there is a need for effective tools for \nanalyzing quality and detecting errors in file systems. This paper presents the \nDIFFuzzer tool, which is based on fuzzing techniques using grey-box and black-box \nprinciples, and implements a differential dynamic analysis approach, where the\nCites: Coverage-based greybox fuzzing as markov chain\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://cyberleninka.ru/article/n/diffuzzer-detecting-file-system-errors-with-differential-grey-box-fuzzing&hl=en&sa=X&d=10323023655556245247&ei=bNjVaO6bMI6IieoPlO6dwA8&scisig=AAZF9b9YVEmkN8Bl0Szmfeqq6GT_&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=9&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "On the Effectiveness of Zero-shot and Few-shot Pretrained Language Models for Software Requirement Classification", "first_label": ["LLM"], "second_label": [], "data": "M Shafikuzzaman, MR Islam, S Zaman, A Ma, AI Sifat- IEEE Access, 2025\nAccurate classification of software requirements, particularly distinguishing between \nfunctional and non-functional requirements, is essential for enabling traceability, \nguiding system design, and ensuring project success. Traditional supervised", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/10820123/11153850.pdf&hl=en&sa=X&d=11947882102757591897&ei=atjVaJ_gNMmk6rQPwcXzuAc&scisig=AAZF9b8nTkSrJUN-rA-zvTdkgh4M&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Code Smell Classification in Python: Are Small Language Models Up to the Task?", "first_label": ["LLM", "Code"], "second_label": [], "data": "IS de Oliveira, J Carneiro, J Ribas, JA Pereira- Simpsio Brasileiro de Engenharia de, 2025\nCode quality is essential for maintainable and evolvable software systems. \nTraditional code smell detection tools rely on AST-based techniques and metric-\ndriven heuristics, which, while effective, often lack interpretability and require\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/sbes/article/download/37047/36832/&hl=en&sa=X&d=18402898699172092166&ei=atjVaJ_gNMmk6rQPwcXzuAc&scisig=AAZF9b9KaLZWt7YdY0lrsIOmj4-Q&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=4&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "SLICET5: Static Program Slicing using Language Models with Copy Mechanism and Constrained Decoding", "first_label": ["LLM"], "second_label": [], "data": "P He, S Wang, TH Chen- arXiv preprint arXiv:2509.17338, 2025\nStatic program slicing is a fundamental technique in software engineering. \nTraditional static slicing tools rely on parsing complete source code, which limits their \napplicability to real-world scenarios where code snippets are incomplete or", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.17338&hl=en&sa=X&d=4921860924420712207&ei=bNjVaMfTEfKOieoPiL7sqAc&scisig=AAZF9b994sWtYCI3oxtYe7Y3m1mM&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Investigating the bugs in reinforcement learning programs: Insights from Stack Overflow and GitHub", "first_label": ["Bug"], "second_label": [], "data": "J Song, Y Li, Y Tian, H Ma, H Li, J Zuo, J Liu, W Niu- Automated Software Engineering, 2026\nReinforcement learning (RL) is increasingly applied in areas such as gaming, robotic \ncontrol, and autonomous driving. Like to deep learning, RL systems also encounter \nfailures during operation. However, RL differs from deep learning in terms of its error", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00555-z&hl=en&sa=X&d=16862924269873925013&ei=bNjVaMfTEfKOieoPiL7sqAc&scisig=AAZF9b-JSYkQBFRHAGIjtZMKV7Q4&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Investigating the Impact of GitHub Discussions on Maintainers' Workload and Community Dynamics", "first_label": [], "second_label": [], "data": "A Maciel, M Wessel, I Wiese, I Steinmacher- Simpsio Brasileiro de Engenharia de, 2025\nResumo The introduction of GitHub Discussions, a space for informal communication \non GitHub, offers open-source communities a mechanism for engaging contributors \nbeyond traditional issue tracking and code review. While promising, the specific", "link": "https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/sbes/article/download/36984/36769&hl=en&sa=X&d=16157876462530351610&ei=bNjVaMfTEfKOieoPiL7sqAc&scisig=AAZF9b8jZyCBkq9Id4-gF9qUbPDB&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Identifying and Addressing Test Smells in JavaScript: A Developer-Centric Study", "first_label": ["Software Testing"], "second_label": ["Detection"], "data": "J Oliveira, L Mateus, G Amaral, T Virgnio, C Bezerra- Simpsio Brasileiro de, 2025\nTest smells are poor practices in test code that can compromise maintainability, \nreliability, and clarity. While the concept has been widely studied in languages such \nas Java and Python, research on test smells in JavaScript remains limiteddespite\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/sbes/article/download/36998/36783&hl=en&sa=X&d=12047644788338771341&ei=bdjVaNK0Aeak6rQP4M2KgAY&scisig=AAZF9b_dC_GkZbjF1f3zsm99Uw4P&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Integrating Large Language Models into Automated Software Testing", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "YS Iznaga, L Rato, P Salgueiro, JL Len- environments, 2025\nThis work investigates the use of LLMs to enhance automation in software testing, \nwith a particular focus on generating high-quality, context-aware test scripts from \nnatural language descriptions, while addressing both text-to-code and text+ code-to", "link": "https://scholar.google.com/scholar_url?url=https://www.preprints.org/frontend/manuscript/6dce9a44c01bba11d8679b804f89ffe3/download_pub&hl=en&sa=X&d=5631235108066530487&ei=btjVaOeyFKSgieoPmvLA-Ac&scisig=AAZF9b8frdiwv1HUKakv2-IdeP9i&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Highlight Test Code: Visualizing the Co-Evolution of Test and Production Code in Software Repositories", "first_label": ["Code", "Software Testing"], "second_label": [], "data": "C Miranda, G Avelino, PS Neto- Simpsio Brasileiro de Engenharia de Software, 2025\nThe asynchronous evolution of test and production code can compromise software \nquality and maintainability. However, identifying and analyzing such co-evolution \ndynamics remains a complex task, often hindered by the lack of scalable tools and", "link": "https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/sbes/article/download/37075/36860&hl=en&sa=X&d=17577561774027938597&ei=btjVaOeyFKSgieoPmvLA-Ac&scisig=AAZF9b_hW2BJp09WS8xmuDqO8pYI&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Prompt-with-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering", "first_label": ["LLM"], "second_label": [], "data": "Z Li, A Sergeyuk, M Izadi- arXiv preprint arXiv:2509.17096, 2025\nLarge Language Models are transforming software engineering, yet prompt \nmanagement in practice remains ad hoc, hindering reliability, reuse, and integration \ninto industrial workflows. We present Prompt-with-Me, a practical solution for", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.17096&hl=en&sa=X&d=3366051982113319524&ei=btjVaKfTB5Cq6rQPzKzJyAY&scisig=AAZF9b9gMkxshg0LjCOmRXqaBd0I&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Attentionsmelling: Using Large Language Models to Identify Code Smells", "first_label": ["LLM", "Code"], "second_label": [], "data": "A Gomes, D Sousa, P Maia, M Paixao- Brasileiro de Engenharia de Software (SBES), 2025\nResumo Large Language Models (LLMs) are becoming essential tools in software \nengineering, automating tasks like code generation, unit testing, and code review. \nHowever, their potential to identify code smells, indicators of poor code quality", "link": "https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/sbes/article/download/37005/36790&hl=en&sa=X&d=13013973983049932384&ei=btjVaKfTB5Cq6rQPzKzJyAY&scisig=AAZF9b8EJS9xSLzrZstcWz4_Qsy5&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=7&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "YourCoLo: Leveraging One-to-Many Relationships and Inter-Code Connections for User Review-Based Code Localization", "first_label": ["Code"], "second_label": ["Localization"], "data": "K Chi, C Niu, Z Yang, C Li, Y Feng, J Ge, B Luo, D Lo- ACM Transactions on Software\nIn an era where mobile devices are ubiquitous, digital distribution platforms such as \nthe Google Play Store have become integral to our daily lives, hosting millions of \napplications and serving billions of users. Users can leave reviews to provide\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3769010&hl=en&sa=X&d=16030377404662286117&ei=btjVaKfTB5Cq6rQPzKzJyAY&scisig=AAZF9b_Wl3nAW86c2-o7_u4Cyhl0&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=8&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Conversational Automated Program Repair for ARM Assembly Code using LLMs", "first_label": ["APR", "LLM", "Code"], "second_label": ["Repair"], "data": "J Gomes, D Silveira, T Jorge\nThis paper explores the development of the Automated Program Repair (APR) field, \nwith a specific emphasis on the use of Large Language Models (LLMs) to tackle the \nchallenges of ARM assembly code in the AIR project, a joint initiative between GMV", "link": "https://scholar.google.com/scholar_url?url=https://www.horizon-schumann.eu/wp-content/uploads/2025/07/Conversational_Automated_Program_Repair_for_ARM_Assembly_Code_using_LLMs_final.pdf&hl=en&sa=X&d=4367788842176228212&ei=bdjVaIrCD8nXieoPvqrN8Qs&scisig=AAZF9b_8xrU3osMG0qpQXxLpnrK7&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FuzzRDUCC: Fuzzing with Reconstructed Def-Use Chain Coverage", "first_label": ["Fuzzing"], "second_label": [], "data": "K Feng, J Singer, AK Marnerides- arXiv preprint arXiv:2509.04967, 2025\nBinary-only fuzzing often struggles with achieving thorough code coverage and \nuncovering hidden vulnerabilities due to limited insight into a program's internal \ndataflows. Traditional grey-box fuzzers guide test case generation primarily using", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04967&hl=en&sa=X&d=12793668697793724612&ei=bdjVaIrCD8nXieoPvqrN8Qs&scisig=AAZF9b9DbASTknJLZ9Qw2muyThkA&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FuzzBox: Blending Fuzzing into Emulation for Binary-Only Embedded Targets", "first_label": ["Fuzzing"], "second_label": [], "data": "C Cesarano, R Natella- arXiv preprint arXiv:2509.05643, 2025\nCoverage-guided fuzzing has been widely applied to address zero-day \nvulnerabilities in general-purpose software and operating systems. This approach \nrelies on instrumenting the target code at compile time. However, applying it to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05643&hl=en&sa=X&d=4585422960426806286&ei=bdjVaIrCD8nXieoPvqrN8Qs&scisig=AAZF9b-p7mmDlvT3yh-ZhB_TgxIV&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Leveraging SystemC-TLM-based Virtual Prototypes for Embedded Software Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "C Ghinami, J Winzer, N Bosbach, LM Reimann- arXiv preprint arXiv, 2025\nSystemC-based virtual prototypes have emerged as widely adopted tools to test \nsoftware ahead of hardware availability, reducing the time-to-market and improving \nsoftware reliability. Recently, fuzzing has become a popular method for automated", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01318&hl=en&sa=X&d=1341175212014518141&ei=bdjVaIrCD8nXieoPvqrN8Qs&scisig=AAZF9b9xqbJnzFJ8oCl2uemQ46wF&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Syntactic multilingual probing of pre-trained language models of code", "first_label": ["LLM", "Code"], "second_label": [], "data": "JAH Lpez, M Weyssow, JS Cuadrado, H Sahraoui- Journal of Systems and, 2026\nPre-trained language models (PLMs) have demonstrated remarkable abilities in \ncoding tasks, establishing themselves as a state-of-the-art technique in machine \nlearning for code. However, due to their deep neural network-based structure, PLMs", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225002730&hl=en&sa=X&d=912414639058686127&ei=bdjVaIrCD8nXieoPvqrN8Qs&scisig=AAZF9b_JpbZnEYTzTsY6dFTnCppp&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Localizing Malicious Outputs from CodeLLM", "first_label": ["LLM", "Code"], "second_label": [], "data": "M Borana, J Liang, SS Rajan, S Chattopadhyay- arXiv preprint arXiv:2509.17070, 2025\nWe introduce FreqRank, a mutation-based defense to localize malicious components \nin LLM outputs and their corresponding backdoor triggers. FreqRank assumes that \nthe malicious sub-string (s) consistently appear in outputs for triggered inputs and \nuses a frequency-based ranking system to identify them. Our ranking system then \nleverages this knowledge to localize the backdoor triggers present in the inputs. We \ncreate nine malicious models through fine-tuning or custom instructions for three\nCites: Stealthy backdoor attack for code models", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.17070&hl=en&sa=X&d=2487925136899898871&ei=a9jVaPLOLaOj6rQPr53X-Qw&scisig=AAZF9b9aczRN_cy72xXRa4MbDGni&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["5 new citations to articles by Hong Jin Kang"]}
{"title": "Why android app testing falls short: empirical insights from open-source projects and a practitioner survey", "first_label": ["Software Testing"], "second_label": [], "data": "T Mahmud, M Che, A Ngu, G Yang- Empirical Software Engineering, 2025\nAndroid dominates the mobile operating system market, yet ensuring the quality and \nreliability of Android applications remains a persistent challenge. The diversity of \ndevices, screen sizes, and OS versions complicates testing, leading to fragmented \nadoption of best practices. Despite advancements in automated testing, there is \nLimited empirical evidence on how developers test Android applications and the \nextent to which existing tools and frameworks are utilized effectively. In this paper, we\nCites: Androevolve: Automated update for android deprecated-api usages", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10726-x&hl=en&sa=X&d=13245643045530486566&ei=a9jVaPLOLaOj6rQPr53X-Qw&scisig=AAZF9b_1SsEOxu2Pc8fum_eh3ZIu&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["5 new citations to articles by Hong Jin Kang"]}
{"title": "When Code Crosses Borders: A Security-Centric Evaluation of LLM-based Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "H Chang, G Meng, S Xiao, K Chen, K Sun, Y Li- arXiv preprint arXiv:2509.06504, 2025\nWith the growing demand for cross-language codebase migration, evaluating LLMs' \nsecurity implications in translation tasks has become critical. Existing evaluations \nprimarily focus on syntactic or functional correctness at the function level, neglecting\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.06504&hl=en&sa=X&d=15964686870607645440&ei=SkTUaKeYOKOj6rQPxs2duQU&scisig=AAZF9b9rJmR42d8IPErh15fFE3f8&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "PromeFuzz: A Knowledge-Driven Approach to Fuzzing Harness Generation with Large Language Models", "first_label": ["LLM", "Fuzzing"], "second_label": ["Generation"], "data": "Y Liu, J Deng, X Jia, Y Wang, M Wang, L Huang, T Wei\nFuzzing has long been recognized as an effective technique for uncovering security \nvulnerabilities by automatically generating and executing a diverse set of inputs [2, 3, \n6, 8, 14, 15, 18, 20, 24, 26, 30, 32, 34, 46, 52, 53, 55, 58]. Traditional fuzzing tools", "link": "https://scholar.google.com/scholar_url?url=https://pvz122.github.io/pdf/25-promefuzz.pdf&hl=en&sa=X&d=12396611312661296556&ei=S0TUaIjDDpXP6rQP5rHHiQo&scisig=AAZF9b-wSitwHBsEc3RIko2Rlc5c&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Fuzzing JavaScript Engines by Fusing JavaScript and WebAssembly", "first_label": ["Fuzzing"], "second_label": [], "data": "J Lin, C Luo, M Zhang, L Lin, P Li, C Qian - 2026\nJavaScript engines are a fundamental part of modern browsers, and many efforts \nhave been invested in testing them to enhance their security. However, the \nincorporation of WebAssembly into JavaScript engines introduces new attack\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://peng-hui.github.io/data/paper/icse26:mad-eye.pdf&hl=en&sa=X&d=7025301240690243176&ei=S0TUaIjDDpXP6rQP5rHHiQo&scisig=AAZF9b87H2l6opoFTjGi99T54n3u&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Enhancing Vulnerability-Fixing Commit Classification: The Synergy of User-Guided and LLM", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "Y Zheng, H Zhuang, D Wang, H Cao, C Qian\nWith the increasing complexity of software development environments, identifying \nand fixing vulnerabilities has become a key aspect of software maintenance. One \nway to improve the efficiency and effectiveness of vulnerability-fixing is to classify\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=http://poster-openaccess.com/files/ICIC2025/3920.pdf&hl=en&sa=X&d=4621968745240783450&ei=TETUaJfsBsmk6rQPxc_v6QY&scisig=AAZF9b8ft-6jddYIlsXjNrKNhV8T&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "1 new citation to articles by Hong Jin Kang", "1 new citation to articles by Thanh Le-Cong", "1 new citation to articles by Bach Le"]}
{"title": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution (arXiv version)", "first_label": ["LLM"], "second_label": [], "data": "K Even-Mendoza, A Brownlee, A Geiger, C Hanna - 2025\nGenetic Improvement (GI) of software automatically creates alternative software \nversions that are improved according to certain properties of interests (eg, running-\ntime). Search-based GI excels at navigating large program spaces, but operates\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://kclpure.kcl.ac.uk/portal/en/publications/llm-guided-genetic-improvement-envisioning-semantic-aware-automat&hl=en&sa=X&d=17522263310458421835&ei=TETUaKayF5u1ieoP1tDwoQs&scisig=AAZF9b9Mrgn6Wd2hitLrRWwo4Pj-&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "LLM as an Execution Estimator: Recovering Missing Dependency for Practical Time-travelling Debugging", "first_label": ["LLM", "Bug"], "second_label": [], "data": "Y Pei, H Wang, W Zhang, Y Lin, W Kong- arXiv preprint arXiv:2508.18721, 2025\nDynamic data dependency, answering\" why a variable has this value?\", is critical for \ndebugging. Given a program stepsreading a variablev, finding the dynamic definition \nofvis challenging. Traditional methods require either (1) exhaustive instrumentation", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.18721&hl=en&sa=X&d=9469297087740937979&ei=SkTUaM7fDuvD6rQP6euP0Ao&scisig=AAZF9b99kfXihCB2m5Hyo4na6QuH&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "MSFuzz: Directed Greybox Fuzzing Using Multi-Target Sensitivity-Based Energy Scheduling", "first_label": ["Fuzzing"], "second_label": [], "data": "C Qin, Z Ma\nDirected Greybox Fuzzing (DGF) effectively targets specific program locations for bug \ndiscovery, but existing tools face challenges in multi-target directed fuzzing due to \nstatic stage division and coarse energy scheduling. Key challenges include global \noptimization biases that overlook lower-priority targets, inadequate prioritization of \nseeds that reach multiple targets, and inflexible exploration-exploitation stage \nallocation. This paper presents adaptive strategies to tackle these issues: a multi\nCites: Directed greybox fuzzing\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=http://poster-openaccess.com/files/ICIC2025/3948.pdf&hl=en&sa=X&d=15747512734137565556&ei=SkTUaKqKJKDWieoPyfiAmA8&scisig=AAZF9b_R_IL7DL7ECBT5e3k37l6w&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["1 new citation to articles by Abhik Roychoudhury"]}
{"title": "Paladin: Defending LLM-enabled Phishing Emails with a New Trigger-Tag Paradigm", "first_label": ["LLM"], "second_label": [], "data": "Y Pang, W Meng, X Liao, T Wang- arXiv preprint arXiv:2509.07287, 2025\nWith the rapid development of large language models, the potential threat of their \nmalicious use, particularly in generating phishing content, is becoming increasingly \nprevalent. Leveraging the capabilities of LLMs, malicious users can synthesize", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.07287&hl=en&sa=X&d=841142860163656335&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b9zUiVve_NVtg5_7UjR-gXJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Backdoor Attacks and Defenses in Computer Vision Domain: A Survey", "first_label": [], "second_label": [], "data": "BH Abbasi, Y Zhang, L Zhang, S Gao- arXiv preprint arXiv:2509.07504, 2025\nBackdoor (trojan) attacks embed hidden, controllable behaviors into machine-\nlearning models so that models behave normally on benign inputs but produce \nattacker-chosen outputs when a trigger is present. This survey reviews the rapidly", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.07504&hl=en&sa=X&d=3269854252125827141&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b9hUL9vDNoEXnWcZIb5H3Bf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Leveraging CVAE Encoding for Backdoor Attacks in Few-Shot Learning with Prototypical Networks", "first_label": [], "second_label": [], "data": "Q Yan, S Liang, A Ullah- IEEE Transactions on Dependable and Secure, 2025\nFew-shot learning (FSL) has demonstrated tremendous potential when challenged \nwith limited training data, but the assessment of its vulnerability to backdoor attacks is \nstill at an early stage. However, recent research revealed this deep learning", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11152502/&hl=en&sa=X&d=6687930075784700670&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b9ptsbEWBr80FGSyzcZR2Er&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Prototype-Guided Robust Learning against Backdoor Attacks", "first_label": [], "second_label": [], "data": "W Guo, M Pintor, A Demontis, B Biggio- arXiv preprint arXiv:2509.08748, 2025\nBackdoor attacks poison the training data to embed a backdoor in the model, \ncausing it to behave normally on legitimate inputs but maliciously when specific \ntrigger signals appear. Training a benign model from a dataset poisoned by", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.08748&hl=en&sa=X&d=9079518275239981489&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b8nbcMJrz3EP9De5YM82FpF&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Exploit Tool Invocation Prompt for Tool Behavior Hijacking in LLM-Based Agentic System", "first_label": ["LLM"], "second_label": ["Agent", "Exploit"], "data": "Y Liu, Y Xie, M Luo, Z Liu, Z Zhang, K Zhang, Z Li- arXiv preprint arXiv, 2025\nLLM-based agentic systems leverage large language models to handle user queries, \nmake decisions, and execute external tools for complex tasks across domains like \nchatbots, customer service, and software engineering. A critical component of these", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05755%3F&hl=en&sa=X&d=7380962265010499197&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b_WNN5iEJzU4LQ3fLBGGpF6&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Prompt-in-Content Attacks: Exploiting Uploaded Inputs to Hijack LLM Behavior", "first_label": ["LLM"], "second_label": ["Exploit"], "data": "Z Lian, W Wang, Q Zeng, T Nakanishi, T Kitasuka, C Su- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) are widely deployed in applications that accept user-\nsubmitted content, such as uploaded documents or pasted text, for tasks like \nsummarization and question answering. In this paper, we identify a new class of", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.19287%3F&hl=en&sa=X&d=15365588001769154326&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b9rDXev84fKcPnDvE_cVDTn&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Oyster-I: Beyond Refusal--Constructive Safety Alignment for Responsible Language Models", "first_label": ["LLM"], "second_label": [], "data": "R Duan, J Liu, X Jia, S Zhao, R Cheng, F Wang, C Wei- arXiv preprint arXiv, 2025\nLarge language models (LLMs) typically deploy safety mechanisms to prevent \nharmful content generation. Most current approaches focus narrowly on risks posed \nby malicious actors, often framing risks as adversarial events and relying on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01909%3F&hl=en&sa=X&d=6590160868100905669&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b8p2pmNGwnqdehrNy547NkZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Jailbreak Attack with Multimodal Virtual Scenario Hypnosis for Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "X Shi, S Chen, G Zhang, W Wei, Y Li, Z Fan, J Liu- Pattern Recognition, 2025\nDue to the inherent vulnerabilities of large Vision-Language Models (VLMs), security \ngovernance has emerged as a critical concern, particularly given the risks posed by \nnoisy and biased training data as well as adversarial attacks, including data", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0031320325010520&hl=en&sa=X&d=18404876866865125967&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b9xJx3YOX0I9CBN24pCw_YG&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Backdoor defense based on adversarial prediction proximity and contrastive knowledge distillation", "first_label": [], "second_label": [], "data": "L Huang, LY Zhang, CC Chang, W Wang, C Qin- Pattern Recognition, 2025\nHighlightsWe propose a scheme that can realize backdoor detection and backdoor \npurification.Our scheme can defend against both visible and invisible backdoors.\nPoisoned labels can be detected without using the label-by-label way.Adversarial", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0031320325009975&hl=en&sa=X&d=16049830957057689748&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b9yG7oV3XS0gADdXNotiCMQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Why language models hallucinate", "first_label": ["LLM"], "second_label": [], "data": "AT Kalai, O Nachum, SS Vempala, E Zhang- arXiv preprint arXiv:2509.04664, 2025\nLike students facing hard exam questions, large language models sometimes guess \nwhen uncertain, producing plausible yet incorrect statements instead of admitting \nuncertainty. Such\" hallucinations\" persist even in state-of-the-art systems and\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04664&hl=en&sa=X&d=17470905045322269269&ei=S0TUaMDrMo6IieoP-daq8AQ&scisig=AAZF9b9-xvJdrsXYLi4Kkc78fX8P&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models", "first_label": ["LLM", "Bug", "Repository-Level"], "second_label": [], "data": "J Liu, Z Liu, Z Cheng, M He, X Shi, Y Guo, X Zhu, Y Guo- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have exhibited significant proficiency in code \ndebugging, especially in automatic program repair, which may substantially reduce \nthe time consumption of developers and enhance their efficiency. Significant\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04078%3F&hl=en&sa=X&d=12419661760319839544&ei=SUTUaMySBOvD6rQP6euP0Ao&scisig=AAZF9b8SHef7li0_lXitWcja8LI-&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
