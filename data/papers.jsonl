{"title": "CODEMENV: Benchmarking Large Language Models on Code Migration", "first_label": ["LLM", "Code"], "second_label": [], "data": "K Cheng, X Shen, Y Yang, T Wang, Y Cao, MA Ali\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have shown remarkable capabilities across various \nsoftware engineering tasks; however, their effectiveness in code migration, adapting \ncode to run in different environments, remains insufficiently studied. In this work, we\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00894&hl=en&sa=X&d=11203773371204290692&ei=KWNDaMecD7XCieoPt6N7&scisig=AAZF9b9TDVO2Og3WPkp2gR-1hZyY&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Teaching an Old LLM Secure Coding: Localized Preference Optimization on Distilled Preferences", "first_label": ["LLM"], "second_label": ["Localization"], "data": "M Saqib, S Chakraborty, S Karmaker\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM generated code often contains security issues. We address two key challenges \nin improving secure code generation. First, obtaining high quality training data \ncovering a broad set of security issues is critical. To address this, we introduce a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00419&hl=en&sa=X&d=3471320712326210844&ei=KWNDaMecD7XCieoPt6N7&scisig=AAZF9b-zP6iuspafIpJ9gFQhBsZE&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Rethinking the effects of data contamination in Code Intelligence", "first_label": ["Code"], "second_label": [], "data": "Z Yang, H Lin, Y He, J Xu, Z Sun, S Liu, P Wang, Z Yu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, code intelligence has gained increasing importance in the field of \nautomated software engineering. Meanwhile, the widespread adoption of Pretrained \nLanguage Models (PLMs) and Large Language Models (LLMs) has raised concerns\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02791&hl=en&sa=X&d=13914802631128746138&ei=KWNDaMecD7XCieoPt6N7&scisig=AAZF9b9FbJDsSBQv15gRiA2JZNoe&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Towards More Effective Fault Detection in LLM-Based Unit Test Generation", "first_label": ["LLM", "Software Testing"], "second_label": ["Detection", "Generation"], "data": "G Wang, Q Xu, LC Briand, K Liu\\xc2\\xa0- arXiv preprint arXiv:2506.02954, 2025\nUnit tests play a vital role in uncovering potential faults in software. While tools like \nEvoSuite focus on maximizing code coverage, recent advances in large language \nmodels (LLMs) have shifted attention toward LLM-based test generation. However\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02954&hl=en&sa=X&d=5602972151000617790&ei=KWNDaMecD7XCieoPt6N7&scisig=AAZF9b-teZsjTIJdP31OgBwjNz0D&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research", "Thanh Le-Cong - new related research"]}
{"title": "A Preference-Driven Methodology for High-Quality Solidity Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "Z Peng, X Yin, C Ying, C Ni, Y Luo\\xc2\\xa0- arXiv preprint arXiv:2506.03006, 2025\nWhile Large Language Models (LLMs) have demonstrated remarkable progress in \ngenerating functionally correct Solidity code, they continue to face critical challenges \nin producing gas-efficient and secure code, which are critical requirements for real\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03006&hl=en&sa=X&d=17726484644696653033&ei=KWNDaMecD7XCieoPt6N7&scisig=AAZF9b-kQj0MkmtCeWsZksOvGyp1&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "EvoTaint: Incremental Static Taint Analysis of Evolving Android Apps", "first_label": [], "second_label": [], "data": "J GUO, H CAI - 2025\nEvoTaint: Incremental Static Taint Analysis of Evolving Android Apps Page 1 EvoTaint: \n\\r\\nIncremental Static Taint Analysis of Evolving Android Apps JIAWEI GUO, University at \n\\r\\nBuffalo, SUNY, USA HAIPENG CAI\\xe2\\x88\\x97, University at Buffalo, SUNY, USA In the last\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Haipeng-Cai/publication/392269894_EvoTaint_Incremental_Static_Taint_Analysis_of_Evolving_Android_Apps/links/683bc581d1054b0207f8b234/EvoTaint-Incremental-Static-Taint-Analysis-of-Evolving-Android-Apps.pdf&hl=en&sa=X&d=11445709114946387781&ei=KWNDaMecD7XCieoPt6N7&scisig=AAZF9b_QhW6jcbhyhVy4Rs4l2Tz-&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "A Multi-agent LLM-based JUit Test Generation with Strong Oracles", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation", "Agent"], "data": "Q Xu, G Wang, L Briand, K Liu\\xc2\\xa0- arXiv preprint arXiv:2506.02943, 2025\nUnit testing plays a critical role in ensuring software correctness. However, writing \nunit tests manually is laborious, especially for strong typed languages like Java, \nmotivating the need for automated approaches. Traditional methods primarily rely on\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02943&hl=en&sa=X&d=9080051622854454343&ei=KWNDaMecD7XCieoPt6N7&scisig=AAZF9b-W733SKwSoE4FIE6fi3cJw&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Exploring Prompt Patterns in AI-Assisted Code Generation: Towards Faster and More Effective Developer-AI Collaboration", "first_label": ["Code"], "second_label": ["Generation"], "data": "S DiCuffa, A Zambrana, P Yadav, S Madiraju, K Suman\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe growing integration of AI tools in software development, particularly Large \nLanguage Models (LLMs) such as ChatGPT, has revolutionized how developers \napproach coding tasks. However, achieving high-quality code often requires iterative\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.01604&hl=en&sa=X&d=2802840246323475232&ei=KWNDaMecD7XCieoPt6N7&scisig=AAZF9b_SsZ4-K7lqqE0zYDkae7M-&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Simplifying Root Cause Analysis in Kubernetes with StateGraph and LLM", "first_label": ["LLM"], "second_label": ["Graph"], "data": "Y Xiang, CP Chen, L Zeng, W Yin, X Liu, H Li, W Xu\\xc2\\xa0- arXiv preprint arXiv:2506.02490, 2025\nKubernetes, a notably complex and distributed system, utilizes an array of controllers \nto uphold cluster management logic through state reconciliation. Nevertheless, \nmaintaining state consistency presents significant challenges due to unexpected\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02490&hl=en&sa=X&d=5123869491118168077&ei=KWNDaMecD7XCieoPt6N7&scisig=AAZF9b941F9ak4iWL2XhEVmYDE88&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "7 new citations to articles by Abhik Roychoudhury"]}
{"title": "RIMFuzz: real-time impact-aware mutation for library API fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "X Wang, L Zhao\\xc2\\xa0- Journal of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs libraries merely expose APIs to developers rather than directly handling user \ninput, applying fuzzing to libraries requires fuzz drivers to help process fuzzer-\nprovided input and invoke APIs. To reduce manual effort and avoid reliance on\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00050-1&hl=en&sa=X&d=11566396351270247841&ei=KWNDaMecD7XCieoPt6N7&scisig=AAZF9b9NzGapAGT-Gt26V3wejXNn&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "8 new citations to articles by Abhik Roychoudhury", "Abhik Roychoudhury - new related research"]}
{"title": "Improving LLM Agents with Reinforcement Learning on Cryptographic CTF Challenges", "first_label": ["LLM"], "second_label": ["Agent", "Graph"], "data": "L Muzsai, D Imolai, A Luk\\xc3\\xa1cs\\xc2\\xa0- arXiv preprint arXiv:2506.02048, 2025\nLarge Language Models (LLMs) still struggle with the structured reasoning and tool-\nassisted computation needed for problem solving in cybersecurity applications. In \nthis work, we introduce\" random-crypto\", a cryptographic Capture-the-Flag (CTF) \nchallenge generator framework that we use to fine-tune a tool-augmented Llama-3.1-\n8B with Guided Reinforcement Prompt Optimisation (GRPO), allowing the agent to \niteratively write and execute Python inside an isolated REPL. GRPO yields a+ 53\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTeams of llm agents can exploit zero-day vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02048&hl=en&sa=X&d=18189145546159441726&ei=KWNDaPDDCZLXieoPwNDK0Qk&scisig=AAZF9b_5rlalF1mfqKk70xRHnoWh&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "AI in Security", "first_label": [], "second_label": [], "data": "DP Sharma, A Habibi Lashkari, MD Firoozjaei\\xe2\\x80\\xa6\\xc2\\xa0- Understanding AI in\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the rapid advancements in Artificial Intelligence (AI), its role in cybersecurity has \nbecome increasingly significant. AI is a double-edged sword, empowering both \ndefenders and attackers in the evolving threat landscape. This chapter explores the \ngeneral framework of AI in security, emphasizing its applications in threat detection, \nnetwork security, malware analysis, and fraud prevention. It highlights the challenges \nof building a universal AI security framework, addressing issues such as data\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-91524-6_3&hl=en&sa=X&d=446135133632427158&ei=KWNDaPDDCZLXieoPwNDK0Qk&scisig=AAZF9b_AfzJEslnJSMeBMWkvu9j2&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based Backdoor Attacks for Jailbreaking Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "J Kong, H Fang, X Yang, K Gao, B Chen, ST Xia\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSupervised fine-tuning (SFT) aligns large language models (LLMs) with human \nintent by training them on labeled task-specific data. Recent studies have shown that \nmalicious attackers can inject backdoors into these models by embedding triggers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17601%3F&hl=en&sa=X&d=14932585774719166007&ei=KWNDaIL9F-bGieoP1sTUqQ8&scisig=AAZF9b-bRcbQ7r2VSTXuEVUTZE69&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, M Dras, U Naseem\\xc2\\xa0- arXiv preprint arXiv:2506.02442, 2025\nThis paper presents a systematic evaluation of Large Language Models'(LLMs) \nbehavior on long-tail distributed (encrypted) texts and their safety implications. We \nintroduce a two-dimensional framework for assessing LLM safety:(1) instruction\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02442&hl=en&sa=X&d=15102350404536711280&ei=KWNDaIL9F-bGieoP1sTUqQ8&scisig=AAZF9b_4gGVOvmiHUrKGvn2E4Vhh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift", "first_label": ["LLM"], "second_label": [], "data": "S Liang, J Liang, T Pang, C Du, A Liu, M Zhu, X Cao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInstruction tuning enhances large vision-language models (LVLMs) but increases \ntheir vulnerability to backdoor attacks due to their open design. Unlike prior studies in \nstatic settings, this paper explores backdoor attacks in LVLM instruction tuning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.pdf&hl=en&sa=X&d=5142527777954789704&ei=KWNDaIL9F-bGieoP1sTUqQ8&scisig=AAZF9b_Zz7b9xsyiBVRqo7nDX3YO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack", "first_label": ["LLM"], "second_label": [], "data": "S Cappelletti, T Poppi, S Poppi, ZX Yong\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly evaluated on multiple-choice \nquestion answering (MCQA) tasks using* first-token probability*(FTP), which selects \nthe answer option whose initial token has the highest likelihood. While efficient, FTP\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15323%3F&hl=en&sa=X&d=5513891085179250670&ei=KWNDaIL9F-bGieoP1sTUqQ8&scisig=AAZF9b8ts6vJnVnPKgZRZk2J59vT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Stealthy LLM-Driven Data Poisoning Attacks Against Embedding-Based Retrieval-Augmented Recommender Systems", "first_label": ["LLM"], "second_label": [], "data": "F Nazary, Y Deldjoo, T Di Noia, E Di Sciascio\\xc2\\xa0- arXiv preprint arXiv:2505.05196, 2025\nWe present a systematic study of provider-side data poisoning in retrieval-\naugmented recommender systems (RAG-based). By modifying only a small fraction \nof tokens within item descriptions--for instance, adding emotional keywords or\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.05196&hl=en&sa=X&d=7153996738322631678&ei=KWNDaIL9F-bGieoP1sTUqQ8&scisig=AAZF9b9XYvMXz8xtJ6dU7EDwB2B7&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Lifelong Safety Alignment for Language Models", "first_label": ["LLM"], "second_label": [], "data": "H Wang, Z Qin, Y Zhao, C Du, M Lin, X Wang, T Pang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLMs have made impressive progress, but their growing capabilities also expose \nthem to highly flexible jailbreaking attacks designed to bypass safety alignment. \nWhile many existing defenses focus on known types of attacks, it is more critical to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20259%3F&hl=en&sa=X&d=16834372085988299596&ei=KWNDaIL9F-bGieoP1sTUqQ8&scisig=AAZF9b9d_59vHSVRWjToyCIlG2f5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "PS Pandey, S Simko, K Pelrine, Z Jin\\xc2\\xa0- arXiv preprint arXiv:2505.16789, 2025\nAs large language models gain popularity, their vulnerability to adversarial attacks \nremains a primary concern. While fine-tuning models on domain-specific datasets is \noften employed to improve model performance, it can introduce vulnerabilities within\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16789%3F&hl=en&sa=X&d=9827187220639785834&ei=KWNDaIL9F-bGieoP1sTUqQ8&scisig=AAZF9b-hRa3CIybDfceUhaRlecWD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution", "first_label": [], "second_label": [], "data": "J Guo, X Wen, W Jiang, C Huang, J Li, H Li\\xc2\\xa0- arXiv preprint arXiv:2505.15308, 2025\nWith the widespread application of super-resolution (SR) in various fields, \nresearchers have begun to investigate its security. Previous studies have \ndemonstrated that SR models can also be subjected to backdoor attacks through\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15308&hl=en&sa=X&d=13335437674086498390&ei=KWNDaIL9F-bGieoP1sTUqQ8&scisig=AAZF9b8WmdvUXiuzvPutlRNCBmNP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "An Embarrassingly Simple Defense Against LLM Abliteration Attacks", "first_label": ["LLM"], "second_label": [], "data": "HA Shairah, HAAK Hammoud, B Ghanem, G Turkiyyah\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are typically aligned to comply with safety guidelines \nby refusing harmful instructions. A recent attack, termed abliteration, isolates and \nsuppresses the single latent direction most responsible for refusal behavior, enabling\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19056&hl=en&sa=X&d=3737202939224050048&ei=KWNDaIL9F-bGieoP1sTUqQ8&scisig=AAZF9b8QKV5yRTnfm0WbZVG9RAGO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AgentAuditor: Human-Level Safety and Security Evaluation for LLM Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "H Luo, S Dai, C Ni, X Li, G Zhang, K Wang, T Liu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite the rapid advancement of LLM-based agents, the reliable evaluation of their \nsafety and security remains a significant challenge. Existing rule-based or LLM-\nbased evaluators often miss dangers in agents' step-by-step actions, overlook subtle\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00641&hl=en&sa=X&d=523652018719672976&ei=KWNDaIL9F-bGieoP1sTUqQ8&scisig=AAZF9b-gq3lghzRvyDwMaj5uZok5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "GenFair: Systematic Test Generation for Fairness Fault Detection in Large Language Models", "first_label": ["LLM", "Software Testing"], "second_label": ["Detection", "Generation"], "data": "M Srinivasan, J Abdel\\xc2\\xa0- arXiv preprint arXiv:2506.03024, 2025\nLarge Language Models (LLMs) are increasingly deployed in critical domains, yet \nthey often exhibit biases inherited from training data, leading to fairness concerns. \nThis work focuses on the problem of effectively detecting fairness violations\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03024&hl=en&sa=X&d=1395882172513838978&ei=KWNDaNuDG_CuieoP583H-QE&scisig=AAZF9b-w6t_kNtySNxVBUSKCIHCp&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "3 new citations to articles by Hong Jin Kang"]}
{"title": "An LLM Agent for Functional Bug Detection in Network Protocols", "first_label": ["LLM", "Bug"], "second_label": ["Detection", "Agent"], "data": "M Zheng, C Wang, X Liu, J Guo, S Feng, X Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.00714, 2025\nFunctional correctness is critical for ensuring the reliability and security of network \nprotocol implementations. Functional bugs, instances where implementations \ndiverge from behaviors specified in RFC documents, can lead to severe\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00714&hl=en&sa=X&d=14025741833580725532&ei=KWNDaNuDG_CuieoP583H-QE&scisig=AAZF9b8vkBixnPr2fRq2ZYFDK47O&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "7 new citations to articles by Abhik Roychoudhury"]}
{"title": "Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents", "first_label": ["LLM", "Code"], "second_label": ["Agent", "Reasoning"], "data": "K Hariharan, U Girit, A Wang, J Andreas\\xc2\\xa0- arXiv preprint arXiv:2506.00172, 2025\nBenchmarks for large language models (LLMs) have predominantly assessed short-\nhorizon, localized reasoning. Existing long-horizon suites (eg SWE-bench) rely on \nmanually curated issues, so expanding or tuning difficulty demands expensive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00172&hl=en&sa=X&d=7723120566071680437&ei=KWNDaNuDG_CuieoP583H-QE&scisig=AAZF9b-MEatAoZUO5Dw1f9NQmtaH&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Which Factors Make Code LLMs More Vulnerable to Backdoor Attacks? A Systematic Study", "first_label": ["LLM", "Code"], "second_label": [], "data": "C Wang, Z Yang, Y Harel, D Lo\\xc2\\xa0- arXiv preprint arXiv:2506.01825, 2025\nCode LLMs are increasingly employed in software development. However, studies \nhave shown that they are vulnerable to backdoor attacks: when a trigger (a specific \ninput pattern) appears in the input, the backdoor will be activated and cause the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.01825&hl=en&sa=X&d=16166340572421918430&ei=KWNDaLzPGZLXieoPwNDK0Qk&scisig=AAZF9b-phsc8qq-f3lOMccCIs3x-&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "3 new citations to articles by Hong Jin Kang"]}
{"title": "Semi-supervised software vulnerability assessment via code lexical and structural information fusion", "first_label": ["Vulnerabilities", "Code"], "second_label": [], "data": "W Pei, Y Huang, X Chen, G Lu, Y Liu, C Ni\\xc2\\xa0- Automated Software Engineering, 2025\nIn recent years, data-driven approaches have become popular for software \nvulnerability assessment (SVA). However, these approaches need a large amount of \nlabeled SVA data to construct effective SVA models. This process demands security\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00526-4&hl=en&sa=X&d=12150716079684109674&ei=KWNDaLzPGZLXieoPwNDK0Qk&scisig=AAZF9b8zXJiBu6kjaWbL323Dh99f&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "AI Powered Code Generation: The Next Era of Automated Software Development", "first_label": ["Code"], "second_label": ["Generation"], "data": "H Verma, S Choudhary, K Pandey\\xc2\\xa0- International Journal of Sciences and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn the ever-changing software engineering paradigm, artificial intelligence has \nbecome the revolutionary driver, changing the method by which code is generated, \noptimized, & deployed. The paper delves into the emergence of AI-enabled code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.ijsci.com/index.php/home/article/download/167/143&hl=en&sa=X&d=5827903349629826673&ei=KWNDaLzPGZLXieoPwNDK0Qk&scisig=AAZF9b-P4SV97piIohZWqUsrg_jj&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Automated Vulnerability Scanning and Security Audit Framework for Maritime Systems", "first_label": ["Vulnerabilities"], "second_label": [], "data": "A Vineetha Harish - 2025\nThe maritime industry is a well-established sector, with the shipping industry dating \nback hundreds of years. The devices in this sector differ from those in the Information \nTechnology (IT) sector in their usage, operations, hardware, andprotocols. \nTechnological advancements have introduced new challenges in the sector, \nincluding the increased risk of cyber attacks. To effectively identify, respond to, and \nanalyse these threats, it is essential to understand the cyber securityvulnerabilities in\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaComparison of static application security testing tools and large\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://pearl.plymouth.ac.uk/cgi/viewcontent.cgi%3Farticle%3D1554%26context%3Dsecam-theses&hl=en&sa=X&d=2189587239999303496&ei=KWNDaIr4DbWv6rQPgJOzyAw&scisig=AAZF9b-OYqJbkX0x-Ao2H8TVwJmC&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le", "2 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Xin ZHOU"]}
{"title": "Comparative Analysis of Static Application Security Testing Tools on Real-world Java Vulnerabilities", "first_label": ["Vulnerabilities", "Software Testing"], "second_label": [], "data": "W Ansgariusson, J St\\xc3\\xa5hl - 2025\nWith the increasing complexity and scale of modern software systems, ensuring \nsoftware security is more critical than ever. As projects grow, so does the likelihood of \nvulnerabilities being introduced. Static Application Security Testing (SAST) tools \nassist developers in identifying such vulnerabilities during development. In this study, \nfive Java SAST tools (Bearer, CodeQL, Horusec, Semgrep and SonarQube) were \nevaluated based primarily on their vulnerability detection rate and execution time to\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaComparison of static application security testing tools and large\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://lup.lub.lu.se/student-papers/search/publication/9189955&hl=en&sa=X&d=13866902737926222762&ei=KWNDaIr4DbWv6rQPgJOzyAw&scisig=AAZF9b-y_7Nr_GjnxK9G2GTopJNh&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le", "2 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Xin ZHOU"]}
{"title": "OmniGIRL: A Multilingual and Multimodal Benchmark for GitHub Issue Resolution", "first_label": ["GitHub Issue"], "second_label": [], "data": "L Guo, W Tao, R Jiang, Y Wang, J Chen, X Liu, Y Ma\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe GitHub issue resolution task aims to resolve issues reported in repositories \nautomatically. With advances in large language models (LLMs), this task has gained \nincreasing attention, and several benchmarks are proposed to evaluate the issue\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.04606&hl=en&sa=X&d=17721785651242552030&ei=KWNDaLjzCqm7ieoP1JuLsA8&scisig=AAZF9b9vdcHDALBkXHSBcEUw295J&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Evaluation of LLMs for mathematical problem solving", "first_label": ["LLM"], "second_label": [], "data": "R Wang, R Wang, Y Shen, C Wu, Q Zhou, R Chandra\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown impressive performance on a range of \neducational tasks, but are still understudied for their potential to solve mathematical \nproblems. In this study, we compare three prominent LLMs, including GPT-4o, \nDeepSeek-V3, and Gemini-2.0, on three mathematics datasets of varying \ncomplexities (GSM8K, MATH500, and UNSW datasets). We take a five-dimensional \napproach based on the Structured Chain-of-Thought (SCoT) framework to assess\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomatic Programming: Large Language Models and Beyond\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00309&hl=en&sa=X&d=302127274804275545&ei=KWNDaPDvEIqIieoPj_7kqQE&scisig=AAZF9b9UKjKGP2_xDdhHHPY45-tx&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "How Programming Concepts and Neurons Are Shared in Code Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "AH Kargaran, Y Liu, F Yvon, H Sch\\xc3\\xbctze\\xc2\\xa0- arXiv preprint arXiv:2506.01074, 2025\nSeveral studies have explored the mechanisms of large language models (LLMs) in \ncoding tasks, but most have focused on programming languages (PLs) in a \nmonolingual setting. In this paper, we investigate the relationship between multiple \nPLs and English in the concept space of LLMs. We perform a few-shot translation \ntask on 21 PL pairs using two Llama-based models. By decoding the embeddings of \nintermediate layers during this task, we observe that the concept space is closer to\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBaishakhi Ray, Abhik Roychoudhury, Shin Hwei Tan, and\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.01074&hl=en&sa=X&d=3020487052088765627&ei=KWNDaPDvEIqIieoPj_7kqQE&scisig=AAZF9b963QyJEZqju52Zn2dNXpOn&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "CyberGym: Evaluating AI Agents' Cybersecurity Capabilities with Real-World Vulnerabilities at Scale", "first_label": ["Vulnerabilities"], "second_label": ["Agent"], "data": "Z Wang, T Shi, J He, M Cai, J Zhang, D Song\\xc2\\xa0- arXiv preprint arXiv:2506.02548, 2025\nLarge language model (LLM) agents are becoming increasingly skilled at handling \ncybersecurity tasks autonomously. Thoroughly assessing their cybersecurity \ncapabilities is critical and urgent, given the high stakes in this domain. However, \nexisting benchmarks fall short, often failing to capture real-world scenarios or being \nlimited in scope. To address this gap, we introduce CyberGym, a large-scale and \nhigh-quality cybersecurity evaluation framework featuring 1,507 real-world\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02548&hl=en&sa=X&d=873453502677392460&ei=KWNDaPDvEIqIieoPj_7kqQE&scisig=AAZF9b8xjaPhE5MC9fd6Nl6Oq05-&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "Enhancing Software Engineering Through AI: A Comprehensive Exploration", "first_label": [], "second_label": [], "data": "N Nwasra, A Alsalemi\\xc2\\xa0- 2025 1st International Conference on Computational\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe integration of Artificial Intelligence (AI) techniques into Software Engineering \n(SE) has opened new avenues for improving software development, testing, and \nmaintenance processes. This paper explores the transformative potential of AI-driven \napproaches in addressing some of the most persistent challenges in modern \nsoftware engineering workflows. Specifically, it highlights the application of AI for \nautomated bug detection and fixing in open-source software projects, which often\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Program Repair\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11013170/&hl=en&sa=X&d=17143292876618282581&ei=KWNDaPDvEIqIieoPj_7kqQE&scisig=AAZF9b_SzfEf_pbw3uYLkporTJWc&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "LIBAFLGO: Evaluating and Advancing Directed Greybox Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "E Geretto, A Jemmett, C Giuffrida, H Bos\nWhile greybox fuzzing is routinely applied in production environments with great \nsuccess, directed greybox fuzzing has struggled to gain real-world adoption\\xe2\\x80\\x94\ndespite the great (intuitive) promise and the many optimizations proposed in \nliterature. In practice, directed fuzzers struggle for three critical issues. First, popular \nimplementations build on and compare to ancient baselines, often derived from \nAFLGo. Unfortunately, none of the optimizations that are essential for performance in\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://download.vusec.net/papers/libaflgo_eurosp25.pdf&hl=en&sa=X&d=3588514315333430002&ei=KWNDaPDvEIqIieoPj_7kqQE&scisig=AAZF9b9_dufLgPupNfMrhFNXyzrr&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "Improving LLM-Generated Code Quality with GRPO", "first_label": ["LLM", "Code"], "second_label": [], "data": "M Robeyns, L Aitchison\\xc2\\xa0- arXiv preprint arXiv:2506.02211, 2025\nLarge Language Models (LLMs) are gaining widespread use for code generation. \nRecent training procedures use execution feedback as a reward signal, typically \nfocusing on the functional correctness of the code, using unit test pass rate as a \nreward signal. However, this reward signal fails to capture notions of maintainability, \nquality and safety of the code produced. We address this under-explored area and \ndevelop a comprehensive library to quantify various aspects of code quality, and use\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaACECode: A Reinforcement Learning Framework for Aligning\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02211&hl=en&sa=X&d=16267907864718546505&ei=KWNDaPS8DI-UywTXk47YAw&scisig=AAZF9b9DhYkiDLvHKyPP6Kqiu6SI&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang"]}
{"title": "How do Pre-Trained Models Support Software Engineering? An Empirical Study in Hugging Face", "first_label": [], "second_label": [], "data": "A Gonz\\xc3\\xa1lez, X Franch, D Lo, S Mart\\xc3\\xadnez-Fern\\xc3\\xa1ndez\\xc2\\xa0- arXiv preprint arXiv:2506.03013, 2025\nOpen-Source Pre-Trained Models (PTMs) provide extensive resources for various \nMachine Learning (ML) tasks, yet these resources lack a classification tailored to \nSoftware Engineering (SE) needs. To address this gap, we derive a taxonomy \nencompassing 147 SE tasks and apply an SE-oriented classification to PTMs in a \npopular open-source ML repository, Hugging Face (HF). Our repository mining study \nbegan with a systematically gathered database of PTMs from the HF API, considering\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAssessing and Advancing Benchmarks for Evaluating Large\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03013&hl=en&sa=X&d=5692275965436272309&ei=KWNDaPLLFviJ6rQP4Lq-sAo&scisig=AAZF9b8sD4_NBzDXCoEcstmgjHYl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "AutoMixAlign: Adaptive Data Mixing for Multi-Task Preference Optimization in LLMs", "first_label": ["LLM"], "second_label": [], "data": "NE Corrado, J Katz-Samuels, A Devraj, H Yun\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWhen aligning large language models (LLMs), their performance on various tasks \n(such as being helpful, harmless, and honest) depends heavily on the composition of \ntheir training data. However, selecting a data mixture that achieves strong \nperformance across all tasks is challenging. Existing approaches rely on large \nablation studies, heuristics, or human intuition, but these can be prohibitively \nexpensive and suboptimal. We study this problem in the setting of preference\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCodeultrafeedback: An llm-as-a-judge dataset for aligning large\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00569&hl=en&sa=X&d=13222213487580864623&ei=KWNDaPLLFviJ6rQP4Lq-sAo&scisig=AAZF9b_uLNZfPbv1B_2xW_9oNKMN&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=3&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "Enhancing LLM-Based Code Generation with Complexity Metrics: A Feedback-Driven Approach", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "M Sepidband, H Taherkhani, S Wang, H Hemmati\\xc2\\xa0- arXiv preprint arXiv:2505.23953, 2025\nAutomatic code generation has gained significant momentum with the advent of \nLarge Language Models (LLMs) such as GPT-4. Although many studies focus on \nimproving the effectiveness of LLMs for code generation, very limited work tries to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23953&hl=en&sa=X&d=13582085771309006894&ei=J_tBaLXmL4qIieoPj_7kqQE&scisig=AAZF9b_CMfsY4xEKkIm7N9DVXs0b&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "HardTests: Synthesizing High-Quality Test Cases for LLM Coding", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "Z He, YM Choi, K Zhang, J Ji, J Zhou, D Xu, I Bercovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nVerifiers play a crucial role in large language model (LLM) reasoning, needed by \npost-training techniques such as reinforcement learning. However, reliable verifiers \nare hard to get for difficult coding problems, because a well-disguised wrong solution\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24098&hl=en&sa=X&d=3676350848881047114&ei=J_tBaLXmL4qIieoPj_7kqQE&scisig=AAZF9b-nTHkCLE3pbXjQ3HdGnwxz&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "Unlocking Code Simplicity: The Role of Prompt Patterns in Managing LLM Code Complexity", "first_label": ["LLM", "Code"], "second_label": [], "data": "A Della Porta, G Recupito, S Lambiase, D Di Nucci\\xe2\\x80\\xa6\nThe rapid growth of generative artificial intelligence, especially Large Language \nModels (LLMs), has greatly influenced software engineering by automating code \ngeneration tasks. Despite the potential, challenges in code maintainability and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://atdepo.github.io/assets/papers/patterns_complexity.pdf&hl=en&sa=X&d=12326388923183369801&ei=J_tBaLXmL4qIieoPj_7kqQE&scisig=AAZF9b8NNBgnrmk0FkEiYAYKSDVx&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "Spectre: Automated Aliasing Specifications Generation for Library APIs with Fuzzing", "first_label": ["Fuzzing"], "second_label": ["Generation"], "data": "S Kan, Y Li, W He, Z Xing, L Zhu, Y Sui\\xc2\\xa0- ACM Transactions on Software Engineering\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nStatic program analysis of real-world software that integrates numerous library \nApplication Programming Interfaces (APIs) faces significant challenges due to \ninaccessible or highly complex source code. A common workaround is to use\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3725811&hl=en&sa=X&d=2352067302594285580&ei=J_tBaJ-KMYOuieoP-ZTn2Aw&scisig=AAZF9b8vKjatyW94SPNBNu4L2TwN&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "8 new citations to articles by Abhik Roychoudhury", "Abhik Roychoudhury - new related research", "David Lo - new related research"]}
{"title": "LLM Agents Should Employ Security Principles", "first_label": ["LLM"], "second_label": ["Agent"], "data": "K Zhang, Z Su, PY Chen, E Bertino, X Zhang, N Li\\xc2\\xa0- arXiv preprint arXiv:2505.24019, 2025\nLarge Language Model (LLM) agents show considerable promise for automating \ncomplex tasks using contextual reasoning; however, interactions involving multiple \nagents and the system's susceptibility to prompt injection and other forms of context \nmanipulation introduce new vulnerabilities related to privacy leakage and system \nexploitation. This position paper argues that the well-established design principles in \ninformation security, which are commonly referred to as security principles, should be\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24019&hl=en&sa=X&d=10754342589978314789&ei=J_tBaPqfIb2W6rQPmdrokQU&scisig=AAZF9b9WXSbqMs3YY-6YiS90274z&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "R Ko, J Jeong, S Zheng, C Xiao, T Kim, M Onizuka\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are rapidly evolving into autonomous agents that \ncooperate across organizational boundaries, enabling joint disaster response, \nsupply-chain optimization, and other tasks that demand decentralized expertise \nwithout surrendering data ownership. Yet, cross-domain collaboration shatters the \nunified trust assumptions behind current alignment and containment techniques. An \nagent benign in isolation may, when receiving messages from an untrusted peer\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTeams of llm agents can exploit zero-day vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23847&hl=en&sa=X&d=12877987841461213152&ei=J_tBaPqfIb2W6rQPmdrokQU&scisig=AAZF9b-0Dc_aqKLzG9BeK_25VV9I&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "ALDExA: Automated LLM-Assisted Detection of CVE Exploitation Attempts in Host-Captured Data", "first_label": ["LLM"], "second_label": ["Detection", "Exploit"], "data": "N Ilg, M Pfitzenmaier, D Germek, P Duplys, M Menth\\xc2\\xa0- IEEE Access, 2025\nCurrently, the detection of CommonVulnerabilities and Exposures (CVE) exploitation \nattempts heavily depends on rule sets manually written for the detection unit. As the \nnumber of published CVEs increases each year, there is a need to advance \nautomation efforts for CVE detection. For this purpose, we introduce ALDExA, a \nframework that fetches CVE information and corresponding exploit codes to identify \nan exploit string supported by a Large Language Model (LLM). An exploit string is a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11018393.pdf&hl=en&sa=X&d=11004532408836097929&ei=J_tBaPqfIb2W6rQPmdrokQU&scisig=AAZF9b_rygDfabG_5qarxS4QqmGP&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=2&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "Modified Visual Language Model for Robust Use-After-Free Vulnerability Detection", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "L Jie, L Zhang, S Yan, Y Chen, F Yan, Y Feng\nUse-After-Free (UAF) vulnerabilities pose significant risks to software security as \nsystems grow increasingly complex. Traditional Large Language Models (LLMs) like \nBERT, CodeBERT, and GPT excel in pattern recognition but often treat code as flat \ntoken sequences, neglecting essential structural and semantic insights from static \nanalysis. This limitation hampers their robustness against code perturbations and \ntheir ability to generalize to real-world and complex UAFs such as inter-procedural\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTeams of llm agents can exploit zero-day vulnerabilities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Lidi-Jie/publication/392239819_Modified_Visual_Language_Model_for_Robust_Use-After-Free_Vulnerability_Detection/links/683a78cf8a76251f22eaa6e4/Modified-Visual-Language-Model-for-Robust-Use-After-Free-Vulnerability-Detection.pdf&hl=en&sa=X&d=11591715598152814295&ei=J_tBaPqfIb2W6rQPmdrokQU&scisig=AAZF9b9U9Q7tMxMlMnBlQBCJdYGz&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=3&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang", "2 new citations to articles by Xin ZHOU"]}
{"title": "LPASS: Linear Probes as Stepping Stones for vulnerability detection using compressed LLMs", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "L Ibanez-Lissen, L Gonzalez-Manzano, JM de Fuentes\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are being extensively used for cybersecurity \npurposes. One of them is the detection of vulnerable codes. For the sake of efficiency \nand effectiveness, compression and fine-tuning techniques are being developed, \nrespectively. However, they involve spending substantial computational efforts. In \nthis vein, we analyse how Linear Probes (LPs) can be used to provide an estimation \non the performance of a compressed LLM at an early phase--before fine-tuning. We\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection: Emerging results\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24451&hl=en&sa=X&d=2394315711310610645&ei=J_tBaMLwLLXCieoPt6N7&scisig=AAZF9b9IinR24RIrpm2DTM7Bxnev&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU", "David Lo - new related research", "1 new citation to articles by Hong Jin Kang"]}
{"title": "The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models", "first_label": ["APR"], "second_label": ["Repair"], "data": "F Vallecillos Ruiz, M Hort, L Moonen\\xc2\\xa0- arXiv e-prints, 2025\nAutomatic program repair (APR) aims to reduce the manual efforts required to \nidentify and fix errors in source code. Before the rise of LLM-based agents, a \ncommon strategy was to increase the number of generated patches, sometimes to\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ui.adsabs.harvard.edu/abs/2025arXiv250502931V/abstract&hl=en&sa=X&d=17470407147567288266&ei=J_tBaIn1H4OuieoP-ZTn2Aw&scisig=AAZF9b_mTBrB9ej9K91Gs8V1w5Fn&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Quang-Cuong Bui - new related research", "Abhik Roychoudhury - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Adversarial Preference Learning for Robust LLM Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Wang, P Wang, C Xi, B Tang, J Zhu, W Wei, C Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern language models often rely on Reinforcement Learning from Human \nFeedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to \nadversarial attacks due to three key limitations:(1) the inefficiency and high cost of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24369&hl=en&sa=X&d=11526575995055803369&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b-W-NvoVHgcod4hvfb1oD11&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "System Prompt Extraction Attacks and Defenses in Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "BC Das, MH Amini, Y Wu\\xc2\\xa0- arXiv preprint arXiv:2505.23817, 2025\nThe system prompt in Large Language Models (LLMs) plays a pivotal role in guiding \nmodel behavior and response generation. Often containing private configuration \ndetails, user roles, and operational instructions, the system prompt has become an\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23817&hl=en&sa=X&d=8359490024520200495&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b9kewGVoQUmVLeek21BFko2&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Evaluatiing the efficacy of LLM Safety Solutions: The Palit Benchmark Dataset", "first_label": ["LLM"], "second_label": [], "data": "S Palit, D Woods\\xc2\\xa0- arXiv preprint arXiv:2505.13028, 2025\nLarge Language Models (LLMs) are increasingly integrated into critical systems in \nindustries like healthcare and finance. Users can often submit queries to LLM-\nenabled chatbots, some of which can enrich responses with information retrieved\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13028%3F&hl=en&sa=X&d=1273460049730580919&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b9ByON4eaZyjRTpM1-cA_zU&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Benchmarking Large Language Models for Cryptanalysis and Mismatched-Generalization", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, C Zhu, U Naseem\\xc2\\xa0- arXiv preprint arXiv:2505.24621, 2025\nRecent advancements in Large Language Models (LLMs) have transformed natural \nlanguage understanding and generation, leading to extensive benchmarking across \ndiverse tasks. However, cryptanalysis a critical area for data security and encryption\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24621&hl=en&sa=X&d=653713479646221893&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b9TVZeOS4hNS7uC_nMr7uyt&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Wang, W Wang, S Wang, Z Li, Z Ji, Z Lyu, D Wu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Large Language Models (LLMs) has led to the \nemergence of Multi-Agent Systems (MAS) to perform complex tasks through \ncollaboration. However, the intricate nature of MAS, including their architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12442&hl=en&sa=X&d=8825331941370095164&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b_j6hKF2Zy8dNMOx-tobM6E&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AgentXploit: End-to-End Redteaming of Black-Box AI Agents", "first_label": [], "second_label": ["Agent"], "data": "Z Wang, V Siu, Z Ye, T Shi, Y Nie, X Zhao, C Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe strong planning and reasoning capabilities of Large Language Models (LLMs) \nhave fostered the development of agent-based systems capable of leveraging \nexternal tools and interacting with increasingly complex environments. However\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.05849&hl=en&sa=X&d=13145039506086791936&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b_5aWzkLQOK0HBWClMmbpt1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Ripple Effect: On Unforeseen Complications of Backdoor Attacks", "first_label": [], "second_label": [], "data": "R Zhang, Y Shen, H Li, W Jiang, H Chen, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent research highlights concerns about the trustworthiness of third-party Pre-\nTrained Language Models (PTLMs) due to potential backdoor attacks. These \nbackdoored PTLMs, however, are effective only for specific pre-defined downstream\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11586&hl=en&sa=X&d=15157304470732077928&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b997v4XRj8-KVQslhBMZvqE&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadDepth: Backdoor Attacks Against Monocular Depth Estimation in the Physical World", "first_label": [], "second_label": [], "data": "J Guo, L Zhou, Z Wang, J He, Q Song, A Chen, W Jiang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, deep learning-based Monocular Depth Estimation (MDE) models \nhave been widely applied in fields such as autonomous driving and robotics. \nHowever, their vulnerability to backdoor attacks remains unexplored. To fill the gap in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16154%3F&hl=en&sa=X&d=5415910119131408953&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b_P0jMEgHvYQo3O-kEno08o&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "first_label": ["LLM"], "second_label": [], "data": "G Chen, F Song, Z Zhao, X Jia, Y Liu, Y Qiao, W Zhang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreak attacks to Large audio-language models (LALMs) are studied recently, but \nthey achieve suboptimal effectiveness, applicability, and practicability, particularly, \nassuming that the adversary can fully manipulate user prompts. In this work, we first\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14103&hl=en&sa=X&d=12355582258955555442&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b84twuHlVXU1hPFciKO3AfT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "TRIDENT: Enhancing Large Language Model Safety with Tri-Dimensional Diversified Red-Teaming Data Synthesis", "first_label": ["LLM"], "second_label": [], "data": "X Wu, X Mao, F Li, X Zhang, X Li, C Teng, D Ji, Z Li\\xc2\\xa0- arXiv preprint arXiv:2505.24672, 2025\nLarge Language Models (LLMs) excel in various natural language processing tasks \nbut remain vulnerable to generating harmful content or being exploited for malicious \npurposes. Although safety alignment datasets have been introduced to mitigate such\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24672&hl=en&sa=X&d=8807618287327385097&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b_IdBuNmJzpASLhMF6kt1gz&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A survey of coverage-guided greybox fuzzing with deep neural models", "first_label": ["Fuzzing"], "second_label": [], "data": "J Qiu, Y Jiang, Y Miao, W Luo, L Pan, X Zheng\\xc2\\xa0- Information and Software Technology, 2025\nCoverage-guided greybox fuzzing (CGF) has emerged as a powerful technique for \nsoftware vulnerability detection, yet traditional techniques often struggle with the \nincreasing complexity of modern software systems and the vastness of input spaces. \nDeep neural networks (DNNs) have begun to fundamentally transform CGF by \naddressing these limitations through automated feature extraction, adaptive input \ngeneration, and intelligent path prioritization. However, despite these advancements\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925001363&hl=en&sa=X&d=13643876251527966728&ei=J_tBaKWyJ5LXieoPwNDK0Qk&scisig=AAZF9b8H31RZwVpkSZO2E_952tv6&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "Multidimensional Approaches in Bug Detection for Parallel Programming and Text-to-Code Semantic Parsing", "first_label": ["Code", "Bug"], "second_label": ["Detection"], "data": "M Alsofyani - 2025\nThis dissertation applies deep learning and large language models to two domains: \nparallel programming fault detection and text-to-code translation, aiming to enhance \nsoftware reliability and natural language-driven code generation. Due to their \nunpredictable nature, concurrency bugs-particularly data race bugs\\xe2\\x80\\x94present \nsignificant challenges in fault detection for parallel programming. We investigate \ndeep learning and LLM-based approaches for detecting data race bugs in OpenMP\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaImproving automatically generated code from Codex via\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://stars.library.ucf.edu/cgi/viewcontent.cgi%3Farticle%3D1130%26context%3Detd2024&hl=en&sa=X&d=8723753203795174331&ei=J_tBaKWyJ5LXieoPwNDK0Qk&scisig=AAZF9b8Dl393s8oGCWHEZDg7I85P&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Flat Minima Perspective on Understanding Augmentations and Model Robustness", "first_label": [], "second_label": [], "data": "W Yoo, SW Yoon\\xc2\\xa0- arXiv preprint arXiv:2505.24592, 2025\nModel robustness indicates a model's capability to generalize well on unforeseen \ndistributional shifts, including data corruption, adversarial attacks, and domain shifts. \nData augmentation is one of the prevalent and effective ways to enhance robustness. \nDespite the great success of augmentations in different fields, a general theoretical \nunderstanding of their efficacy in improving model robustness is lacking. We offer a \nunified theoretical framework to clarify how augmentations can enhance model\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFuzz Testing based Data Augmentation to Improve Robustness of\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24592&hl=en&sa=X&d=1198345596814614490&ei=J_tBaKWyJ5LXieoPwNDK0Qk&scisig=AAZF9b-isYEqXolh_9-VVf16H9Hq&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "Principal Context-aware Diffusion Guided Data Augmentation for Fault Localization", "first_label": ["Fault Localization"], "second_label": ["Localization"], "data": "S Fu, Y Lei\\xc2\\xa0- arXiv preprint arXiv:2505.24079, 2025\nTest cases are indispensable for conducting effective fault localization (FL). \nHowever, test cases in practice are severely class imbalanced, ie the number of \nfailing test cases (ie minority class) is much less than that of passing ones (ie majority \nclass). The severe class imbalance between failing and passing test cases have \nhindered the FL effectiveness. To address this issue, we propose PCD-DAug: a \nPrincipal Context-aware Diffusion guided Data Augmentation approach that\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCodeflaws: a programming competition benchmark for evaluating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24079&hl=en&sa=X&d=2752401929477553722&ei=J_tBaKWyJ5LXieoPwNDK0Qk&scisig=AAZF9b-Sw6EN56n5as-y9e2X3E0V&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury", "David Lo - new related research", "Thanh Le-Cong - new related research"]}
{"title": "\\xe3\\x82\\xb3\\xe3\\x83\\xbc\\xe3\\x83\\x89\\xe3\\x82\\xaf\\xe3\\x83\\xad\\xe3\\x83\\xbc\\xe3\\x83\\xb3\\xe9\\x9b\\x86\\xe7\\xb4\\x84\\xe3\\x81\\xab\\xe3\\x82\\x88\\xe3\\x82\\x8b\\xe3\\x83\\x95\\xe3\\x82\\xa1\\xe3\\x82\\xb8\\xe3\\x83\\xb3\\xe3\\x82\\xb0\\xe3\\x81\\xae\\xe5\\xae\\x9f\\xe8\\xa1\\x8c\\xe5\\x8a\\xb9\\xe7\\x8e\\x87\\xe8\\xaa\\xbf\\xe6\\x9f\\xbb", "first_label": [], "second_label": [], "data": "\\xe5\\xbe\\xb3\\xe4\\xba\\x95\\xe7\\xbf\\x94\\xe6\\xa2\\xa7\\xef\\xbc\\x8c \\xe5\\x90\\x89\\xe7\\x94\\xb0\\xe5\\x89\\x87\\xe8\\xa3\\x95\\xef\\xbc\\x8c \\xe5\\xb4\\x94\\xe6\\x81\\xa9\\xef\\xbc\\x8c \\xe4\\xba\\x95\\xe4\\xb8\\x8a\\xe5\\x85\\x8b\\xe9\\x83\\x8e\\xef\\xbc\\x8c \\xe8\\x82\\xa5\\xe5\\xbe\\x8c\\xe8\\x8a\\xb3\\xe6\\xa8\\xb9\\xc2\\xa0- \\xe3\\x82\\xb3\\xe3\\x83\\xb3\\xe3\\x83\\x94\\xe3\\x83\\xa5\\xe3\\x83\\xbc\\xe3\\x82\\xbf \\xe3\\x82\\xbd\\xe3\\x83\\x95\\xe3\\x83\\x88\\xe3\\x82\\xa6\\xe3\\x82\\xa7\\xe3\\x82\\xa2, 2025\n\\xe6\\x8a\\x84\\xe9\\x8c\\xb2 \\xe3\\x83\\x95\\xe3\\x82\\xa1\\xe3\\x82\\xb8\\xe3\\x83\\xb3\\xe3\\x82\\xb0\\xe3\\x81\\xaf\\xe9\\xab\\x98\\xe9\\x80\\x9f\\xe3\\x81\\xaa\\xe3\\x83\\x86\\xe3\\x82\\xb9\\xe3\\x83\\x88\\xe3\\x82\\xb1\\xe3\\x83\\xbc\\xe3\\x82\\xb9\\xe7\\x94\\x9f\\xe6\\x88\\x90\\xe3\\x81\\xa8\\xe5\\xae\\x9f\\xe8\\xa1\\x8c\\xe3\\x81\\xab\\xe3\\x82\\x88\\xe3\\x81\\xa3\\xe3\\x81\\xa6\\xe8\\x84\\x86\\xe5\\xbc\\xb1\\xe6\\x80\\xa7\\xe3\\x82\\x92\\xe6\\xa4\\x9c\\xe5\\x87\\xba\\xe3\\x81\\x99\\xe3\\x82\\x8b\\xe6\\x89\\x8b\\xe6\\xb3\\x95\\xe3\\x81\\xa7\\xe3\\x81\\x82\\xe3\\x82\\x8b. \nAFL \\xe3\\x81\\xaf\\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe3\\x83\\x96\\xe3\\x83\\xad\\xe3\\x83\\x83\\xe3\\x82\\xaf\\xe3\\x83\\xac\\xe3\\x83\\x99\\xe3\\x83\\xab\\xe3\\x81\\xae\\xe5\\xae\\x9f\\xe8\\xa1\\x8c\\xe3\\x83\\x91\\xe3\\x82\\xb9\\xe3\\x82\\x92\\xe8\\xa6\\xb3\\xe6\\xb8\\xac\\xe3\\x81\\x97, \\xe6\\x9c\\xaa\\xe7\\x99\\xba\\xe8\\xa6\\x8b\\xe3\\x81\\xae\\xe3\\x83\\x91\\xe3\\x82\\xb9\\xe3\\x82\\x92\\xe9\\x80\\x9a\\xe9\\x81\\x8e\\xe3\\x81\\x99\\xe3\\x82\\x8b\\xe3\\x83\\x86\\xe3\\x82\\xb9\\xe3\\x83\\x88\\xe3\\x82\\xb1\\xe3\\x83\\xbc\\xe3\\x82\\xb9\\xe3\\x82\\x92\n\\xe5\\x8a\\xb9\\xe7\\x8e\\x87\\xe7\\x9a\\x84\\xe3\\x81\\xab\\xe6\\x8e\\xa2\\xe7\\xb4\\xa2\\xe3\\x81\\x99\\xe3\\x82\\x8b\\xe3\\x83\\x95\\xe3\\x82\\xa1\\xe3\\x82\\xb8\\xe3\\x83\\xb3\\xe3\\x82\\xb0\\xe3\\x83\\x84\\xe3\\x83\\xbc\\xe3\\x83\\xab\\xe3\\x81\\xa7\\xe3\\x81\\x82\\xe3\\x82\\x8b. \\xe6\\x9c\\xac\\xe7\\xa0\\x94\\xe7\\xa9\\xb6\\xe3\\x81\\xa7\\xe3\\x81\\xaf, \\xe5\\xaf\\xbe\\xe8\\xb1\\xa1\\xe3\\x81\\xae\\xe3\\x82\\xbd\\xe3\\x83\\xbc\\xe3\\x82\\xb9\\xe3\\x82\\xb3\\xe3\\x83\\xbc\\xe3\\x83\\x89\\xe5\\x86\\x85\\xe3\\x81\\xae\\xe3\\x82\\xb3\\xe3\\x83\\xbc\\xe3\\x83\\x89\n\\xe3\\x82\\xaf\\xe3\\x83\\xad\\xe3\\x83\\xbc\\xe3\\x83\\xb3\\xe9\\x9b\\x86\\xe7\\xb4\\x84\\xe3\\x81\\xab\\xe3\\x82\\x88\\xe3\\x82\\x8b, AFL \\xe3\\x81\\xae\\xe3\\x83\\x91\\xe3\\x82\\xb9\\xe6\\x8e\\xa2\\xe7\\xb4\\xa2\\xe5\\x8a\\xb9\\xe7\\x8e\\x87\\xe3\\x81\\xae\\xe5\\xa4\\x89\\xe5\\x8c\\x96\\xe3\\x82\\x92\\xe8\\xaa\\xbf\\xe6\\x9f\\xbb\\xe3\\x81\\x97\\xe3\\x81\\x9f. \\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe3\\x83\\x96\\xe3\\x83\\xad\\xe3\\x83\\x83\\xe3\\x82\\xaf\\xe3\\x82\\x92\\xe5\\x90\\xab\\xe3\\x82\\x80\\xe3\\x82\\xb3\\xe3\\x83\\xbc\\xe3\\x83\\x89\n\\xe3\\x82\\xaf\\xe3\\x83\\xad\\xe3\\x83\\xbc\\xe3\\x83\\xb3\\xe3\\x82\\x92\\xe9\\x9b\\x86\\xe7\\xb4\\x84\\xe3\\x81\\x99\\xe3\\x82\\x8b\\xe3\\x81\\x93\\xe3\\x81\\xa8\\xe3\\x81\\xa7, \\xe3\\x83\\x91\\xe3\\x82\\xb9\\xe3\\x81\\x8c\\xe5\\x8d\\x98\\xe7\\xb4\\x94\\xe5\\x8c\\x96\\xe3\\x81\\x95\\xe3\\x82\\x8c, AFL \\xe3\\x81\\x8c\\xe8\\xa6\\xb3\\xe6\\xb8\\xac\\xe3\\x81\\x99\\xe3\\x82\\x8b\\xe3\\x83\\x91\\xe3\\x82\\xb9\\xe3\\x81\\xae\\xe6\\x95\\xb0\\xe3\\x81\\x8c\\xe6\\xb8\\x9b\\xe5\\xb0\\x91\\xe3\\x81\\x97, \n\\xe6\\x9c\\xaa\\xe7\\x99\\xba\\xe8\\xa6\\x8b\\xe3\\x81\\xae\\xe3\\x83\\x91\\xe3\\x82\\xb9\\xe3\\x81\\xab\\xe5\\x88\\xb0\\xe9\\x81\\x94\\xe3\\x81\\x97\\xe3\\x82\\x84\\xe3\\x81\\x99\\xe3\\x81\\x8f\\xe3\\x81\\xaa\\xe3\\x82\\x8b\\xe3\\x81\\xa8\\xe8\\x80\\x83\\xe3\\x81\\x88\\xe3\\x81\\x9f. \\xe5\\xae\\x9f\\xe9\\xa8\\x93\\xe3\\x81\\xae\\xe7\\xb5\\x90\\xe6\\x9e\\x9c\\xe3\\x81\\xa8\\xe3\\x81\\x97\\xe3\\x81\\xa6, AFL \\xe3\\x81\\x8c\\xe7\\x99\\xba\\xe8\\xa6\\x8b\\xe3\\x81\\x97\\xe3\\x81\\x9f\\xe3\\x83\\x91\\xe3\\x82\\xb9\\xe6\\x95\\xb0\\xe3\\x81\\xab\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCoverage-based greybox fuzzing as markov chain\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.jstage.jst.go.jp/article/jssst/42/2/42_2_135/_pdf&hl=en&sa=X&d=16179085468725345769&ei=J_tBaKWyJ5LXieoPwNDK0Qk&scisig=AAZF9b8VdqKlzN8hjg9tffa-9fxI&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "Operating system service extensions for microkernels", "first_label": [], "second_label": [], "data": "RW Skowyra, S Jero, J Furgala, BC Ward, R Khazan\\xc2\\xa0- US Patent 12,314,734, 2025\nAccording to embodiments of the present disclosure, a system includes: a \nmicrokernel having a low-level application programming interface (API) and \nproviding memory protection domains to user-level processes; and an abstraction \nlayer running on top of the microkernel and comprising a plurality of service \nextensions to the microkernel and configured to provide a high-level operating \nsystem (OS) API for use by one or more application processes running in user space\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTiming analysis of a protected operating system kernel\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://patents.google.com/patent/US12314734B1/en&hl=en&sa=X&d=5383696432805697768&ei=J_tBaKWyJ5LXieoPwNDK0Qk&scisig=AAZF9b-H-4SoyvjzdAwXCSkPMLBt&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "Fault localization of AI-enabled cyber-physical systems by exploiting temporal neuron activation", "first_label": ["Fault Localization"], "second_label": ["Exploit", "Localization"], "data": "D Lyu, Y Li, Z Zhang, P Arcaini, XY Zhang, F Ishikawa\\xe2\\x80\\xa6\\xc2\\xa0- Journal of Systems and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern cyber\\xe2\\x80\\x93physical systems (CPS) are evolving to integrate deep neural \nnetworks (DNNs) as controllers, leading to the emergence of AI-enabled CPSs. An \ninadequately trained DNN controller may produce incorrect control actions, exposing\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225001438&hl=en&sa=X&d=3286846770327067741&ei=J_tBaPWrKqKr6rQPiJHk4QU&scisig=AAZF9b-jUE3fT364wIMjAbdvLNMM&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Variational Prefix Tuning for diverse and accurate code summarization using pre-trained language models", "first_label": ["LLM", "Code"], "second_label": [], "data": "J Zhao, Y Song, E Cohen\\xc2\\xa0- Journal of Systems and Software, 2025\nRecent advancements in source code summarization have leveraged transformer-\nbased pre-trained models, including Large Language Models of Code (LLMCs), to \nautomate and improve the generation of code summaries. However, existing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.09062&hl=en&sa=X&d=10492238756586633693&ei=J_tBaLbjJc6r6rQPj9ui4AE&scisig=AAZF9b-kVaz6dOvEUYfWxHidq5aY&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Graph neural network for fault localization in sequence-based models", "first_label": ["Fault Localization"], "second_label": ["Localization", "Graph"], "data": "MA Raza, M Wardat\\xc2\\xa0- Empirical Software Engineering, 2025\nDeep learning models, particularly sequence-based models (SBMs) like Recurrent \nNeural Networks (RNNs), Long Short-Term Memory Networks (LSTMs), Gated \nRecurrent Units (GRUs), Transformers, and patch-based architectures, are crucial for\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10666-6&hl=en&sa=X&d=5230572584348431032&ei=J_tBaLbjJc6r6rQPj9ui4AE&scisig=AAZF9b-7MzoJsp70OzaEX6QItv9k&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "LLM-enhanced service Semantic Representation and Category co-occurrence feature Augmentation for Web API recommendation", "first_label": ["LLM"], "second_label": [], "data": "G Zou, P Li, S Yang, S Hu, S Pang, Y Gan\\xc2\\xa0- Information Processing & Management, 2025\nWeb API recommendation for mashup development has become increasingly \nchallenging due to the rapid growth of available APIs. Current approaches face two \ncritical limitations: semantic inconsistency in service descriptions and insufficient\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0306457325001608&hl=en&sa=X&d=9859834031812963668&ei=J_tBaLbjJc6r6rQPj9ui4AE&scisig=AAZF9b-Q8Xoyt2GZwk-3fcDMDIac&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
