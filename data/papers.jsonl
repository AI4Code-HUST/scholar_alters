{"title": "OpenCodeInstruct: A Large-scale Instruction Tuning Dataset for Code LLMs", "first_label": ["LLM", "Code"], "second_label": [], "data": "WU Ahmad, A Ficek, M Samadi, J Huang, V Noroozi\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have transformed software development by \nenabling code generation, automated debugging, and complex reasoning. However, \ntheir continued advancement is constrained by the scarcity of high-quality, publicly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.04030&hl=en&sa=X&d=5917653904305649400&ei=2Ub4Z-XTEY-j6rQPo73a4AM&scisig=AFWwaeaybbbls4eyzwf1B3I5oC44&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AFWwaeYwgMeQSPpxCfDXmGy5aE3n&html=&pos=0&folt=rel", "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research", "Bach Le - new related research", "Xin ZHOU - new related research"]}
{"title": "How Accurately Do Large Language Models Understand Code?", "first_label": ["LLM", "Code"], "second_label": [], "data": "S Haroon, AF Khan, A Humayun, W Gill, AH Amjad\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly used in post-development tasks \nsuch as code repair and testing. A key factor in these tasks' success is the model's \ndeep understanding of code. However, the extent to which LLMs truly understand\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.04372&hl=en&sa=X&d=13848317151172529366&ei=2Ub4Z-XTEY-j6rQPo73a4AM&scisig=AFWwaeaAEeCieX1LHkvPVUHyVgKS&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AFWwaeYwgMeQSPpxCfDXmGy5aE3n&html=&pos=1&folt=rel", "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research", "Bach Le - new related research", "4 new citations to articles by Hong Jin Kang"]}
{"title": "RustEvo^ 2: An Evolving Benchmark for API Evolution in LLM-based Rust Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "L Liang, J Gong, M Liu, C Wang, G Ou, Y Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have become pivotal tools for automating code \ngeneration in software development. However, these models face significant \nchallenges in producing version-aware code for rapidly evolving languages like\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.16922%3F&hl=en&sa=X&d=16675224894932160996&ei=2Ub4Z-XTEY-j6rQPo73a4AM&scisig=AFWwaea4g_0zH5bNDjn1WSqwrFGh&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AFWwaeYwgMeQSPpxCfDXmGy5aE3n&html=&pos=2&folt=rel", "ref": ["Thanh Le-Cong - new related research"]}
{"title": "L0-Reasoning Bench: Evaluating Procedural Correctness in Language Models via Simple Program Execution", "first_label": [], "second_label": [], "data": "S Sun, CP Hsieh, F Ladhak, E Arakelyan, SA Serano\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nComplex reasoning tasks often rely on the ability to consistently and accurately apply \nsimple rules across incremental steps, a foundational capability which we term\" level-\n0\" reasoning. To systematically evaluate this capability, we introduce L0-Bench, a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.22832&hl=en&sa=X&d=3581934578808224243&ei=2Ub4Z-XTEY-j6rQPo73a4AM&scisig=AFWwaebs81HMSqHZ7PO00Lpfwg7f&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AFWwaeYwgMeQSPpxCfDXmGy5aE3n&html=&pos=3&folt=rel", "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research", "Bach Le - new related research", "Xin ZHOU - new related research"]}
{"title": "LLM Test Generation via Iterative Hybrid Program Analysis", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "S Gu, N Nashid, A Mesbah\\xc2\\xa0- arXiv preprint arXiv:2503.13580, 2025\nAutomating unit test generation remains a significant challenge, particularly for \ncomplex methods in real-world projects. While Large Language Models (LLMs) have \nmade strides in code generation, they struggle to achieve high branch coverage due\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.13580&hl=en&sa=X&d=207857029493572923&ei=2Ub4Z-XTEY-j6rQPo73a4AM&scisig=AFWwaeYzdRQn3PjIc4QGlsuh6_K4&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AFWwaeYwgMeQSPpxCfDXmGy5aE3n&html=&pos=4&folt=rel", "ref": ["Thanh Le-Cong - new related research", "Bach Le - new related research", "Richard Fang - new related research", "Hong Jin Kang - new related research"]}
{"title": "DDPT: Diffusion-Driven Prompt Tuning for Large Language Model Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Li, S Hyun, MA Babar\\xc2\\xa0- arXiv preprint arXiv:2504.04351, 2025\nLarge Language Models (LLMs) have demonstrated remarkable capabilities in code \ngeneration. However, the quality of the generated code is heavily dependent on the \nstructure and composition of the prompts used. Crafting high-quality prompts is a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.04351&hl=en&sa=X&d=10777735064745098709&ei=2Ub4Z_b5FZuw6rQPjdfcmQQ&scisig=AFWwaeZu_rFKtOje-Q7rbJBNmDlF&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=1&folt=rel", "ref": ["David Lo - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "LocAgent: Graph-Guided LLM Agents for Code Localization", "first_label": ["LLM", "Code"], "second_label": ["Agent", "Localization"], "data": "Z Chen, X Tang, G Deng, F Wu, J Wu, Z Jiang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode localization--identifying precisely where in a codebase changes need to be \nmade--is a fundamental yet challenging task in software maintenance. Existing \napproaches struggle to efficiently navigate complex codebases when identifying\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.09089%3F&hl=en&sa=X&d=276668227003209980&ei=2Ub4Z_b5FZuw6rQPjdfcmQQ&scisig=AFWwaebrlhR4TOxAKNYgDQ0UAK82&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=2&folt=rel", "ref": ["David Lo - new related research"]}
{"title": "Generative Large Language Model usage in Smart Contract Vulnerability Detection", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection"], "data": "P Ince, J Yu, JK Liu, X Du\\xc2\\xa0- arXiv preprint arXiv:2504.04685, 2025\nRecent years have seen an explosion of activity in Generative AI, specifically Large \nLanguage Models (LLMs), revolutionising applications across various fields. Smart \ncontract vulnerability detection is no exception; as smart contracts exist on public\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.04685&hl=en&sa=X&d=3782065939597708655&ei=2Ub4Z_b5FZuw6rQPjdfcmQQ&scisig=AFWwaeZid-0xDC6cki9Q59anhPrN&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=5&folt=rel", "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "OASIS: Order-Augmented Strategy for Improved Code Search", "first_label": ["Code"], "second_label": ["Search"], "data": "Z Gao, Z Zhan, X Li, E Yu, H Zhang, Y Zhang, J Li\\xc2\\xa0- arXiv preprint arXiv:2503.08161, 2025\nCode embeddings capture the semantic representations of code and are crucial for \nvarious code-related large language model (LLM) applications, such as code search. \nPrevious training primarily relies on optimizing the InfoNCE loss by comparing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.08161%3F&hl=en&sa=X&d=15392589071867118103&ei=2Ub4Z_b5FZuw6rQPjdfcmQQ&scisig=AFWwaea_nsVmM7D1NOV7k0ju42Z6&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=6&folt=rel", "ref": ["David Lo - new related research"]}
{"title": "SmartBugBert: BERT-Enhanced Vulnerability Detection for Smart Contract Bytecode", "first_label": ["Vulnerabilities", "Smart Contracts", "Code", "Bug"], "second_label": ["Detection"], "data": "J Bu, W Li, Z Li, Z Zhang, X Li\\xc2\\xa0- arXiv preprint arXiv:2504.05002, 2025\nSmart contracts deployed on blockchain platforms are vulnerable to various security \nvulnerabilities. However, only a small number of Ethereum contracts have released \ntheir source code, so vulnerability detection at the bytecode level is crucial. This\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.05002&hl=en&sa=X&d=6150372104347240756&ei=2Ub4Z_b5FZuw6rQPjdfcmQQ&scisig=AFWwaeb2WS1H06_-kEaW3oJ1KhL-&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=7&folt=rel", "ref": ["David Lo - new related research"]}
{"title": "Enhancing Smart Contract Vulnerability Detection in DApps Leveraging Fine-Tuned LLM", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection"], "data": "J Bu, W Li, Z Li, Z Zhang, X Li\\xc2\\xa0- arXiv preprint arXiv:2504.05006, 2025\nDecentralized applications (DApps) face significant security risks due to \nvulnerabilities in smart contracts, with traditional detection methods struggling to \naddress emerging and machine-unauditable flaws. This paper proposes a novel\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.05006&hl=en&sa=X&d=3716949235882934426&ei=2Ub4Z_b5FZuw6rQPjdfcmQQ&scisig=AFWwaeYhOxTQXubByPB5TSI1XIvX&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=8&folt=rel", "ref": ["David Lo - new related research", "Richard Fang - new related research", "Hong Jin Kang - new related research"]}
{"title": "LLMs are Bug Replicators: An Empirical Study on LLMs' Capability in Completing Bug-prone Code", "first_label": ["LLM", "Code", "Bug"], "second_label": [], "data": "L Guo, S Ye, Z Sun, X Chen, Y Zhang, B Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable performance in \ncode completion. However, the training data used to develop these models often \ncontain a significant amount of buggy code. Yet, it remains unclear to what extent\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.11082&hl=en&sa=X&d=9189825353695587011&ei=2Ub4Z_b5FZuw6rQPjdfcmQQ&scisig=AFWwaeZYDliimmo8dCt2DNKqsCtm&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=9&folt=rel", "ref": ["David Lo - new related research"]}
{"title": "An Evaluation of the Impact of Code Generation Tools on Software Development", "first_label": ["Code"], "second_label": ["Generation"], "data": "LFM Osorio, PA dos Santos Neto, G Avelino, WAL Lira\\xc2\\xa0- Simp\\xc3\\xb3sio Brasileiro de\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nContext: The rise of AI-assisted tools like GitHub Copilot aims to improve productivity \nin software development, raising questions about their practical impact on developer \nperformance and code quality. Problem: While AI-assisted tools are promoted for \nenhancing productivity, empirical evidence on their real-world impact remains \nlimited. This study addresses whether such tools improve programming workflows, \nfocusing on developers with varying experience levels and examining effects on\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaThanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/sbsi/article/download/34379/34170/&hl=en&sa=X&d=3475411260493206906&ei=2Ub4Z-_NFJWz6rQPveLUmAo&scisig=AFWwaea7SKoUpbPD5bymc7jUS7ef&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AFWwaebZb4G2z_XAHxtUtGUOv8go&html=&pos=0&folt=cit", "ref": ["1 new citation to articles by Bach Le", "1 new citation to articles by Thanh Le-Cong"]}
{"title": "R2Vul: Learning to Reason about Software Vulnerabilities with Reinforcement Learning and Structured Reasoning Distillation", "first_label": ["Vulnerabilities"], "second_label": [], "data": "M Weyssow, C Yang, J Chen, Y Li, H Huang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have shown promising performance in software \nvulnerability detection (SVD), yet their reasoning capabilities remain unreliable. \nExisting approaches relying on chain-of-thought (CoT) struggle to provide relevant\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.04699&hl=en&sa=X&d=5785686524278912976&ei=2Ub4Z8zsG-OO6rQPq-P-gAo&scisig=AFWwaebENSFvsakJL8hNltnJjy6R&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AFWwaeZADCuvrSiGaZ1pge7b9bMB&html=&pos=3&folt=rel", "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Evaluating the Role of Large Language Models in Test Configuration Code Generation: An Empirical Study", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation"], "data": "S Katepally - 2025\nBackground: Automating software development tasks is becoming increasingly \nrelevant as software systems become complex, and Large Language Models (LLMs) \nhave been gaining popularity for their ability to generate code from textual \ndescriptions, offering potential benefits in various coding scenarios Problem \nStatement: Despite progress in using LLMs for code generation, research on XML-\nstyle test configuration code generation remains limited. This study explores how\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaExploring Parameter-Efficient Fine-Tuning Techniques for Code\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.diva-portal.org/smash/record.jsf%3Fpid%3Ddiva2:1949520&hl=en&sa=X&d=13946686766702512593&ei=2Ub4Z9HfGJGu6rQPyMPCuAs&scisig=AFWwaebZjl6pcp_F69N4Jbybj5o2&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AFWwaeZamHljvPChNBtOABcetGTp&html=&pos=0&folt=cit", "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "Leveraging Large Language Models for Security-Focused Code Reviews", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "D McQuade\nThis study investigates the potential application of Large Language Models (LLMs) in \nenhancing software security through automated vulnerability detection during the \ncode review process. The research examines the efficacy of LLMs in identifying \nsecurity vulnerabilities that human reviewers, particularly those without extensive \nsecurity backgrounds, might overlook. Through analysis of historically significant \nCommon Vulnerabilities and Exposures (CVEs) in popular open-source projects\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection and repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://adsecvn.com/wp-content/uploads/2025/03/LLM_Code_Reviews.pdf&hl=en&sa=X&d=10362399872801253051&ei=2Ub4Z9HfGJGu6rQPyMPCuAs&scisig=AFWwaeZAJvF78KyLNU_FomXddKVU&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AFWwaeZamHljvPChNBtOABcetGTp&html=&pos=1&folt=cit", "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "ELT-Bench: An End-to-End Benchmark for Evaluating AI Agents on ELT Pipelines", "first_label": [], "second_label": ["Agent"], "data": "T Jin, Y Zhu, D Kang\\xc2\\xa0- arXiv preprint arXiv:2504.04808, 2025\nPractitioners are increasingly turning to Extract-Load-Transform (ELT) pipelines with \nthe widespread adoption of cloud data warehouses. However, designing these \npipelines often involves significant manual work to ensure correctness. Recent\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.04808&hl=en&sa=X&d=17618773598726971491&ei=2Ub4Z-aMGr6l6rQP6IGIqAI&scisig=AFWwaeZtqP-28GczAcquqwQEokUH&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=0&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Emerging Cyber Attack Risks of Medical AI Agents", "first_label": [], "second_label": ["Agent"], "data": "J Qiu, L Li, J Sun, H Wei, Z Xu, K Lam, W Yuan\\xc2\\xa0- arXiv preprint arXiv:2504.03759, 2025\nLarge language models (LLMs)-powered AI agents exhibit a high level of autonomy \nin addressing medical and healthcare challenges. With the ability to access various \ntools, they can operate within an open-ended action space. However, with the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.03759&hl=en&sa=X&d=2197394737877831403&ei=2Ub4Z-aMGr6l6rQP6IGIqAI&scisig=AFWwaeaDfSE-QTy5FZtsSiO83H84&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=1&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Les Dissonances: Cross-Tool Harvesting and Polluting in Multi-Tool Empowered LLM Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Z Li, J Cui, X Liao, L Xing\\xc2\\xa0- arXiv preprint arXiv:2504.03111, 2025\nLarge Language Model (LLM) agents are autonomous systems powered by LLMs, \ncapable of reasoning and planning to solve problems by leveraging a set of tools. \nHowever, the integration of multi-tool capabilities in LLM agents introduces\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.03111&hl=en&sa=X&d=16787567624520007863&ei=2Ub4Z-aMGr6l6rQP6IGIqAI&scisig=AFWwaeZ1aVR1vsCpBgrDw-H6FAoH&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=2&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "LLM-based Unit Test Generation for Dynamically-Typed Programs", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "R Liu, Z Zhang, Y Hu, Y Lin, X Gao, H Sun\\xc2\\xa0- arXiv preprint arXiv:2503.14000, 2025\nAutomated unit test generation has been widely studied, but generating effective \ntests for dynamically typed programs remains a significant challenge. Existing \napproaches, including search-based software testing (SBST) and recent LLM-based\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.14000&hl=en&sa=X&d=7430576131620821752&ei=2Ub4Z-aMGr6l6rQP6IGIqAI&scisig=AFWwaeY9lDQzBc37lJzEKJmFY6Qx&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=3&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Does context matter? contextualjudgebench for evaluating llm-based judges in contextual settings", "first_label": ["LLM"], "second_label": [], "data": "A Xu, S Bansal, Y Ming, S Yavuz, S Joty\\xc2\\xa0- arXiv preprint arXiv:2503.15620, 2025\nThe large language model (LLM)-as-judge paradigm has been used to meet the \ndemand for a cheap, reliable, and fast evaluation of model outputs during AI system \ndevelopment and post-deployment monitoring. While judge models--LLMs finetuned\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.15620&hl=en&sa=X&d=4694277635380098830&ei=2Ub4Z-aMGr6l6rQP6IGIqAI&scisig=AFWwaeZWWBCgHzhwdV7rV4U7IIiY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=6&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Dancing with Critiques: Enhancing LLM Reasoning with Stepwise Natural Language Self-Critique", "first_label": ["LLM"], "second_label": [], "data": "Y Li, J Xu, T Liang, X Chen, Z He, Q Liu, R Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nEnhancing the reasoning capabilities of large language models (LLMs), particularly \nfor complex tasks requiring multi-step logical deductions, remains a significant \nchallenge. Traditional inference time scaling methods utilize scalar reward signals\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.17363%3F&hl=en&sa=X&d=11521510970677819720&ei=2Ub4Z-aMGr6l6rQP6IGIqAI&scisig=AFWwaeZ1FoGj3fIwjgWCbOxO43ev&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=7&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "CapArena: Benchmarking and Analyzing Detailed Image Captioning in the LLM Era", "first_label": ["LLM"], "second_label": [], "data": "K Cheng, W Song, J Fan, Z Ma, Q Sun, F Xu, C Yan\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nImage captioning has been a longstanding challenge in vision-language research. \nWith the rise of LLMs, modern Vision-Language Models (VLMs) generate detailed \nand comprehensive image descriptions. However, benchmarking the quality of such\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.12329%3F&hl=en&sa=X&d=407472380549964642&ei=2Ub4Z-aMGr6l6rQP6IGIqAI&scisig=AFWwaeYceA6AtNeTroAmdGm1ugPz&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=8&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Navigating Rifts in Human-LLM Grounding: Study and Benchmark", "first_label": ["LLM"], "second_label": [], "data": "O Shaikh, H Mozannar, G Bansal, A Fourney, E Horvitz\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models excel at following instructions but often struggle with the \ncollaborative aspects of conversation that humans naturally employ. This limitation in \ngrounding--the process by which conversation participants establish mutual\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.13975&hl=en&sa=X&d=6056628797355529511&ei=2Ub4Z-aMGr6l6rQP6IGIqAI&scisig=AFWwaeYuzwNKVc6ZCL0NUy7wCU7P&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=9&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Knowledge Representation for Integrating Clinical and Administrative Data in Claims Processing", "first_label": [], "second_label": [], "data": "N Jayawardena\\xc2\\xa0- International Journal of Data Science, Big Data\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis paper addresses the increasingly complex challenge of integrating clinical and \nadministrative data in health insurance claims processing through advanced \nknowledge representation techniques. Driven by rising healthcare costs and the \ngrowing prevalence of electronic health records, there is an urgent need to establish \nrobust, scalable, and semantically aware frameworks for linking heterogeneous data \nsources. By introducing formalisms that combine logical inference, ontological\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSurveying neuro-symbolic approaches for reliable artificial\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://kernpublic.com/index.php/IJDSBDAPM/article/download/2025-MARCH-04/4&hl=en&sa=X&d=9620520256098350845&ei=2Ub4Z96YE5m7ieoP3oH9uAU&scisig=AFWwaeYbWw_qcdEPlQ5a0pp8NRXZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AFWwaeZ0cPfysy_B7V1I3HcGE9Io&html=&pos=0&folt=cit", "ref": ["4 new citations to articles by Hong Jin Kang"]}
{"title": "The H-Elena Trojan Virus to Infect Model Weights: A Wake-Up Call on the Security Risks of Malicious Fine-Tuning", "first_label": [], "second_label": [], "data": "V Tejedor, C Zuheros, C Pel\\xc3\\xa1ez-Gonz\\xc3\\xa1lez\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) offer powerful capabilities in text generation and are \nincreasingly adopted across a wide range of domains. However, their open \naccessibility and fine-tuning capabilities pose new security threats. This advance \ngenerates new challenges in terms of security and control over the systems that use \nthese models. We hypothesize that LLMs can be designed, adapted, and used \nmaliciously, so their extensive and confident use entails risks that should be taken\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaStealthy backdoor attack for code models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.03823&hl=en&sa=X&d=4497889825907294098&ei=2Ub4Z96YE5m7ieoP3oH9uAU&scisig=AFWwaeawnUsLCfgYu5MTYKwR1IZS&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AFWwaeZ0cPfysy_B7V1I3HcGE9Io&html=&pos=1&folt=cit", "ref": ["4 new citations to articles by Hong Jin Kang"]}
{"title": "HaPy-Bug--Human Annotated Python Bug Resolution Dataset", "first_label": ["Bug"], "second_label": [], "data": "P Przymus, M Fejzer, J Nar\\xc4\\x99bski, R Wo\\xc5\\xbaniak, \\xc5\\x81 Halada\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWe present HaPy-Bug, a curated dataset of 793 Python source code commits \nassociated with bug fixes, with each line of code annotated by three domain experts. \nThe annotations offer insights into the purpose of modified files, changes at the line \nlevel, and reviewers' confidence levels. We analyze HaPy-Bug to examine the \ndistribution of file purposes, types of modifications, and tangled changes. \nAdditionally, we explore its potential applications in bug tracking, the analysis of bug\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBugsinpy: a database of existing bugs in python programs to\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.04810&hl=en&sa=X&d=14796298888512808939&ei=2Ub4Z96YE5m7ieoP3oH9uAU&scisig=AFWwaeYeuxs95UiH0nX0RS_Hq0VE&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AFWwaeZ0cPfysy_B7V1I3HcGE9Io&html=&pos=3&folt=cit", "ref": ["4 new citations to articles by Hong Jin Kang"]}
{"title": "Toward LLM-Driven GDPR Compliance Checking for Android Apps", "first_label": ["LLM"], "second_label": [], "data": "M Alecci, N Sannier, M Ceci, S Abualhaija, J Samhi\\xe2\\x80\\xa6\\xc2\\xa0- 33rd ACM International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAndroid apps extensively collect sensitive personal data from our devices daily. \nDespite stringent regulations like the European Union's General Data Protection \nRegulation (GDPR), many applications (apps) fail to comply with these legal\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://orbilu.uni.lu/bitstream/10993/64674/1/FSE_IVR_2025_RegCheck.pdf&hl=en&sa=X&d=9430644475903485929&ei=2Ub4Z47WHZWrieoPtfXHiQw&scisig=AFWwaeY9mg3zPUX9ptxQyzP3T_Nw&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=3&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Do Developers Depend on Deprecated Library Versions? A Mining Study of Log4j", "first_label": [], "second_label": [], "data": "H Yoshioka, S Lertbanjongngam, M Inaba, Y Fan\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLog4j has become a widely adopted logging library for Java programs due to its long \nhistory and high reliability. Its widespread use is notable not only because of its \nmaturity but also due to the complexity and depth of its features, which have made it\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.03167&hl=en&sa=X&d=17142084561539849326&ei=2Ub4Z47WHZWrieoPtfXHiQw&scisig=AFWwaeaX8kuemmCFKNqJ5rQtzpsR&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=4&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "BESA: Extending Bugs Triggered by Runtime Testing via Static Analysis", "first_label": ["Bug", "Software Testing", "Static Analysis"], "second_label": [], "data": "JJ Bai\\xc2\\xa0- Proceedings of the Twentieth European Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDue to limited test cases and execution scenarios, runtime testing often has \ninsufficient code coverage and thus misses many real bugs. To tackle this problem, \nwe propose a novel idea that static analysis of the triggered bug in runtime testing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3689031.3696089&hl=en&sa=X&d=11971501184870035235&ei=2Ub4Z47WHZWrieoPtfXHiQw&scisig=AFWwaebDNiyhkoXdOVlEYm5l6Q09&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=5&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "A Comprehensive Study of LLM Secure Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "SC Dai, J Xu, G Tao\\xc2\\xa0- arXiv preprint arXiv:2503.15554, 2025\nLLMs are widely used in software development. However, the code generated by \nLLMs often contains vulnerabilities. Several secure code generation methods have \nbeen proposed to address this issue, but their current evaluation schemes leave\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.15554%3F&hl=en&sa=X&d=1363137439941333778&ei=2Ub4Z47WHZWrieoPtfXHiQw&scisig=AFWwaea70lzbx-2dnx-SlddbyIDc&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=6&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Automatic Software Vulnerability Detection in Binary Code", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "S Liu, L Li, X Ban, C Chen, J Zhang\\xc2\\xa0- Machine Learning for Cyber Security: 6th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCybersecurity is critical in today's digital world, where the severity of threats from \nsoftware vulnerabilities grows significantly each year. Many techniques have been \ndeveloped to analyze vulnerabilities in source code. However, source code is not\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DgtJSEQAAQBAJ%26oi%3Dfnd%26pg%3DPA148%26ots%3D4r_QwP4uxA%26sig%3DcvmUxVdJjhji1ZVTJ5iM3lu67oM&hl=en&sa=X&d=8963754288088414031&ei=2Ub4Z47WHZWrieoPtfXHiQw&scisig=AFWwaeZep79dGvTHXvqqfWTiFBYy&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=9&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
