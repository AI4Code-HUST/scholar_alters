{"title": "Multi Language Models for On-the-Fly Syntax Highlighting", "first_label": ["LLM"], "second_label": [], "data": "ME Palma, P Rani, HC Gall- arXiv preprint arXiv:2510.04166, 2025\nSyntax highlighting is a critical feature in modern software development \nenvironments, enhancing code readability and developer productivity. However, \ndelivering accurate highlighting in real time remains challenging for online and web", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04166%3F&hl=en&sa=X&d=2254729212502568662&ei=5IUBaaWMB9rZzwKkk-bABQ&scisig=ABGrvjIMpU0YGaMDVoPzEyw5QYUR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Hong Jin Kang - new related research"]}
{"title": "A Program Synthesis Dataset for LLM Temperature Analysis", "first_label": ["LLM"], "second_label": [], "data": "Z Sgodi, I Kollth, P Hegeds, R Ferenc- IEEE Access, 2025\nLarge Language Models (LLMs) play an increasingly critical role in software \nengineering research, aiding tasks such as program synthesis, automated program \nrepair, and test case generation. While extensive evaluations of LLMs exist, those\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11216419.pdf&hl=en&sa=X&d=15789985321447297160&ei=5IUBaaWMB9rZzwKkk-bABQ&scisig=ABGrvjLNewKPXm6mo80GjqlQ2E8O&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "David Lo - new related research", "Thanh Le-Cong - new related research", "1 new citation to articles by Quang-Cuong Bui", "1 new citation to articles by Xin ZHOU", "Xin ZHOU - new related research"]}
{"title": "MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing", "first_label": ["LLM", "Fuzzing", "Bug"], "second_label": [], "data": "S Ou, Y Li, L Yu, C Wei, T Wen, Q Chen, Y Chen- IEEE Transactions on, 2025\nDeep learning (DL) frameworks serve as the backbone for a wide range of artificial \nintelligence applications. However, bugs within DL frameworks can cascade into \ncritical issues in higher-level applications, jeopardizing reliability and security. While", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/32/4359463/11201027.pdf&hl=en&sa=X&d=1422528139240657868&ei=5YUBafTNO_XSieoP5dXGqA0&scisig=ABGrvjI1tTlw2XwsJvzcyylBVxMq&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Bug Histories as Sources of Compiler Fuzzing Mutators", "first_label": ["Fuzzing", "Bug"], "second_label": [], "data": "L Liu, F Qin, O Legunsen, M d'Amorim- arXiv preprint arXiv:2510.07834, 2025\nBugs in compilers, which are critical infrastructure today, can have outsized negative \nimpacts. Mutational fuzzers aid compiler bug detection by systematically mutating \ncompiler inputs, ie, programs. Their effectiveness depends on the quality of the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07834&hl=en&sa=X&d=9037187058146226309&ei=5YUBafTNO_XSieoP5dXGqA0&scisig=ABGrvjIG6zX5TgS9MStSGVHyXUtI&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "NatGVD: Natural Adversarial Example Attack towards Graph-based Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "A Rath, W Qi, Y Li, X Wang- arXiv preprint arXiv:2510.04987, 2025\nGraph-based models learn rich code graph structural information and present \nsuperior performance on various code analysis tasks. However, the robustness of \nthese models against adversarial example attacks in the context of vulnerability", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04987&hl=en&sa=X&d=16144354957589846642&ei=5YUBafTNO_XSieoP5dXGqA0&scisig=ABGrvjKVVWD-G2UrNfBQI0a18maw&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "E2Edev: Benchmarking Large Language Models in End-to-End Software Development Task", "first_label": ["LLM"], "second_label": [], "data": "J Liu, C Huang, Z Guan, W Lei, Y Deng- arXiv preprint arXiv:2510.14509, 2025\nE2EDev comprises (i) a fine-grained set of user requirements,(ii){multiple BDD test \nscenarios with corresponding Python step implementations for each requirement}, \nand (iii) a fully automated testing pipeline built on the Behave framework. To ensure", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.14509&hl=en&sa=X&d=15900279319022234305&ei=5YUBafTNO_XSieoP5dXGqA0&scisig=ABGrvjJ71cvauMgej6922cy2tGye&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Exploring the Power of Diffusion Large Language Models for Software Engineering: An Empirical Investigation", "first_label": ["LLM"], "second_label": [], "data": "J Zhang, T Li, X Zhang, Q Hu, B Shi- arXiv preprint arXiv:2510.04605, 2025\nAutoregressive Large Language Models (AR-LLMs) are widely used in software \nengineering (SE) but face limitations in processing code structure information and \nsuffer from high inference latency. Diffusion LLMs (DLLMs) offer a promising", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04605&hl=en&sa=X&d=10573600647646258285&ei=5YUBafTNO_XSieoP5dXGqA0&scisig=ABGrvjL5R-YlKad_jWq6RXhc4mcD&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "DT4LM: Differential Testing for Reliable Language Model Updates in Classification Tasks", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "X Zuo, Y Xiao, X Cao, W Wang, JS Dong- IEEE Transactions on Software, 2025\nIn the field of Natural Language Processing (NLP), Language Models (LMs) are \nfrequently updated to enhance performance. However, these updates can introduce \nunintended regressions, cases where the updated model fails on inputs correctly", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11205851/&hl=en&sa=X&d=4279235962652410820&ei=5YUBafTNO_XSieoP5dXGqA0&scisig=ABGrvjKlOHcizD46rps8GlscSi_q&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Selecting and Combining Large Language Models for Scalable Code Clone Detection", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "M Chochlov, GA Ahmed, JV Patten, Y Han, G Lu- arXiv preprint arXiv, 2025\nSource code clones pose risks ranging from intellectual property violations to \nunintended vulnerabilities. Effective and efficient scalable clone detection, especially \nfor diverged clones, remains challenging. Large language models (LLMs) have", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15480&hl=en&sa=X&d=9943637308311023337&ei=5YUBafTNO_XSieoP5dXGqA0&scisig=ABGrvjKwntTHj-gYFVYkC1ZboyXO&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Large Language Models for Software Testing: A Research Roadmap", "first_label": ["LLM", "Software Testing"], "second_label": ["Search"], "data": "C Augusto, A Bertolino, G De Angelis, F Lonetti- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) are starting to be profiled as one of the most \nsignificant disruptions in the Software Testing field. Specifically, they have been \nsuccessfully applied in software testing tasks such as generating test code, or", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25043&hl=en&sa=X&d=1208330022631398164&ei=5YUBafTNO_XSieoP5dXGqA0&scisig=ABGrvjLqU3HMhvF_5yODTZeYJl6a&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "PCRepair: A Context-Aware Template-Based Approach for Automated Program Repair", "first_label": ["APR"], "second_label": ["Repair"], "data": "H Cao, W Zhang, Y Wang, Y Chu, M Deng, Z He- International Journal of Software, 2025\nAutomated Program Repair (APR) is increasingly vital for managing the complexity of \nmodern software systems. However, current APR techniques suffer from inefficiently \nselecting repair components, resulting in suboptimal patches. To address these\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.worldscientific.com/doi/abs/10.1142/S0218194025500731&hl=en&sa=X&d=10736890690647149823&ei=5YUBafTNO_XSieoP5dXGqA0&scisig=ABGrvjKIfDzI4FxEk_Z2oR6hTnmJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "MAVUL: Multi-Agent Vulnerability Detection via Contextual Reasoning and Interactive Refinement", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Agent", "Reasoning"], "data": "Y Li, K Joshi, X Wang, E Wong- arXiv preprint arXiv:2510.00317, 2025\nThe widespread adoption of open-source software (OSS) necessitates the mitigation \nof vulnerability risks. Most vulnerability detection (VD) methods are limited by \ninadequate contextual understanding, restrictive single-round interactions, and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.00317&hl=en&sa=X&d=577185325914480253&ei=5IUBaebWIM6E6rQPlNvGgAg&scisig=ABGrvjIbyn7OuStXpJ3sqMy4JVsK&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Repair", "Reasoning"], "data": "XC Wen, Z Lin, Y Yang, C Gao, D Ye- arXiv preprint arXiv:2510.05480, 2025\nThe exponential increase in software vulnerabilities has created an urgent need for \nautomatic vulnerability repair (AVR) solutions. Recent research has formulated AVR \nas a sequence generation problem and has leveraged large language models", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05480&hl=en&sa=X&d=17087307418542281791&ei=5IUBaebWIM6E6rQPlNvGgAg&scisig=ABGrvjJlsQcjOBCSZutD9pRzL3u0&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Source Code Guardrail: AI Driven Solution to Distinguish Critical vs. Generic Code for Enterprise LLM Security", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Sharma, A Gupta- International Conference on Provable Security, 2025\nAbstract The adoption of Large Language Models (LLMs) in businesses raises the \npossibility of inadvertent intellectual property (IP) and secret data leaks to public \nartificial intelligence systems. Organizations are using security solutions, including", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-2961-2_23&hl=en&sa=X&d=5184326828152072441&ei=5IUBaebWIM6E6rQPlNvGgAg&scisig=ABGrvjJOJG-OQ4wH-x-OhS5wRNe2&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "TIT: A Tree-Structured Instruction Tuning Approach for LLM-Based Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "H Jiang, Y Wang, H Lin, P Zou, Z Zhou, A Jia, X Li- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have shown strong performance in automated \nsource-to-target code translation through pretraining on extensive code corpora. \nHowever, mainstream LLM-based code translation methods suffer from two critical", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.09400&hl=en&sa=X&d=13736189209612319180&ei=5IUBaebWIM6E6rQPlNvGgAg&scisig=ABGrvjLfQpVO1yEU3BC2VHg0FKp1&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Propagation-Based Vulnerability Impact Assessment for Software Supply Chains", "first_label": ["Vulnerabilities"], "second_label": [], "data": "B Ruan, Z Lin, J Liu, C Zhang, KJZ Liang\nIdentifying the impact scope and scale is critical for software supply chain \nvulnerability assessment. However, existing studies face substantial limitations. First, \nprior studies either work at coarse package-level granularityproducing many false", "link": "https://scholar.google.com/scholar_url?url=https://profile.wohin.me/static/papers/ase25.pdf&hl=en&sa=X&d=9435696112223263876&ei=5IUBaebWIM6E6rQPlNvGgAg&scisig=ABGrvjJ-ANHBgYNlO8H7B786ANVF&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "2 new citations to articles by Bach Le", "1 new citation to articles by Hong Jin Kang"]}
{"title": "Large Language Models for Code Editing", "first_label": ["LLM", "Code"], "second_label": [], "data": "RJ Mooney, A Shi\nPretrained language models have been shown to be effective in many \nsoftwarerelated generation tasks; however, they are not well-suited for editing tasks \nduring maintaining the software as they are not designed to reason about edits. To", "link": "https://scholar.google.com/scholar_url?url=https://users.ece.utexas.edu/~gligoric/papers/Zhang25PhD.pdf&hl=en&sa=X&d=10229569576199033599&ei=5IUBaebWIM6E6rQPlNvGgAg&scisig=ABGrvjLpWoTa-j_SG0xO2_Fs3G5S&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "LLM-Assisted Synthesis of High-Assurance C Programs", "first_label": ["LLM"], "second_label": [], "data": "P Mukherjee, M Lu, B Delaware - 2025\nWe present SYNVERa novel, general purpose synthesizer for C programs \nequipped with machine-checked proofs of correctness using the Verified Software \nToolchain. To do so, SYNVER employs two Large Language Models (LLMs): the first\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://prasitagit.github.io/papers/SynverPreprint.pdf&hl=en&sa=X&d=10034668577701533579&ei=5IUBaebWIM6E6rQPlNvGgAg&scisig=ABGrvjKedmUATdp-iuZhyQwb-bpX&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Empowering Triple-Entry Accounting with Machine Learning and Blockchain: Unveiling Transparency Through Advanced Analytics", "first_label": ["Blockchain"], "second_label": [], "data": "AI Weinberg, A Faccia- Palgrave Studies in Financial Services Technology, 2025\nTraditional double-entry bookkeeping, a longstanding cornerstone of accounting \npractices, has historically governed financial record-keeping methodologies \n(Sangster, 2016). Its enduring legacy, spanning centuries, has provided a structured \nframework for tracking. Financial flows between two entities or accounts. However, \nas the intricacies of global business transactions and regulatory frameworks have \nevolved, the inherent limitations of this conventional system have become\nCites: Smart contract development: Challenges and opportunities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/content/pdf/10.1007/978-3-032-03523-3.pdf%23page%3D81&hl=en&sa=X&d=17032172227213005992&ei=5YUBaayIEtWY6rQP4IbZiQw&scisig=ABGrvjKXVBjm-9xZ22ZvQcztwdqH&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:ABGrvjKFoYpfVt7EiQsbVsLwN3n6&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le"]}
{"title": "Investigating the use of exemplary data for software vulnerability prediction", "first_label": ["Vulnerabilities"], "second_label": [], "data": "PK Kudjo, S Mensah, E Owusu, JK Appati- International Journal of System Assurance, 2025\nVulnerability prediction models (VPMs) are statistical machine learning algorithms \nthat are trained to identify vulnerable components in large software systems. \nRecently, a wide range of software metrics, like the number of dependencies and the", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s13198-025-03017-7&hl=en&sa=X&d=8318202847132729632&ei=5oUBafnDJIm16rQPw4j56AI&scisig=ABGrvjJnorXrLXP24DAbURcim6Db&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:ABGrvjLiNx7BmV3CtCrSb8n_Y3dH&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "TeTRIS: General-purpose Fuzzing for Translation Bugs in Source-to-Source Code Transpilers", "first_label": ["Fuzzing", "Code", "Bug"], "second_label": ["Generation"], "data": "Y Arafat, S Nagy - 2025\nAmid the rise of heterogeneous computing and concerns over systems and \napplication security, developers are increasingly embracing transpilers: a growing \nclass of tools for converting code from one programming language into another. As\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://futures.cs.utah.edu/papers/25ACSAC.pdf&hl=en&sa=X&d=7907468188891103628&ei=5oUBafnDJIm16rQPw4j56AI&scisig=ABGrvjLBdVkI2F9PVfJevtu33KlG&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:ABGrvjLiNx7BmV3CtCrSb8n_Y3dH&html=&pos=1&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "SymbFuzz: Symbolic Execution Guided Hardware Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "SS Miftah, A Srivastava, H Kim, S Wei, K Basu- Proceedings of the 58th IEEE/ACM, 2025\nModern hardware incorporates reusable designs to reduce cost and time to market, \ninadvertently increasing exposure to security vulnerabilities. While formal verification \nand simulation-based approaches have been traditionally utilized to mitigate these", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3725843.3756131&hl=en&sa=X&d=13892451739855032330&ei=5oUBaajDNt7M6rQP173fsAE&scisig=ABGrvjIckMkLWaPrI55dPwVGCMUZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Large-Scale Empirical Analysis of Continuous Fuzzing: Insights from 1 Million Fuzzing Sessions", "first_label": ["Fuzzing"], "second_label": [], "data": "T Shirai, O Nourry, Y Kashiwa, K Fujiwara, Y Kamei- arXiv preprint arXiv, 2025\nSoftware vulnerabilities are constantly being reported and exploited in software \nproducts, causing significant impacts on society. In recent years, the main approach \nto vulnerability detection, fuzzing, has been integrated into the continuous integration", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16433&hl=en&sa=X&d=4720648398624229113&ei=5oUBaajDNt7M6rQP173fsAE&scisig=ABGrvjLvN3fPNsFOAfS3JY64ZdkS&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Minoris: Practical Out-of-Emulator Kernel Module Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Xiang, F Wang, Y Chen, Q Liu, H Wang, J Wang- IEEE Transactions on, 2025\nVulnerabilities in the Linux kernel can be exploited to perform privilege escalation \nand take over the whole system. Fuzzing has been leveraged to detect Linux kernel \nvulnerabilities during the last decade. However, existing kernel fuzzing techniques", "link": "https://scholar.google.com/scholar_url?url=http://www.malgenomeproject.org/papers/tdsc25_minoris.pdf&hl=en&sa=X&d=4018952161547770155&ei=5oUBaajDNt7M6rQP173fsAE&scisig=ABGrvjJ6DkbswJoR00cuvD4KKxo6&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Extraction and Mutation at a High Level: Template-Based Fuzzing for JavaScript Engines", "first_label": ["Fuzzing"], "second_label": [], "data": "WK Wong, D Xiao, CT Lai, Y Peng, D Wu, S Wang- Proceedings of the ACM on, 2025\nJavaScript (JS) engines implement complex language semantics and optimization \nstrategies to support the dynamic nature of JS, making them difficult to test thoroughly \nand prone to subtle, security-critical bugs. Existing fuzzers often struggle to generate", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3763154&hl=en&sa=X&d=604366854830515299&ei=5oUBaajDNt7M6rQP173fsAE&scisig=ABGrvjJ8_etpKvSy6Zr28o1_lt7G&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Hong Jin Kang - new related research"]}
{"title": "E-FuzzEdge: Optimizing Embedded Device Security with Scalable In-Place Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "D Rusconi, O Yousef, M Picca, F Toffalini, A Lanzi- arXiv preprint arXiv:2510.01393, 2025\nIn this paper we show E-FuzzEdge, a novel fuzzing architecture targeted towards \nimproving the throughput of fuzzing campaigns in contexts where scalability is \nunavailable. E-FuzzEdge addresses the inefficiencies of hardware-in-the-loop", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01393&hl=en&sa=X&d=876126288656849057&ei=5oUBaajDNt7M6rQP173fsAE&scisig=ABGrvjI29yYRKrlJ80KOjroLHXeT&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Clutch Control: An Attention-based Combinatorial Bandit for Efficient Mutation in JavaScript Engine Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "M Foley, S Maffeis, MF Rozi, T Takahashi- arXiv preprint arXiv:2510.12732, 2025\nJavaScript engines are widely used in web browsers, PDF readers, and server-side \napplications. The rise in concern over their security has led to the development of \nseveral targeted fuzzing techniques. However, existing approaches use random", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12732%3F&hl=en&sa=X&d=1368299778829400409&ei=5oUBaajDNt7M6rQP173fsAE&scisig=ABGrvjI4CAZkWhcKOyqw3pENwwii&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "DFAFUZZ: Fuzzing for Embedded JavaScript Virtual Machines with Type-Directed DFA", "first_label": ["Fuzzing"], "second_label": [], "data": "H Lai, B Hua\nJavaScript is rapidly being deployed in securitycritical embedded domains, including \nIoT devices, edge computing, and smart automotive applications. Embedded \nJavaScript virtual machines (VMs) are critical in powering such deployments, which", "link": "https://scholar.google.com/scholar_url?url=https://csslab-ustc.github.io/publications/2025/js-vm-bugs.pdf&hl=en&sa=X&d=14086662969394613156&ei=5oUBaajDNt7M6rQP173fsAE&scisig=ABGrvjIDsQUp4KqbY58bTWR9VXh_&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=6&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "CNCFuzzer: Directed Blackbox Fuzzing of Computer Numerical Control System Based on Message Behaviour Guidance", "first_label": ["Fuzzing"], "second_label": [], "data": "Z Li, D Fang, Y Chen, S Li, J Peng, Z Song, S Lv, L Sun- ACM Transactions on Software\nIn the era of the Industrial Internet of Things, Computer Numerical Control (CNC) \nSystems are confronted with a pervasive threat from attackers. Uncovering their \nsecurity vulnerabilities before being exploited becomes imperative. Enterprise-level", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3771764&hl=en&sa=X&d=4976772631307591836&ei=5oUBaajDNt7M6rQP173fsAE&scisig=ABGrvjJOL17g1mtB2oB5KMVu8rnH&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=7&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Enhancing Domain-Specific Code Completion via Collaborative Inference with Large and Small Language Models", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Yu, Z Gao, L Bao, Z Liu- ACM Transactions on Software Engineering and, 2025\nLarge language model-based code completion has demonstrated excellent \nperformance, but still encounters challenges in capturing domain-specific knowledge \nfor more precise completion within specific domains, ie, domain-specific code", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3770748&hl=en&sa=X&d=2019769577165862416&ei=5oUBaajDNt7M6rQP173fsAE&scisig=ABGrvjKO1fKaLDZwwCDDcSmDx0Da&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=8&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "QuanBench: Benchmarking Quantum Code Generation with Large Language Models", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "X Guo, M Wang, J Zhao- arXiv preprint arXiv:2510.16779, 2025\nLarge language models (LLMs) have demonstrated good performance in general \ncode generation; however, their capabilities in quantum code generation remain \ninsufficiently studied. This paper presents QuanBench, a benchmark for evaluating\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16779&hl=en&sa=X&d=17566044421726947035&ei=5oUBaajDNt7M6rQP173fsAE&scisig=ABGrvjLz_dVACfzQ6yk2NfyB_EtZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=9&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "MulVuln: Enhancing Pre-trained LMs with Shared and Language-Specific Knowledge for Multilingual Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "V Nguyen, S Nepal, X Yuan, T Wu, F Chen, C Rudolph- arXiv preprint arXiv, 2025\nSoftware vulnerabilities (SVs) pose a critical threat to safety-critical systems, driving \nthe adoption of AI-based approaches such as machine learning and deep learning \nfor software vulnerability detection. Despite promising results, most existing methods", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04397%3F&hl=en&sa=X&d=15852306161444656354&ei=6IUBaY2XDPXSieoP5dXGqA0&scisig=ABGrvjK1G5x4sOA0GtoSv3NYa9I1&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Fuzzing C++ Compilers via Type-Driven Mutation", "first_label": ["Fuzzing"], "second_label": [], "data": "B Wang, C Chen, M Deng, J Chen, X Zhang, Y Lin- Proceedings of the ACM on, 2025\nC++ is a system-level programming language for modern software development, \nwhich supports multiple programming paradigms, including object-oriented, generic, \nand functional programming. The intrinsic complexity of these paradigms and their", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3763094&hl=en&sa=X&d=9567278433097235731&ei=6IUBaY2XDPXSieoP5dXGqA0&scisig=ABGrvjKncNY8xjPjRhCyvL8v-_9Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "InstructRepair: Instruct Large Language Models with Rich Bug Information for Automated Program Repair", "first_label": ["APR", "LLM", "Bug"], "second_label": ["Repair"], "data": "A Fu, P Xu, J Li, B Kuang, Y Gao- IEEE Transactions on Information Forensics and, 2025\nAutomated Program Repair (APR) repairs software bugs based on buggy code \nsnippets automatically. It is instrumental in reducing the time and effort required for \nsoftware maintenance. Recently, large language models (LLMs) have been utilized", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11194216/&hl=en&sa=X&d=15287113091370652463&ei=6IUBaY2XDPXSieoP5dXGqA0&scisig=ABGrvjKRQ4NA9Q2bph15_TI0m8Cp&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "CG-Bench: Can Language Models Assist Call Graph Construction in the Real World?", "first_label": ["LLM", "Static Analysis"], "second_label": ["Graph"], "data": "T Yuan, W Zhang, D Chen, J Wang- Proceedings of the 1st ACM SIGPLAN, 2025\nLanguage models for coding are shifting their focus from function-level to repository-\nlevel, with complex function invocations. We introduce CG-Bench, the first manually \nconstructed benchmark that measures the ability to understand call graphs for", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3759425.3763379&hl=en&sa=X&d=11570618845570061776&ei=6IUBaY2XDPXSieoP5dXGqA0&scisig=ABGrvjJTTJMRIMAuaa7eEoue4X54&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Evaluating SAP Joule for Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "J Heisler, J Reisinger, A Fischer- arXiv preprint arXiv:2509.24828, 2025\nSAP has released its own proprietary generative model SAP Joule, intended for \nvarious generative tasks, including serving as a code assistant for software \nengineers. While Joule is yet not focused on SAP-specific ABAP code generation, it", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24828&hl=en&sa=X&d=3752269403016204218&ei=54UBaeShOrmAieoPq7Lh4A8&scisig=ABGrvjLpXYT2r5xqlsKkyCoj-yKi&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Bridging Developer Instructions and Code Completion Through Instruction-Aware Fill-in-the-Middle Paradigm", "first_label": ["Code"], "second_label": ["Generation"], "data": "Z Sun, C Yang, C Peng, P Gao, X Du, L Li, D Lo- arXiv preprint arXiv:2509.24637, 2025\nLarge Language Models (LLMs) have significantly advanced code completion, yet \nthey often fail when the developer's intent is underspecified in the code context. To \naddress this, developers usually add natural language instructions (eg, comments)", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24637&hl=en&sa=X&d=17305794744039020422&ei=54UBaeShOrmAieoPq7Lh4A8&scisig=ABGrvjIXtniY6prk7AuLk4Car0zn&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "CodeChemist: Functional Knowledge Transfer for Low-Resource Code Generation via Test-Time Scaling", "first_label": ["Code", "Software Testing"], "second_label": ["Generation"], "data": "K Wang, T Li, X Zhang, A Liu, X Liu, Z Liu, Z Zhang- arXiv preprint arXiv, 2025\nCode Large Language Models (CodeLLMs) are increasingly used in code \ngeneration tasks across a wide range of applications. However, their performance is \noften inconsistent across different programming languages (PLs), with low-resource", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.00501&hl=en&sa=X&d=13774139849002505440&ei=54UBaeShOrmAieoPq7Lh4A8&scisig=ABGrvjIZgYctrFpkfTmzGsuF18nV&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Fortifying LLM-Based Code Generation with Graph-Based Reasoning on Secure Coding Practices", "first_label": ["LLM", "Code"], "second_label": ["Generation", "Reasoning", "Graph"], "data": "R Patir, K Guo, H Cai, H Hu- arXiv preprint arXiv:2510.09682, 2025\nThe code generation capabilities of Large Language Models (LLMs) have \ntransformed the field of software development. However, this advancement also \npresents significant security challenges, as LLM-generated code often contains\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.09682&hl=en&sa=X&d=6457581180391498391&ei=54UBaeShOrmAieoPq7Lh4A8&scisig=ABGrvjJKh0qvAQhEQtaEmOGqxxp8&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Q Wei, T Yang, Y Wang, X Li, L Li, Z Yin, Y Zhan, T Holz- arXiv preprint arXiv, 2025\nLarge Language Model (LLM) agents use memory to learn from past interactions, \nenabling autonomous planning and decision-making in complex environments. \nHowever, this reliance on memory introduces a critical security risk: an adversary can", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02373%3F&hl=en&sa=X&d=4598414696562770679&ei=54UBaZXrKoGpieoP_8jXuAM&scisig=ABGrvjLcKUFODXFVJs9Ve_rH2C-9&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Defender to Devil? Unintended Risk Interactions Induced by LLM Defenses", "first_label": ["LLM"], "second_label": [], "data": "X Meng, T Cong, L Wang, W Chen, Z Li, S Guo- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have shown remarkable performance across \nvarious applications, but their deployment in sensitive domains raises significant \nconcerns. To mitigate these risks, numerous defense strategies have been proposed", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07968&hl=en&sa=X&d=16628375445005170696&ei=54UBaZXrKoGpieoP_8jXuAM&scisig=ABGrvjJFN6fFD2JlXKrvW9Fj6lWu&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Defeating Cerberus: Concept-Guided Privacy-Leakage Mitigation in Multimodal Language Models", "first_label": ["LLM"], "second_label": [], "data": "B Zhang, IE Akkus, R Chen, A Dethise, K Satzke- arXiv preprint arXiv, 2025\nMultimodal large language models (MLLMs) have demonstrated remarkable \ncapabilities in processing and reasoning over diverse modalities, but their advanced \nabilities also raise significant privacy concerns, particularly regarding Personally", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25525%3F&hl=en&sa=X&d=188731358198544290&ei=54UBaZXrKoGpieoP_8jXuAM&scisig=ABGrvjIwjkFghofBSEaOxZSxk382&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "HarmRLVR: Weaponizing Verifiable Rewards for Harmful LLM Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Liu, L Li, X Wang, J Shao- arXiv preprint arXiv:2510.15499, 2025\nRecent advancements in Reinforcement Learning with Verifiable Rewards (RLVR) \nhave gained significant attention due to their objective and verifiable reward signals, \ndemonstrating strong performance in reasoning and code generation tasks", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15499&hl=en&sa=X&d=3684055427722867634&ei=54UBaZXrKoGpieoP_8jXuAM&scisig=ABGrvjIQtg1gf4x__eiLyp1jaShs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Proactive defense against LLM Jailbreak", "first_label": ["LLM"], "second_label": [], "data": "W Zhao, J Peng, D Ben-Levi, Z Yu, J Yang- arXiv preprint arXiv:2510.05052, 2025\nThe proliferation of powerful large language models (LLMs) has necessitated robust \nsafety alignment, yet these models remain vulnerable to evolving adversarial attacks, \nincluding multi-turn jailbreaks that iteratively search for successful queries. Current", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05052&hl=en&sa=X&d=12643963361954479351&ei=54UBaZXrKoGpieoP_8jXuAM&scisig=ABGrvjITm70eJQ3DAJ41GbIUFyZv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Fewer Weights, More Problems: A Practical Attack on LLM Pruning", "first_label": ["LLM"], "second_label": [], "data": "K Egashira, R Staab, T Gloaguen, M Vero, M Vechev- arXiv preprint arXiv, 2025\nModel pruning, ie, removing a subset of model weights, has become a prominent \napproach to reducing the memory footprint of large language models (LLMs) during \ninference. Notably, popular inference engines, such as vLLM, enable users to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07985%3F&hl=en&sa=X&d=15877205037372109377&ei=54UBaZXrKoGpieoP_8jXuAM&scisig=ABGrvjLc2zMGjcFTGp-_8sfDhRmv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Microsaccade-Inspired Probing: Positional Encoding Perturbations Reveal LLM Misbehaviours", "first_label": ["LLM"], "second_label": [], "data": "R Melo, R Abreu, CS Pasareanu- arXiv preprint arXiv:2510.01288, 2025\nWe draw inspiration from microsaccades, tiny involuntary eye movements that reveal \nhidden dynamics of human perception, to propose an analogous probing method for \nlarge language models (LLMs). Just as microsaccades expose subtle but informative", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01288&hl=en&sa=X&d=4079834350174690212&ei=54UBaZXrKoGpieoP_8jXuAM&scisig=ABGrvjJMtJXAVeeF7NG9Bep4U4CZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "first_label": ["LLM"], "second_label": ["Agent"], "data": "VK Bonagiri, P Kumaragurum, K Nguyen, B Plaut- arXiv preprint arXiv:2510.16492, 2025\nAs Large Language Model (LLM) agents increasingly operate in complex \nenvironments with real-world consequences, their safety becomes critical. While \nuncertainty quantification is well-studied for single-turn tasks, multi-turn agentic", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16492&hl=en&sa=X&d=12122099661687534348&ei=54UBaZXrKoGpieoP_8jXuAM&scisig=ABGrvjI4CtI_SmXhnMCPP-z7iPl7&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM Unlearning Under the Microscope: A Full-Stack View on Methods and Metrics", "first_label": ["LLM"], "second_label": [], "data": "C Fan, C Wang, Y Huang, S Pal, S Liu- arXiv preprint arXiv:2510.07626, 2025\nMachine unlearning for large language models (LLMs) aims to remove undesired \ndata, knowledge, and behaviors (eg, for safety, privacy, or copyright) while \npreserving useful model capabilities. Despite rapid progress over the past two years", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07626%3F&hl=en&sa=X&d=2219175947074663426&ei=54UBaZXrKoGpieoP_8jXuAM&scisig=ABGrvjJT5bdpnV9SaCOVVwX2gtdv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Demystifying the Roles of LLM Layers in Retrieval, Knowledge, and Reasoning", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "X Song, K Wang, PX Li, L Yin, S Liu- arXiv preprint arXiv:2510.02091, 2025\nRecent studies suggest that the deeper layers of Large Language Models (LLMs) \ncontribute little to representation learning and can often be removed without \nsignificant performance loss. However, such claims are typically drawn from narrow\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02091%3F&hl=en&sa=X&d=1937934351809912348&ei=54UBaZXrKoGpieoP_8jXuAM&scisig=ABGrvjIcqjlNfwqLU3ZuXogdd9E9&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Closing the Feedback Loop in Text2Vis: Refining Visualization with Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "S Shi, T Ren, G Zhu, G Feng, J Hu- Proceedings of the 33rd ACM International, 2025\nText-to-Visualization (Text2Vis) generates data visualizations directly from natural \nlanguage queries, democratizing access to data insights. Early Text2Vis efforts, \nprimarily relying on rule-based systems and machine learning models, struggled to \nhandle semantically intricate queries. The advent of large language models (LLMs) \nallows for better generalization in generating visualization code. However, LLM-\nbased approaches have mainly focused on textual or code-level optimizations\nCites: Automated repair of programs from large language models. In", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3746027.3755862&hl=en&sa=X&d=17886266967035108315&ei=5oUBaYf-EbeO6rQPiqDbmAc&scisig=ABGrvjJRGEk6A98xJd-bvuj37beJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
{"title": "Chimera: Transparent and High-Performance ISAX Heterogeneous Computing via Binary Rewriting", "first_label": [], "second_label": [], "data": "J He, Q Pan, R Zhao, J Qi, K Liang, J Xu, Z Li, Y Wang - 2026\nISAX heterogeneous processors integrate cores that share a common base ISA, with \ncertain cores offering extension ISAs (eg, vector extension) to accelerate \ncomputation. ISAX balances performance and energy efficiency while facilitating the \nreuse of existing software ecosystems. RISC-V, which adopts the ISAX architecture, \nhas gained extensive attention in both industry and academia. Binary translation via \nbinary rewriting enables transparent ISAX heterogeneous computing by translating\nCites: Binary Rewriting without Control Flow Recovery\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://eurosys26p57.github.io/Chimerapaper/Eurosys2026Chimera.pdf&hl=en&sa=X&d=10395665859674281648&ei=5oUBaYf-EbeO6rQPiqDbmAc&scisig=ABGrvjIjKudm3MrBVVWFogZWBsZJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
