{"title": "Training Language Models to Generate Quality Code with Program Analysis Feedback", "first_label": ["LLM", "Code"], "second_label": [], "data": "F Yao, Z Wang, L Liu, J Cui, L Zhong, X Fu, H Mai\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode generation with large language models (LLMs), often termed vibe coding, is \nincreasingly adopted in production but fails to ensure code quality, particularly in \nsecurity (eg, SQL injection vulnerabilities) and maintainability (eg, missing type\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22704&hl=en&sa=X&d=13720297852295427429&ei=0hpTaOizIKalieoP6s6swAY&scisig=AAZF9b9qU1hJff-ona5ynwmi0w3O&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Your Agent Can Defend Itself against Backdoor Attacks", "first_label": [], "second_label": ["Agent"], "data": "L Changjiang, L Jiacheng, C Bochuan, C Jinghui\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite their growing adoption across domains, large language model (LLM)-\npowered agents face significant security risks from backdoor attacks during training \nand fine-tuning. These compromised agents can subsequently be manipulated to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08336&hl=en&sa=X&d=9281612337423238890&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b8EnIakTDvZQGsyv1duPVA5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Adversarial Preference Learning for Robust LLM Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Wang, P Wang, C Xi, B Tang, J Zhu, W Wei, C Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern language models often rely on Reinforcement Learning from Human \nFeedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to \nadversarial attacks due to three key limitations:(1) the inefficiency and high cost of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24369%3F&hl=en&sa=X&d=11526575995055803369&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b_ilBi9AMSJoKPXxHc_hWg5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Yuan, Y Xu, J Shi, P Zhou, L Sun\\xc2\\xa0- arXiv preprint arXiv:2505.23561, 2025\nModel merging for Large Language Models (LLMs) directly fuses the parameters of \ndifferent models finetuned on various tasks, creating a unified model for multi-domain \ntasks. However, due to potential vulnerabilities in models available on open-source\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23561&hl=en&sa=X&d=6617189016454156514&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b-hKaNf3ql6GqPXtJeaxsCC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based Backdoor Attacks for Jailbreaking Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "J Kong, H Fang, X Yang, K Gao, B Chen, ST Xia\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSupervised fine-tuning (SFT) aligns large language models (LLMs) with human \nintent by training them on labeled task-specific data. Recent studies have shown that \nmalicious attackers can inject backdoors into these models by embedding triggers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17601%3F&hl=en&sa=X&d=14932585774719166007&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b-bRcbQ7r2VSTXuEVUTZE69&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge", "first_label": ["LLM"], "second_label": [], "data": "S Li, C Xu, J Wang, X Gong, C Chen, J Zhang, J Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable intelligence across \nvarious tasks, which has inspired the development and widespread adoption of LLM-\nas-a-Judge systems for automated model testing, such as red teaming and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09443&hl=en&sa=X&d=2052322274134661445&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b9u9cyhYi06xXXt37CLZpdh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Syntactic paraphrase-based synthetic data generation for backdoor attacks against Chinese language models", "first_label": ["LLM"], "second_label": ["Generation"], "data": "M Hu, Y Yang, D Pan, Z Guo, L Xiao, D Lin, S Zhao\\xc2\\xa0- Information Fusion, 2025\nAbstract Language Models (LMs) have shown significant advancements in various \nNatural Language Processing (NLP) tasks. However, recent studies indicate that \nLMs are particularly susceptible to malicious backdoor attacks, where attackers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S156625352500449X&hl=en&sa=X&d=11939540759867308872&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b_omHEFDqgnSwVne_pfKwnY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Lifelong Safety Alignment for Language Models", "first_label": ["LLM"], "second_label": [], "data": "H Wang, Z Qin, Y Zhao, C Du, M Lin, X Wang, T Pang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLMs have made impressive progress, but their growing capabilities also expose \nthem to highly flexible jailbreaking attacks designed to bypass safety alignment. \nWhile many existing defenses focus on known types of attacks, it is more critical to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20259%3F&hl=en&sa=X&d=16834372085988299596&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b9d_59vHSVRWjToyCIlG2f5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "PS Pandey, S Simko, K Pelrine, Z Jin\\xc2\\xa0- arXiv preprint arXiv:2505.16789, 2025\nAs large language models gain popularity, their vulnerability to adversarial attacks \nremains a primary concern. While fine-tuning models on domain-specific datasets is \noften employed to improve model performance, it can introduce vulnerabilities within\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16789%3F&hl=en&sa=X&d=9827187220639785834&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b-hRa3CIybDfceUhaRlecWD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "An Embarrassingly Simple Defense Against LLM Abliteration Attacks", "first_label": ["LLM"], "second_label": [], "data": "HA Shairah, HAAK Hammoud, B Ghanem, G Turkiyyah\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are typically aligned to comply with safety guidelines \nby refusing harmful instructions. A recent attack, termed abliteration, isolates and \nsuppresses the single latent direction most responsible for refusal behavior, enabling\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19056&hl=en&sa=X&d=3737202939224050048&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b8QKV5yRTnfm0WbZVG9RAGO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring", "first_label": ["LLM"], "second_label": [], "data": "Y Li, Q Sheng, Y Yang, X Zhang, J Cao\\xc2\\xa0- arXiv preprint arXiv:2506.09996, 2025\nThough safety alignment has been applied to most large language models (LLMs), \nLLM service providers generally deploy a subsequent moderation as the external \nsafety guardrail in real-world products. Existing moderators mainly practice a\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09996&hl=en&sa=X&d=8967671192696781749&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b-I099JquXawda445fWweEs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Malo in the Code Jungle: Explainable Fault Localization for Decentralized Applications", "first_label": ["Fault Localization", "Code"], "second_label": ["Localization"], "data": "H Zhang, J Wu, Z Wu, Z Chen, D Lin, J Chen, Y Zhou\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDecentralized applications (DApps) have long been sitting ducks for hackers due to \ntheir valuable cryptocurrency assets, exposing them to various security risks. When a \nDApp is attacked, promptly identifying faults is crucial to minimizing financial losses\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11034691/&hl=en&sa=X&d=7651709202352945146&ei=0hpTaJ_6IeWs6rQPkO7OyQk&scisig=AAZF9b8cw1Hmz_K4wN9ajW1PUmQk&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Enhancing vulnerability repair through the extraction and matching of repair patterns", "first_label": ["Vulnerabilities"], "second_label": ["Repair"], "data": "X Cao, J Wang, P Wu\\xc2\\xa0- Journal of Systems and Software, 2025\nThe application of deep learning models in software vulnerability repair is \nincreasingly crucial. However, current deep learning-based vulnerability repair \nmodels primarily rely on implicit learning when generating patches, making it \nchallenging to effectively reuse existing repair patterns for new vulnerabilities. \nAdditionally, while introducing large-scale external data helps leverage historical \nexperience, it often leads to information redundancy and increased computational\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaEmpirical study on synthesis engines for semantics-based program\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225001967&hl=en&sa=X&d=13017805190019539176&ei=0hpTaOe-I72W6rQPs9Oj8A8&scisig=AAZF9b-4HC3uxcHqQKRh9Jh9LlMi&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le", "David Lo - new related research", "1 new citation to articles by Quang-Cuong Bui", "2 new citations to articles by Xin ZHOU", "5 new citations to articles by Abhik Roychoudhury"]}
{"title": "BLOKZ\\xc4\\xb0NC\\xc4\\xb0R TEKNOLOJ\\xc4\\xb0S\\xc4\\xb0 VE AKILLI S\\xc3\\x96ZLE\\xc5\\x9eMELER\\xc4\\xb0N ULUSLARARASI T\\xc4\\xb0CARETTE KULLANILAB\\xc4\\xb0L\\xc4\\xb0RL\\xc4\\xb0\\xc4\\x9e\\xc4\\xb0N\\xc4\\xb0N HUKUK VE EKONOM\\xc4\\xb0 EKSEN\\xc4\\xb0NDE ANAL\\xc4\\xb0Z\\xc4\\xb0", "first_label": [], "second_label": [], "data": "AA KARAYEL\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar?cluster=17024255858295271479&hl=en&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le"]}
{"title": "Mind the Gap: A Readability-Aware Metric for Test Code Complexity", "first_label": ["Code", "Software Testing"], "second_label": [], "data": "WC Ou\\xc3\\xa9draogo, Y Li, X Dang, X Zhou, A Koyuncu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomatically generated unit tests-from search-based tools like EvoSuite or LLMs-\nvary significantly in structure and readability. Yet most evaluations rely on metrics like \nCyclomatic Complexity and Cognitive Complexity, designed for functional code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.06764&hl=en&sa=X&d=8031478776401773975&ei=0hpTaKzhJ6Kr6rQP49vTsAY&scisig=AAZF9b-NjCZivc__tn99Kq7Xgxd6&oi=scholaralrt&hist=ylyK0_8AAAAJ:9162293956065397449:AAZF9b-XLYhOpfmwS_vhRk8lFc-r&html=&pos=0&folt=art", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new articles"]}
{"title": "Beyond Surface Similarity: Evaluating LLM-Based Test Refactorings with Structural and Semantic Awareness", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "WC Ou\\xc3\\xa9draogo, Y Li, X Dang, X Zhou, A Koyuncu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly employed to automatically refactor \nunit tests, aiming to enhance readability, naming, and structural clarity while \npreserving functional behavior. However, evaluating such refactorings remains\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.06767&hl=en&sa=X&d=6563163690120506226&ei=0hpTaKzhJ6Kr6rQP49vTsAY&scisig=AAZF9b9xD9hAdx6dPyiL2w3mENFA&oi=scholaralrt&hist=ylyK0_8AAAAJ:9162293956065397449:AAZF9b-XLYhOpfmwS_vhRk8lFc-r&html=&pos=1&folt=art", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new articles"]}
{"title": "2025 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)| 979-8-3315-2615-3/25/$31.00\\xc2\\xa9 2025 IEEE| DOI: 10.1109\\xc2\\xa0\\xe2\\x80\\xa6", "first_label": ["LLM", "Code"], "second_label": [], "data": "I Adewuyi, S Alamir, I Al Azher, H Alhoori, G An\\xe2\\x80\\xa6\nAuthor Index Page 1 Author Index Adewuyi, Israel 88 Alamir, Salwa 49 Al Azher, Ibrahim \n\\r\\n137 Alhoori, Hamed 137 An, Gabin 17, 120 Arefin, Md Fahim 80 Athale, Mihir 169 \n\\r\\nBabkin, Petr 49 Bartholf, Michael 177 Beger, Claas 128 Bhatele, Abhinav 193 Brunelle\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11028216/&hl=en&sa=X&d=8985289990599930919&ei=0hpTaKiVJs6r6rQPxrLf-As&scisig=AAZF9b9YD7Ag3FCp_aht3SXe7nc2&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A Hybrid Analysis-Based Construction Method for Tainted Control Flow Graphs of Binary Programs", "first_label": ["Static Analysis"], "second_label": ["Graph"], "data": "H Xie, X Li, Z Shen\\xc2\\xa0- 2025 8th World Conference on Computing and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, control flow graphs (CFGs) have gained increasing prominence in \nbinary vulnerability detection due to their comprehensive representation of a \nprogram's execution paths. However, traditional methods for constructing CFGs often \nencounter significant challenges, such as limited precision in static analysis and high \nruntime overhead in dynamic analysis. To address these limitations, this paper \nproposes a novel hybrid approach that combines static taint analysis with dynamic\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAssessing generalizability of codebert\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11028008/&hl=en&sa=X&d=2323627711953533258&ei=0hpTaKKKL6y16rQPzoCEgAc&scisig=AAZF9b911nwzTo2_R_SZDdV7BFt4&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "Code Researcher: Deep Research Agent for Large Systems Code and Commit History", "first_label": ["Code"], "second_label": ["Agent", "Search"], "data": "R Singh, S Joel, AMN Wadhwa\nAbstract Large Language Model (LLM)-based coding agents have shown promising \nresults on coding benchmarks, but their effectiveness on systems code remains \nunderexplored. Due to the size and complexities of systems code, making changes \nto a systems codebase is a daunting task, even for humans. It requires researching \nabout many pieces of context, derived from the large codebase and its massive \ncommit history, before making changes. Inspired by the recent progress on deep\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/Code_Researcher-1.pdf&hl=en&sa=X&d=8745151553672657428&ei=0hpTaJucKe2rieoPk6bG-Qo&scisig=AAZF9b8dlKIL6kyXCmNjlioxJUqV&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "Adaptive header identification and unsupervised clustering strategy for enhanced protocol reverse engineering", "first_label": [], "second_label": [], "data": "M Zhu, C Gu, X Zhang, Q Yuan, M Ju, G Zhang, X Chen\\xc2\\xa0- Expert Systems with\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nProtocol reverse engineering is critical for ensuring network security and \nunderstanding proprietary communication mechanisms. Most traditional network \ntrace-based methods face challenges such as high computational complexity, \nexcessive memory usage, and sensitivity to payload variations. In this paper, we \npropose a method that integrates adaptive message header recognition with \nunsupervised clustering strategies for protocol reverse engineering. Utilizing mean\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBLEEM: Packet Sequence Oriented Fuzzing for Protocol\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S095741742502086X&hl=en&sa=X&d=1649016524055649226&ei=0hpTaJucKe2rieoPk6bG-Qo&scisig=AAZF9b_s7bLi5aGjWRMXbckOPvZC&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "ASC-Hook: Efficient System Call Interception for ARM", "first_label": [], "second_label": [], "data": "Y Shen, M Xie, T Wu, W Zhang, R Wang, G Zhang\\xc2\\xa0- Proceedings of the 26th ACM\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSystem call interception is essential for tools that modify or monitor application \nbehavior. However, current system call interception solutions on ARM platforms still \nface challenges related to performance and completeness. This paper introduces \nASC-Hook, an efficient and comprehensive binary rewriting framework specifically \ndesigned for intercepting system calls on ARM architectures. ASC-Hook tackles two \ncritical challenges: the misalignment of the target address caused by directly\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBinary Rewriting without Control Flow Recovery\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3735452.3735524&hl=en&sa=X&d=2744921428114210080&ei=0hpTaJucKe2rieoPk6bG-Qo&scisig=AAZF9b-XmZhXSWPcPOmcbaggfq-u&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "Isolating Noisy Labelled Test Cases in Human-in-the-Loop Oracle Learning", "first_label": ["Software Testing"], "second_label": [], "data": "CG Kapugama\\xc2\\xa0- 2025 International Research Conference on Smart\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIncorrectly labelled test cases can adversely affect the training process of human-in-\nthe-loop oracle learning techniques. This paper introduces ISONOISE, a technique \ndesigned to identify such mislabelled test cases introduced during human-in-the-\nloop oracle learning. This technique can be applied to programs taking numeric \ninputs. Given a compromised automatic test oracle and its training test suite, \nISONOISE first isolates the test cases suspected of being mislabelled. This task is\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSemantic Program Repair Using a Reference Implementation\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11030983/&hl=en&sa=X&d=4802306526262104356&ei=0hpTaJucKe2rieoPk6bG-Qo&scisig=AAZF9b_ZAfdCbgDd2dTtMKH4zIQr&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "RIMFuzz: real-time impact-aware mutation for library API fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "X Wang, L Zhao\\xc2\\xa0- Journal of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs libraries merely expose APIs to developers rather than directly handling user \ninput, applying fuzzing to libraries requires fuzz drivers to help process fuzzer-\nprovided input and invoke APIs. To reduce manual effort and avoid reliance on\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00050-1&hl=en&sa=X&d=11566396351270247841&ei=0hpTaNqsLNGM6rQPs-LTyAw&scisig=AAZF9b9NzGapAGT-Gt26V3wejXNn&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Visualization Task Taxonomy to Understand the Fuzzing Internals", "first_label": ["Fuzzing"], "second_label": [], "data": "S Kummita, M Miao, E Bodden, S Wei\\xc2\\xa0- ACM Transactions on Software Engineering\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGreybox fuzzing is used extensively in research and practice. There are umpteen \npublications that improve greybox fuzzing. However, to what extent do these \nimprovements affect the internal components or internals of a given fuzzer is not yet\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3718346&hl=en&sa=X&d=6310038100822609560&ei=cttQaLfLJte5ieoP1rfqmQU&scisig=AAZF9b_Ue_jmzHRI425oDGHolQub&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "KRAKEN: Program-Adaptive Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A ZHOU, H HUANG, C ZHANG - 2025\nDespite numerous advances, most existing fuzzers still require more than 24 hours to \nthoroughly test the target programs to achieve satisfactory code coverage or bug \ndetection results [7, 32, 42, 64]. Recently, as cloud-based computing and multicore\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://seviezhou.github.io/files/kraken.pdf&hl=en&sa=X&d=6944396394299119143&ei=cttQaLfLJte5ieoP1rfqmQU&scisig=AAZF9b9QILhkfV1b1x87AW8NkoEo&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Fuzzing Graph Database Applications with Graph Transformations", "first_label": ["Fuzzing"], "second_label": ["Graph"], "data": "S Dumbrava, MWM Oudemans, B Kulahcioglu Ozkan\\xc2\\xa0- International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGraph databases have surged in popularity, and applications increasingly employ \nthem to store and retrieve interconnected data. However, testing graph database-\nbacked applications has distinctive challenges. Due to the sheer dimension of the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-94706-3_7&hl=en&sa=X&d=17411223200189550748&ei=cttQaLfLJte5ieoP1rfqmQU&scisig=AAZF9b9hC_iu-fBtu3ntJrcVfGlm&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Leveraging activation and optimisation layers as dynamic strategies in the multi-task fuzzing scheme", "first_label": ["Fuzzing"], "second_label": [], "data": "S Bamohabbat Chafjiri, P Legg, MA Tsompanas\\xe2\\x80\\xa6 - 2025\nFuzzing is a common technique for identifying vulnerabilities in software. Recent \napproaches, like She et al.'s Multi-Task Fuzzing (MTFuzz), use neural networks to \nimprove fuzzing efficiency. However, key elements like network architecture and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1016/j.csi.2025.104011&hl=en&sa=X&d=18210490462320417689&ei=cttQaLfLJte5ieoP1rfqmQU&scisig=AAZF9b-SniAFgKPoPY_eeSgA0SFX&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift", "first_label": ["LLM"], "second_label": [], "data": "S Liang, J Liang, T Pang, C Du, A Liu, M Zhu, X Cao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInstruction tuning enhances large vision-language models (LVLMs) but increases \ntheir vulnerability to backdoor attacks due to their open design. Unlike prior studies in \nstatic settings, this paper explores backdoor attacks in LVLM instruction tuning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.pdf&hl=en&sa=X&d=5142527777954789704&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b_Zz7b9xsyiBVRqo7nDX3YO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, M Dras, U Naseem\\xc2\\xa0- arXiv preprint arXiv:2506.02442, 2025\nThis paper presents a systematic evaluation of Large Language Models'(LLMs) \nbehavior on long-tail distributed (encrypted) texts and their safety implications. We \nintroduce a two-dimensional framework for assessing LLM safety:(1) instruction\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02442&hl=en&sa=X&d=15102350404536711280&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b_4gGVOvmiHUrKGvn2E4Vhh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Evaluatiing the efficacy of LLM Safety Solutions: The Palit Benchmark Dataset", "first_label": ["LLM"], "second_label": [], "data": "S Palit, D Woods\\xc2\\xa0- arXiv preprint arXiv:2505.13028, 2025\nLarge Language Models (LLMs) are increasingly integrated into critical systems in \nindustries like healthcare and finance. Users can often submit queries to LLM-\nenabled chatbots, some of which can enrich responses with information retrieved\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13028%3F&hl=en&sa=X&d=1273460049730580919&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b9ByON4eaZyjRTpM1-cA_zU&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents", "first_label": ["LLM", "Code"], "second_label": ["Agent", "Reasoning"], "data": "K Hariharan, U Girit, A Wang, J Andreas\\xc2\\xa0- arXiv preprint arXiv:2506.00172, 2025\nBenchmarks for large language models (LLMs) have predominantly assessed short-\nhorizon, localized reasoning. Existing long-horizon suites (eg SWE-bench) rely on \nmanually curated issues, so expanding or tuning difficulty demands expensive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00172&hl=en&sa=X&d=7723120566071680437&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b-MEatAoZUO5Dw1f9NQmtaH&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Ip leakage attacks targeting llm-based multi-agent systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Wang, W Wang, S Wang, Z Li, Z Ji, Z Lyu, D Wu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Large Language Models (LLMs) has led to the \nemergence of Multi-Agent Systems (MAS) to perform complex tasks through \ncollaboration. However, the intricate nature of MAS, including their architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12442&hl=en&sa=X&d=8825331941370095164&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b_j6hKF2Zy8dNMOx-tobM6E&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "first_label": ["LLM"], "second_label": [], "data": "G Chen, F Song, Z Zhao, X Jia, Y Liu, Y Qiao, W Zhang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreak attacks to Large audio-language models (LALMs) are studied recently, but \nthey achieve suboptimal effectiveness, applicability, and practicability, particularly, \nassuming that the adversary can fully manipulate user prompts. In this work, we first\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14103&hl=en&sa=X&d=12355582258955555442&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b84twuHlVXU1hPFciKO3AfT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Securing AI Agents with Information-Flow Control", "first_label": [], "second_label": ["Agent"], "data": "M Costa, B K\\xc3\\xb6pf, A Kolluri, A Paverd, M Russinovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI agents become increasingly autonomous and capable, ensuring their security \nagainst vulnerabilities such as prompt injection becomes critical. This paper explores \nthe use of information-flow control (IFC) to provide security guarantees for AI agents\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23643%3F&hl=en&sa=X&d=4534448032257376326&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b-ruPZ7fbYUs0K6HirRZr2z&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Words reveal wants: How well can simple LLM-based AI agents replicate people's choices based on their social media posts", "first_label": ["LLM"], "second_label": ["Agent"], "data": "S Goethals, J Luther, S Matz\\xc2\\xa0- Adjunct Proceedings of the 33rd ACM Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs artificial intelligence systems take on increasingly agentic roles, they begin \nmaking decisions on behalf of users rather than merely supporting them. \nConsequently, it becomes crucial to understand how closely these systems can\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3708319.3733689&hl=en&sa=X&d=2217390685673034747&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b9SWHaYFGLzkiYnbHT29Ug6&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Shots to Stories: LLM-Assisted Video Editing with Unified Language Representations", "first_label": ["LLM"], "second_label": [], "data": "Y Li, H Xu, F Tian\\xc2\\xa0- arXiv preprint arXiv:2505.12237, 2025\nLarge Language Models (LLMs) and Vision-Language Models (VLMs) have \ndemonstrated remarkable reasoning and generalization capabilities in video \nunderstanding; however, their application in video editing remains largely\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12237&hl=en&sa=X&d=10505763597250854428&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b90gQPI6R4RwX9k19MeWwCR&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents", "first_label": [], "second_label": ["Agent", "Reasoning"], "data": "X Yu, B Peng, R Xu, M Galley, H Cheng, S Nath, J Gao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent progress in reasoning with large language models (LLMs), such as \nDeepSeek-R1, demonstrates impressive capabilities in domains like mathematics \nand coding, by exhibiting complex cognitive behaviors such as verification, goal\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00320&hl=en&sa=X&d=5278749394870424961&ei=cttQaLvyLay16rQP8djq6A8&scisig=AAZF9b9b-0jt4alWRaYfXuIUsA9R&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Multi-source cross-domain vulnerability detection based on code pre-trained model", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "Y Cao, Y Dong\\xc2\\xa0- Information and Software Technology, 2025\nContext: In recent years, deep learning-based vulnerability detection methods have \nachieved significant success. These methods predict vulnerabilities by automatically \nlearning patterns from code annotated with vulnerability information. However\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S095058492500103X&hl=en&sa=X&d=15955544814733929240&ei=cttQaPLeH9SWieoP89D1uAI&scisig=AAZF9b81Qmv0jwO9frlyKQ4ruxkr&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Zheng, X Qian, H Zhou, S Yang, Y He, S Jana\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models (LMs) show promise for vulnerability detection but struggle with \nlong, real-world code due to sparse and uncertain vulnerability locations. These \nissues, exacerbated by token limits, often cause models to miss vulnerability-related\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17460&hl=en&sa=X&d=9334848497739178959&ei=cttQaJ-yHs6r6rQP0M7u0Ao&scisig=AAZF9b_EDz61GJXVBfE-c2mGro5g&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Debugging and Help-Seeking With Chatbots in CS1", "first_label": ["Bug"], "second_label": [], "data": "S Yang - 2025\nFor many beginner programmers, encountering errors in code can be frustrating and \ndisheartening\\xe2\\x80\\x94leading some to questions their belonging in computer science (CS). \nIn these moments, timely debugging help is essential to sustain motivation and foster \nlearning. While students have traditionally turned to peers or teaching assistants for \nguidance, many now seek debugging support from conversational Large Language \nModels (LLMs). These chatbots offer promise in providing immediate help, but their\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/44ea4f2adeb64e8bf54209dfbae38a5c/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=en&sa=X&d=17651482257810592070&ei=cttQaK2hJau26rQPmILk4AI&scisig=AAZF9b8bwrhTgzrfX4-sFKJVqHC1&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": "GAL-KARS: Exploiting LLMs for Graph Augmentation in Knowledge-Aware Recommender Systems", "first_label": ["LLM"], "second_label": ["Exploit", "Graph"], "data": "G Spillo, C Musto, M Mannavola, M de Gemmis, P Lops\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 33rd\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn this paper, we propose a recommendation model that exploits a graph \naugmentation technique based on Large Language Models (LLMs) to enrich the \ninformation encoded in its underlying Knowledge Graph (KG). Our work relies on the \nassumption that the triples encoded in a KG can often be noisy or incomplete, and \nthis may lead to sub-optimal modeling of both the characteristics of items and the \nusers' preferences. In this setting, graph augmentation can be a suitable solution to\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLessLeak-Bench: A First Investigation of Data Leakage in LLMs\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3699682.3728342&hl=en&sa=X&d=1949338591660211917&ei=cttQaKS7LO2rieoPnJq6oQ8&scisig=AAZF9b_8SRhBfjt4RVj4nSQqrZnI&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "From Theory to Practice: Code Generation Using LLMs for CAPEC and CWE Frameworks", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "M Shahzad, J Wilson, I Al Azher, H Alhoori, M Rahimi\\xc2\\xa0- 2025 IEEE/ACM International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe increasing complexity and volume of software systems have heightened the \nimportance of identifying and mitigating security vulnerabilities. The existing software \nvulnerability datasets frequently fall short in providing comprehensive, detailed code \nsnippets explicitly linked to specific vulnerability descriptions, reducing their utility for \nadvanced research and hindering efforts to develop a deeper understanding of \nsecurity vulnerabilities. To address this challenge, we present a novel dataset that\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection and repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/llm4code/2025/261500a137/27uerFwNhrq&hl=en&sa=X&d=13790469415771046125&ei=cttQaKS7LO2rieoPnJq6oQ8&scisig=AAZF9b-PmjBmccmRY4bcIsgYoBhC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "An LLM Agent for Functional Bug Detection in Network Protocols", "first_label": ["LLM", "Bug"], "second_label": ["Detection", "Agent"], "data": "M Zheng, C Wang, X Liu, J Guo, S Feng, X Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.00714, 2025\nFunctional correctness is critical for ensuring the reliability and security of network \nprotocol implementations. Functional bugs, instances where implementations \ndiverge from behaviors specified in RFC documents, can lead to severe\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00714&hl=en&sa=X&d=14025741833580725532&ei=cttQaIa6L_uvieoPlKmY8Ag&scisig=AAZF9b8vkBixnPr2fRq2ZYFDK47O&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Leveraging LLM Enhanced Commit Messages to Improve Machine Learning Based Test Case Prioritization", "first_label": ["LLM", "Commit Message", "Software Testing"], "second_label": [], "data": "Y Mahmoud, A Azim, R Liscano, K Smith, YK Chang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 21st\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn the rapidly evolving landscape of software development, software testing is critical \nfor maintaining code quality and reducing defects. Effective test case prioritization \nemploys techniques to identify defects early and ensure software quality. New\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3727582.3728681&hl=en&sa=X&d=2338002588478877175&ei=cttQaIa6L_uvieoPlKmY8Ag&scisig=AAZF9b9ZZdQSJWoVODzmMybSzj_D&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "End-User Customization of Trigger-Action Rules Through Fine-Tuned LLMs", "first_label": ["LLM"], "second_label": [], "data": "G Cimino, V Deufemia\\xc2\\xa0- International Symposium on End User Development, 2025\nAbstract While Trigger-Action Platforms (TAPs) provide an effective solution for end-\nusers to automate interactions between smart devices and online services through \ncustomizable rules, their flexibility is often limited by restricted access to source code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-95452-8_2&hl=en&sa=X&d=2148692169908663268&ei=cttQaMGjIqalieoPsZriwAs&scisig=AAZF9b_Mv7kTvNKKktKs_aihUb5T&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "SURVIVING GENERATIVE AI: TEMPORAL TRAJECTORY OF RESILIENCE IN STACK OVERFLOW AND GITHUB", "first_label": [], "second_label": [], "data": "D Scholtz, A Griva, K Conboy\\xc2\\xa0- LMDE 2025 CONFERENCE\nPlatforms such as Stack Overflow and GitHub serve as the lifeblood for global \nknowledge exchange for software development, yet they face profound challenges \nfrom emerging technologies like Generative AI (GAI) that accelerate knowledge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://lmde.net/images/BoA_LMDE_2025.pdf%23page%3D311&hl=en&sa=X&d=10770644147813442473&ei=cttQaMGjIqalieoPsZriwAs&scisig=AAZF9b_lXpdds-L9OhASwo3GMSLr&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Access Control Modeling and Validation for Ethereum Smart Contracts", "first_label": ["Smart Contracts", "Ethereum"], "second_label": [], "data": "I Achour, H Idoudi, S Ayed\\xc2\\xa0- Concurrency and Computation: Practice and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSmart contracts are self\\xe2\\x80\\x90executing programs that operate on a blockchain network. \nThey are designed to automate transaction execution without the need for \nintermediaries. Once deployed in the blockchain network, smart contracts cannot be\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.70108&hl=en&sa=X&d=6638502576514252848&ei=cttQaMGjIqalieoPsZriwAs&scisig=AAZF9b9ZwDFro6wpA1J_m2o9u6lg&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A Neuro-Symbolic Artificial Intelligence and Zero-Knowledge Blockchain Framework for a Patient-Owned Digital-Twin Marketplace in US Value-Based Care.", "first_label": ["Blockchain"], "second_label": [], "data": "YT Adeshina\nAs the US healthcare system shifts toward value-based care, there is a growing need \nfor patient-centered technologies that ensure data ownership, interoperability, and \ntrust. This paper proposes a novel framework integrating neuro-symbolic artificial \nintelligence (AI) and zero-knowledge (ZK) blockchain to enable a secure, scalable, \nand ethically grounded digital-twin marketplace for patient data. The goal is to \nempower individuals to own and control their health digital twins\\xe2\\x80\\x94comprehensive\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSurveying neuro-symbolic approaches for reliable artificial\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Taofeek-Yusuff/publication/392626529_A_Neuro-Symbolic_Artificial_Intelligence_and_Zero-Knowledge_Blockchain_Framework_for_a_Patient-Owned_Digital-Twin_Marketplace_in_US_Value-Based_Care/links/684b1bc4bc28f5215e941f0f/A-Neuro-Symbolic-Artificial-Intelligence-and-Zero-Knowledge-Blockchain-Framework-for-a-Patient-Owned-Digital-Twin-Marketplace-in-US-Value-Based-Care.pdf&hl=en&sa=X&d=4356628560497418595&ei=cttQaNH-IKKr6rQPx5XhkQQ&scisig=AAZF9b9LRdSlHcVvibowhC6tkQpU&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["1 new citation to articles by Hong Jin Kang"]}
