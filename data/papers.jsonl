{"title": "Context-aware prompting for LLM-based program repair", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "Y Li, M Cai, J Chen, Y Xu, L Huang, J Li\\xc2\\xa0- Automated Software Engineering, 2025\nAutomated program repair (APR) plays a crucial role in ensuring the quality of \nsoftware code, as manual bug-fixing is extremely time-consuming and labor-\nintensive. Traditional APR tools (eg, template-based approaches) face the challenge \nof generalizing to different bug patterns, while deep learning (DL)-based methods \nheavily rely on training datasets and struggle to fix unseen bugs. Recently, large \nlanguage models (LLMs) have shown great potential in APR due to their ability to\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaS3: Syntax- and Semantic-Guided Repair Synthesis via\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00512-w&hl=en&sa=X&d=3912460072881824433&ei=hKoGaIeTF4WlieoPqbWj8Q4&scisig=AFWwaeYuO0eROorwpxEZoeeWt8hd&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AFWwaebZb4G2z_XAHxtUtGUOv8go&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "uBSaaS: A Unified Blockchain Service as a Service Framework for Streamlined Blockchain Services Integration", "first_label": [], "second_label": [], "data": "HTT Pham, F Jiang, L Pan, A Bonti, M Abdelrazek\nBlockchain application development remains complex and costly due to specialized \ncryptographic requirements and platform-specific protocols. Existing solutions often \nprovide only isolated services, hindering cross-chain interoperability and limiting \nbroader adoption. This paper addresses these gaps by introducing SChare, a \nplatform founded on a unified Blockchain Service as a Service (uBSaaS) framework \nthat abstracts blockchain-intensive tasks into microservices. This architecture\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.scitepress.org/Papers/2025/133358/133358.pdf&hl=en&sa=X&d=11579980666615008460&ei=hKoGaIeTF4WlieoPqbWj8Q4&scisig=AFWwaea30P44Neopy7wk_SlWNcVO&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AFWwaebZb4G2z_XAHxtUtGUOv8go&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "Leveraging Next-Gen E-Voting Using Proof-of-Stake (PoS) for Secure Elections", "first_label": [], "second_label": [], "data": "M Ramaswamy, M Gowthami\\xc2\\xa0- \\xe2\\x80\\xa6\\xc2\\xa0and Development for Sustainable Innovation and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nTraditional voting systems struggle with scalability, security, and transparency, \nmaking blockchain a promising solution due to its decentralization and immutability. \nHowever, Proof-of-Work (PoW) is inefficient for large-scale voting due to high energy \nconsumption. This project leverages Proof-of-Stake (PoS) as an energy-efficient \nalternative, ensuring security and scalability. It maintains voter confidentiality, \nprevents duplicate voting through a one-vote token mechanism, and uses a staked\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.igi-global.com/chapter/leveraging-next-gen-e-voting-using-proof-of-stake-pos-for-secure-elections/376156&hl=en&sa=X&d=10187790774824683082&ei=hKoGaIeTF4WlieoPqbWj8Q4&scisig=AFWwaeZIbEbQ6Vv0deYPlwQ0JsUU&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AFWwaebZb4G2z_XAHxtUtGUOv8go&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "On Simulation-Guided LLM-based Code Generation for Safe Autonomous Driving Software", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "A Nouri, J Andersson, KDJ Hornig, Z Fei, E Knabe\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomated Driving System (ADS) is a safety-critical software system responsible for \nthe interpretation of the vehicle's environment and making decisions accordingly. \nThe unbounded complexity of the driving context, including unforeseeable events\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.02141&hl=en&sa=X&d=11030603002805149689&ei=hKoGaL_fFfOy6rQP1tr_uA8&scisig=AFWwaeYUmC_6TmFAo66Flf543eb1&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AFWwaeYwgMeQSPpxCfDXmGy5aE3n&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Smart Contract Vulnerability Detection Using Large Language Models and Graph Structural Analysis.", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection"], "data": "RY Choi, Y Song, M Jang, T Kim, J Ahn, DH Im\\xc2\\xa0- Computers, Materials & Continua, 2025\nSmart contracts are self-executing programs on blockchains that manage complex \nbusiness logic with transparency and integrity. However, their immutability after \ndeployment makes programming errors particularly critical, as such errors can be\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://search.ebscohost.com/login.aspx%3Fdirect%3Dtrue%26profile%3Dehost%26scope%3Dsite%26authtype%3Dcrawler%26jrnl%3D15462218%26AN%3D184143386%26h%3DgBiCt2Vo1kRt%252FCK1%252BSWWfB4p5FKnCdgFxhLvS20Pk1p9Cza3sO62Nc8OZpQoxEZ8SeN%252BTYixYvZr7BkNZzwhoA%253D%253D%26crl%3Dc&hl=en&sa=X&d=4504820058459498391&ei=hKoGaL_fFfOy6rQP1tr_uA8&scisig=AFWwaebpASe2BZfIWxlYp5PyJgmc&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AFWwaeYwgMeQSPpxCfDXmGy5aE3n&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "Compromising LLM Driven Embodied Agents with Contextual Backdoor Attacks", "first_label": ["LLM"], "second_label": ["Agent"], "data": "A Liu, Y Zhou, X Liu, T Zhang, S Liang, J Wang, Y Pu\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have transformed the development of embodied \nintelligence. By providing a few contextual demonstrations (such as rationales and \nsolution examples) developers can utilize the extensive internal knowledge of LLMs\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10943262/&hl=en&sa=X&d=12719951651069852610&ei=hKoGaNDGG7GyieoPmoPVSA&scisig=AFWwaeZpVIpHx7agj5Gt0-h7Qtt8&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "White-box structure analysis of pre-trained language models of code for effective attacking", "first_label": ["Code"], "second_label": [], "data": "C Liu, X Ren, Y Xue\\xc2\\xa0- Information and Software Technology, 2025\nContext: Pre-trained language models of code (PLMs-C for short) have dramatically \nimproved the state-of-the-art on various programming language processing tasks. \nObjective: Due to these well-performed models being easily disturbed by slight\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925000692&hl=en&sa=X&d=10831422306869385650&ei=hKoGaNDGG7GyieoPmoPVSA&scisig=AFWwaeaYut7czcHGT0TluKBywRaC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "L4: Diagnosing large-scale llm training failures via automated log analysis", "first_label": ["LLM"], "second_label": [], "data": "Z Jiang, J Huang, Z Chen, Y Li, G Yu, C Feng, Y Yang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs Large Language Models (LLMs) show their capabilities across various \napplications, training customized LLMs has become essential for modern \nenterprises. However, due to the complexity of LLM training, which requires massive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.20263&hl=en&sa=X&d=14583207368034027437&ei=hKoGaNDGG7GyieoPmoPVSA&scisig=AFWwaebRe6Hz8JgakljjX6ZP8ib_&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Trajectory Balance with Asynchrony: Decoupling Exploration and Learning for Fast, Scalable LLM Post-Training", "first_label": ["LLM"], "second_label": [], "data": "BR Bartoldson, S Venkatraman, J Diffenderfer, M Jain\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nReinforcement learning (RL) is a critical component of large language model (LLM) \npost-training. However, existing on-policy algorithms used for post-training are \ninherently incompatible with the use of experience replay buffers, which can be\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.18929&hl=en&sa=X&d=9558060532125767644&ei=hKoGaNDGG7GyieoPmoPVSA&scisig=AFWwaeYoVzcxOA7NOnZtm52EYzED&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Jenga: Effective Memory Management for Serving LLM with Heterogeneity", "first_label": ["LLM"], "second_label": [], "data": "C Zhang, K Du, S Liu, W Kwon, X Mo, Y Wang, X Liu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are widely used but expensive to run, especially as \ninference workloads grow. To lower costs, maximizing the request batch size by \nmanaging GPU memory efficiently is crucial. While PagedAttention has recently been\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.18292&hl=en&sa=X&d=7739656753816907647&ei=hKoGaNDGG7GyieoPmoPVSA&scisig=AFWwaebgcPGXUDU8gTuYj4zLJnGn&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining", "first_label": ["LLM"], "second_label": [], "data": "J Li, M Armandpour, I Mirzadeh, S Mehta, V Shankar\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) trained on historical web data inevitably become \noutdated. We investigate evaluation strategies and update methods for LLMs as new \ndata becomes available. We introduce a web-scale dataset for time-continual\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.02107&hl=en&sa=X&d=214404728453281301&ei=hKoGaNDGG7GyieoPmoPVSA&scisig=AFWwaeaLFt5tc4ITJQUEXtdrdKV4&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Optimizing Language Models for Inference Time Objectives using Reinforcement Learning", "first_label": [], "second_label": [], "data": "Y Tang, K Zheng, G Synnaeve, R Munos\\xc2\\xa0- arXiv preprint arXiv:2503.19595, 2025\nIn this work, we investigate the merits of explicitly optimizing for inference time \nalgorithmic performance during model training. We show how optimizing for \ninference time performance can improve overall model efficacy. We consider generic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.19595%3F&hl=en&sa=X&d=8707254376221907976&ei=hKoGaNDGG7GyieoPmoPVSA&scisig=AFWwaea3RqIz48sR7GuNBXpH0BvA&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Automatically Improving LLM-based Verilog Generation using EDA Tool Feedback", "first_label": ["LLM"], "second_label": ["Generation"], "data": "J Blocklove, S Thakur, B Tan, H Pearce, S Garg, R Karri\\xc2\\xa0- ACM Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nTraditionally, digital hardware designs are written in the Verilog hardware description \nlanguage (HDL) and debugged manually by engineers. This can be time-consuming \nand error-prone for complex designs. Large Language Models (LLMs) are emerging\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3723876&hl=en&sa=X&d=11120037060516813768&ei=hKoGaNDGG7GyieoPmoPVSA&scisig=AFWwaebvSur0Y23nrD-o0dD19pfz&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Whispering Under the Eaves: Protecting User Privacy Against Commercial and LLM-powered Automatic Speech Recognition Systems", "first_label": ["LLM"], "second_label": [], "data": "W Jin, Y Cao, J Su, D Wang, Y Zhang, M Xue, J Hao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe widespread application of automatic speech recognition (ASR) supports large-\nscale voice surveillance, raising concerns about privacy among users. In this paper, \nwe concentrate on using adversarial examples to mitigate unauthorized disclosure of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.00858&hl=en&sa=X&d=17126862472531589341&ei=hKoGaNDGG7GyieoPmoPVSA&scisig=AFWwaeacs3ubXF-l97503QMSL1Mt&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "DeepSeek-R1 Thoughtology: Let's< think> about LLM Reasoning", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "SV Marjanovi\\xc4\\x87, A Patel, V Adlakha, M Aghajohari\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Reasoning Models like DeepSeek-R1 mark a fundamental shift in how LLMs \napproach complex problems. Instead of directly producing an answer for a given \ninput, DeepSeek-R1 creates detailed multi-step reasoning chains, seemingly\"\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.07128&hl=en&sa=X&d=11093818491604568461&ei=hKoGaNDGG7GyieoPmoPVSA&scisig=AFWwaeY0KvP-dOcXDNdY7ocWzhYS&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AFWwaeaPsVnV5GguxDkLdcyPdvnA&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Reasoning with LLMs for Zero-Shot Vulnerability Detection", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Reasoning"], "data": "A Zibaeirad, M Vieira\\xc2\\xa0- arXiv preprint arXiv:2503.17885, 2025\nAutomating software vulnerability detection (SVD) remains a critical challenge in an \nera of increasingly complex and interdependent software systems. Despite \nsignificant advances in Large Language Models (LLMs) for code analysis, prevailing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.17885&hl=en&sa=X&d=16151102993317123730&ei=hKoGaPnIH8eUywTViqN4&scisig=AFWwaeaU1duZG60YHiU0D1fyotku&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "CTDip: a diversity-guided test program synthesis approach for boosting compiler bug detection", "first_label": ["Bug", "Software Testing"], "second_label": ["Detection"], "data": "Y Tang, J Zeng, J Zhang, W Li, Z Huang\\xc2\\xa0- Empirical Software Engineering, 2025\nCompiler testing is an important task for assuring the quality of compilers. However, \nmost mutation-based compiler testing approaches still suffer from the effectiveness \nissue due to ineffective mutation strategies. In this paper, we propose CTDip, a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10642-0&hl=en&sa=X&d=17927180477555540458&ei=hKoGaPnIH8eUywTViqN4&scisig=AFWwaebILt68yqbUH_cAQrtqkdY7&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "LLMigrate: Transforming\" Lazy\" Large Language Models into Efficient Source Code Migrators", "first_label": ["LLM", "Code"], "second_label": [], "data": "Y Liu, J Hu, Y Shan, G Li, Y Zou, Y Dong, T Xie\\xc2\\xa0- arXiv preprint arXiv:2503.23791, 2025\nRewriting C code in Rust provides stronger memory safety, yet migrating large \ncodebases such as the 32-million-line Linux kernel remains challenging. While rule-\nbased translators (eg, C2Rust) provide accurate yet largely unsafe Rust programs\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.23791&hl=en&sa=X&d=8803774605220961224&ei=hKoGaPnIH8eUywTViqN4&scisig=AFWwaeY4DQ4Us-xpoOzQ65ucSN24&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "BESA: Extending Bugs Triggered by Runtime Testing via Static Analysis", "first_label": ["Bug", "Software Testing", "Static Analysis"], "second_label": [], "data": "JJ Bai\\xc2\\xa0- Proceedings of the Twentieth European Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDue to limited test cases and execution scenarios, runtime testing often has \ninsufficient code coverage and thus misses many real bugs. To tackle this problem, \nwe propose a novel idea that static analysis of the triggered bug in runtime testing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3689031.3696089&hl=en&sa=X&d=11971501184870035235&ei=hKoGaPnIH8eUywTViqN4&scisig=AFWwaebDNiyhkoXdOVlEYm5l6Q09&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Advanced code time complexity prediction approach using contrastive learning", "first_label": ["Code"], "second_label": [], "data": "S Park, J Hahn, E Orwig, SK Ko, YS Han\\xc2\\xa0- Engineering Applications of Artificial\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIt is a crucial task to predict the algorithmic time complexity for estimating the \nefficiency of a software code. Since the problem is known to be undecidable in \ntheory, there is no 100% accurate tools to solve the problem. Even humans often\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0952197625006311&hl=en&sa=X&d=16349264168467483688&ei=hKoGaPnIH8eUywTViqN4&scisig=AFWwaebzdf93mAmknfqCUiHXyi_o&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Every Sample Matters: Leveraging Mixture-of-Experts and High-Quality Data for Efficient and Accurate Code LLM", "first_label": ["LLM", "Code"], "second_label": [], "data": "L Team, W Cai, Y Cao, C Chen, C Chen, S Chen, Q Cui\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent advancements in code large language models (LLMs) have demonstrated \nremarkable capabilities in code generation and understanding. It is still challenging \nto build a code LLM with comprehensive performance yet ultimate efficiency. Many\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.17793&hl=en&sa=X&d=6822469255660902021&ei=hKoGaPnIH8eUywTViqN4&scisig=AFWwaeZ8vcQc_PT5mFMW0Uih-mYZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Efficient Fuzzing Infrastructure for Pointer-to-Object Association", "first_label": ["Fuzzing"], "second_label": [], "data": "H Ling, H Huang, Y Cai, C Zhang\\xc2\\xa0- ACM Transactions on Software Engineering and\\xc2\\xa0\\xe2\\x80\\xa6\nRuntime feedback is at the heart of efficient greybox fuzzing, and the collection of \nruntime feedback is the most important infrastructure for greybox fuzzing. However, \nexisting fuzzers have difficulty collecting runtime feedback for the memory, which is\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3730580&hl=en&sa=X&d=4503812625842861821&ei=hKoGaPnIH8eUywTViqN4&scisig=AFWwaeZjzBNZpNmRSEL69kiYZkzi&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "An Empirical Study of Rust-Specific Bugs in the rustc Compiler", "first_label": ["Bug"], "second_label": [], "data": "Z Liu, Y Feng, Y Ni, S Li, X Yin, Q Shi, B Xu, Z Su\\xc2\\xa0- arXiv preprint arXiv:2503.23985, 2025\nRust is gaining popularity for its well-known memory safety guarantees and high \nperformance, distinguishing it from C/C++ and JVM-based languages. Its compiler, \nrustc, enforces these guarantees through specialized mechanisms such as trait\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.23985&hl=en&sa=X&d=17777641218616878868&ei=hKoGaPnIH8eUywTViqN4&scisig=AFWwaeZ-9atblOv80axiJVZvPuu-&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AFWwaeaeIo1O_qAhRJzogmnex0DM&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Artificial Intelligence for Software Engineering: The Journey so far and the Road ahead", "first_label": [], "second_label": [], "data": "I Ahmed, A Aleti, H Cai, A Chatzigeorgiou, P He, X Hu\\xe2\\x80\\xa6\\xc2\\xa0- ACM Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nArtificial intelligence and recent advances in deep learning architectures, including \ntransformer networks and large language models, change the way people think and \nact to solve problems. Software engineering, as an increasingly complex process to \ndesign, develop, test, deploy, and maintain large-scale software systems for solving \nreal-world challenges, is profoundly affected by many revolutionary artificial \nintelligence tools in general, and machine learning in particular. In this roadmap for\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaVgx: Large-scale sample generation for boosting learning-based\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3719006&hl=en&sa=X&d=7262573879989499014&ei=hKoGaOf-EpWrieoPsaHL0Qg&scisig=AFWwaeY7EVIGUJEVmQB0rWf7x8NP&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AFWwaebib5Pw9QKWi9BJ6ThKDwc5&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang", "David Lo - new related research"]}
{"title": "Adapting Knowledge Prompt Tuning for Enhanced Automated Program Repair", "first_label": ["APR"], "second_label": ["Repair"], "data": "X Cai, L Jiang\\xc2\\xa0- arXiv preprint arXiv:2504.01523, 2025\nAutomated Program Repair (APR) aims to enhance software reliability by \nautomatically generating bug-fixing patches. Recent work has improved the state-of-\nthe-art of APR by fine-tuning pre-trained large language models (LLMs), such as\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.01523&hl=en&sa=X&d=9461921674059523797&ei=hKoGaIW6EZm7ieoPya6U2A4&scisig=AFWwaebGEkQCoR5RF1sA1OAr_sCy&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AFWwaeZjZJIN-8rhXrY_SmCmGQgD&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Fine-Grained Code Clone Detection by Keywords-Based Connection of Program Dependency Graph", "first_label": ["Code"], "second_label": ["Detection"], "data": "Y Wu, W Suo, S Feng, C Wu, D Zou, H Jin\\xc2\\xa0- IEEE Transactions on Reliability, 2025\nCode clone detection is intended to identify functionally similar code fragments, a \nmatter of escalating significance in contemporary software engineering. Numerous \nmethodologies have been proffered for the detection of code clones, among which\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10967509/&hl=en&sa=X&d=14562124566562428890&ei=hKoGaPLbGMCSieoP_drdwAU&scisig=AFWwaebBqzKIzkMhIcCulLtP40DU&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Fuzzing: On Benchmarking Outcome as a Function of Benchmark Properties", "first_label": ["Fuzzing"], "second_label": [], "data": "D WOLFF, A ROYCHOUDHURY - 2025\nAuthors' addresses: Dylan Wolff, wolffd@ comp. nus. edu. sg, National University of \nSingapore, Singapore; Marcel B\\xc3\\xb6hme, marcel. boehme@ mpi-sp. org, Max Planck \nInstitute for Security and Privacy, Germany; Abhik Roychoudhury, abhik@ comp. nus\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://abhikrc.com/pdf/TOSEM-fuzzers.pdf&hl=en&sa=X&d=3899393433676860100&ei=hKoGaPLbGMCSieoP_drdwAU&scisig=AFWwaeaeFcyvm9WOp5KG7c6FnRV_&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "ProphetAgent: Automatically Synthesizing GUI Tests from Test Cases in Natural Language for Mobile Apps", "first_label": ["Software Testing"], "second_label": ["Agent"], "data": "Q Kong, Z Lv, Y Xiong, J Sun, T Su, D Wang, L Li\\xe2\\x80\\xa6\nGUI tests is crucial for ensuring software quality and user satisfaction of mobile apps. \nIn practice, companies often maintain extensive test cases written in natural \nlanguage. Testers need to convert these test cases into executable scripts for\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://tingsu.github.io/files/fse2025-ProphetAgent.pdf&hl=en&sa=X&d=7730193664929118236&ei=hKoGaPLbGMCSieoP_drdwAU&scisig=AFWwaeZ6YGFVZwCFt3PMIF5kZaXj&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AFWwaeYRVjm7Uk5GklbyG-nM5aLh&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
