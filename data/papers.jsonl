{"title": "InstructRepair: Instruct Large Language Models with Rich Bug Information for Automated Program Repair", "first_label": ["APR", "LLM", "Bug"], "second_label": ["Repair"], "data": "A Fu, P Xu, J Li, B Kuang, Y Gao- IEEE Transactions on Information Forensics and, 2025\nAutomated Program Repair (APR) repairs software bugs based on buggy code \nsnippets automatically. It is instrumental in reducing the time and effort required for \nsoftware maintenance. Recently, large language models (LLMs) have been utilized", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11194216/&hl=en&sa=X&d=15287113091370652463&ei=6_3_aP73JM6E6rQPjY_jkQI&scisig=ABGrvjKRQ4NA9Q2bph15_TI0m8Cp&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Towards Speeding up Program Repair with Non-Autoregressive Model", "first_label": ["APR"], "second_label": ["Repair"], "data": "Z Yang, Y Pan, Z Yang, Z Yu- arXiv preprint arXiv:2510.01825, 2025\nEnlightened by the success of machine learning techniques in various application \nareas, recent years have witnessed a surge of research efforts on automatic program \nrepair (APR) using machine learning techniques. Previous machine learning-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01825&hl=en&sa=X&d=13565386759645709244&ei=6_3_aP73JM6E6rQPjY_jkQI&scisig=ABGrvjLcaUrVIG2KVg-f03OTMEUr&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A Multi-Language Object-Oriented Programming Benchmark for Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "S Wang, L Ding, L Shen, Y Luo, H Hu, L Zhang, F Lin- arXiv preprint arXiv, 2025\nEstablishing fair and robust benchmarks is essential for evaluating intelligent code \ngeneration by large language models (LLMs). Our survey of 35 existing benchmarks \nuncovers three major imbalances: 85.7% focus on a single programming language;", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.26111&hl=en&sa=X&d=2388658668398987935&ei=6_3_aP73JM6E6rQPjY_jkQI&scisig=ABGrvjLOMqK6KseaqrwLOyii9NBd&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "LLMs are All You Need? Improving Fuzz Testing for MOJO with Large Language Models", "first_label": ["LLM", "Fuzzing", "Software Testing"], "second_label": [], "data": "L Huang, P Zhao, H Chen- arXiv preprint arXiv:2510.10179, 2025\nThe rapid development of large language models (LLMs) has revolutionized \nsoftware testing, particularly fuzz testing, by automating the generation of diverse and \neffective test inputs. This advancement holds great promise for improving software", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10179%3F&hl=en&sa=X&d=1799101126036134381&ei=6_3_aP73JM6E6rQPjY_jkQI&scisig=ABGrvjJpTzJLdPRF-_YdbFCpjP7v&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "PLSEMANTICSBENCH: Large Language Models As Programming Language Interpreters", "first_label": ["LLM"], "second_label": [], "data": "A Thimmaiah, J Zhang, J Srinivasa, JJ Li, M Gligoric- arXiv preprint arXiv:2510.03415, 2025\nAs large language models (LLMs) excel at code reasoning, a natural question arises: \ncan an LLM execute programs (ie, act as an interpreter) purely based on a \nprogramming language's formal semantics? If so, it will enable rapid prototyping of", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03415&hl=en&sa=X&d=2539578870795389971&ei=6_3_aP73JM6E6rQPjY_jkQI&scisig=ABGrvjLDcDk0eY78Xm7hHQxmswny&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "X Yin, C Ni, X Li, L Chen, G Ma, X Yang\nRecently, Large Language Models (LLMs) have gained attention for their ability to \nhandle a broad range of tasks, including unit test generation. Despite their success, \nLLMs may exhibit hallucinations when generating unit tests for focal methods or", "link": "https://scholar.google.com/scholar_url?url=https://vinci-grape.github.io/papers/Enhancing_LLM_s_Ability_to_Generate_More_Repository_Aware_Unit_Tests_Through_Precise_Context_Injection.pdf&hl=en&sa=X&d=3506872574868649515&ei=6_3_aP73JM6E6rQPjY_jkQI&scisig=ABGrvjKPA0zq2FXS1WyPoCr65qwT&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research"]}
{"title": "IT project infrastructure setup automation with help of large language models", "first_label": ["LLM"], "second_label": [], "data": "VA Ivlev, IV Nikiforov, SM Ustinov- Computing, Telecommunication and Control, 2025\nThis study conducts an analysis of existing large language models (LLMs) and AI \nagents, identifying Llama 2 as the most suitable model for automating IT project \nenvironment configuration. A mathematical model of the proposed method is", "link": "https://scholar.google.com/scholar_url?url=https://infocom.spbstu.ru/userfiles/files/articles/2025/2/74-90.pdf&hl=en&sa=X&d=8794046321267415771&ei=6_3_aP73JM6E6rQPjY_jkQI&scisig=ABGrvjLemX1zaSQ4K09Gbc4ROV8O&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Enhanced Architecture of Structure Semantics for SyntaxAware Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "C Zhou, Z Li, H Huang, Y Xiang, F Liu, Z Hao- Software: Practice and Experience, 2025\nObjective The task of code generation aims to transform natural language \ndescriptions into corresponding target code. Among the various approaches, syntax\naware code generation has emerged as a significant approach that strives to", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.70025&hl=en&sa=X&d=17163292334780918507&ei=6_3_aP73JM6E6rQPjY_jkQI&scisig=ABGrvjIEfWSCelZJddhXkIyGi8VD&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Clarifying Semantics of In-Context Examples for Unit Test Generation", "first_label": ["Software Testing"], "second_label": ["Generation"], "data": "C Yang, L Yang, Z Wang, D Wang, J Zhou, J Chen- arXiv preprint arXiv:2510.01994, 2025\nRecent advances in large language models (LLMs) have enabled promising \nperformance in unit test generation through in-context learning (ICL). However, the \nquality of in-context examples significantly influences the effectiveness of generated", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01994&hl=en&sa=X&d=12911584122052136706&ei=6_3_aP73JM6E6rQPjY_jkQI&scisig=ABGrvjLb3Bbe-8d0CQPxZ5ASyZfN&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "RepoSummary: Feature-Oriented Summarization and Documentation Generation for Code Repositories", "first_label": ["Code"], "second_label": ["Generation"], "data": "Y Zhu, X Zhao, X Li, Y Zou, H Yuan, Y Wang, B Xie- arXiv preprint arXiv:2510.11039, 2025\nRepository summarization is a crucial research question in development and \nmaintenance for software engineering. Existing repository summarization techniques \nprimarily focus on summarizing code according to the directory tree, which is\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.11039&hl=en&sa=X&d=1535321579264936728&ei=6_3_aP73JM6E6rQPjY_jkQI&scisig=ABGrvjKiRCNaOwIB_iF4UzpYHptL&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation", "first_label": ["LLM", "Fault Localization"], "second_label": ["Localization"], "data": "F Liu, T Wang, L Zhang, Z Yang, J Jiang, Z Sun- arXiv preprint arXiv:2509.25676, 2025\nProviding timely and personalized guidance for students' programming assignments, \noffers significant practical value for helping students complete assignments and \nenhance their learning. In recent years, various automated Fault Localization (FL)", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25676&hl=en&sa=X&d=16831300563596066577&ei=6v3_aL39I5jO6rQPk_O3wAE&scisig=ABGrvjKOmbi2TriQ76tXIs_L9sIr&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Hong Jin Kang - new related research"]}
{"title": "MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing", "first_label": ["LLM", "Fuzzing", "Bug"], "second_label": [], "data": "S Ou, Y Li, L Yu, C Wei, T Wen, Q Chen, Y Chen- IEEE Transactions on, 2025\nDeep learning (DL) frameworks serve as the backbone for a wide range of artificial \nintelligence applications. However, bugs within DL frameworks can cascade into \ncritical issues in higher-level applications, jeopardizing reliability and security. While", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/32/4359463/11201027.pdf&hl=en&sa=X&d=1422528139240657868&ei=6v3_aL39I5jO6rQPk_O3wAE&scisig=ABGrvjI1tTlw2XwsJvzcyylBVxMq&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Abhik Roychoudhury - new related research", "Thanh Le-Cong - new related research", "David Lo - new related research"]}
{"title": "Learning Project-wise Subsequent Code Edits via Interleaving Neural-based Induction and Tool-based Deduction", "first_label": ["Code"], "second_label": [], "data": "C Liu, Y Lin, Y Huang, J Chang, B Qi, B Jiang, Z Huang\nIn industrial and open-source software engineering tasks, developers often perform \nproject-wise code editing tasks, including feature enhancement, refactoring, and bug \nfixing, where the leading AI models are expected to support the productivity. Hence", "link": "https://scholar.google.com/scholar_url?url=http://linyun.info/publications/ase25.pdf&hl=en&sa=X&d=10948765072096116511&ei=6v3_aL39I5jO6rQPk_O3wAE&scisig=ABGrvjKBXCNGAlGU6UXYxWVhAkgt&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Xin ZHOU - new related research", "4 new citations to articles by Abhik Roychoudhury", "Thanh Le-Cong - new related research"]}
{"title": "CG-Bench: Can Language Models Assist Call Graph Construction in the Real World?", "first_label": ["LLM", "Static Analysis"], "second_label": ["Graph"], "data": "T Yuan, W Zhang, D Chen, J Wang- Proceedings of the 1st ACM SIGPLAN, 2025\nLanguage models for coding are shifting their focus from function-level to repository-\nlevel, with complex function invocations. We introduce CG-Bench, the first manually \nconstructed benchmark that measures the ability to understand call graphs for", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3759425.3763379&hl=en&sa=X&d=11570618845570061776&ei=6v3_aL39I5jO6rQPk_O3wAE&scisig=ABGrvjJTTJMRIMAuaa7eEoue4X54&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=3&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Source Code Guardrail: AI Driven Solution to Distinguish Critical vs. Generic Code for Enterprise LLM Security", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Sharma, A Gupta- International Conference on Provable Security, 2025\nAbstract The adoption of Large Language Models (LLMs) in businesses raises the \npossibility of inadvertent intellectual property (IP) and secret data leaks to public \nartificial intelligence systems. Organizations are using security solutions, including\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-2961-2_23&hl=en&sa=X&d=5184326828152072441&ei=6v3_aL39I5jO6rQPk_O3wAE&scisig=ABGrvjJOJG-OQ4wH-x-OhS5wRNe2&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=4&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Evaluating and Improving GPT-Based Expansion of Abbreviations", "first_label": ["LLM"], "second_label": [], "data": "Y Jiang, C Li, Z Zhao, F Fan, L Zhang, H Liu- IEEE Transactions on Software, 2025\nSource code identifiers often contain abbreviations. Such abbreviations may reduce \nthe readability of the source code, which in turn hinders the maintenance of the \nsoftware applications. To this end, accurate and automated approaches to", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11207729/&hl=en&sa=X&d=8201994419341712724&ei=7f3_aIi9EZjO6rQPk_O3wAE&scisig=ABGrvjLOR3_lzFuLmQt9UtiheCi2&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Beyond SWE-Bench: A Compiler-Assisted Pipeline for Multi-language Automated", "first_label": [], "second_label": [], "data": "D Flores-Araiza, S Hinojosa- Advances in Soft Computing: 24th Mexican, 2025\nAutomated program repair (APR) research predominantly focuses on Python \nenvironments, creating significant infrastructure gaps for compiled languages like C, \nC++, and Java that dominate production systems. We present the first systematic", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DdHqQEQAAQBAJ%26oi%3Dfnd%26pg%3DPA115%26ots%3DPJdiwDMG_X%26sig%3DtMRPYdObnIzeu6XA_yjJd-Ha2iY&hl=en&sa=X&d=11355528957197608093&ei=7f3_aIi9EZjO6rQPk_O3wAE&scisig=ABGrvjILhwlLt5WuLiSNgOnh9c3t&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Rethinking Code Review Workflows with LLM Assistance", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "BB Magnsson, FS Aalsteinsson\nCode reviews are a critical yet time-consuming aspect of modern software \ndevelopment, increasingly challenged by growing system complexity and the \ndemand for faster delivery. This thesis presents a study conducted at WirelessCar", "link": "https://scholar.google.com/scholar_url?url=https://odr.chalmers.se/server/api/core/bitstreams/2cc084f4-7576-4faf-89e6-ba46c26e4b20/content&hl=en&sa=X&d=4354460236496870256&ei=7f3_aIi9EZjO6rQPk_O3wAE&scisig=ABGrvjLLlL_gAyRL6RSQ6ooeNdZZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Sparse-MoE: Syntax-Aware Multi-view Mixture of Experts for Long-Sequence Software Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "Y Wu, L Xiao- International Conference on Advanced Data Mining, 2025\nAccurately locating security vulnerabilities in ever-growing codebases is critical for \nprotecting modern software ecosystems. Yet real-world detectors must contend with \nthree intertwined hurdles: extreme class imbalance, thousand-token functions that", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-3456-2_24&hl=en&sa=X&d=3457907681491117995&ei=7f3_aIi9EZjO6rQPk_O3wAE&scisig=ABGrvjITVNj8d63TvnIRYpTF77q0&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Federated Adaptive Large Language Model Fine-Tuning Framework for Software Development", "first_label": ["LLM"], "second_label": [], "data": "J Chen, Z Cai, W Chen, W Wang, Z Zheng, PS Yu- IEEE Transactions on Services, 2025\nLarge Language Models (LLMs) have achieved remarkable progress in code \nintelligence tasks, significantly en hancing the efficiency of software development. \nHowever, several challenges remain. First, fine-tuning LLMs for specific tasks", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11214287/&hl=en&sa=X&d=8361169225896784104&ei=7f3_aIi9EZjO6rQPk_O3wAE&scisig=ABGrvjJq2-TFut3K-md9IQEEA1el&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "SpecAgent: A Speculative Retrieval and Forecasting Agent for Code Completion", "first_label": ["Code"], "second_label": ["Generation", "Agent"], "data": "G Ma, A Koul, Q Chen, Y Wu, S Kuhar, Y Yu- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) excel at code-related tasks but often struggle in \nrealistic software repositories, where project-specific APIs and cross-file \ndependencies are crucial. Retrieval-augmented methods mitigate this by injecting\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.17925&hl=en&sa=X&d=3299397357636031554&ei=7f3_aIi9EZjO6rQPk_O3wAE&scisig=ABGrvjIOzA0E2pWK6kawREa-Eqes&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=7&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Publishered in ACM Transactions on the Web (TWEB)", "first_label": [], "second_label": [], "data": "A BODAGHI, BCM FUNG, KA SCHMITT - 2025\nAddressing the challenge of toxic language in online discussions is crucial for the \ndevelopment of effective toxicity detection models. This pioneering work focuses on \naddressing imbalanced datasets in toxicity detection by introducing a novel \napproach to augment toxic language data. We create a balanced dataset by \ninstructing fine-tuning of Large Language Models (LLMs) using Reinforcement \nLearning with Human Feedback (RLHF). Recognizing the challenges in collecting\nCites: Exploring Parameter-Efficient Fine-Tuning Techniques for Code", "link": "https://scholar.google.com/scholar_url?url=https://dmas.lab.mcgill.ca/fung/pub/BFS25tweb_preprint.pdf&hl=en&sa=X&d=6587404050022299375&ei=7P3_aP_tLtyOieoP1t-zoQM&scisig=ABGrvjIJE4et6M9OV1uWO6rdmCFL&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ABGrvjKBQMI3rG05-NPhg-jRvIpb&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "POLAR: AUTOMATING CYBER THREAT PRIORITIZA-TION THROUGH LLM-POWERED ASSESSMENT", "first_label": ["LLM"], "second_label": [], "data": "TTLLMP ASSESSMENT\nThe rapid expansion of the cyber threat landscape, with over 11,000 new \nvulnerabilities reported in 2024 alone, has intensified the need for effective threat \nprioritization. Existing approaches, from rule-based systems to machine learning \nmodels, struggle with scalability, distribution shift, and context-independent scoring, \noften mis-ranking threats in dynamic exploitation environments. In this work, we \npresent POLAR, an LLM-based framework that automates cyber threat prioritization\nCites: Large language model for vulnerability detection and repair", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DeLDjevX5p5&hl=en&sa=X&d=5004893358629008711&ei=7P3_aP_tLtyOieoP1t-zoQM&scisig=ABGrvjJbBzvhzEMtmdpI52o_WEgp&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ABGrvjKBQMI3rG05-NPhg-jRvIpb&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "Leveraging Large Language Models For Automated Software Vulnerability Detection and Analysis", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "A BOUCENA - 2025\nThe growing integration of software across various sectors has amplified the urgency \nto develop effective mechanisms for safeguarding systems against sophisticated \ncyberattacks. This thesis investigates the application of modern artificial intelligence \nspecifically transformer-based models for improving software vulnerability detection. \nThe research focuses on designing intelligent algorithms capable of autonomously \nanalyzing source code and identifying subtle security flaws. It emphasizes automated\nCites: Large language model for vulnerability detection and repair", "link": "https://scholar.google.com/scholar_url?url=https://dspace.univ-guelma.dz/jspui/bitstream/123456789/18272/1/F5_8_BOUCENA_AMINA_1752072283.pdf&hl=en&sa=X&d=17743756367724898508&ei=7P3_aP_tLtyOieoP1t-zoQM&scisig=ABGrvjKWcuS-8N8q839RZdLXTzAO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ABGrvjKBQMI3rG05-NPhg-jRvIpb&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "LocVul: Line-level vulnerability localization based on a Sequence-to-Sequence approach", "first_label": ["Vulnerabilities"], "second_label": ["Localization"], "data": "I Kalouptsoglou, M Siavvas, A Ampatzoglou- Information and Software, 2026\nContext: The development of secure software systems depends on early and \naccurate vulnerability identification. Manual inspection is a time-consuming process \nthat requires specialized knowledge. Therefore, as software complexity grows, \nautomated solutions become essential. Vulnerability Prediction (VP) is an emerging \nmechanism that identifies whether software components contain vulnerabilities, \ncommonly using Machine Learning models trained on classifying components as\nCites: Large language model for vulnerability detection: Emerging results\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925002794&hl=en&sa=X&d=6632975054889539125&ei=7P3_aP_tLtyOieoP1t-zoQM&scisig=ABGrvjJM5HMQVE_yVywlWcc93dra&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ABGrvjKBQMI3rG05-NPhg-jRvIpb&html=&pos=3&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU", "Hong Jin Kang - new related research"]}
{"title": "Automation of Automation: Mapping LLM Capabilities to the Modular Plant Engineering Workflow", "first_label": ["LLM"], "second_label": [], "data": "L Vogt, L Urbas- 2025 IEEE 30th International Conference on Emerging, 2025\nLarge Language Models (LLMs) have shown promising capabilities in supporting \nand automating a variety of clearly defined, structured tasks. The engineering of \nmodular plants also follows standardized workflow structures and uses standardized \nartifacts such as P&IDs, flow diagrams or HAZOPs. Therefore, the engineering of \nmodular plants has the potential to be significantly supported or automated by AI \ntools. The articles objective is to determine which aspects of the modular plant\nCites: Automatic Programming: Large Language Models and Beyond", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11205600/&hl=en&sa=X&d=3209204046171112004&ei=6_3_aMrnN4GpieoPyfaRyA4&scisig=ABGrvjJmSyT-Ksl47hbffp7WA3OP&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "SYXSS: Web Application Vulnerability Detection Tool Based on Improved Genetic Algorithm and Fuzz Testing", "first_label": ["Vulnerabilities", "Fuzzing", "Software Testing"], "second_label": ["Detection"], "data": "Y Su, H Qu- 2025 5th International Conference on Intelligent, 2025\nGenetic algorithm-based black-box vulnerability detection has been widely used in \npractical applications. However, the existing black-box vulnerability detection \ntechnology based on genetic algorithm has problems such as insufficient \nfinegrainedness in the encoding method of attack vectors and the genetic algorithm \ntends to converge prematurely to local optima. To address these issues, we analyze \nthe characteristics of XSS attacks and propose a more fine-grained functional\nCites: Fuzzing: Challenges and Reflections", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11199567/&hl=en&sa=X&d=449569989814717983&ei=6_3_aMrnN4GpieoPyfaRyA4&scisig=ABGrvjLQ37K1ldchIY1bd8iTEN3j&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Profile Coverage: Using Android Compilation Profiles to Evaluate Dynamic Testing", "first_label": ["Software Testing"], "second_label": [], "data": "J Bleier, F Kehrer, J Cito, M Lindorfer\nThe rising complexity of Android apps makes comprehensive dynamic testing \ninfeasible, especially for third-party apps. Knowing which methods are exercised by \nreal users typically requires costly user studies or access to usage telemetry. We \nshow that Android's compilation profiles, specifically Cloud Profiles collected by the \nGoogle Play Store, offer a readily available, underutilized source of such information. \nThese operational profiles aggregate which methods are commonly executed across\nCites: Time-travel Testing of Android Apps\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://themoep.at/research/2025-profile-coverage.pdf&hl=en&sa=X&d=2960125355597032294&ei=6_3_aMrnN4GpieoPyfaRyA4&scisig=ABGrvjLJVAdC7mGv9E7d9SsUr2V6&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Survey for MQTT Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "SY Chowdhury, R Sun, B Dudley- Proceedings of the 2025 Workshop on Re-design, 2025\nMessage Queuing Telemetry Transport (MQTT) has emerged as a promising \ncommunication protocol for Internet of Things (IoT) ecosystems, enabling lightweight, \nscalable publish-subscribe messaging across resource-constrained devices. As", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3733823.3764515&hl=en&sa=X&d=13012329971672204999&ei=7P3_aMzdDJjO6rQPk_O3wAE&scisig=ABGrvjId2cO-K_7acZfnhIhoKULY&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "DynamiQ: Unlocking the Potential of Dynamic Task Allocation in Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "W Yan, T Murray, B Rubinstein, VT Pham- arXiv preprint arXiv:2510.04469, 2025\nWe present DynamiQ, a full-fledged and optimized successor to AFLTeam that \nsupports dynamic and adaptive parallel fuzzing. Unlike most existing approaches \nthat treat individual seeds as tasks, DynamiQ leverages structural information from", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04469&hl=en&sa=X&d=10962816615102660239&ei=7P3_aMzdDJjO6rQPk_O3wAE&scisig=ABGrvjJffOk8ddKWXV2Kdd4qJSnB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Function Clustering-Based Fuzzing Termination: Toward Smarter Early Stopping", "first_label": ["Fuzzing"], "second_label": [], "data": "L Ding, W Yang, Y Xue\nFuzzing is a testing technique that generates a large number of inputs to cause \nprogram crashes. As software development accelerates and projects scale, the \ndemand for fuzz testing in software assurance has increased. Performing", "link": "https://scholar.google.com/scholar_url?url=https://wzyang.cn/files/FuzzingTermination.pdf&hl=en&sa=X&d=16741608997780760317&ei=7P3_aMzdDJjO6rQPk_O3wAE&scisig=ABGrvjJOoGioSM_8JoIy2nxjy7ve&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Multi Language Models for On-the-Fly Syntax Highlighting", "first_label": ["LLM"], "second_label": [], "data": "ME Palma, P Rani, HC Gall- arXiv preprint arXiv:2510.04166, 2025\nSyntax highlighting is a critical feature in modern software development \nenvironments, enhancing code readability and developer productivity. However, \ndelivering accurate highlighting in real time remains challenging for online and web\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04166%3F&hl=en&sa=X&d=2254729212502568662&ei=7P3_aMzdDJjO6rQPk_O3wAE&scisig=ABGrvjIMpU0YGaMDVoPzEyw5QYUR&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Bach Le - new related research"]}
{"title": "A Scalable Vulnerability Detection System with Multi-View Graph Representations", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "S Dou, H Zheng, J Shan, Y Wu, D Zou, X Huang, Y Liu- ACM Transactions on, 2025\nDeep learning (DL) has been extensively utilized in source code vulnerability \ndetection due to its robust automatic feature extraction capabilities. To achieve \nscalable vulnerability scanning, some prior studies intend to process the source code", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3770075&hl=en&sa=X&d=14953216934661661615&ei=6v3_aNLQObmAieoPlr2tqAg&scisig=ABGrvjIFKzTAARKmQs4FcWCEoWpB&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "Enhancing Domain-Specific Code Completion via Collaborative Inference with Large and Small Language Models", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Yu, Z Gao, L Bao, Z Liu- ACM Transactions on Software Engineering and, 2025\nLarge language model-based code completion has demonstrated excellent \nperformance, but still encounters challenges in capturing domain-specific knowledge \nfor more precise completion within specific domains, ie, domain-specific code", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3770748&hl=en&sa=X&d=2019769577165862416&ei=6v3_aNLQObmAieoPlr2tqAg&scisig=ABGrvjKO1fKaLDZwwCDDcSmDx0Da&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "ALMAS: an autonomous llm-based multi-agent software engineering framework", "first_label": ["LLM"], "second_label": ["Agent"], "data": "V Tawosi, K Ramani, S Alamir, X Liu- arXiv preprint arXiv:2510.03463, 2025\nMulti-agent Large Language Model (LLM) systems have been leading the way in \napplied LLM research across a number of fields. One notable area is software \ndevelopment, where researchers have advanced the automation of code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03463&hl=en&sa=X&d=6189494284468520954&ei=6v3_aNLQObmAieoPlr2tqAg&scisig=ABGrvjJrdVeB80cic_brCTfqWIPK&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Improving the Efficiency of LLM Agent Systems through Trajectory Reduction", "first_label": ["LLM"], "second_label": ["Agent"], "data": "YA Xiao, P Gao, C Peng, Y Xiong- arXiv preprint arXiv:2509.23586, 2025\nMulti-turn agent systems based on Large Language Models (LLMs) have been \nincreasingly popular for software engineering tasks. While LLM agents show decent \neffectiveness, the high computational cost of input tokens due to the ever-growing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23586%3F&hl=en&sa=X&d=12596444921036280365&ei=6v3_aNLQObmAieoPlr2tqAg&scisig=ABGrvjLC0C_0GltjgtJTt8p-QsJp&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "LLM Agents for Automated Dependency Upgrades", "first_label": ["LLM"], "second_label": ["Agent"], "data": "V Tawosi, S Alamir, X Liu, M Veloso- arXiv preprint arXiv:2510.03480, 2025\nAs a codebase expands over time, its library dependencies can become outdated \nand require updates to maintain innovation and security. However, updating a library \ncan introduce breaking changes in the code, necessitating significant developer time", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03480&hl=en&sa=X&d=6490656773391404708&ei=6v3_aNLQObmAieoPlr2tqAg&scisig=ABGrvjLTI-aGv2gyB5kKiU57yoCH&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Real-VulLLM: An LLM Based Assessment Framework in the Wild", "first_label": ["LLM"], "second_label": [], "data": "R Safdar, D Mateen, ST Ali, W Hussain- arXiv preprint arXiv:2510.04056, 2025\nArtificial Intelligence (AI) and more specifically Large Language Models (LLMs) have \ndemonstrated exceptional progress in multiple areas including software engineering, \nhowever, their capability for vulnerability detection in the wild scenario and its", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04056&hl=en&sa=X&d=7464868966945655593&ei=6v3_aNLQObmAieoPlr2tqAg&scisig=ABGrvjIaO4pEKfAZ4-It9iNMVajB&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "The Richer Representation Fallacy: Are We Just Adding Noise to LLM-based Software Vulnerability Detectors?", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "H Hanif, S Maffeis, NB Anuar\nLarge Language Models (LLMs) have established strong baselines for software \nvulnerability detection, leading to a common assumption that their performance can \nbe enhanced by augmenting them with supplementary information such as Abstract", "link": "https://scholar.google.com/scholar_url?url=https://www.doc.ic.ac.uk/~maffeis/papers/icoco25.pdf&hl=en&sa=X&d=9374945953362351896&ei=6v3_aNLQObmAieoPlr2tqAg&scisig=ABGrvjJP7g6ze4j15IMQXWKX48ED&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Backdoor-Powered Prompt Injection Attacks Nullify Defense Methods", "first_label": [], "second_label": [], "data": "Y Chen, H Li, Y Sui, Y Song, B Hooi- arXiv preprint arXiv:2510.03705, 2025\nWith the development of technology, large language models (LLMs) have dominated \nthe downstream natural language processing (NLP) tasks. However, because of the \nLLMs' instruction-following abilities and inability to distinguish the instructions in the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03705&hl=en&sa=X&d=9793005798347645046&ei=7f3_aNXmAb7WieoPn4GZgQE&scisig=ABGrvjJ2v68AhMUTz-vIWEu8QJ-h&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Poisoned to Aware: Fostering Backdoor Self-Awareness in LLMs", "first_label": ["LLM"], "second_label": [], "data": "G Shen, S Cheng, X Xu, Y Zhou, H Guo, Z Zhang- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) can acquire deceptive behaviors through backdoor \nattacks, where the model executes prohibited actions whenever secret triggers \nappear in the input. Existing safety training methods largely fail to address this", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05169&hl=en&sa=X&d=9405091671790165810&ei=7f3_aNXmAb7WieoPn4GZgQE&scisig=ABGrvjKDn53FGdNyyBI6d9isJWID&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "HarmMetric Eval: Benchmarking Metrics and Judges for LLM Harmfulness Assessment", "first_label": ["LLM"], "second_label": [], "data": "L Yang, T Zheng, K Xiu, Y Chen, D Wang, P Zhao- arXiv preprint arXiv, 2025\nThe alignment of large language models (LLMs) with human values is critical for their \nsafe deployment, yet jailbreak attacks can subvert this alignment to elicit harmful \noutputs from LLMs. In recent years, a proliferation of jailbreak attacks has emerged", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.24384%3F&hl=en&sa=X&d=6954529287697046870&ei=7f3_aNXmAb7WieoPn4GZgQE&scisig=ABGrvjLTm62_wZwng_7ayKNaQNrl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Genesis: Evolving Attack Strategies for LLM Web Agent Red-Teaming", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Z Zhang, J He, Y Cai, D Ye, P Zhao, R Feng, H Wang- arXiv preprint arXiv, 2025\nAs large language model (LLM) agents increasingly automate complex web tasks, \nthey boost productivity while simultaneously introducing new security risks. However, \nrelevant studies on web agent attacks remain limited. Existing red-teaming", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.18314&hl=en&sa=X&d=14799970374377988040&ei=7f3_aNXmAb7WieoPn4GZgQE&scisig=ABGrvjLlUwaYV7x4iFtGtsyDIHdw&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "MetaBreak: Jailbreaking Online LLM Services via Special Token Manipulation", "first_label": ["LLM"], "second_label": [], "data": "W Zhu, Z Xiang, W Niu, L Guan- arXiv preprint arXiv:2510.10271, 2025\nUnlike regular tokens derived from existing text corpora, special tokens are artificially \ncreated to annotate structured conversations during the fine-tuning process of Large \nLanguage Models (LLMs). Serving as metadata of training data, these tokens play a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10271%3F&hl=en&sa=X&d=10904776402205985786&ei=7f3_aNXmAb7WieoPn4GZgQE&scisig=ABGrvjL7g_73UHz_DwhnWsdL9iGk&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Webcloak: Characterizing and mitigating the threats of llm-driven web agents as intelligent scrapers", "first_label": ["LLM"], "second_label": ["Agent"], "data": "X Li, T Qiu, Y Jin, L Wang, H Guo, X Jia, X Wang- Proceedings of the 2026, 2026\nThe rise of web agents powered by large language models (LLMs) is reshaping the \nlandscape of human-computer interaction, enabling users to automate complex web \ntasks with natural language commands. However, this progress introduces serious", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Xinfeng-Li-7/publication/396418425_WebCloak_Characterizing_and_Mitigating_Threats_from_LLM-Driven_Web_Agents_as_Intelligent_Scrapers/links/68ea2bc4f3032e2b4be84935/WebCloak-Characterizing-and-Mitigating-Threats-from-LLM-Driven-Web-Agents-as-Intelligent-Scrapers.pdf&hl=en&sa=X&d=11222165444201781035&ei=7f3_aNXmAb7WieoPn4GZgQE&scisig=ABGrvjIK6rwNOFCGhsxEhJgoFqxB&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "C Ziakas, N Loo, N Jain, A Russo- arXiv preprint arXiv:2510.07239, 2025\nAutomated red-teaming has emerged as a scalable approach for auditing Large \nLanguage Models (LLMs) prior to deployment, yet existing approaches lack \nmechanisms to efficiently adapt to model-specific vulnerabilities at inference. We", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07239%3F&hl=en&sa=X&d=7730973334197366962&ei=7f3_aNXmAb7WieoPn4GZgQE&scisig=ABGrvjK7SFLw8g1qTWHeOk7VhS4x&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Investigating the Impact of Dark Patterns on LLM-Based Web Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "D Ersoy, B Lee, A Shreekumar, A Arunasalam- arXiv preprint arXiv, 2025\nAs users increasingly turn to large language model (LLM) based web agents to \nautomate online tasks, agents may encounter dark patterns: deceptive user interface \ndesigns that manipulate users into making unintended decisions. Although dark", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.18113&hl=en&sa=X&d=9332036408692793636&ei=7f3_aNXmAb7WieoPn4GZgQE&scisig=ABGrvjL2GoCmABLkIStSVW1f9lld&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Securing with Dual-LLM Architecture: ChatTEDU An Open Access Chatbot's Defense", "first_label": ["LLM"], "second_label": [], "data": "H Emekci, G Budakoglu- IEEE Access, 2025\nOpen access chatbots face escalating cybersecurity risks due to adversarial \nexploitation. This paper presents the case of ChatTEDU, a dual-LLM architecture \ndesigned to protect open-access AI systems from sophisticated adversarial attacks", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11207588.pdf&hl=en&sa=X&d=8815365068079578094&ei=7f3_aNXmAb7WieoPn4GZgQE&scisig=ABGrvjIotmfuTMIEf8JuZ6CJRHKR&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Certifiable Safe RLHF: Fixed-Penalty Constraint Optimization for Safer Language Models", "first_label": ["LLM"], "second_label": [], "data": "K Pandit, S Ganguly, A Banerjee, S Angizi, A Ghosh- arXiv preprint arXiv:2510.03520, 2025\nEnsuring safety is a foundational requirement for large language models (LLMs). \nAchieving an appropriate balance between enhancing the utility of model outputs \nand mitigating their potential for harm is a complex and persistent challenge\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03520%3F&hl=en&sa=X&d=4542062984345920079&ei=7f3_aNXmAb7WieoPn4GZgQE&scisig=ABGrvjJDzwAj4loLOT-k6frxeTtz&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Toward Responsible AI in High-Stakes Domains: A Dataset for Building Static Analysis with LLMs in Structural Engineering", "first_label": ["LLM", "Static Analysis"], "second_label": [], "data": "C Avila, D Ilbay, P Tapia, D Rivera- Data, 2025\nModern engineering increasingly operates within socio-technical networks, such as \nthe interdependence of energy grids, transport systems, and building codes, where \ndecisions must be reliable and transparent. Large language models (LLMs) such as \nGPT promise efficiency by interpreting domain-specific queries and generating \noutputs, yet their predictive nature can introduce biases or fabricated valuesrisks \nthat are unacceptable in structural engineering, where safety and compliance are\nCites: Large language models for computer-aided design: A survey", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2306-5729/10/11/169&hl=en&sa=X&d=766730263518304787&ei=6_3_aOiaEe2ZieoP7ueJyQk&scisig=ABGrvjKHAP0I9PYk8gjfXZ0iqeNq&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:ABGrvjKFoYpfVt7EiQsbVsLwN3n6&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le"]}
{"title": "Secure and Efficient Data Interoperability Protocols for Multi-Blockchains Systems", "first_label": ["Blockchain"], "second_label": [], "data": "T Yu, F Luo, G Ranzi, J Wu- IEEE Transactions on Information Forensics and, 2025\nThe proliferation of decentralized applications across different autonomous \nblockchains raises the need to enable cross-chain data interoperability (CCDI). \nHowever, prior approaches for supporting CCDI often hit scalability bottlenecks \nregarding critical metrics, eg, memory, or remain prone to withholding and \ncensorship attacks. This paper proposes two protocols to implement secure and \nefficient CCDI under adversarial conditions. The cross-chain token exchange (CCTE)\nCites: Smart contract development: Challenges and opportunities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11214554/&hl=en&sa=X&d=9698410463802438095&ei=6_3_aOiaEe2ZieoP7ueJyQk&scisig=ABGrvjIJ9p-N0tGQI-dQi_uNTJdh&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:ABGrvjKFoYpfVt7EiQsbVsLwN3n6&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le"]}
{"title": "LSPFuzz: Hunting Bugs in Language Servers", "first_label": ["Fuzzing", "Bug"], "second_label": [], "data": "H Zhu, S Chen, V Terragni, L Wei, J Wu, Y Liu- arXiv preprint arXiv, 2025\nThe Language Server Protocol (LSP) has revolutionized the integration of code \nintelligence in modern software development. There are approximately 300 LSP \nserver implementations for various languages and 50 editors offering LSP", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.00532&hl=en&sa=X&d=3201719160230213096&ei=7f3_aIbCILmAieoPlr2tqAg&scisig=ABGrvjKlQ__ltef17HmH0t9-5iwk&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Adversarial Evaluation of Machine Learning-Based Python Source Code Vulnerability Detectors", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "T Farasat, A Bouzid, J Posegga - 2025\nAbstract Machine learning models for Python source code vulnerability detection \nhave demonstrated impressive accuracy in identifying security vulnerabilities. \nHowever, their robustness against adversarial manipulation remains largely", "link": "https://scholar.google.com/scholar_url?url=https://ceur-ws.org/Vol-4075/paper2.pdf&hl=en&sa=X&d=202226442539048737&ei=7f3_aIbCILmAieoPlr2tqAg&scisig=ABGrvjIbbFql9Om6SGeHUSvmUchu&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "AutoMT: A Multi-Agent LLM Framework for Automated Metamorphic Testing of Autonomous Driving Systems", "first_label": ["LLM", "Software Testing"], "second_label": ["Agent"], "data": "L Liang, C Tan, Y Deng, Y Cai, TY Chen, X Zheng- arXiv preprint arXiv:2510.19438, 2025\nAutonomous Driving Systems (ADS) are safety-critical, where failures can be severe. \nWhile Metamorphic Testing (MT) is effective for fault detection in ADS, existing \nmethods rely heavily on manual effort and lack automation. We present AutoMT, a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.19438&hl=en&sa=X&d=276175826318936325&ei=7f3_aIbCILmAieoPlr2tqAg&scisig=ABGrvjL_SadLfxADYPHNE0Ah5TRH&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "BloomAPR: A Bloom's Taxonomy-based Framework for Assessing the Capabilities of LLM-Powered APR Solutions", "first_label": ["LLM"], "second_label": [], "data": "Y Ma, J Shin, L Da Silva, Z Ming, S Wang, F Khomh- arXiv preprint arXiv, 2025\nRecent advances in large language models (LLMs) have accelerated the \ndevelopment of AI-driven automated program repair (APR) solutions. However, these \nsolutions are typically evaluated using static benchmarks such as Defects4J and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25465&hl=en&sa=X&d=11066311399156471814&ei=7f3_aIbCILmAieoPlr2tqAg&scisig=ABGrvjLV6fSkcBPGA5NmFimfwxQS&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Large Language Models for Software Testing: A Research Roadmap", "first_label": ["LLM", "Software Testing"], "second_label": ["Search"], "data": "C Augusto, A Bertolino, G De Angelis, F Lonetti- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) are starting to be profiled as one of the most \nsignificant disruptions in the Software Testing field. Specifically, they have been \nsuccessfully applied in software testing tasks such as generating test code, or\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25043&hl=en&sa=X&d=1208330022631398164&ei=7f3_aIbCILmAieoPlr2tqAg&scisig=ABGrvjLqU3HMhvF_5yODTZeYJl6a&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "MAVUL: Multi-Agent Vulnerability Detection via Contextual Reasoning and Interactive Refinement", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Agent", "Reasoning"], "data": "Y Li, K Joshi, X Wang, E Wong- arXiv preprint arXiv:2510.00317, 2025\nThe widespread adoption of open-source software (OSS) necessitates the mitigation \nof vulnerability risks. Most vulnerability detection (VD) methods are limited by \ninadequate contextual understanding, restrictive single-round interactions, and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.00317&hl=en&sa=X&d=577185325914480253&ei=mIL-aNiJB7mAieoPlr2tqAg&scisig=ABGrvjIbyn7OuStXpJ3sqMy4JVsK&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Towards Human-interpretable Explanation in Code Clone Detection using LLM-based Post Hoc Explainer", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "T Racharak, C Ragkhitwetsagul, C Junplong- arXiv preprint arXiv, 2025\nRecent studies highlight various machine learning (ML)-based techniques for code \nclone detection, which can be integrated into developer tools such as static code \nanalysis. With the advancements brought by ML in code understanding, ML-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22978&hl=en&sa=X&d=13116222657243354012&ei=mIL-aNiJB7mAieoPlr2tqAg&scisig=ABGrvjLcsdvC_Wkq4bjALj1X_8xA&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "That's Deprecated! Understanding, Detecting, and Steering Knowledge Conflicts in Language Models for Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Detection", "Generation"], "data": "J Bae, C Churchwell, M Hermon, TA Hsieh, J Xu- arXiv preprint arXiv, 2025\nThis paper investigates how large language models (LLMs) behave when faced with \ndiscrepancies between their parametric knowledge and conflicting information \ncontained in a prompt. Building on prior question-answering (QA) research, we", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.19116&hl=en&sa=X&d=17901384243922605770&ei=mIL-aNiJB7mAieoPlr2tqAg&scisig=ABGrvjLZVf3VGVMR0WZAkCggQrBj&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research", "David Lo - new related research", "Bach Le - new related research"]}
{"title": "Local Agentic RAG-Based Information System Development for Intelligent Analysis of GitHub Code Repositories in Computer Science Education", "first_label": ["Code"], "second_label": ["Agent"], "data": "Z Hu, MM Paprotskyi, V Vysotska, L Chyrun, Y Ushenko\nThis study presents the development and evaluation of a local agent-based Retrieval-\nAugmented Generation (Agentic RAG) system designed for the intelligent analysis of \nGitHub repositories in computer science education and IT practice. The novelty of", "link": "https://scholar.google.com/scholar_url?url=https://www.mecs-press.org/ijmecs/ijmecs-v17-n5/IJMECS-V17-N5-7.pdf&hl=en&sa=X&d=15899062735032558573&ei=mIL-aNiJB7mAieoPlr2tqAg&scisig=ABGrvjIz9ZvXb18eqWpoqNMeLmro&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "TIT: A Tree-Structured Instruction Tuning Approach for LLM-Based Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "H Jiang, Y Wang, H Lin, P Zou, Z Zhou, A Jia, X Li- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have shown strong performance in automated \nsource-to-target code translation through pretraining on extensive code corpora. \nHowever, mainstream LLM-based code translation methods suffer from two critical", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.09400&hl=en&sa=X&d=13736189209612319180&ei=mIL-aNiJB7mAieoPlr2tqAg&scisig=ABGrvjLfQpVO1yEU3BC2VHg0FKp1&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "GenDetect: Generative Large Language Model Usage in Smart Contract Vulnerability Detection", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection"], "data": "P Ince, J Yu, JK Liu, X Du, X Luo- International Conference on Provable Security, 2025\nThe last 18 months have seen an explosion of activity in both industry and research \nin the Generative AI space, specifically Large Language Models (LLMs). Smart \ncontract vulnerability detection is no exception; as smart contracts exist on public", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-2961-2_22&hl=en&sa=X&d=11789653647626691564&ei=mIL-aNiJB7mAieoPlr2tqAg&scisig=ABGrvjLKF8la5kBRNxoIkNPsZexT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research", "Xin ZHOU - new related research"]}
{"title": "Large Language Models for Code Editing", "first_label": ["LLM", "Code"], "second_label": [], "data": "RJ Mooney, A Shi\nPretrained language models have been shown to be effective in many \nsoftwarerelated generation tasks; however, they are not well-suited for editing tasks \nduring maintaining the software as they are not designed to reason about edits. To\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://users.ece.utexas.edu/~gligoric/papers/Zhang25PhD.pdf&hl=en&sa=X&d=10229569576199033599&ei=mIL-aNiJB7mAieoPlr2tqAg&scisig=ABGrvjLpWoTa-j_SG0xO2_Fs3G5S&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents", "first_label": ["Code"], "second_label": ["Agent"], "data": "Z Yang, H Guan, V Nicolet, B Paulsen, J Dodds- arXiv preprint arXiv, 2025\nCloud infrastructure is managed through a mix of interfaces--traditionally, cloud \nconsoles, command-line interfaces (CLI), and SDKs are the tools of choice. Recently, \nInfrastructure-as-Code/IaC frameworks (eg, Terraform) have quickly gained \npopularity. Unlike conventional tools, IaC~ frameworks encode the infrastructure in a\" \nsource-of-truth\" configuration. They are capable of automatically carrying out \nmodifications to the cloud--deploying, updating, or destroying resources--to bring the\nCites: A Survey of LLM-based Automated Program Repair: Taxonomies", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.20211&hl=en&sa=X&d=10851345926058134501&ei=mIL-aJDhGdyOieoP1t-zoQM&scisig=ABGrvjJzIsIiqPDhV6XX0lKRqo0t&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:ABGrvjKFoYpfVt7EiQsbVsLwN3n6&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le", "6 new citations to articles by Abhik Roychoudhury", "4 new citations to articles by Xin ZHOU"]}
{"title": "Large Language Models for Fault Localization: An Empirical Study", "first_label": ["LLM", "Fault Localization"], "second_label": ["Localization"], "data": "YJ Xiao, RQ Hu, WW Gong, HW Li, AQ Jie- arXiv preprint arXiv:2510.20521, 2025\nLarge language models (LLMs) have demonstrated remarkable capabilities in code-\nrelated tasks, particularly in automated program repair. However, the effectiveness of \nsuch repairs is highly dependent on the performance of upstream fault localization, \nfor which comprehensive evaluations are currently lacking. This paper presents a \nsystematic empirical study on LLMs in the statement-level code fault localization task. \nWe evaluate representative open-source models (Qwen2. 5-coder-32b-instruct\nCites: When Fine-Tuning LLMs Meets Data Privacy: An Empirical Study", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.20521&hl=en&sa=X&d=5100410454727867903&ei=mIL-aJDhGdyOieoP1t-zoQM&scisig=ABGrvjJc2sVw22hcAhom6_0_gwgI&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:ABGrvjKFoYpfVt7EiQsbVsLwN3n6&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "Rapid G-CodingObtaining G-code Using AI", "first_label": ["Code"], "second_label": [], "data": "D Tiro- IOP Conference Series: Materials Science and, 2025\nThe traditional process of creating G-code is time-intensive and requires expertise in \nCNC programming. Recently, several AI software have appeared. They \ncommunicate using prompts, and the user can also provide a drawing, which the AI \nprocesses. AI software, such as ChatGPT, Bing AI Copilot, became publicly available \napproximately two years ago. The question arises whether G-code can be obtained \nusing these software. A review of the literature confirmed that no studies have\nCites: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://iopscience.iop.org/article/10.1088/1757-899X/1339/1/012014/pdf&hl=en&sa=X&d=9058890831364105878&ei=mIL-aJDhGdyOieoP1t-zoQM&scisig=ABGrvjJZdkbjbA92PQw1DWWsR0yb&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:ABGrvjKFoYpfVt7EiQsbVsLwN3n6&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le", "1 new citation to articles by Thanh Le-Cong"]}
{"title": "SymbFuzz: Symbolic Execution Guided Hardware Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "SS Miftah, A Srivastava, H Kim, S Wei, K Basu- Proceedings of the 58th IEEE/ACM, 2025\nModern hardware incorporates reusable designs to reduce cost and time to market, \ninadvertently increasing exposure to security vulnerabilities. While formal verification \nand simulation-based approaches have been traditionally utilized to mitigate these", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3725843.3756131&hl=en&sa=X&d=13892451739855032330&ei=mYL-aLamINWY6rQPrbXRgQY&scisig=ABGrvjIckMkLWaPrI55dPwVGCMUZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "MALF: A Multi-Agent LLM Framework for Intelligent Fuzzing of Industrial Control Protocols", "first_label": ["LLM", "Fuzzing"], "second_label": ["Agent"], "data": "B Ning, X Zong, K He- arXiv preprint arXiv:2510.02694, 2025\nIndustrial control systems (ICS) are vital to modern infrastructure but increasingly \nvulnerable to cybersecurity threats, particularly through weaknesses in their \ncommunication protocols. This paper presents MALF (Multi-Agent LLM Fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02694&hl=en&sa=X&d=17402884467768873558&ei=mYL-aLamINWY6rQPrbXRgQY&scisig=ABGrvjKY-EhTZJxLf3FSS8GSogrU&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Large-Scale Empirical Analysis of Continuous Fuzzing: Insights from 1 Million Fuzzing Sessions", "first_label": ["Fuzzing"], "second_label": [], "data": "T Shirai, O Nourry, Y Kashiwa, K Fujiwara, Y Kamei- arXiv preprint arXiv, 2025\nSoftware vulnerabilities are constantly being reported and exploited in software \nproducts, causing significant impacts on society. In recent years, the main approach \nto vulnerability detection, fuzzing, has been integrated into the continuous integration", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16433&hl=en&sa=X&d=4720648398624229113&ei=mYL-aLamINWY6rQPrbXRgQY&scisig=ABGrvjLvN3fPNsFOAfS3JY64ZdkS&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Minoris: Practical Out-of-Emulator Kernel Module Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Xiang, F Wang, Y Chen, Q Liu, H Wang, J Wang- IEEE Transactions on, 2025\nVulnerabilities in the Linux kernel can be exploited to perform privilege escalation \nand take over the whole system. Fuzzing has been leveraged to detect Linux kernel \nvulnerabilities during the last decade. However, existing kernel fuzzing techniques", "link": "https://scholar.google.com/scholar_url?url=http://www.malgenomeproject.org/papers/tdsc25_minoris.pdf&hl=en&sa=X&d=4018952161547770155&ei=mYL-aLamINWY6rQPrbXRgQY&scisig=ABGrvjJ6DkbswJoR00cuvD4KKxo6&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Extraction and Mutation at a High Level: Template-Based Fuzzing for JavaScript Engines", "first_label": ["Fuzzing"], "second_label": [], "data": "WK Wong, D Xiao, CT Lai, Y Peng, D Wu, S Wang- Proceedings of the ACM on, 2025\nJavaScript (JS) engines implement complex language semantics and optimization \nstrategies to support the dynamic nature of JS, making them difficult to test thoroughly \nand prone to subtle, security-critical bugs. Existing fuzzers often struggle to generate", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3763154&hl=en&sa=X&d=604366854830515299&ei=mYL-aLamINWY6rQPrbXRgQY&scisig=ABGrvjJ8_etpKvSy6Zr28o1_lt7G&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Hong Jin Kang - new related research"]}
{"title": "E-FuzzEdge: Optimizing Embedded Device Security with Scalable In-Place Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "D Rusconi, O Yousef, M Picca, F Toffalini, A Lanzi- arXiv preprint arXiv:2510.01393, 2025\nIn this paper we show E-FuzzEdge, a novel fuzzing architecture targeted towards \nimproving the throughput of fuzzing campaigns in contexts where scalability is \nunavailable. E-FuzzEdge addresses the inefficiencies of hardware-in-the-loop", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01393&hl=en&sa=X&d=876126288656849057&ei=mYL-aLamINWY6rQPrbXRgQY&scisig=ABGrvjI29yYRKrlJ80KOjroLHXeT&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Clutch Control: An Attention-based Combinatorial Bandit for Efficient Mutation in JavaScript Engine Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "M Foley, S Maffeis, MF Rozi, T Takahashi- arXiv preprint arXiv:2510.12732, 2025\nJavaScript engines are widely used in web browsers, PDF readers, and server-side \napplications. The rise in concern over their security has led to the development of \nseveral targeted fuzzing techniques. However, existing approaches use random", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12732%3F&hl=en&sa=X&d=1368299778829400409&ei=mYL-aLamINWY6rQPrbXRgQY&scisig=ABGrvjI4CAZkWhcKOyqw3pENwwii&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=6&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "DFAFUZZ: Fuzzing for Embedded JavaScript Virtual Machines with Type-Directed DFA", "first_label": ["Fuzzing"], "second_label": [], "data": "H Lai, B Hua\nJavaScript is rapidly being deployed in securitycritical embedded domains, including \nIoT devices, edge computing, and smart automotive applications. Embedded \nJavaScript virtual machines (VMs) are critical in powering such deployments, which", "link": "https://scholar.google.com/scholar_url?url=https://csslab-ustc.github.io/publications/2025/js-vm-bugs.pdf&hl=en&sa=X&d=14086662969394613156&ei=mYL-aLamINWY6rQPrbXRgQY&scisig=ABGrvjIDsQUp4KqbY58bTWR9VXh_&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=7&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "TeTRIS: General-purpose Fuzzing for Translation Bugs in Source-to-Source Code Transpilers", "first_label": ["Fuzzing", "Code", "Bug"], "second_label": ["Generation"], "data": "Y Arafat, S Nagy - 2025\nAmid the rise of heterogeneous computing and concerns over systems and \napplication security, developers are increasingly embracing transpilers: a growing \nclass of tools for converting code from one programming language into another. As", "link": "https://scholar.google.com/scholar_url?url=https://futures.cs.utah.edu/papers/25ACSAC.pdf&hl=en&sa=X&d=7907468188891103628&ei=mYL-aLamINWY6rQPrbXRgQY&scisig=ABGrvjLBdVkI2F9PVfJevtu33KlG&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=8&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "CNCFuzzer: Directed Blackbox Fuzzing of Computer Numerical Control System Based on Message Behaviour Guidance", "first_label": ["Fuzzing"], "second_label": [], "data": "Z Li, D Fang, Y Chen, S Li, J Peng, Z Song, S Lv, L Sun- ACM Transactions on Software\nIn the era of the Industrial Internet of Things, Computer Numerical Control (CNC) \nSystems are confronted with a pervasive threat from attackers. Uncovering their \nsecurity vulnerabilities before being exploited becomes imperative. Enterprise-level\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3771764&hl=en&sa=X&d=4976772631307591836&ei=mYL-aLamINWY6rQPrbXRgQY&scisig=ABGrvjJOL17g1mtB2oB5KMVu8rnH&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=9&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Bytecode-centric Detection of Known-to-be-vulnerable Dependencies in Java Projects", "first_label": ["Code"], "second_label": ["Detection"], "data": "S Schott, SE Ponta, W Fischer, J Klauke, E Bodden- arXiv preprint arXiv:2510.19393, 2025\nOn average, 71% of the code in typical Java projects comes from open-source \nsoftware (OSS) dependencies, making OSS dependencies the dominant component \nof modern software code bases. This high degree of OSS reliance comes with a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.19393&hl=en&sa=X&d=10613122554181403814&ei=mYL-aK3DEP2lieoP1Jf4uAw&scisig=ABGrvjIocRFvpdgqEqTQ-CbVBHAt&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:ABGrvjLiNx7BmV3CtCrSb8n_Y3dH&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "International Al Safety Report: First Key Update Capabilities and Risk Implications", "first_label": [], "second_label": [], "data": "Y Bengio, B Bucknall, S Clare, C Prunkl- -Robotics-Safety &, 2025\nThe field of AI is moving too quickly for a single yearly publication to keep pace. \nSignificant changes can occur on a timescale of months, sometimes weeks. This is \nwhy we are releasing Key Updates: shorter, focused reports that highlight the most \nimportant developments between full editions of the International AI Safety Report. \nWith these updates, we aim to provide policymakers, researchers, and the public with \nup-to-date information to support wise decisions about AI governance.\nCites: CVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real", "link": "https://scholar.google.com/scholar_url?url=https://s-rsa.com/index.php/agi/article/view/16253&hl=en&sa=X&d=4918445860926400796&ei=l4L-aOG3MJjO6rQPk_O3wAE&scisig=ABGrvjIoDgJlAaJO3IqOv5yNSECN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:ABGrvjIL7aJF81gdGo1gERw9ebUT&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "CourtGuard: A Local, Multiagent Prompt Injection Classifier", "first_label": [], "second_label": ["Agent"], "data": "I Wu, M Maslowski- arXiv preprint arXiv:2510.19844, 2025\nAs large language models (LLMs) become integrated into various sensitive \napplications, prompt injection, the use of prompting to induce harmful behaviors from \nLLMs, poses an ever increasing risk. Prompt injection attacks can cause LLMs to \nleak sensitive data, spread misinformation, and exhibit harmful behaviors. To defend \nagainst these attacks, we propose CourtGuard, a locally-runnable, multiagent prompt \ninjection classifier. In it, prompts are evaluated in a court-like multiagent LLM system\nCites: Adaptive attacks break defenses against indirect prompt injection\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.19844&hl=en&sa=X&d=192353389651444270&ei=l4L-aOG3MJjO6rQPk_O3wAE&scisig=ABGrvjIMVTHBYOsAKEnIO9rgsK3e&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:ABGrvjIL7aJF81gdGo1gERw9ebUT&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Toward Agentic Software Engineering Beyond Code: Framing Vision, Values, and Vocabulary", "first_label": ["Code"], "second_label": ["Agent"], "data": "R Hoda- arXiv preprint arXiv:2510.19692, 2025\nAgentic AI is poised to usher in a seismic paradigm shift in Software Engineering \n(SE). As technologists rush head-along to make agentic AI a reality, SE researchers \nare driven to establish agentic SE as a research area. While early visions of agentic \nSE are primarily focused on code-related activities, early empirical evidence calls for \na consideration of a range of socio-technical concerns to make it work in practice. \nThis paper contributes to the emerging community vision by:(a) recommending an\nCites: Unified Software Engineering agent as AI Software Engineer", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.19692&hl=en&sa=X&d=10135497587338355947&ei=mYL-aItYgamJ6g_J9pHIDg&scisig=ABGrvjKl0xKR4Afz81jXBAhVuUFw&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "E-Test: E'er-Improving Test Suites", "first_label": ["Software Testing"], "second_label": [], "data": "K Qiu, L Di Grazia, L Mariani, M Pezz - 2026\nTest suites are inherently imperfect, and testers can always enrich a suite with new \ntest cases that improve its quality and, consequently, the reliability of the target \nsoftware system. However, finding test cases that explore execution scenarios \nbeyond the scope of an existing suite can be extremely challenging and labor-\nintensive, particularly when managing large test suites over extended periods. In this \npaper, we propose E-Test, an approach that reduces the gap between the execution\nCites: Oracle-guided Program Selection from Large Language Models", "link": "https://scholar.google.com/scholar_url?url=https://www.lucadigrazia.com/papers/icse2026.pdf&hl=en&sa=X&d=6844206366695153302&ei=mYL-aItYgamJ6g_J9pHIDg&scisig=ABGrvjIzmNX1fc3o3iqlXJvIJ-pS&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury", "4 new citations to articles by Xin ZHOU"]}
{"title": "Progress in AI Safety via Normative NLP Research and Software Engineering Research", "first_label": [], "second_label": ["Search"], "data": "D Gros - 2025\nWe are in a period of rapidly increasing machine intelligence. When reviewing \nprogress, we conclude that there is a clear possibility of machines performing a \ndominant fraction of economic activity within the next few decades (reaching high \nlevel machine intelligence (HLMI) or artificial general intelligence (AGI)), which \nrequires a focus on safety. We contribute to this effort in two parts. In the first part, we \nfocus on Normative NLP, or designing Natural Language Processing systems that\nCites: Automated Repair of Programs from Large Language Models", "link": "https://scholar.google.com/scholar_url?url=https://escholarship.org/content/qt1c2056gd/qt1c2056gd.pdf&hl=en&sa=X&d=13728304821488546821&ei=mYL-aItYgamJ6g_J9pHIDg&scisig=ABGrvjJCVfuziDrNSe0rpEvJI02y&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "On Interaction Effects in Greybox Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "K Kitsios, M Bhme, A Bacchelli- arXiv preprint arXiv:2510.19984, 2025\nA greybox fuzzer is an automated software testing tool that generates new test inputs \nby applying randomly chosen mutators (eg, flipping a bit or deleting a block of bytes) \nto a seed input in random order and adds all coverage-increasing inputs to the \ncorpus of seeds. We hypothesize that the order in which mutators are applied to a \nseed input has an impact on the effectiveness of greybox fuzzers. In our experiments, \nwe fit a linear model to a dataset that contains the effectiveness of all possible\nCites: Directed greybox fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.19984&hl=en&sa=X&d=14688388263622970039&ei=mYL-aItYgamJ6g_J9pHIDg&scisig=ABGrvjKUUxnLAbdjGlV5kqjWnLnA&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "HotCat: Green and Effective Feature Selection toward Hotfix Bug Taxonomy", "first_label": ["Bug"], "second_label": [], "data": "L de la Cal, Y Cao, AI Ercevik, G Pinna, L Twist\nHotBugs. jar is a novel benchmark targeting time-critical (aka hot) fixes. We propose \nan approach to analyze the taxonomy of the bugs in HotBugs. jar by extending \nPatchCat into HotCat, integrating hotfix metadata with multi-objective optimization. \nUsing NSGA-II, we evolve bitmask-based feature subsets that balance accuracy, \nNormalized Mutual Information (NMI), and runtime. On 88 records across 17 \ncategories, Hot-Cat achieved 0.59 accuracy and 0.58 NMI in 129 seconds, with\nCites: SemFix: Program Repair via Semantic Analysis\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://solar.cs.ucl.ac.uk/pdf/de-la-Cal_2025_SSBSE.pdf&hl=en&sa=X&d=2027299733475932392&ei=mYL-aItYgamJ6g_J9pHIDg&scisig=ABGrvjLthbolOJzWRx132YNx7qOK&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "MulVuln: Enhancing Pre-trained LMs with Shared and Language-Specific Knowledge for Multilingual Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "V Nguyen, S Nepal, X Yuan, T Wu, F Chen, C Rudolph- arXiv preprint arXiv, 2025\nSoftware vulnerabilities (SVs) pose a critical threat to safety-critical systems, driving \nthe adoption of AI-based approaches such as machine learning and deep learning \nfor software vulnerability detection. Despite promising results, most existing methods", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04397%3F&hl=en&sa=X&d=15852306161444656354&ei=moL-aJGuLc-F6rQPotzKiQ0&scisig=ABGrvjK1G5x4sOA0GtoSv3NYa9I1&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "NatGVD: Natural Adversarial Example Attack towards Graph-based Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "A Rath, W Qi, Y Li, X Wang- arXiv preprint arXiv:2510.04987, 2025\nGraph-based models learn rich code graph structural information and present \nsuperior performance on various code analysis tasks. However, the robustness of \nthese models against adversarial example attacks in the context of vulnerability", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04987&hl=en&sa=X&d=16144354957589846642&ei=moL-aJGuLc-F6rQPotzKiQ0&scisig=ABGrvjKVVWD-G2UrNfBQI0a18maw&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Fuzzing C++ Compilers via Type-Driven Mutation", "first_label": ["Fuzzing"], "second_label": [], "data": "B Wang, C Chen, M Deng, J Chen, X Zhang, Y Lin- Proceedings of the ACM on, 2025\nC++ is a system-level programming language for modern software development, \nwhich supports multiple programming paradigms, including object-oriented, generic, \nand functional programming. The intrinsic complexity of these paradigms and their", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3763094&hl=en&sa=X&d=9567278433097235731&ei=moL-aJGuLc-F6rQPotzKiQ0&scisig=ABGrvjKncNY8xjPjRhCyvL8v-_9Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Exploring the Power of Diffusion Large Language Models for Software Engineering: An Empirical Investigation", "first_label": ["LLM"], "second_label": [], "data": "J Zhang, T Li, X Zhang, Q Hu, B Shi- arXiv preprint arXiv:2510.04605, 2025\nAutoregressive Large Language Models (AR-LLMs) are widely used in software \nengineering (SE) but face limitations in processing code structure information and \nsuffer from high inference latency. Diffusion LLMs (DLLMs) offer a promising", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04605&hl=en&sa=X&d=10573600647646258285&ei=moL-aJGuLc-F6rQPotzKiQ0&scisig=ABGrvjL5R-YlKad_jWq6RXhc4mcD&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in Node. js Packages", "first_label": [], "second_label": [], "data": "R Ni, AZH Yang, MC Hsu, N Sabino, L Jia, R Martins- arXiv preprint arXiv, 2025\nProgram analysis tools often produce large volumes of candidate vulnerability \nreports that require costly manual review, creating a practical challenge: how can \nsecurity analysts prioritize the reports most likely to be true vulnerabilities? This", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.20739&hl=en&sa=X&d=813196697098463917&ei=moL-aJGuLc-F6rQPotzKiQ0&scisig=ABGrvjKsA2KvzQL4x-2t-tZVcM9o&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Verifying MPI API Usage Requirements with Contracts", "first_label": [], "second_label": [], "data": "YM Oraji, S Schwitanski, A Hck, J Jenke, S Kreutzer- European MPI Users' Group, 2025\nParallel programming models such as MPI and OpenSHMEM enable the use of large-\nscale distributed-memory computers in HPC. However, programmers often miss \nsubtle rules regarding their APIs, such as properly synchronizing local memory", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-07194-1_4&hl=en&sa=X&d=7304007085462772725&ei=moL-aJGuLc-F6rQPotzKiQ0&scisig=ABGrvjIwPCshLmnDyWJNp6a1Woqp&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Repair", "Reasoning"], "data": "XC Wen, Z Lin, Y Yang, C Gao, D Ye- arXiv preprint arXiv:2510.05480, 2025\nThe exponential increase in software vulnerabilities has created an urgent need for \nautomatic vulnerability repair (AVR) solutions. Recent research has formulated AVR \nas a sequence generation problem and has leveraged large language models\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05480&hl=en&sa=X&d=17087307418542281791&ei=moL-aJGuLc-F6rQPotzKiQ0&scisig=ABGrvjJlsQcjOBCSZutD9pRzL3u0&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "From Defender to Devil? Unintended Risk Interactions Induced by LLM Defenses", "first_label": ["LLM"], "second_label": [], "data": "X Meng, T Cong, L Wang, W Chen, Z Li, S Guo- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have shown remarkable performance across \nvarious applications, but their deployment in sensitive domains raises significant \nconcerns. To mitigate these risks, numerous defense strategies have been proposed", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07968&hl=en&sa=X&d=16628375445005170696&ei=moL-aNKsEM-F6rQPotzKiQ0&scisig=ABGrvjJFN6fFD2JlXKrvW9Fj6lWu&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Formalization Driven LLM Prompt Jailbreaking via Reinforcement Learning", "first_label": ["LLM"], "second_label": [], "data": "Z Wang, D He, Z Zhang, X Li, L Zhu, M Li, J Liu- arXiv preprint arXiv:2509.23558, 2025\nLarge language models (LLMs) have demonstrated remarkable capabilities, yet they \nalso introduce novel security challenges. For instance, prompt jailbreaking attacks \ninvolve adversaries crafting sophisticated prompts to elicit responses from LLMs that", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23558%3F&hl=en&sa=X&d=2749826917926664463&ei=moL-aNKsEM-F6rQPotzKiQ0&scisig=ABGrvjJFVp0bzO3VanGduO9Dw3f2&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "HarmRLVR: Weaponizing Verifiable Rewards for Harmful LLM Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Liu, L Li, X Wang, J Shao- arXiv preprint arXiv:2510.15499, 2025\nRecent advancements in Reinforcement Learning with Verifiable Rewards (RLVR) \nhave gained significant attention due to their objective and verifiable reward signals, \ndemonstrating strong performance in reasoning and code generation tasks", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15499&hl=en&sa=X&d=3684055427722867634&ei=moL-aNKsEM-F6rQPotzKiQ0&scisig=ABGrvjIQtg1gf4x__eiLyp1jaShs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Proactive defense against LLM Jailbreak", "first_label": ["LLM"], "second_label": [], "data": "W Zhao, J Peng, D Ben-Levi, Z Yu, J Yang- arXiv preprint arXiv:2510.05052, 2025\nThe proliferation of powerful large language models (LLMs) has necessitated robust \nsafety alignment, yet these models remain vulnerable to evolving adversarial attacks, \nincluding multi-turn jailbreaks that iteratively search for successful queries. Current", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05052&hl=en&sa=X&d=12643963361954479351&ei=moL-aNKsEM-F6rQPotzKiQ0&scisig=ABGrvjITm70eJQ3DAJ41GbIUFyZv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Fewer Weights, More Problems: A Practical Attack on LLM Pruning", "first_label": ["LLM"], "second_label": [], "data": "K Egashira, R Staab, T Gloaguen, M Vero, M Vechev- arXiv preprint arXiv, 2025\nModel pruning, ie, removing a subset of model weights, has become a prominent \napproach to reducing the memory footprint of large language models (LLMs) during \ninference. Notably, popular inference engines, such as vLLM, enable users to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07985%3F&hl=en&sa=X&d=15877205037372109377&ei=moL-aNKsEM-F6rQPotzKiQ0&scisig=ABGrvjLc2zMGjcFTGp-_8sfDhRmv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Microsaccade-Inspired Probing: Positional Encoding Perturbations Reveal LLM Misbehaviours", "first_label": ["LLM"], "second_label": [], "data": "R Melo, R Abreu, CS Pasareanu- arXiv preprint arXiv:2510.01288, 2025\nWe draw inspiration from microsaccades, tiny involuntary eye movements that reveal \nhidden dynamics of human perception, to propose an analogous probing method for \nlarge language models (LLMs). Just as microsaccades expose subtle but informative", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01288&hl=en&sa=X&d=4079834350174690212&ei=moL-aNKsEM-F6rQPotzKiQ0&scisig=ABGrvjJMtJXAVeeF7NG9Bep4U4CZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "first_label": ["LLM"], "second_label": ["Agent"], "data": "VK Bonagiri, P Kumaragurum, K Nguyen, B Plaut- arXiv preprint arXiv:2510.16492, 2025\nAs Large Language Model (LLM) agents increasingly operate in complex \nenvironments with real-world consequences, their safety becomes critical. While \nuncertainty quantification is well-studied for single-turn tasks, multi-turn agentic", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16492&hl=en&sa=X&d=12122099661687534348&ei=moL-aNKsEM-F6rQPotzKiQ0&scisig=ABGrvjI4CtI_SmXhnMCPP-z7iPl7&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM Unlearning Under the Microscope: A Full-Stack View on Methods and Metrics", "first_label": ["LLM"], "second_label": [], "data": "C Fan, C Wang, Y Huang, S Pal, S Liu- arXiv preprint arXiv:2510.07626, 2025\nMachine unlearning for large language models (LLMs) aims to remove undesired \ndata, knowledge, and behaviors (eg, for safety, privacy, or copyright) while \npreserving useful model capabilities. Despite rapid progress over the past two years", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07626%3F&hl=en&sa=X&d=2219175947074663426&ei=moL-aNKsEM-F6rQPotzKiQ0&scisig=ABGrvjJT5bdpnV9SaCOVVwX2gtdv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Demystifying the Roles of LLM Layers in Retrieval, Knowledge, and Reasoning", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "X Song, K Wang, PX Li, L Yin, S Liu- arXiv preprint arXiv:2510.02091, 2025\nRecent studies suggest that the deeper layers of Large Language Models (LLMs) \ncontribute little to representation learning and can often be removed without \nsignificant performance loss. However, such claims are typically drawn from narrow", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02091%3F&hl=en&sa=X&d=1937934351809912348&ei=moL-aNKsEM-F6rQPotzKiQ0&scisig=ABGrvjIcqjlNfwqLU3ZuXogdd9E9&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SoK: Taxonomy and Evaluation of Prompt Security in Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "H Hong, S Feng, N Naderloui, S Yan, J Zhang, B Liu- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have rapidly become integral to real-world \napplications, powering services across diverse sectors. However, their widespread \ndeployment has exposed critical security risks, particularly through jailbreak prompts\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15476&hl=en&sa=X&d=16332206608507819703&ei=moL-aNKsEM-F6rQPotzKiQ0&scisig=ABGrvjInhjWj4hHpDo9BRzvE6k5O&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Bug Histories as Sources of Compiler Fuzzing Mutators", "first_label": ["Fuzzing", "Bug"], "second_label": [], "data": "L Liu, F Qin, O Legunsen, M d'Amorim- arXiv preprint arXiv:2510.07834, 2025\nBugs in compilers, which are critical infrastructure today, can have outsized negative \nimpacts. Mutational fuzzers aid compiler bug detection by systematically mutating \ncompiler inputs, ie, programs. Their effectiveness depends on the quality of the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07834&hl=en&sa=X&d=9037187058146226309&ei=mIL-aJebK77WieoPn4GZgQE&scisig=ABGrvjIG6zX5TgS9MStSGVHyXUtI&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Agentpack: A dataset of code changes, co-authored by agents and humans", "first_label": ["Code", "Code Change"], "second_label": ["Agent"], "data": "Y Zi, Z Wu, A Boruch-Gruszecki, J Bell, A Guha- arXiv preprint arXiv:2509.21891, 2025\nFine-tuning large language models for code editing has typically relied on mining \ncommits and pull requests. The working hypothesis has been that commit messages \ndescribe human intent in natural language, and patches to code describe the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.21891&hl=en&sa=X&d=8401534489153068556&ei=mIL-aJebK77WieoPn4GZgQE&scisig=ABGrvjKcIN_9P4bK8KEjoZRhHjoO&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "PCRepair: A Context-Aware Template-Based Approach for Automated Program Repair", "first_label": ["APR"], "second_label": ["Repair"], "data": "H Cao, W Zhang, Y Wang, Y Chu, M Deng, Z He- International Journal of Software, 2025\nAutomated Program Repair (APR) is increasingly vital for managing the complexity of \nmodern software systems. However, current APR techniques suffer from inefficiently \nselecting repair components, resulting in suboptimal patches. To address these", "link": "https://scholar.google.com/scholar_url?url=https://www.worldscientific.com/doi/abs/10.1142/S0218194025500731&hl=en&sa=X&d=10736890690647149823&ei=mIL-aJebK77WieoPn4GZgQE&scisig=ABGrvjKIfDzI4FxEk_Z2oR6hTnmJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Challenge on Optimization of Context Collection for Code Completion", "first_label": ["Code"], "second_label": ["Generation"], "data": "D Ustalov, E Bogomolov, A Bezzubov, Y Golubev- arXiv preprint arXiv, 2025\nThe rapid advancement of workflows and methods for software engineering using AI \nemphasizes the need for a systematic evaluation and analysis of their ability to \nleverage information from entire projects, particularly in large code bases. In this", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04349%3F&hl=en&sa=X&d=3126744820627406093&ei=mIL-aJebK77WieoPn4GZgQE&scisig=ABGrvjKnnFFcEPzyzZuaXwbxsC1c&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Zhyper: Factorized Hypernetworks for Conditioned LLM Fine-Tuning", "first_label": ["LLM"], "second_label": [], "data": "MHI Abdalla, Z Wang, C Frey, S Eger, J Grabocka- arXiv preprint arXiv:2510.19733, 2025\nLarge Language Model (LLM) conditioning refers to instructing an LLM to generate \ncontent in accordance with the norms and values of a specific culture, beliefs of a \nparticular political orientation, or any desired text-specified semantic conditioning. \nUnfortunately, prompt engineering does not ensure that LLMs behave in accordance \nwith a desired conditioning due to the inductive bias of the pre-training and \nalignment datasets. Prior works have focused on fine-tuning LLMs by directly\nCites: Exploring Parameter-Efficient Fine-Tuning Techniques for Code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.19733&hl=en&sa=X&d=9469391369852812555&ei=moL-aJjZAYePieoPtcvwuAc&scisig=ABGrvjKhdqdRmrhp1QYTpK045b4U&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ABGrvjKBQMI3rG05-NPhg-jRvIpb&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "Python Code Verification and Improvement Using Large Language Models", "first_label": ["Verification", "LLM", "Code"], "second_label": [], "data": "- 2025\nThe explosive growth of artificial intelligence (AI) has propelled large language \nmodels (LLMs) from academic curiosities to everyday development companions. By \ntranslating natural language descriptions directly into source code, LLMs promise \nunprecedented boosts in programmer productivity and faster delivery cycles. Yet, this \npromise is overshadowed by persistent concerns. Empirical studies show that \nautomatically generated code frequently embeds critical security weaknesses, subtle\nCites: Exploring Parameter-Efficient Fine-Tuning Techniques for Code", "link": "https://scholar.google.com/scholar_url?url=https://dspace.jaist.ac.jp/dspace/bitstream/10119/20038/5/paper.pdf&hl=en&sa=X&d=6870264913723236490&ei=moL-aJjZAYePieoPtcvwuAc&scisig=ABGrvjKB-AjqgAB5fUkzyYCIzkXY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ABGrvjKBQMI3rG05-NPhg-jRvIpb&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "What Do They Fix? LLM-Aided Categorization of Security Patches for Critical Memory Bugs", "first_label": ["LLM", "Bug"], "second_label": [], "data": "X Li, J Pu, Y Wu, X Zou, S Zhu, Q Wu, Z Zhang, J Hsu- arXiv preprint arXiv, 2025\nOpen-source software projects are foundational to modern software ecosystems, with \nthe Linux kernel standing out as a critical exemplar due to its ubiquity and \ncomplexity. Although security patches are continuously integrated into the Linux\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22796&hl=en&sa=X&d=5877456260761011502&ei=l4L-aLGAHM6E6rQPjY_jkQI&scisig=ABGrvjIeON_T-kQB0Y1OLfGe7VuN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
