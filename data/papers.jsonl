{"title": "Analyzing the dependability of Large Language Models for code clone generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "A Eagal, KT Stolee, JP Ore\\xc2\\xa0- Journal of Systems and Software, 2025\nThe ability to generate multiple equivalent versions of the same code segment \nacross different programming languages and within the same language is valuable \nfor code translation, language migration, and code comprehension in education\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225002171&hl=en&sa=X&d=8172210399981332567&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b8neGEDrN-Ld8JkOzvj3eeF&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "KBL: a golden keywords-based query reformulation approach for bug localization", "first_label": ["Bug"], "second_label": ["Localization"], "data": "B Cai, W Zou, Q Meng, H Xu, J Zhang\\xc2\\xa0- Empirical Software Engineering, 2025\nReformulating initial bug reports to obtain better queries for buggy code retrieval is \nan important research direction in the bug localization area. Existing query \nreformulation strategies of bug reports are generally unsupervised and may lack\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10694-2&hl=en&sa=X&d=8373958395174059718&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b8k5U65jZhLvSn4GsfMGhBx&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Retrieval-Augmented Code Review Comment Generation", "first_label": ["Code Review", "Code"], "second_label": ["Generation"], "data": "H Hong, J Baik\\xc2\\xa0- arXiv preprint arXiv:2506.11591, 2025\nAutomated code review comment generation (RCG) aims to assist developers by \nautomatically producing natural language feedback for code changes. Existing \napproaches are primarily either generation-based, using pretrained language\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11591&hl=en&sa=X&d=15885059784306332833&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b-1WT7RGxAC1bABTNtyDxhD&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "HPCTransCompile: An AI Compiler Generated Dataset for High-Performance CUDA Transpilation and LLM Preliminary Exploration", "first_label": ["LLM"], "second_label": [], "data": "J Lv, X He, Y Liu, X Dai, Y Hu, S Yin\\xc2\\xa0- arXiv preprint arXiv:2506.10401, 2025\nThe rapid growth of deep learning has driven exponential increases in model \nparameters and computational demands. NVIDIA GPUs and their CUDA-based \nsoftware ecosystem provide robust support for parallel computing, significantly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10401&hl=en&sa=X&d=14309937792901999617&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b_LyVd5W0C0U28-mRiJrH9j&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Reductive Analysis with Compiler-Guided Large Language Models for Input-Centric Code Optimizations", "first_label": ["LLM", "Code"], "second_label": [], "data": "X Wang, X Hui, C Liao, X Shen\\xc2\\xa0- Proceedings of the ACM on Programming\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInput-centric program optimization aims to optimize code by considering the relations \nbetween program inputs and program behaviors. Despite its promise, a long-\nstanding barrier for its adoption is the difficulty of automatically identifying critical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729282&hl=en&sa=X&d=4066048552262082451&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b_cHHDNeP008iH4qW9Tn7JR&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A First Look at Bugs in LLM Inference Engines", "first_label": ["LLM", "Bug"], "second_label": [], "data": "M Liu, S Zhong, W Bi, Y Zhang, Z Chen, Z Chen, X Liu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language model-specific inference engines (in short as\\\\emph {LLM inference \nengines}) have become a fundamental component of modern AI infrastructure, \nenabling the deployment of LLM-powered applications (LLM apps) across cloud and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09713&hl=en&sa=X&d=1829118811417287869&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b9PFvonW4DF-GngDik42RDE&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Bach Le - new related research"]}
{"title": "SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications", "first_label": ["LLM"], "second_label": [], "data": "J Li, X Li, G Qu, P Jacobsson, B Qin, B Hui, S Si, N Huo\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nResolution of complex SQL issues persists as a significant bottleneck in real-world \ndatabase applications. Current Large Language Models (LLMs), while adept at text-\nto-SQL translation, have not been rigorously evaluated on the more challenging task\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18951&hl=en&sa=X&d=15016797413837099283&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b8EvGjCaMjnyqMJC8gRoyX7&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A Framework for Creating Non-Regressive Test Cases via Branch Consistency Analysis Driven by Descriptions", "first_label": ["Software Testing"], "second_label": [], "data": "Y Zhang, P Xue, Z Yang, X Ren, X Li, L Wu, J Zhao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomated test-generation research overwhelmingly assumes the correctness of \nfocal methods, yet practitioners routinely face non-regression scenarios where the \nfocal method may be defective. A baseline evaluation of EvoSuite and two leading\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07486&hl=en&sa=X&d=12300473129148860276&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b8EYaZUm5p8en4HDg1pCFjV&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "On the Effectiveness of LLM-as-a-judge for Code Generation and Summarization", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "G Crupi, R Tufano, A Velasco, A Mastropaolo\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAbstract Large Language Models (LLMs) have been recently exploited as judges for \ncomplex natural language processing tasks, such as Q&A (Question & Answer). The \nbasic idea is to delegate to an LLM the assessment of the \\xe2\\x80\\x9cquality\\xe2\\x80\\x9d of the output\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/journal/ts/5555/01/11071936/2851vlBjr9e&hl=en&sa=X&d=3855054686599960749&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b_3TIYnXdiW1O8VBlraopqf&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "AdaDec: Uncertainty-Guided Adaptive Decoding for LLM-based Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "K He, M Liu, C Wang, Z Li, Y Wang, X Peng, Z Zheng\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode generation with large language models (LLMs) is highly sensitive to token \nselection during decoding, particularly at uncertain decision points that influence \nprogram logic. While standard strategies like greedy and beam search treat all\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/abs/2506.08980&hl=en&sa=X&d=13258586616362940623&ei=iUxsaO7iGaalieoP6cDi4QI&scisig=AAZF9b8MEr3Z8_Z7RsEYbOc3Nj4V&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "ZTaint-Havoc: From Havoc Mode to Zero-Execution Fuzzing-Driven Taint Inference", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Xie, W Zhang, D She\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nFuzzing is a popular software testing technique for discovering vulnerabilities. A \ncentral problem in fuzzing is identifying hot bytes that can influence program \nbehavior. Taint analysis can track the data flow of hot bytes in a white-box fashion\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728916&hl=en&sa=X&d=11807420278266769302&ei=iUxsaO7wJM2l6rQPh4i_0AE&scisig=AAZF9b8qJKOy3h08rQgyQ5y4FnqB&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "FuzzCode: Code Large Language Model-Based Fuzz Testing for Industrial IoT Programs", "first_label": ["LLM", "Fuzzing", "Code", "Software Testing"], "second_label": [], "data": "L Yang, C Wei, J Yang, W Xia, Y Yang, Y Luo, D Niyato\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Internet of Things\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFuzz testing is an dynamic program analysis technique designed for discovering \nvulnerabilities in IoT systems. The core goal is to deliberately feed maliciously crafted \ninputs into an IoT device or service, triggering vulnerabilities such as system crashes\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11028927/&hl=en&sa=X&d=8104462651931100859&ei=iUxsaO7wJM2l6rQPh4i_0AE&scisig=AAZF9b8NEppCb0nwiT9UFTmtv4yr&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Adversarial Attack Classification and Robustness Testing for Large Language Models for Code", "first_label": ["LLM", "Code", "Software Testing"], "second_label": [], "data": "Y Liu, A Foundjem, F Khomh, H Li\\xc2\\xa0- arXiv preprint arXiv:2506.07942, 2025\nLarge Language Models (LLMs) have become vital tools in software development \ntasks such as code generation, completion, and analysis. As their integration into \nworkflows deepens, ensuring robustness against vulnerabilities especially those\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07942&hl=en&sa=X&d=10411796502631711196&ei=iUxsaO7wJM2l6rQPh4i_0AE&scisig=AAZF9b-eMQpfZUdxJwBqS5XD673H&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Reasoning"], "data": "XC Wen, Y Yang, C Gao, Y Xiao, D Ye\\xc2\\xa0- arXiv preprint arXiv:2506.07390, 2025\nLarge language models (LLMs) demonstrate considerable proficiency in numerous \ncoding-related tasks; however, their capabilities in detecting software vulnerabilities \nremain limited. This limitation primarily stems from two factors:(1) the absence of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07390%3F&hl=en&sa=X&d=10299031030894150274&ei=iUxsaO7wJM2l6rQPh4i_0AE&scisig=AAZF9b_gI2XqGy6iUeaE4tdr-c1h&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "AdaptiveLLM: A Framework for Selecting Optimal Cost-Efficient LLM for Code-Generation Based on CoT Length", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Cheng, F Liu, C Wu, L Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.10525, 2025\nWhile Large Language Models (LLMs) have significantly advanced code generation \nefficiency, they face inherent challenges in balancing performance and inference \ncosts across diverse programming tasks. Dynamically selecting the optimal LLM\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10525&hl=en&sa=X&d=12946040656504681529&ei=iUxsaO7wJM2l6rQPh4i_0AE&scisig=AAZF9b8m2TloB0C3Hd11YMxRGFIR&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Program Generation Methods: Types and Instances", "first_label": [], "second_label": ["Generation"], "data": "D Borodin, A Prutzkow\\xc2\\xa0- International Journal of Open Information Technologies, 2025\nThe study systematizes existing approaches by chronological principle and \ncategories. The strategy of searching for sources consists of using modern library \nplatforms and keywords on the topic of program generation. We classified program\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=http://injoit.org/index.php/j1/article/download/2161/1937&hl=en&sa=X&d=8796434817097384330&ei=iUxsaO7wJM2l6rQPh4i_0AE&scisig=AAZF9b-idOfsqT7sK1pekHEp51Od&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "PyXray: Practical Cross-Language Call Graph Construction through Object Layout Analysis", "first_label": ["Static Analysis"], "second_label": ["Graph"], "data": "G Alexopoulos, T Sotiropoulos, G Gousios, Z Su\\xe2\\x80\\xa6\nA great number of software packages combine code in high-level languages, such \nas Python, with binary extensions compiled from low-level languages such as C, C++ \nor Rust to either boost efficiency or enable specific functionalities. In this context, high\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://grgalex.gr/assets/pdf/pyxray_icse26.pdf&hl=en&sa=X&d=15584438577859100231&ei=iUxsaO7wJM2l6rQPh4i_0AE&scisig=AAZF9b9eMKy4n1itl9D4CR9WopG3&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "FuncVul: An Effective Function Level Vulnerability Detection Model using LLM and Code Chunk", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "S Halder, ME Ahmed, S Camtepe\\xc2\\xa0- arXiv preprint arXiv:2506.19453, 2025\nSoftware supply chain vulnerabilities arise when attackers exploit weaknesses by \ninjecting vulnerable code into widely used packages or libraries within software \nrepositories. While most existing approaches focus on identifying vulnerable\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.19453&hl=en&sa=X&d=2355126994281101941&ei=iUxsaMT3E82l6rQPh4i_0AE&scisig=AAZF9b8nV7dMzuUWlB0QlvHRGoC6&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "To Model, to Prompt, or to Code? The Choice Is Yours: A Multi-Paradigmatic Approach to Software Development", "first_label": ["Code"], "second_label": [], "data": "T Buchmann, F Schw\\xc3\\xa4gerl, R Peinl - 2025\nThis paper considers three fundamental approaches to software development, \nnamely manual coding, modeldriven software engineering, and code generation by \nlarge language models. All of these approaches have their individual pros and cons, \nmotivating the desire for an integrated approach. We present MoProCo, a technical \nsolution to integrate the three approaches into a single tool chain, allowing the \ndeveloper to split a software engineering task into modeling, prompting or coding\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomatic Programming: Large Language Models and Beyond\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.scitepress.org/Papers/2025/135571/135571.pdf&hl=en&sa=X&d=11698545604526486650&ei=iUxsaJyWG7vM6rQP-5ru-QU&scisig=AAZF9b_Yc2npUX2Rjr_kPnbBx0Y0&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Exploring Zero-Shot Prompting for Generating Data Format Descriptions", "first_label": [], "second_label": [], "data": "P Anantharaman, V Varadharaju\\xc2\\xa0- 2025 IEEE Security and Privacy Workshops (SPW), 2025\nParsers validate and process untrusted user input and transform it into data \nstructures that provide easier access. Software engineers either build these parsers \nfor data formats from scratch or leverage libraries targeting specific formats. The \nrecent surge in data description languages (DDLs) and parser combinator libraries \nfor parsing data formats has aided developers in producing parsers using \nstandardized tools. However, producing a parser for an unfamiliar data format in an\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11050832/&hl=en&sa=X&d=2153662549751710342&ei=iUxsaJyWG7vM6rQP-5ru-QU&scisig=AAZF9b_UqdNXSkM6j71YOe3hos5y&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "TransferFuzz-Pro: Large Language Model Driven Code Debugging Technology for Verifying Propagated Vulnerability", "first_label": ["Vulnerabilities", "LLM", "Fuzzing", "Code", "Bug"], "second_label": [], "data": "S Li, K Xie, Y Li, H Li, Y Ren, L Sun, H Zhu\\xc2\\xa0- IEEE Transactions on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode reuse in software development frequently facilitates the spread of \nvulnerabilities, leading to imprecise scopes of affected software in CVE reports. \nTraditional methods focus primarily on detecting reused vulnerability code in target \nsoftware but lack the ability to confirm whether these vulnerabilities can be triggered \nin new software contexts. In previous work, we introduced the TransferFuzz \nframework to address this gap by using historical trace-based fuzzing. However, its\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11066171/&hl=en&sa=X&d=4037450502686363181&ei=iUxsaJyWG7vM6rQP-5ru-QU&scisig=AAZF9b_wsst2tlkLPk6iCbi8LdVm&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "LLM-Driven Code Refactoring: Opportunities and Limitations", "first_label": ["LLM", "Code"], "second_label": [], "data": "J Cordeiro, S Noei, Y Zou\\xc2\\xa0- 2025 IEEE/ACM Second IDE Workshop (IDE), 2025\nRefactoring is a systematic process of improving code quality while preserving the \nfunctional behavior of the software. In recent years, integrated development \nenvironments (IDEs) have added or improved automatic refactoring in their features, \nto enhance developers' productivity and reduce the likelihood of human errors. With \nthe advancement and increasing popularity of large language models (LLMs), \ncoding automation using them has gained enormous attention and has shown to be\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAngelix: Scalable multiline program patch synthesis via symbolic\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/ide/2025/018800a032/27ZLzLyi5ZS&hl=en&sa=X&d=12236558554458443249&ei=iUxsaJyWG7vM6rQP-5ru-QU&scisig=AAZF9b9cjO-riikBduPhXcgXPwAV&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Designing With AI: A Study of Non-Developer Software Creation Using ChatGPT", "first_label": ["LLM"], "second_label": [], "data": "MK Taspunar - 2025\nThis thesis investigates the potential of enabling non-developers to create functional \nsoftware applications comparable to those built by experienced developers through \nthe use of AI-assisted coding tools, specifically focusing on ChatGPT. The study \nexplores whether AI-powered code generation can effectively bridge the gap \nbetween users with no programming background and professional developers, thus \ndemocratizing software development. A mixed-methods approach was employed\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.diva-portal.org/smash/get/diva2:1975899/FULLTEXT01.pdf&hl=en&sa=X&d=4213015147011324533&ei=iUxsaJKmGK6l6rQP7MCumQ8&scisig=AAZF9b9mpknJwkOIq3p9_XsB_zJi&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le", "1 new citation to articles by Thanh Le-Cong"]}
{"title": "BCAAS: A Blockchain-Based Certificateless Anonymous Aggregate Signcryption Scheme Using Edge Computing", "first_label": ["Blockchain"], "second_label": [], "data": "X Chen, Q Cheng, X Luo\\xc2\\xa0- IEEE Transactions on Vehicular Technology, 2025\nWith the advancement of intelligent transportation systems, advanced traffic \ninformation service systems have emerged as critical infrastructure that integrates \nmulti-source data to offer real-time traffic condition services. Current systems mainly \nrely on cloud computing for centralized data storage and flexible resource \nscheduling. However, this architecture is vulnerable to service disruptions from \nsingle-point failures. The centrally stored sensitive data raises privacy breach risks\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11063329/&hl=en&sa=X&d=16402366462725922424&ei=iUxsaJKmGK6l6rQP7MCumQ8&scisig=AAZF9b8FAtu9SKVYMZdHs_HmfpGf&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "Time and Cost Savings Associated With the Use of Smart Contracts on the Swedish Real Estate Market", "first_label": ["Smart Contracts"], "second_label": [], "data": "H G\\xc3\\xb6ranson - 2025\nThe Swedish real estate sector, while efficient compared to global standards, \nremains characterized by manual, paper-heavy processes that introduce \nadministrative delays and transaction costs. This thesis explores the potential of \nsmart contracts, self-executing agreements based on blockchain technology, to \nreduce time and cost inefficiencies in residential property transactions on the \nSwedish real estate market. Using a mixed-methods approach that includes semi\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.diva-portal.org/smash/get/diva2:1979253/FULLTEXT01.pdf&hl=en&sa=X&d=14630972224412669177&ei=iUxsaJKmGK6l6rQP7MCumQ8&scisig=AAZF9b-oJ-TzPHlrHAL8BupcVNMP&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "Learning never stops: Improving software vulnerability type identification via incremental learning", "first_label": ["Vulnerabilities"], "second_label": [], "data": "J Xue, X Chen, Z Cui, Y Liu\\xc2\\xa0- Journal of Systems and Software, 2025\nAs new vulnerabilities are continuously discovered, software vulnerability type \nidentification (SVTI) data is dynamic. Moreover, SVTI data often exhibits a long-tailed \ndistribution, where some vulnerability types (ie, head classes) have numerous\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225002134&hl=en&sa=X&d=8336644414088433817&ei=iUxsaKS9HLWP6rQP2NG60As&scisig=AAZF9b_2IKzcE3nveqhF8ZQiR11H&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "1 new citation to articles by Xin ZHOU"]}
{"title": "From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Y Mao, T Cui, P Liu, D You, H Zhu\\xc2\\xa0- arXiv preprint arXiv:2506.15170, 2025\nLarge language models (LLMs) are rapidly evolving from single-modal systems to \nmultimodal LLMs and intelligent agents, significantly expanding their capabilities \nwhile introducing increasingly severe security risks. This paper presents a systematic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15170&hl=en&sa=X&d=16427093263132639213&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b-zqUEdPZ8IyWJxfUDycl5Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Emoji attack: Enhancing jailbreak attacks against judge llm detection", "first_label": ["LLM"], "second_label": ["Detection"], "data": "Z Wei, Y Liu, NB Erichson\\xc2\\xa0- Forty-second International Conference on Machine\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreaking techniques trick Large Language Models (LLMs) into producing \nrestricted output, posing a potential threat. One line of defense is to use another LLM \nas a Judge to evaluate the harmfulness of generated text. However, we reveal that\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DQ0rKYiVEZq&hl=en&sa=X&d=17491126507172914063&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b_yTB1R20z-t6ApkecZnFST&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems", "first_label": ["LLM"], "second_label": ["Agent", "Search"], "data": "X Li, J Chen, X Fang, S Ding, H Duan, Q Liu, K Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown remarkable capabilities in solving \ndiverse tasks. However, their proficiency in iteratively optimizing complex solutions \nthrough learning from previous feedback remains insufficiently explored. To bridge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10764&hl=en&sa=X&d=1134890120116902745&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b8s_mGNSGwzfKFs6o2hgsbd&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "L Jiang, Z Zhang, Z Wang, X Sun, Z Li, L Zhen, X Xu\\xc2\\xa0- arXiv preprint arXiv:2506.16760, 2025\nLarge Vision-Language Models (LVLMs) demonstrate exceptional performance \nacross multimodal tasks, yet remain vulnerable to jailbreak attacks that bypass built-\nin safety mechanisms to elicit restricted content generation. Existing black-box\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16760&hl=en&sa=X&d=12136733750645262486&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b8NosIP6RI9jYFVbBgmH01C&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring", "first_label": ["LLM"], "second_label": [], "data": "Y Li, Q Sheng, Y Yang, X Zhang, J Cao\\xc2\\xa0- arXiv preprint arXiv:2506.09996, 2025\nThough safety alignment has been applied to most large language models (LLMs), \nLLM service providers generally deploy a subsequent moderation as the external \nsafety guardrail in real-world products. Existing moderators mainly practice a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09996&hl=en&sa=X&d=8967671192696781749&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b-I099JquXawda445fWweEs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM Jailbreak Oracle", "first_label": ["LLM"], "second_label": [], "data": "S Lin, A Suri, A Oprea, C Tan\\xc2\\xa0- arXiv preprint arXiv:2506.17299, 2025\nAs large language models (LLMs) become increasingly deployed in safety-critical \napplications, the lack of systematic methods to assess their vulnerability to jailbreak \nattacks presents a critical security gap. We introduce the jailbreak oracle problem\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17299&hl=en&sa=X&d=13276394224623482198&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b9_2v0eFVwHwueuxrSl-vyP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Use Property-Based Testing to Bridge LLM Code Generation and Validation", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation"], "data": "L He, Z Chen, Z Zhang, J Shao, X Gao, L Sheng\\xc2\\xa0- arXiv preprint arXiv:2506.18315, 2025\nLarge Language Models (LLMs) excel at code generation, but ensuring their outputs \nto be functionally correct, especially in complex programming tasks, is a persistent \nchallenge. While traditional Test-Driven Development (TDD) offers a path for code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18315&hl=en&sa=X&d=3101719763251668573&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b8VwRdS0BYT5dVQlhiDylYe&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning", "first_label": ["LLM"], "second_label": [], "data": "GJ Perin, R Chen, X Chen, NST Hirata, Z Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have become indispensable in real-world \napplications. However, their widespread adoption raises significant safety concerns, \nparticularly in responding to socially harmful questions. Despite substantial efforts to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15606&hl=en&sa=X&d=5494164285246185827&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b83jkzg6GWJfE0yBor7b9qA&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Context manipulation attacks: Web agents are susceptible to corrupted memory", "first_label": [], "second_label": ["Agent"], "data": "AS Patlan, A Hebbar, P Viswanath, P Mittal\\xc2\\xa0- arXiv preprint arXiv:2506.17318, 2025\nAutonomous web navigation agents, which translate natural language instructions \ninto sequences of browser actions, are increasingly deployed for complex tasks \nacross e-commerce, information retrieval, and content discovery. Due to the stateless\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17318&hl=en&sa=X&d=5832395619822196251&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b9s0vj_fsKQ_zB6ujfs5QJc&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "When Style Breaks Safety: Defending Language Models Against Superficial Style Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Xiao, S Tonekaboni, W Gerych, V Suriyakumar\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) can be prompted with specific styles (eg, formatting \nresponses as lists), including in jailbreak queries. Although these style patterns are \nsemantically unrelated to the malicious intents behind jailbreak queries, their safety\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07452&hl=en&sa=X&d=14291869118481763294&ei=iUxsaODeIe2rieoP-PKl6QY&scisig=AAZF9b-0bTujJ8d_dpW8Eytxq3G4&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Leveraging activation and optimisation layers as dynamic strategies in the multi-task fuzzing scheme", "first_label": ["Fuzzing"], "second_label": [], "data": "S Bamohabbat Chafjiri, P Legg, MA Tsompanas\\xe2\\x80\\xa6 - 2025\nFuzzing is a common technique for identifying vulnerabilities in software. Recent \napproaches, like She et al.'s Multi-Task Fuzzing (MTFuzz), use neural networks to \nimprove fuzzing efficiency. However, key elements like network architecture and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1016/j.csi.2025.104011&hl=en&sa=X&d=18210490462320417689&ei=iUxsaPn6Hde5ieoPgIGkkA0&scisig=AAZF9b-SniAFgKPoPY_eeSgA0SFX&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Reassessing Code Authorship Attribution in the Era of Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "AK Dipongkor, Z Yao, K Moran\\xc2\\xa0- arXiv preprint arXiv:2506.17120, 2025\nThe study of Code Stylometry, and in particular Code Authorship Attribution (CAA), \naims to analyze coding styles to identify the authors of code samples. CAA is crucial \nin cybersecurity and software forensics for addressing, detecting plagiarism, and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17120&hl=en&sa=X&d=12069506939304281396&ei=iUxsaLTNFpPN6rQPhMr3yAg&scisig=AAZF9b9OxubQtYi2lTNPr1YQmcjb&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "ConTested: Consistency-Aided Tested Code Generation with LLM", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation"], "data": "J Dong, J Sun, W Zhang, JS Dong, D Hao\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent advancements in large language models (LLMs) have significantly improved \ncode generation, which generates code snippets automatically based on natural \nlanguage requirements. Despite achieving state-of-the-art performance, LLMs often\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728902&hl=en&sa=X&d=551936643568606765&ei=iUxsaLTNFpPN6rQPhMr3yAg&scisig=AAZF9b_BffNT3Tq28AAfyZzriimH&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "TypyBench: Evaluating LLM Type Inference for Untyped Python Repositories", "first_label": ["LLM"], "second_label": [], "data": "H Dong, J Yang, X Deng, Y Jiang, G Pekhimenko\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nType inference for dynamic languages like Python is a persistent challenge in \nsoftware engineering. While large language models (LLMs) have shown promise in \ncode understanding, their type inference capabilities remain underexplored. We\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dxl9sv9vEDy&hl=en&sa=X&d=5590401666570182726&ei=iUxsaLTNFpPN6rQPhMr3yAg&scisig=AAZF9b_1v2ZiYt35IkKDr0FkrnZ_&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Nemotron-CORTEXA: Enhancing LLM Agents for Software Engineering Tasks via Improved Localization and Solution Diversity", "first_label": ["LLM"], "second_label": ["Agent", "Localization"], "data": "A Sohrabizadeh, J Song, M Liu, R Roy, C Lee\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nLarge Language Models (LLMs) have demonstrated significant potential in code \ngeneration by following natural language instructions. Unfortunately, crucial real-\nworld software engineering tasks, such as debugging or repository-level feature\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dk6p8UKRdH7&hl=en&sa=X&d=951048739864022913&ei=iUxsaLTNFpPN6rQPhMr3yAg&scisig=AAZF9b-H11fzuFCoL6Gk97_KnR7i&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Precisely Detecting Python Type Errors via LLM-based Unit Test Generation", "first_label": ["LLM", "Software Testing"], "second_label": ["Detection", "Generation"], "data": "C Yang, Z Wang, Y Jiang, L Yang, Y Zheng, J Zhou\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nType errors in Python often lead to runtime failures, posing significant challenges to \nsoftware reliability and developer productivity. Existing static analysis tools aim to \ndetect such errors without execution but frequently suffer from high false positive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2507.02318&hl=en&sa=X&d=10550404789210041321&ei=iUxsaLTNFpPN6rQPhMr3yAg&scisig=AAZF9b_WrA-mJ_gHGIH5oUCaTKbi&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Mapping NVD Records to Their VFCs: How Hard is it?", "first_label": [], "second_label": [], "data": "HH Nguyen, DM Tran, Y Cheng, T Le-Cong, HJ Kang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMapping National Vulnerability Database (NVD) records to vulnerability-fixing \ncommits (VFCs) is crucial for vulnerability analysis but challenging due to sparse \nexplicit links in NVD references. This study explores this mapping's feasibility through\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09702&hl=en&sa=X&d=17350753801902205444&ei=iUxsaLywI8zM6rQP_8mNwQs&scisig=AAZF9b9GdE1B-xLLhUOLme72JT4D&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Today's Cat Is Tomorrow's Dog: Accounting for Time-Based Changes in the Labels of ML Vulnerability Detection Approaches", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "R Paramitha, Y Feng, F Massacci\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nVulnerability datasets used for ML testing implicitly contain retrospective information. \nWhen tested on the field, one can only use the labels available at the time of training \nand testing (eg seen and assumed negatives). As vulnerabilities are discovered\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715731&hl=en&sa=X&d=7396654833478791244&ei=iUxsaLywI8zM6rQP_8mNwQs&scisig=AAZF9b8Le9KZc3LupQcs5YssN_DQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "VulStamp: Vulnerability Assessment using Large Language Model", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "M Hu, X Xie, J Li, M Chen\\xc2\\xa0- arXiv preprint arXiv:2506.11484, 2025\nAlthough modern vulnerability detection tools enable developers to efficiently identify \nnumerous security flaws, indiscriminate remediation efforts often lead to superfluous \ndevelopment expenses. This is particularly true given that a substantial portion of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11484&hl=en&sa=X&d=10210371631874132603&ei=iUxsaLywI8zM6rQP_8mNwQs&scisig=AAZF9b8D5-GPG5LVOP0Ejn5MaoBB&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "PREFACE-A Reinforcement Learning Framework for Code Verification via LLM Prompt Repair", "first_label": ["Verification", "LLM", "Code"], "second_label": ["Repair"], "data": "M Jha, J Wan, H Zhang, D Chen\\xc2\\xa0- Proceedings of the Great Lakes Symposium on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have emerged as powerful tools for code \ngeneration. Yet, they often struggle to produce code that is both syntactically and \nsemantically correct, particularly when correctness must be formally verified\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3716368.3735300&hl=en&sa=X&d=13382965706076482844&ei=iUxsaLywI8zM6rQP_8mNwQs&scisig=AAZF9b-4t4cRZQ4ZX29y9rKLFJ1R&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "AST2CVCode: A New Benchmark Dataset for Source Code Generation on Computer Vision Applications", "first_label": ["Code"], "second_label": ["Generation"], "data": "WS Alshehri, SK Jarraya, AA Allinjawi\\xc2\\xa0- International Conference on Advanced\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBenchmark datasets are important in evaluating various methods for source code \ngeneration tasks. In this paper, we present AST2CVCode, a new benchmark dataset \nto enhance deep learning models for source code generation. AST2CVCode is\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-91337-2_46&hl=en&sa=X&d=15545214955806460595&ei=iUxsaLywI8zM6rQP_8mNwQs&scisig=AAZF9b-xEY_Bo700rs_NZO5gdshG&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=8&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "On Predicting Vulnerability Severity Using In-Context Learning: An Industrial Case Study", "first_label": ["Vulnerabilities"], "second_label": [], "data": "D Rodriguez-Cardenas, DN Palacio, A Schmedding\\xe2\\x80\\xa6 - 2025\nModern software systems demand earlier vulnerability severity detection to protect \nsystems from critical issues such as data leaking or attacker access. Security \nanalysts are in charge of triaging the vulnerability severity by computing a score\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.authorea.com/doi/pdf/10.22541/au.175033470.05916058&hl=en&sa=X&d=13350311129524430544&ei=iUxsaLywI8zM6rQP_8mNwQs&scisig=AAZF9b9J_sXjT3UaQPWnFl14GrrB&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=9&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Artificial intelligence security and privacy: a survey", "first_label": [], "second_label": [], "data": "X He, G Xu, X Han, Q Wang, L Zhao, C Shen, C Lin\\xe2\\x80\\xa6\\xc2\\xa0- Science China Information\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nArtificial intelligence (AI) is revolutionizing both industries and reshaping the global \neconomy. However, the rapid advancement of AI technologies brings significant \nsecurity and privacy challenges. Recent incidents highlight vulnerabilities in AI \nsystems, such as data leakage and malicious code injection, leading to severe \nfinancial losses and privacy breaches. Although existing studies have discussed \nspecific security threats, they often lack detailed granularity and cover a limited\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11432-025-4388-5&hl=en&sa=X&d=4615437522668012197&ei=iUxsaIa0FdSWieoP7_C3mAw&scisig=AAZF9b9vHhHMA0n1vnCfMlLnzwX_&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "What LLM Knows About Cybersecurity", "first_label": ["LLM"], "second_label": [], "data": "D Namiot\\xc2\\xa0- International Journal of Open Information Technologies, 2025\nThe article is devoted to testing large language models (LLM). Cybersecurity \nknowledge is chosen as the subject of testing. The work provides an overview of test \ndatasets (benchmarks) that can be used to test LLM knowledge in the field of \ncybersecurity. Technically, these are tens of thousands of questions covering a wide \nvariety of areas: monitoring computer networks and planning their topology, \nconducting network analysis, creating reports and quickly finding and eliminating\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=http://www.injoit.ru/index.php/j1/article/viewFile/2214/1931&hl=en&sa=X&d=6406596895346885781&ei=iUxsaIa0FdSWieoP7_C3mAw&scisig=AAZF9b9l6Lo6UXsheQzG6rBuJ0Yb&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
