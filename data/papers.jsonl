{"title": "Benchmarking and Enhancing LLM Agents in Localizing Linux Kernel Bugs", "first_label": ["LLM", "Bug"], "second_label": ["Agent"], "data": "Z Zhou, Z Huang, Y He, C Wang, J Wang, Y Wu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe Linux kernel is a critical system, serving as the foundation for numerous systems. \nBugs in the Linux kernel can cause serious consequences, affecting billions of users. \nFault localization (FL), which aims at identifying the buggy code elements in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19489&hl=en&sa=X&d=5423267053063243497&ei=_To6aPOHLvCuieoP583H-QE&scisig=AAZF9b878lFx_yyrSwyxXS7AFUdW&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research", "Hong Jin Kang - new related research", "Bach Le - new related research"]}
{"title": "OmniGIRL: A Multilingual and Multimodal Benchmark for GitHub Issue Resolution", "first_label": [], "second_label": [], "data": "L Guo, W Tao, R Jiang, Y Wang, J Chen, X Liu, Y Ma\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe GitHub issue resolution task aims to resolve issues reported in repositories \nautomatically. With advances in large language models (LLMs), this task has gained \nincreasing attention, and several benchmarks are proposed to evaluate the issue\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.04606&hl=en&sa=X&d=17721785651242552030&ei=_To6aPOHLvCuieoP583H-QE&scisig=AAZF9b9vdcHDALBkXHSBcEUw295J&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "An Initial Exploration of Fine-tuning Small Language Models for Smart Contract Reentrancy Vulnerability Detection", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection"], "data": "IMA Pofcher, J Ellul\\xc2\\xa0- arXiv preprint arXiv:2505.19059, 2025\nLarge Language Models (LLMs) are being used more and more for various coding \ntasks, including to help coders identify bugs and are a promising avenue to support \ncoders in various tasks including vulnerability detection--particularly given the\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19059&hl=en&sa=X&d=12271959285401645103&ei=_To6aPOHLvCuieoP583H-QE&scisig=AAZF9b-tz4VcQl4lnkbigykE95Vr&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "Bach Le - new related research", "Xin ZHOU - new related research"]}
{"title": "SecVulEval: Benchmarking LLMs for Real-World C/C++ Vulnerability Detection", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "MBU Ahmed, NS Harzevili, J Shin, HV Pham, S Wang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown promise in software engineering tasks, \nbut evaluating their effectiveness in vulnerability detection is challenging due to the \nlack of high-quality datasets. Most existing datasets are limited to function-level\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19828&hl=en&sa=X&d=2630223575255048352&ei=_To6aLTPMtOj6rQPzMDA4AM&scisig=AAZF9b92zF2W1A5nttkMmSQwbQlW&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "3 new citations to articles by Xin ZHOU", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Advancing Large Language Models for Code Using Code-Structure-Aware Methods", "first_label": ["LLM", "Code"], "second_label": [], "data": "L Gong, A Cheung, D Song, S Wang - 2025\n1.1 Background Traditional neural program synthesis, before rise of large language \nmodels (LLMs), typically involves a multi-step process. First, a domain-specific \nlanguage (DSL) tailored to the specific task is defined. Second, a neural network is\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-50.pdf&hl=en&sa=X&d=8004805679739932688&ei=_To6aLTPMtOj6rQPzMDA4AM&scisig=AAZF9b8CfjWUOH0jV-X-Qo3R-vFv&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Bach Le - new related research", "Xin ZHOU - new related research"]}
{"title": "Eradicating the Unseen: Detecting, Exploiting, and Remediating a Path Traversal Vulnerability across GitHub", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Exploit"], "data": "J Akhoundali, H Hamidi, K Rietveld, O Gadyatskaya\\xc2\\xa0- arXiv preprint arXiv:2505.20186, 2025\nVulnerabilities in open-source software can cause cascading effects in the modern \ndigital ecosystem. It is especially worrying if these vulnerabilities repeat across many \nprojects, as once the adversaries find one of them, they can scale up the attack very\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20186&hl=en&sa=X&d=17964872299739194092&ei=_To6aLTPMtOj6rQPzMDA4AM&scisig=AAZF9b9KOcCUhRClf9qcZGif5Pyf&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "1 new citation to articles by Quang-Cuong Bui", "3 new citations to articles by Xin ZHOU", "5 new citations to articles by Richard Fang"]}
{"title": "Generalizing Large Language Model Usability Across Resource-Constrained", "first_label": ["LLM"], "second_label": [], "data": "YD Tsai\\xc2\\xa0- arXiv preprint arXiv:2505.17040, 2025\nLarge Language Models (LLMs) have achieved remarkable success across a wide \nrange of natural language tasks, and recent efforts have sought to extend their \ncapabilities to multimodal domains and resource-constrained environments\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17040&hl=en&sa=X&d=7601533979950047834&ei=_To6aLTPMtOj6rQPzMDA4AM&scisig=AAZF9b_66D3rDTMr9zmGIqnqzkDw&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "VeriThoughts: Enabling Automated Verilog Code Generation using Reasoning and Formal Verification", "first_label": ["Verification", "Code"], "second_label": ["Generation", "Reasoning"], "data": "P Yubeaton, A Nakkab, W Xiao, L Collini, R Karri\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis paper introduces VeriThoughts, a novel dataset designed for reasoning-based \nVerilog code generation. We establish a new benchmark framework grounded in \nformal verification methods to evaluate the quality and correctness of generated\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20302&hl=en&sa=X&d=11890867777191535926&ei=_To6aLTPMtOj6rQPzMDA4AM&scisig=AAZF9b8pRfOIMOtijrNWgrO9ZW-o&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Evaluating Large Language Models for Code Review", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "U Cihan, A \\xc4\\xb0\\xc3\\xa7\\xc3\\xb6z, V Haratian, E T\\xc3\\xbcz\\xc3\\xbcn\\xc2\\xa0- arXiv preprint arXiv:2505.20206, 2025\nContext: Code reviews are crucial for software quality. Recent AI advances have \nallowed large language models (LLMs) to review and fix code; now, there are tools \nthat perform these reviews. However, their reliability and accuracy have not yet been\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20206&hl=en&sa=X&d=15665831858314714693&ei=_To6aLTPMtOj6rQPzMDA4AM&scisig=AAZF9b_nX5EjD1ohxo-XwLW6C4w4&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Large Language Models in Code Co-generation for Safe Autonomous Vehicles", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "A Nouri, B Cabrero-Daniel, Z Fei, K Ronanki\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware engineers in various industrial domains are already using Large Language \nModels (LLMs) to accelerate the process of implementing parts of software systems. \nWhen considering its potential use for ADAS or AD systems in the automotive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19658&hl=en&sa=X&d=2378770094184758104&ei=_To6aLTPMtOj6rQPzMDA4AM&scisig=AAZF9b8t3vww3k5dUfWAwM3lPjBs&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "An Empirical Study on Strong-Weak Model Collaboration for Repo-level Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "S Gandhi, A Naik, Y Xie, C Rose\\xc2\\xa0- arXiv preprint arXiv:2505.20182, 2025\nWe study cost-efficient collaboration between strong and weak language models for \nrepository-level code generation, where the weak model handles simpler tasks at \nlower cost, and the most challenging tasks are delegated to the strong model. While\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20182&hl=en&sa=X&d=13261729674581282450&ei=_To6aLTPMtOj6rQPzMDA4AM&scisig=AAZF9b-Lg9yAsZ6wE1yu59D_dyjp&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "An LLM-as-Judge Metric for Bridging the Gap with Human Evaluation in SE Tasks", "first_label": ["LLM"], "second_label": [], "data": "X Zhou, K Kim, T Zhang, M Weyssow, LF Gomes\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) and other automated techniques have been \nincreasingly used to support software developers by generating software artifacts \nsuch as code snippets, patches, and comments. However, accurately assessing the \ncorrectness of these generated artifacts remains a significant challenge. On one \nhand, human evaluation provides high accuracy but is labor-intensive and lacks \nscalability. On the other hand, other existing automatic evaluation metrics are\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLeveraging large language model for automatic patch correctness\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20854&hl=en&sa=X&d=14069950555695470496&ei=_To6aIfwO_el6rQP6dvK4Ao&scisig=AAZF9b8c3og41ZUmO1OwSb4ztOoy&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["3 new citations to articles by Xin ZHOU", "2 new citations to articles by Thanh Le-Cong", "Hong Jin Kang - new related research", "3 new citations to articles by Bach Le"]}
{"title": "R-bench: Graduate-level multi-disciplinary benchmarks for llm & mllm complex reasoning evaluation", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "MH Guo, J Xu, Y Zhang, J Song, H Peng, YX Deng\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nReasoning stands as a cornerstone of intelligence, enabling the synthesis of existing \nknowledge to solve complex problems. Despite remarkable progress, existing \nreasoning benchmarks often fail to rigorously evaluate the nuanced reasoning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.02018%3F&hl=en&sa=X&d=8843826795691330105&ei=_jo6aMsmybHqtA_6sKHgAQ&scisig=AAZF9b8oZTpHhJulcZKPuCXTowVa&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A Critical Evaluation of Defenses against Prompt Injection Attacks", "first_label": [], "second_label": [], "data": "Y Jia, Z Shao, Y Liu, J Jia, D Song, NZ Gong\\xc2\\xa0- arXiv preprint arXiv:2505.18333, 2025\nLarge Language Models (LLMs) are vulnerable to prompt injection attacks, and \nseveral defenses have recently been proposed, often claiming to mitigate these \nattacks successfully. However, we argue that existing studies lack a principled\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.18333&hl=en&sa=X&d=15080498822608719167&ei=_jo6aMsmybHqtA_6sKHgAQ&scisig=AAZF9b9w22kjFlvYfKMJ6LeMbcWO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "ACE: A Security Architecture for LLM-Integrated App Systems", "first_label": ["LLM"], "second_label": [], "data": "E Li, T Mallick, E Rose, W Robertson, A Oprea\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM-integrated app systems extend the utility of Large Language Models (LLMs) \nwith third-party apps that are invoked by a system LLM using interleaved planning \nand execution phases to answer user queries. These systems introduce new attack\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.20984&hl=en&sa=X&d=3998395298276971569&ei=_jo6aMsmybHqtA_6sKHgAQ&scisig=AAZF9b9c-SzDc9aTwMz6OjIT80SJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Lifelong Safety Alignment for Language Models", "first_label": ["LLM"], "second_label": [], "data": "H Wang, Z Qin, Y Zhao, C Du, M Lin, X Wang, T Pang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLMs have made impressive progress, but their growing capabilities also expose \nthem to highly flexible jailbreaking attacks designed to bypass safety alignment. \nWhile many existing defenses focus on known types of attacks, it is more critical to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20259&hl=en&sa=X&d=16834372085988299596&ei=_jo6aMsmybHqtA_6sKHgAQ&scisig=AAZF9b_hzOBtTr_Hfs9mhE0Z4SFO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "An Embarrassingly Simple Defense Against LLM Abliteration Attacks", "first_label": ["LLM"], "second_label": [], "data": "HA Shairah, HAAK Hammoud, B Ghanem, G Turkiyyah\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are typically aligned to comply with safety guidelines \nby refusing harmful instructions. A recent attack, termed abliteration, isolates and \nsuppresses the single latent direction most responsible for refusal behavior, enabling\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19056&hl=en&sa=X&d=3737202939224050048&ei=_jo6aMsmybHqtA_6sKHgAQ&scisig=AAZF9b8QKV5yRTnfm0WbZVG9RAGO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Poison in the Well: Feature Embedding Disruption in Backdoor Attacks", "first_label": [], "second_label": [], "data": "Z Feng, J Chen, C Zhou, Y Pu, Q Li, S Ji\\xc2\\xa0- arXiv preprint arXiv:2505.19821, 2025\nBackdoor attacks embed malicious triggers into training data, enabling attackers to \nmanipulate neural network behavior during inference while maintaining high \naccuracy on benign inputs. However, existing backdoor attacks face limitations\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19821&hl=en&sa=X&d=8217579378668490954&ei=_jo6aMsmybHqtA_6sKHgAQ&scisig=AAZF9b89XZjYdu_nSk8rXx0clM5e&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Breaking the Ceiling: Exploring the Potential of Jailbreak Attacks through Expanding Strategy Space", "first_label": [], "second_label": [], "data": "Y Huang, Y Sun, S Ruan, Y Zhang, Y Dong, X Wei\\xc2\\xa0- arXiv preprint arXiv:2505.21277, 2025\nLarge Language Models (LLMs), despite advanced general capabilities, still suffer \nfrom numerous safety risks, especially jailbreak attacks that bypass safety protocols. \nUnderstanding these vulnerabilities through black-box jailbreak attacks, which better\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.21277&hl=en&sa=X&d=177386400362974989&ei=_jo6aMsmybHqtA_6sKHgAQ&scisig=AAZF9b_blT4aeeZZ_by3uKoqFXZb&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LlamaFirewall: An open source guardrail system for building secure AI agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "S Chennabasappa, C Nikolaidis, D Song, D Molnar\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have evolved from simple chatbots into autonomous \nagents capable of performing complex tasks such as editing production code, \norchestrating workflows, and taking higher-stakes actions based on untrusted inputs\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.03574&hl=en&sa=X&d=4439105352924524607&ei=_jo6aMsmybHqtA_6sKHgAQ&scisig=AAZF9b9vbSaup9_At8OcInY6jBmA&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "F Aguilera-Mart\\xc3\\xadnez, F Berzal\\xc2\\xa0- arXiv preprint arXiv:2505.01177, 2025\nAs large language models (LLMs) continue to evolve, it is critical to assess the \nsecurity threats and vulnerabilities that may arise both during their training phase \nand after models have been deployed. This survey seeks to define and categorize\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.01177&hl=en&sa=X&d=7671221624049003302&ei=_jo6aMsmybHqtA_6sKHgAQ&scisig=AAZF9b9G2hD-1XbRFK3ie2HSPQEM&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Protecting Privacy against Membership Inference Attack with LLM Fine-tuning through Flatness", "first_label": ["LLM"], "second_label": [], "data": "T Chen, L Da, H Zhou, P Li, K Zhou, T Chen, H Wei\\xc2\\xa0- Proceedings of the 2025 SIAM\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe privacy concerns associated with the use of Large Language Models (LLMs) \nhave grown dramatically with the development of pioneer LLMs such as ChatGPT. \nDifferential Privacy (DP) techniques that utilize DP-SGD are explored in existing work\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://epubs.siam.org/doi/pdf/10.1137/1.9781611978520.41&hl=en&sa=X&d=17254526290774706544&ei=_jo6aMsmybHqtA_6sKHgAQ&scisig=AAZF9b9QKrfqxl5MqrtGoHHu2KtO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Style2Code: A Style-Controllable Code Generation Framework with Dual-Modal Contrastive Representation Learning", "first_label": ["Code"], "second_label": ["Generation"], "data": "D Zhang, S Kovalchuk, YL He\\xc2\\xa0- arXiv preprint arXiv:2505.19442, 2025\nControllable code generation, the ability to synthesize code that follows a specified \nstyle while maintaining functionality, remains a challenging task. We propose a two-\nstage training framework combining contrastive learning and conditional decoding to \nenable flexible style control. The first stage aligns code style representations with \nsemantic and structural features. In the second stage, we fine-tune a language model \n(eg, Flan-T5) conditioned on the learned style vector to guide generation. Our\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaThanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19442&hl=en&sa=X&d=17612079626158300957&ei=_To6aLawKbeC6rQP9sj2mQ8&scisig=AAZF9b_fT94SwgrPlcOPfn0qyw_V&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 new citations to articles by Thanh Le-Cong", "3 new citations to articles by Bach Le"]}
{"title": "VADER: A Human-Evaluated Benchmark for Vulnerability Assessment, Detection, Explanation, and Remediation", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "ETS Liu, A Wang, S Mateega, C Georgescu, D Tang\\xc2\\xa0- arXiv preprint arXiv:2505.19395, 2025\nEnsuring that large language models (LLMs) can effectively assess, detect, explain, \nand remediate software vulnerabilities is critical for building robust and secure \nsoftware systems. We introduce VADER, a human-evaluated benchmark designed \nexplicitly to assess LLM performance across four key vulnerability-handling \ndimensions: assessment, detection, explanation, and remediation. VADER \ncomprises 174 real-world software vulnerabilities, each carefully curated from GitHub\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19395&hl=en&sa=X&d=9714217024162720024&ei=_To6aOalLMmx6rQP-rCh4AE&scisig=AAZF9b_KSv4AbeUqE6oHh7gdXFuH&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["5 new citations to articles by Richard Fang"]}
{"title": "SV-TrustEval-C: Evaluating Structure and Semantic Reasoning in Large Language Models for Source Code Vulnerability Analysis", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Reasoning"], "data": "Y Li, P Branco, AM Hoole, M Marwah, HM Koduvely\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs Large Language Models (LLMs) evolve in understanding and generating code, \naccurately evaluating their reliability in analyzing source code vulnerabilities \nbecomes increasingly vital. While studies have examined LLM capabilities in tasks \nlike vulnerability detection and repair, they often overlook the importance of both \nstructure and semantic reasoning crucial for trustworthy vulnerability analysis. To \naddress this gap, we introduce SV-TrustEval-C, a benchmark designed to evaluate\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaVgx: Large-scale sample generation for boosting learning-based\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20630&hl=en&sa=X&d=14725032620468664436&ei=_To6aOalLMmx6rQP-rCh4AE&scisig=AAZF9b_6Is0uu0WBjZPcSprHaOAQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=2&folt=cit", "author": ["Richard Fang"], "ref": ["5 new citations to articles by Richard Fang"]}
{"title": "Dynamic Risk Assessments for Offensive Cybersecurity Agents", "first_label": [], "second_label": ["Agent"], "data": "B Wei, B Stroebl, J Xu, J Zhang, Z Li, P Henderson\\xc2\\xa0- arXiv preprint arXiv:2505.18384, 2025\nFoundation models are increasingly becoming better autonomous programmers, \nraising the prospect that they could also automate dangerous offensive cyber-\noperations. Current frontier model audits probe the cybersecurity risks of such \nagents, but most fail to account for the degrees of freedom available to adversaries in \nthe real world. In particular, with strong verifiers and financial incentives, agents for \noffensive cybersecurity are amenable to iterative improvement by would-be\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.18384&hl=en&sa=X&d=14468302384964164487&ei=_To6aOalLMmx6rQP-rCh4AE&scisig=AAZF9b--IEbLd4bgSSUTN_lHAgB1&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=3&folt=cit", "author": ["Richard Fang"], "ref": ["5 new citations to articles by Richard Fang"]}
{"title": "Scalable Auditing for AI Safety", "first_label": [], "second_label": [], "data": "E Jones - 2025\nOver the past ten years, the nature of the most capable deep learning systems has \nchanged dramatically. Ten years ago, many production-ready deep learning systems \nwere specialized classifiers, trained via supervised learning. In contrast, today's deep \nlearning systems are generalists, producing open-ended outputs such as high-\nresolution images and videos, entire books, and functioning code. Language models \nin particular are driving progress across a range of economically valuable tasks, and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-56.pdf&hl=en&sa=X&d=16733119213570676671&ei=_To6aOalLMmx6rQP-rCh4AE&scisig=AAZF9b_YnGCJrfYeeOYG0au5ZaOA&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=4&folt=cit", "author": ["Richard Fang"], "ref": ["5 new citations to articles by Richard Fang"]}
{"title": "Optimizing IoT Cross-rule Vulnerability Detection through Reinforcement Learning-Based Fuzzing", "first_label": ["Vulnerabilities", "Fuzzing"], "second_label": ["Detection"], "data": "TNB Huynh, T Xu, Y Wan, J Dai, X Sun\\xc2\\xa0- Proceedings of the 23rd ACM Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInternet of Things (IoT) devices have become increasingly ubiquitous and essential \nto daily life. These devices are usually controlled based on trigger-action rules, \nmeaning that the devices will take actions according to the rules when trigger\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3715014.3724024&hl=en&sa=X&d=3739162193984948731&ei=_jo6aKCxA-SN6rQPzIKygQU&scisig=AAZF9b8rj-cXp_JqsLDheHYllvAt&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Poster: Machine Learning for Vulnerability Detection as Target Oracle in Automated Fuzz Driver Generation", "first_label": ["Vulnerabilities", "Fuzzing"], "second_label": ["Detection", "Generation"], "data": "G Castiglione, M Maugeri, G Bella\\xc2\\xa0- arXiv preprint arXiv:2505.01123, 2025\nIn vulnerability detection, machine learning has been used as an effective static \nanalysis technique, although it suffers from a significant rate of false positives. \nContextually, in vulnerability discovery, fuzzing has been used as an effective\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.01123&hl=en&sa=X&d=10132122727710830909&ei=_jo6aKCxA-SN6rQPzIKygQU&scisig=AAZF9b_szXZRXqM-Vge79e4XJrq2&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "EmbedAgent: Benchmarking Large Language Models in Embedded System Development", "first_label": ["LLM"], "second_label": ["Agent"], "data": "R Xu, J Cao, M Wu, W Zhong, Y Lu, B He, X Han\\xe2\\x80\\xa6\nAbstract Large Language Models (LLMs) have shown promise in various tasks, yet \nfew benchmarks assess their capabilities in embedded system development. In this \npaper, we introduce EmbedAgent, a paradigm designed to simulate real-world roles\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Jialun-Cao/publication/392093991_EmbedAgent_Benchmarking_Large_Language_Models_in_Embedded_System_Development/links/68347085026fee1034fc0c7c/EmbedAgent-Benchmarking-Large-Language-Models-in-Embedded-System-Development.pdf&hl=en&sa=X&d=13158807724814855754&ei=_jo6aKCxA-SN6rQPzIKygQU&scisig=AAZF9b_s-yg1D0uuq8_0qcWhthUN&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Can Agents Fix Agent Issues?", "first_label": [], "second_label": ["Agent"], "data": "AW Rahardja, J Liu, W Chen, Z Chen, Y Lou\\xc2\\xa0- arXiv preprint arXiv:2505.20749, 2025\nLLM-based agent systems are emerging as a new software paradigm and have been \nwidely adopted across diverse domains such as medicine, robotics, and \nprogramming. However, maintaining these systems requires substantial effort, as\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20749&hl=en&sa=X&d=2398921862739984357&ei=_To6aJbfKvel6rQP6dvK4Ao&scisig=AAZF9b9l_1anChOcWkJfnPl5IhsV&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Co-PatcheR: Collaborative Software Patching with Component (s)-specific Small Reasoning Models", "first_label": [], "second_label": ["Reasoning"], "data": "Y Tang, H Li, K Zhu, M Yang, Y Ding, W Guo\\xc2\\xa0- arXiv preprint arXiv:2505.18955, 2025\nMotivated by the success of general-purpose large language models (LLMs) in \nsoftware patching, recent works started to train specialized patching models. Most \nworks trained one model to handle the end-to-end patching pipeline (including issue\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.18955&hl=en&sa=X&d=3118254343667206438&ei=_To6aJbfKvel6rQP6dvK4Ao&scisig=AAZF9b8jM0tUeXi2cL4m4VbEWwZN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Visualization Task Taxonomy to Understand the Fuzzing Internals", "first_label": ["Fuzzing"], "second_label": [], "data": "S Kummita, M Miao, E Bodden, S Wei\\xc2\\xa0- ACM Transactions on Software Engineering\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGreybox fuzzing is used extensively in research and practice. There are umpteen \npublications that improve greybox fuzzing. However, to what extent do these \nimprovements affect the internal components or internals of a given fuzzer is not yet\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3718346&hl=en&sa=X&d=6310038100822609560&ei=_To6aK-IN6m7ieoP1JuLsA8&scisig=AAZF9b_Ue_jmzHRI425oDGHolQub&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Targeted Fuzzing for Unsafe Rust Code: Leveraging Selective Instrumentation", "first_label": ["Fuzzing", "Code"], "second_label": [], "data": "D Paa\\xc3\\x9fen, JR Giesen, L Davi\\xc2\\xa0- arXiv preprint arXiv:2505.02464, 2025\nRust is a promising programming language that focuses on concurrency, usability, \nand security. It is used in production code by major industry players and got \nrecommended by government bodies. Rust provides strong security guarantees\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.02464&hl=en&sa=X&d=17464682910892089266&ei=_To6aK-IN6m7ieoP1JuLsA8&scisig=AAZF9b-bvKBMc2Po_9BYZAm8NsXQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "DeSocial: Blockchain-based Decentralized Social Networks", "first_label": ["Blockchain"], "second_label": [], "data": "J Huang, X Zhu, M Guo, Y Zhang\\xc2\\xa0- arXiv preprint arXiv:2505.21388, 2025\nWeb 2.0 social platforms are inherently centralized, with user data and algorithmic \ndecisions controlled by the platform. However, users can only passively receive \nsocial predictions without being able to choose the underlying algorithm, which limits \npersonalization. Fortunately, with the emergence of blockchain, users are allowed to \nchoose algorithms that are tailored to their local situation, improving prediction \nresults in a personalized way. In a blockchain environment, each user possesses its\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.21388&hl=en&sa=X&d=4400306142118046643&ei=_To6aO3YL4-UywTXk47YAw&scisig=AAZF9b_d5XZJQ28URhQRb5RfXhoz&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "Deconstructing Obfuscation: A four-dimensional framework for evaluating Large Language Models assembly code deobfuscation capabilities", "first_label": ["LLM", "Code"], "second_label": [], "data": "A Tkachenko, D Suskevic, B Adolphi\\xc2\\xa0- arXiv preprint arXiv:2505.19887, 2025\nLarge language models (LLMs) have shown promise in software engineering, yet \ntheir effectiveness for binary analysis remains unexplored. We present the first \ncomprehensive evaluation of commercial LLMs for assembly code deobfuscation. \nTesting seven state-of-the-art models against four obfuscation scenarios (bogus \ncontrol flow, instruction substitution, control flow flattening, and their combination), we \nfound striking performance variations--from autonomous deobfuscation to complete\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19887&hl=en&sa=X&d=11559749174181962178&ei=_To6aKmMNKuM6rQPsd_4QA&scisig=AAZF9b9WqvYgi-sHImO02eyEtLYm&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Vibe Coding vs. Agentic Coding: Fundamentals and Practical Implications of Agentic AI", "first_label": [], "second_label": ["Agent"], "data": "R Sapkota, KI Roumeliotis, M Karkee\\xc2\\xa0- arXiv preprint arXiv:2505.19443, 2025\nThis review presents a comprehensive analysis of two emerging paradigms in AI-\nassisted software development: vibe coding and agentic coding. While both leverage \nlarge language models (LLMs), they differ fundamentally in autonomy, architectural \ndesign, and the role of the developer. Vibe coding emphasizes intuitive, human-in-\nthe-loop interaction through prompt-based, conversational workflows that support \nideation, experimentation, and creative exploration. In contrast, agentic coding\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomatic Programming: Large Language Models and Beyond\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19443&hl=en&sa=X&d=6910930301357198563&ei=_To6aKmMNKuM6rQPsd_4QA&scisig=AAZF9b_cdZ1N5h6nOrAr5yDiv0jD&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Static Analysis by Abstract Interpretation Against Data Leakage in Machine Learning", "first_label": ["Static Analysis"], "second_label": [], "data": "C Urban, P Suboti\\xc4\\x87, F Drobnjakovi\\xc4\\x87\\xc2\\xa0- Science of Computer Programming, 2025\nData leakage is a well-known problem in machine learning which occurs when the \ntraining and testing datasets are not independent. This phenomenon leads to \nunreliably overly optimistic accuracy estimates at training time, followed by a \nsignificant drop in performance when models are deployed in the real world. This \ncan be dangerous, notably when models are used for risk prediction in high-stakes \napplications. In this paper, we propose an abstract interpretation-based static\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaProgram Repair Guided by Datalog-Defined Static Analysis\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167642325000772&hl=en&sa=X&d=7227989850055366680&ei=_To6aKmMNKuM6rQPsd_4QA&scisig=AAZF9b_sCC0VyFl9uWiEM26_uIiK&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Sensitive Target-Guided Directed Fuzzing for IoT Web Services", "first_label": ["Fuzzing"], "second_label": [], "data": "X Cui, Y Wang, Q Wei\\xc2\\xa0- Computers, Materials and Continua, 2025\nThe development of the Internet of Things (IoT) has brought convenience to people's \nlives, but it also introduces significant security risks. Due to the limitations of IoT \ndevices themselves and the challenges of re-hosting technology, existing fuzzing for \nIoT devices is mainly conducted through black-box methods, which lack effective \nexecution feedback and are blind. Meanwhile, the existing static methods mainly rely \non taint analysis, which has high overhead and high false alarm rates. We propose a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/org/science/article/pii/S1546221825004783&hl=en&sa=X&d=8758460518941859758&ei=_To6aKmMNKuM6rQPsd_4QA&scisig=AAZF9b-qnGqagOInuOevEZuvPFvT&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Multi-Agent Reinforcement Learning in Cybersecurity: From Fundamentals to Applications", "first_label": [], "second_label": ["Agent"], "data": "CR Landolt, C W\\xc3\\xbcrsch, R Meier, A Mermoud\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMulti-Agent Reinforcement Learning (MARL) has shown great potential as an \nadaptive solution for addressing modern cybersecurity challenges. MARL enables \ndecentralized, adaptive, and collaborative defense strategies and provides an \nautomated mechanism to combat dynamic, coordinated, and sophisticated threats. \nThis survey investigates the current state of research in MARL applications for \nautomated cyber defense (ACD), focusing on intruder detection and lateral\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFuzzing: Challenges and Reflections\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19837&hl=en&sa=X&d=2809762777143440505&ei=_To6aKmMNKuM6rQPsd_4QA&scisig=AAZF9b9LOmsJ7wPLpdviZllHRdBF&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Navigating Pitfalls: Evaluating LLMs in Machine Learning Programming Education", "first_label": ["LLM"], "second_label": [], "data": "S Kumar, MA Lones, M Maarek, H Zantout\\xc2\\xa0- arXiv preprint arXiv:2505.18220, 2025\nThe rapid advancement of Large Language Models (LLMs) has opened new \navenues in education. This study examines the use of LLMs in supporting learning in \nmachine learning education; in particular, it focuses on the ability of LLMs to identify \ncommon errors of practice (pitfalls) in machine learning code, and their ability to \nprovide feedback that can guide learning. Using a portfolio of code samples, we \nconsider four different LLMs: one closed model and three open models. Whilst the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaA feasibility study of using automated program repair for\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.18220&hl=en&sa=X&d=10355654207189696676&ei=_To6aKmMNKuM6rQPsd_4QA&scisig=AAZF9b88YgA-T_MSnxqw6BHyE6uZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Constrained adversarial learning for automated software testing: a literature review", "first_label": ["Software Testing"], "second_label": [], "data": "J Vitorino, T Dias, T Fonseca, E Maia, I Pra\\xc3\\xa7a\\xc2\\xa0- Discover Applied Sciences, 2025\nIt is imperative to safeguard computer applications and information systems against \nthe growing number of cyber-attacks. Automated software testing can be a promising \nsolution to quickly analyze many lines of code and detect vulnerabilities and possible \nattack vectors by generating function-specific testing data. This process draws \nsimilarities to the constrained adversarial examples generated by adversarial \nlearning methods, so there could be significant benefits to the integration of these\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFuzz Testing based Data Augmentation to Improve Robustness of\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s42452-025-07073-3&hl=en&sa=X&d=12507978429984970115&ei=_To6aKmMNKuM6rQPsd_4QA&scisig=AAZF9b85yK55b8uVVr2vbiRR2Veu&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "ColorGo: Directed Concolic Execution", "first_label": [], "second_label": [], "data": "J Li, J Shen, Y Su, MR Lyu\\xc2\\xa0- arXiv preprint arXiv:2505.21130, 2025\nDirected fuzzing is a critical technique in cybersecurity, targeting specific sections of \na program. This approach is essential in various security-related domains such as \ncrash reproduction, patch testing, and vulnerability detection. Despite its importance, \ncurrent directed fuzzing methods exhibit a trade-off between efficiency and \neffectiveness. For instance, directed grey-box fuzzing, while efficient in generating \nfuzzing inputs, lacks sufficient precision. The low precision causes time wasted on\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.21130&hl=en&sa=X&d=6330518294936306768&ei=_To6aKmMNKuM6rQPsd_4QA&scisig=AAZF9b9zJohtE9JQCR8dEku_M7tk&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=9&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Rechisel: Effective automatic chisel code generation by llm with reflection", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Niu, X Liu, D Niu, X Wang, Z Jiang, N Guan\\xc2\\xa0- arXiv preprint arXiv:2505.19734, 2025\nCoding with hardware description languages (HDLs) such as Verilog is a time-\nintensive and laborious task. With the rapid advancement of large language models \n(LLMs), there is increasing interest in applying LLMs to assist with HDL coding\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19734&hl=en&sa=X&d=11721354871378454184&ei=_jo6aNTiAY-UywTXk47YAw&scisig=AAZF9b9MMIAf8sNjj9lFzZ3tcSvm&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "CXXCrafter: An LLM-Based Agent for Automated C/C++ Open Source Software Building", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Z Yu, Y Zhang, M Wen, Y Nie, W Zhang, M Yang\\xc2\\xa0- arXiv preprint arXiv:2505.21069, 2025\nProject building is pivotal to support various program analysis tasks, such as \ngenerating intermediate rep-resentation code for static analysis and preparing binary \ncode for vulnerability reproduction. However, automating the building process for\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.21069&hl=en&sa=X&d=16730836823198741100&ei=_jo6aNTiAY-UywTXk47YAw&scisig=AAZF9b8JzCi1FOKZGtQYwZNpTM9d&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "CMU-S3D-25-101 Navigating Challenges with LLM-based Code Generation using Software-specific Insights", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "N Rao\nThe software development process is rapidly evolving with the advancement of \nLarge Language Models (LLMs). LLMs are not only transforming the way code is \nwritten but are also increasingly integrated into AI programming tools, such as\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=http://reports-archive.adm.cs.cmu.edu/anon/anon/usr/ftp/home/ftp/s3d2025/abstracts/25-101.html&hl=en&sa=X&d=2350027781266600992&ei=_jo6aNTiAY-UywTXk47YAw&scisig=AAZF9b-wfq8pUs_8SY62bcII8QwK&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=7&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Zheng, X Qian, H Zhou, S Yang, Y He, S Jana\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models (LMs) show promise for vulnerability detection but struggle with \nlong, real-world code due to sparse and uncertain vulnerability locations. These \nissues, exacerbated by token limits, often cause models to miss vulnerability-related\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17460&hl=en&sa=X&d=9334848497739178959&ei=OXw4aJa0D4qIieoPj_7kqQE&scisig=AAZF9b_EDz61GJXVBfE-c2mGro5g&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research", "1 new citation to articles by Thanh Le-Cong", "Bach Le - new related research", "2 new citations to articles by Hong Jin Kang", "Richard Fang - new related research", "David Lo - new related research", "2 new citations to articles by Bach Le", "Abhik Roychoudhury - new related research", "Xin ZHOU - new related research"]}
{"title": "Gradient-Based Program Repair: Fixing Bugs in Continuous Program Spaces", "first_label": ["APR", "Bug"], "second_label": ["Repair"], "data": "A Silva, G Thor\\xc3\\xa9n, M Monperrus\\xc2\\xa0- arXiv preprint arXiv:2505.17703, 2025\nAutomatic program repair seeks to generate correct code from buggy programs, with \nmost approaches searching the correct program in a discrete, symbolic space of \nsource code tokens. This symbolic search is fundamentally limited by its inability to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17703&hl=en&sa=X&d=16474865879424877259&ei=OXw4aJa0D4qIieoPj_7kqQE&scisig=AAZF9b_Nk8nyD3YHpgwp8sahtoaV&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research", "Hong Jin Kang - new related research"]}
{"title": "Leveraging Open-Source LLMs for Zero-Shot Vulnerability Detection: A Comparative Analysis", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "N Capuano, V Carletti, P Foggia, G Parrella, M Vento\\xc2\\xa0- International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid expansion of the Internet of Things (IoT) has brought significant security \nchallenges, primarily due to vulnerabilities in the firmware of IoT and network \ndevices, which is predominantly written in low-level programming languages such as\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-87775-9_2&hl=en&sa=X&d=8724089268434184607&ei=OXw4aJa0D4qIieoPj_7kqQE&scisig=AAZF9b-ahkowI222f9SeGE9jq2lb&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "HouseFuzz: Service-Aware Grey-Box Fuzzing for Vulnerability Detection in Linux-Based Firmware", "first_label": ["Vulnerabilities", "Fuzzing"], "second_label": ["Detection"], "data": "H Xiao, Z Wei, J Dai, B Li, Y Zhang, M Yang\\xc2\\xa0- 2025 IEEE Symposium on Security and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nTo date, grey-box fuzzing has become an essential technique to detect \nvulnerabilities implied in Linuxbased firmware. However, existing fuzzing \napproaches commonly encounter three overlooked obstacles stemming from\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://yuanxzhang.github.io/paper/housefuzz-oakland25.pdf&hl=en&sa=X&d=2985212275357273259&ei=OXw4aKOkFuWBieoP0PLYiAU&scisig=AAZF9b-79MvgylM8QDOXkXYrQWz8&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "David Lo - new related research"]}
{"title": "Identifying Root Cause of bugs by Capturing Changed Code Lines with Relational Graph Neural Networks", "first_label": ["Code", "Bug"], "second_label": ["Detection", "Graph"], "data": "J Zhang, S Guo, H Li, C Li, Y Chai, R Chen\\xc2\\xa0- arXiv preprint arXiv:2505.00990, 2025\nThe Just-In-Time defect prediction model helps development teams improve software \nquality and efficiency by assessing whether code changes submitted by developers \nare likely to introduce defects in real-time, allowing timely identification of potential\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.00990&hl=en&sa=X&d=17996198631274398381&ei=OXw4aMnrIIOuieoP-ZTn2Aw&scisig=AAZF9b_S66ntoRzUw7soStgrJChb&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "CRAKEN: Cybersecurity LLM Agent with Knowledge-Based Execution", "first_label": ["LLM"], "second_label": ["Agent"], "data": "M Shao, H Xi, N Rani, M Udeshi, VSC Putrevu, K Milner\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Model (LLM) agents can automate cybersecurity tasks and can \nadapt to the evolving cybersecurity landscape without re-engineering. While LLM \nagents have demonstrated cybersecurity capabilities on Capture-The-Flag (CTF)\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17107&hl=en&sa=X&d=15972287277060203373&ei=OXw4aMnrIIOuieoP-ZTn2Aw&scisig=AAZF9b9ztm3EoTSFCd4yC4zLZwar&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Towards Practical Defect-Focused Automated Code Review", "first_label": ["Code Review", "Code", "Software Defect"], "second_label": [], "data": "J Lu, L Jiang, X Li, J Fang, F Zhang, L Yang, C Zuo\\xc2\\xa0- arXiv preprint arXiv:2505.17928, 2025\nThe complexity of code reviews has driven efforts to automate review comments, but \nprior approaches oversimplify this task by treating it as snippet-level code-to-text \ngeneration and relying on text similarity metrics like BLEU for evaluation. These\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17928&hl=en&sa=X&d=12067756449610676850&ei=OXw4aMnrIIOuieoP-ZTn2Aw&scisig=AAZF9b_qGcuYwPmk8Xhnck7wk9eC&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Detecting Taint-Style Vulnerabilities in Microservice-Structured Web Applications", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "F Liu, Y Zhang, T Chen, Y Shi, G Yang, Z Lin, M Yang\\xe2\\x80\\xa6\\xc2\\xa0- 2025 IEEE Symposium on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMicroservice architecture has been becoming increasingly popular for building \nscalable and maintainable applications. A microservice-structured web application \n(shortened to microservice application) enhances security by providing a loose-\ncoupling design and enforcing the security isolation between different microservices. \nHowever, in this paper, our study shows microservice applications still suffer from \ntaintstyle vulnerability, one of the most serious vulnerabilities. We propose a novel\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection: Emerging results\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://yuanxzhang.github.io/paper/mscan-oakland25.pdf&hl=en&sa=X&d=18396175674193620539&ei=OXw4aLubHJ-mieoPoOrjuQU&scisig=AAZF9b8eUIifMEfDqb7jf0bqc780&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["1 new citation to articles by Xin ZHOU"]}
{"title": "Guided Search Strategies in Non-Serializable Environments with Applications to Software Engineering Agents", "first_label": [], "second_label": ["Agent", "Search"], "data": "K Zainullina, A Golubev, M Trofimova, S Polezhaev\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have recently achieved remarkable results in \ncomplex multi-step tasks, such as mathematical reasoning and agentic software \nengineering. However, they often struggle to maintain consistent performance across\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13652%3F&hl=en&sa=X&d=16639264652215845731&ei=OXw4aJPqDZ-mieoPoOrjuQU&scisig=AAZF9b8trwPKX9QyV63_k_pzmKHD&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Enhancing line-level defect prediction using bilinear attention fusion and ranking optimization", "first_label": ["Software Defect"], "second_label": [], "data": "S Qiu, H Huang, Y Kuang, H Luo, X Liu\\xc2\\xa0- Empirical Software Engineering, 2025\nThe aim of software defect prediction is to identify defect-prone code segments, \nthereby facilitating the optimal allocation of testing resources by the quality \nassurance team. Previous defect prediction models have primarily concentrated on a \ncoarse-grained file-level defect prediction, which frequently lacks the necessary \nprecision for defect localization. In response, recent advancements in the field have \nseen the emergence of fine-grained line-level defect prediction methods\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCc2vec: Distributed representations of code changes\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10674-6&hl=en&sa=X&d=16103404085638523760&ei=OXw4aIroEIOuieoP-ZTn2Aw&scisig=AAZF9b_SGOXJDhMOe4gCrJwiQLYc&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang"]}
{"title": "PandaGuard: Systematic Evaluation of LLM Safety in the Era of Jailbreaking Attacks", "first_label": ["LLM"], "second_label": [], "data": "G Shen, D Zhao, L Feng, X He, J Wang, S Shen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have achieved remarkable capabilities but remain \nvulnerable to adversarial prompts known as jailbreaks, which can bypass safety \nalignment and elicit harmful outputs. Despite growing efforts in LLM safety research\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13862&hl=en&sa=X&d=7957433049052051517&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b8uuohndjng7lcz2CFokw4p&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based Backdoor Attacks for Jailbreaking Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "J Kong, H Fang, X Yang, K Gao, B Chen, ST Xia\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSupervised fine-tuning (SFT) aligns large language models (LLMs) with human \nintent by training them on labeled task-specific data. Recent studies have shown that \nmalicious attackers can inject backdoors into these models by embedding triggers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17601&hl=en&sa=X&d=14932585774719166007&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b9Mpttr2wQUEHafuYZfV36C&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Automating Safety Enhancement for LLM-based Agents with Synthetic Risk Scenarios", "first_label": ["LLM"], "second_label": ["Agent"], "data": "X Zhou, W Wang, L Lu, J Shi, G Tie, Y Xu, L Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Model (LLM)-based agents are increasingly deployed in real-world \napplications such as\" digital assistants, autonomous customer service, and decision-\nsupport systems\", where their ability to\" interact in multi-turn, tool-augmented\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17735&hl=en&sa=X&d=12532090448198307722&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b9bre4aTPQdE8jg7Mn1R_NE&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Wang, W Wang, S Wang, Z Li, Z Ji, Z Lyu, D Wu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Large Language Models (LLMs) has led to the \nemergence of Multi-Agent Systems (MAS) to perform complex tasks through \ncollaboration. However, the intricate nature of MAS, including their architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12442&hl=en&sa=X&d=8825331941370095164&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b_j6hKF2Zy8dNMOx-tobM6E&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution", "first_label": [], "second_label": [], "data": "J Guo, X Wen, W Jiang, C Huang, J Li, H Li\\xc2\\xa0- arXiv preprint arXiv:2505.15308, 2025\nWith the widespread application of super-resolution (SR) in various fields, \nresearchers have begun to investigate its security. Previous studies have \ndemonstrated that SR models can also be subjected to backdoor attacks through\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15308&hl=en&sa=X&d=13335437674086498390&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b8WmdvUXiuzvPutlRNCBmNP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Ripple Effect: On Unforeseen Complications of Backdoor Attacks", "first_label": [], "second_label": [], "data": "R Zhang, Y Shen, H Li, W Jiang, H Chen, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent research highlights concerns about the trustworthiness of third-party Pre-\nTrained Language Models (PTLMs) due to potential backdoor attacks. These \nbackdoored PTLMs, however, are effective only for specific pre-defined downstream\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11586&hl=en&sa=X&d=15157304470732077928&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b997v4XRj8-KVQslhBMZvqE&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AgentXploit: End-to-End Redteaming of Black-Box AI Agents", "first_label": [], "second_label": ["Agent"], "data": "Z Wang, V Siu, Z Ye, T Shi, Y Nie, X Zhao, C Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe strong planning and reasoning capabilities of Large Language Models (LLMs) \nhave fostered the development of agent-based systems capable of leveraging \nexternal tools and interacting with increasingly complex environments. However\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.05849&hl=en&sa=X&d=13145039506086791936&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b_5aWzkLQOK0HBWClMmbpt1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Safety Alignment Can Be Not Superficial With Explicit Safety Signals", "first_label": [], "second_label": [], "data": "J Li, JE Kim\\xc2\\xa0- arXiv preprint arXiv:2505.17072, 2025\nRecent studies on the safety alignment of large language models (LLMs) have \nrevealed that existing approaches often operate superficially, leaving models \nvulnerable to various adversarial attacks. Despite their significance, these studies\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17072&hl=en&sa=X&d=3884119238907864380&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b_-WQPT8NKA4EMeavI8x-X5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A4FL: Federated Adversarial Defense via Adversarial Training and Pruning Against Backdoor Attack", "first_label": [], "second_label": [], "data": "B Li, M Hamid, M Saleem, M Aman\\xc2\\xa0- IEEE Access, 2025\nBackdoor attacks threaten federated learning (FL) models, where malicious \nparticipants embed hidden triggers into local models during training. These triggers \ncan compromise crucial applications, such as autonomous systems, when they\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/10992684.pdf&hl=en&sa=X&d=4691259454218143835&ei=OXw4aLHOHYqIieoPj_7kqQE&scisig=AAZF9b-NVXh_0LVfWkgmGPYIRTtu&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM-BSCVM: An LLM-Based Blockchain Smart Contract Vulnerability Management Framework", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM", "Blockchain"], "second_label": [], "data": "Y Jin, C Li, P Fan, P Liu, X Li, C Liu, W Qiu\\xc2\\xa0- arXiv preprint arXiv:2505.17416, 2025\nSmart contracts are a key component of the Web 3.0 ecosystem, widely applied in \nblockchain services and decentralized applications. However, the automated \nexecution feature of smart contracts makes them vulnerable to potential attacks due\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17416&hl=en&sa=X&d=10855861846148419865&ei=OXw4aKvLE8y8ieoPz-jf4A8&scisig=AAZF9b_mYzDvvJxBEB76yl3JeJnw&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Adaptive Plan-Execute Framework for Smart Contract Security Auditing", "first_label": ["Smart Contracts"], "second_label": [], "data": "Z Wei, J Sun, Z Zhang, Z Hou, Z Zhao\\xc2\\xa0- arXiv preprint arXiv:2505.15242, 2025\nLarge Language Models (LLMs) have shown great promise in code analysis and \nauditing; however, they still struggle with hallucinations and limited context-aware \nreasoning. We introduce SmartAuditFlow, a novel Plan-Execute framework that\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15242%3F&hl=en&sa=X&d=12215254457367510356&ei=OXw4aKvLE8y8ieoPz-jf4A8&scisig=AAZF9b947-Kg9JIl0flSbUcHwrKi&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "SmartNote: An LLM-Powered, Personalised Release Note Generator That Just Works", "first_label": ["LLM"], "second_label": [], "data": "F Daneshyan, R He, J Wu, M Zhou\\xc2\\xa0- arXiv preprint arXiv:2505.17977, 2025\nThe release note is a crucial document outlining changes in new software versions. \nYet, many developers view the process of writing software release notes as a tedious \nand dreadful task. Consequently, numerous tools have been developed by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17977&hl=en&sa=X&d=9800160746809662848&ei=OXw4aKvLE8y8ieoPz-jf4A8&scisig=AAZF9b_GgqDLYefmItqDOvP0zOfL&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "AUTOMATIC GENERATION OF ETHEREUM-BASED SMART CONTRACTS FOR AGRI-FOOD TRACEABILITY SYSTEM", "first_label": ["Smart Contracts", "Ethereum"], "second_label": ["Generation"], "data": "P KATHIRESAN, TK SELVI\nThere is a growing demand for transparency along the agri-food chain, both from \ncustomers and governments. The adoption of block chain technology to enable \nsecure traceability for the management of the agri-food chain, provide information \nsuch as the provenance of a food product and prevent food fraud, is emerging \nrapidly, due to the inherent trust and inalterability provided by this technology. \nHowever, developing the right smart contracts for these use cases is even more of a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://erode-sengunthar.ac.in/wp-content/uploads/2025/05/15.-IJCRT2304284.pdf&hl=en&sa=X&d=10559769453103330358&ei=OXw4aPerEvel6rQP6dvK4Ao&scisig=AAZF9b-yaYonZYR24dyIBCf7azkj&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le"]}
{"title": "The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models", "first_label": ["APR"], "second_label": ["Repair"], "data": "FV Ruiz, M Hort, L Moonen\\xc2\\xa0- arXiv preprint arXiv:2505.02931, 2025\nAutomatic program repair (APR) aims to reduce the manual efforts required to \nidentify and fix errors in source code. Before the rise of LLM-based agents, a \ncommon strategy was to increase the number of generated patches, sometimes to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.02931%3F&hl=en&sa=X&d=16837479357373517474&ei=OXw4aMvlGeSN6rQPzIKygQU&scisig=AAZF9b_WjCVulOfH0bpaSqZwLopC&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "CORECRISIS: Threat-Guided and Context-Aware Iterative Learning and Fuzzing of 5G Core Networks", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Dong, T Yang, A Al Ishtiaq, SMM Rashid, A Ranjbar\\xe2\\x80\\xa6\nWe develop CORECRISIS, a stateful black-box fuzz-testing framework for 5G core \nnetwork (5GC) implementations. Unlike previous stateful security analysis efforts of \ncellular networks which rely on manually-crafted, static test inputs and are limited to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.usenix.org/system/files/conference/usenixsecurity25/sec25cycle1-prepub-1292-dong-yilu.pdf&hl=en&sa=X&d=4291979592406815479&ei=OXw4aMvlGeSN6rQPzIKygQU&scisig=AAZF9b8xMpoFy9xYsoZdVl1unvGx&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "WildSync: Automated Fuzzing Harness Synthesis via Wild API Usage Recovery", "first_label": ["Fuzzing"], "second_label": [], "data": "WEIC WU, S NAGY, C HAUSER - 2025\nAuthors' Contact Information: Wei-Cheng Wu, Dartmouth College, Hanover, USA, wei-\ncheng. wu. gr@ dartmouth. edu; Stefan Nagy, University of Utah, Salt Lake City, USA, \nstefan. nagy@ utah. edu; Christophe Hauser, Dartmouth College, Hanover, USA\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://users.cs.utah.edu/~snagy/papers/25ISSTA.pdf&hl=en&sa=X&d=3125007074729669279&ei=OXw4aMvlGeSN6rQPzIKygQU&scisig=AAZF9b8Pijs9BnZif9GfvBHcFCPy&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Fault localization of AI-enabled cyber-physical systems by exploiting temporal neuron activation", "first_label": ["Fault Localization"], "second_label": ["Exploit", "Localization"], "data": "D Lyu, Y Li, Z Zhang, P Arcaini, XY Zhang, F Ishikawa\\xe2\\x80\\xa6\\xc2\\xa0- Journal of Systems and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern cyber\\xe2\\x80\\x93physical systems (CPS) are evolving to integrate deep neural \nnetworks (DNNs) as controllers, leading to the emergence of AI-enabled CPSs. An \ninadequately trained DNN controller may produce incorrect control actions, exposing\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225001438&hl=en&sa=X&d=3286846770327067741&ei=OXw4aMvlGeSN6rQPzIKygQU&scisig=AAZF9b-jUE3fT364wIMjAbdvLNMM&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Programming Models for Correct and Modular Distributed Systems", "first_label": [], "second_label": [], "data": "S Laddad - 2025\nWriting distributed software is hard. Distributed systems are the backbone of the \nmodern Internet, involved in every website load, button click, and data transaction. \nBut these systems face complex correctness challenges. Concurrency, network \ndelays, and machine failures all lead to bugs with brutal consequences: data loss, \nsecurity vulnerabilities, and denial of service. Distributed systems are hard because \nthey have implicit non-determinism. In sequential programs, the order of operations\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaGreybox fuzzing of distributed systems\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-85.pdf&hl=en&sa=X&d=14972060672026920479&ei=OXw4aPKDFaalieoP5f2nkAE&scisig=AAZF9b-s2lffO8y1tMklDVka1rr7&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
{"title": "The state of hybrid artificial intelligence for interstellar missions", "first_label": [], "second_label": [], "data": "A Ellery\\xc2\\xa0- Progress in Aerospace Sciences, 2025\nInterstellar missions will require a high degree of autonomy mediated through \nartificial intelligence (AI). All interstellar missions are characterised by 50-100-year \ntransits to extrasolar systems. High system availability demands that interstellar \nspacecraft are self-repairable imposing significant demands on onboard intelligence. \nWe review the current status of artificial intelligence to assess its capabilities in \nproviding such autonomy. In particular, we focus on hybrid AI methods as these\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Program Repair\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0376042125000260&hl=en&sa=X&d=353621729800259380&ei=OXw4aPKDFaalieoP5f2nkAE&scisig=AAZF9b-Tz9nbgrTgCe-Bce_SiBUH&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
