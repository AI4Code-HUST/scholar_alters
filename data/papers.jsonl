{"title": "MalCVE: Malware Detection and CVE Association Using Large Language Models", "first_label": ["LLM"], "second_label": ["Detection"], "data": "EA Cristea, P Molnes, J Li- arXiv preprint arXiv:2510.15567, 2025\nMalicious software attacks are having an increasingly significant economic impact. \nCommercial malware detection software can be costly, and tools that attribute \nmalware to the specific software vulnerabilities it exploits are largely lacking. \nUnderstanding the connection between malware and the vulnerabilities it targets is \ncrucial for analyzing past threats and proactively defending against current ones. In \nthis study, we propose an approach that leverages large language models (LLMs) to\nCites: Large language model for vulnerability detection and repair", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15567&hl=en&sa=X&d=15144835896631870722&ei=kGf7aILkF97M6rQPpPXkqAI&scisig=ABGrvjLkPduffsYP9O3IznBlFd54&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ABGrvjKBQMI3rG05-NPhg-jRvIpb&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "Large Language Models for Cybersecurity Intelligence, Threat Hunting, and Decision Support", "first_label": ["LLM"], "second_label": [], "data": "S Ren, S Chen- Computer Life, 2025\nLarge language models (LLMs) have emerged as transformative technologies in \ncybersecurity, offering unprecedented capabilities in threat detection, vulnerability \nanalysis, and intelligent decision-making. This review examines the application of \nLLMs across critical cybersecurity domains, including cyber threat intelligence (CTI), \nthreat hunting, vulnerability detection, malware analysis, and decision support \nsystems. The integration of LLMs such as Generative Pre-trained Transformer 4 (GPT\nCites: Large language model for vulnerability detection and repair\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://computer-life.org/index.php/ojs/article/download/27/27&hl=en&sa=X&d=12287820574983375032&ei=kGf7aILkF97M6rQPpPXkqAI&scisig=ABGrvjJtHMFRtPBQ5s8eAL8lOpNm&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ABGrvjKBQMI3rG05-NPhg-jRvIpb&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU", "4 new citations to articles by Richard Fang"]}
{"title": "From Defender to Devil? Unintended Risk Interactions Induced by LLM Defenses", "first_label": ["LLM"], "second_label": [], "data": "X Meng, T Cong, L Wang, W Chen, Z Li, S Guo- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have shown remarkable performance across \nvarious applications, but their deployment in sensitive domains raises significant \nconcerns. To mitigate these risks, numerous defense strategies have been proposed", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07968&hl=en&sa=X&d=16628375445005170696&ei=kGf7aPKXJIOAieoPtpDVoA0&scisig=ABGrvjJFN6fFD2JlXKrvW9Fj6lWu&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "HarmRLVR: Weaponizing Verifiable Rewards for Harmful LLM Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Liu, L Li, X Wang, J Shao- arXiv preprint arXiv:2510.15499, 2025\nRecent advancements in Reinforcement Learning with Verifiable Rewards (RLVR) \nhave gained significant attention due to their objective and verifiable reward signals, \ndemonstrating strong performance in reasoning and code generation tasks", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15499&hl=en&sa=X&d=3684055427722867634&ei=kGf7aPKXJIOAieoPtpDVoA0&scisig=ABGrvjIQtg1gf4x__eiLyp1jaShs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Black-box Optimization of LLM Outputs by Asking for Directions", "first_label": ["LLM"], "second_label": [], "data": "J Zhang, M Ding, Y Liu, J Hong, F Tramr- arXiv preprint arXiv:2510.16794, 2025\nWe present a novel approach for attacking black-box large language models (LLMs) \nby exploiting their ability to express confidence in natural language. Existing black-\nbox attacks require either access to continuous model outputs like logits or", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16794&hl=en&sa=X&d=6671244050561268529&ei=kGf7aPKXJIOAieoPtpDVoA0&scisig=ABGrvjLXQUUVy6vkXFRFjc0L93Bi&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Backdoor Attacks on Neural Networks via One-Bit Flip", "first_label": [], "second_label": [], "data": "X Li, L Luo, Q Zeng- Proceedings of the IEEE/CVF International Conference, 2025\nConventional backdoor attacks on deep neural networks (DNNs) typically assume \nthat an attacker can manipulate the training data or process. However, recent \nresearch introduces a more practical threat model by injecting backdoors at the", "link": "https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/ICCV2025/papers/Li_Backdoor_Attacks_on_Neural_Networks_via_One-Bit_Flip_ICCV_2025_paper.pdf&hl=en&sa=X&d=4888216730673495699&ei=kGf7aPKXJIOAieoPtpDVoA0&scisig=ABGrvjLb5YodaTVZfNhrFVblkNBy&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Proactive defense against LLM Jailbreak", "first_label": ["LLM"], "second_label": [], "data": "W Zhao, J Peng, D Ben-Levi, Z Yu, J Yang- arXiv preprint arXiv:2510.05052, 2025\nThe proliferation of powerful large language models (LLMs) has necessitated robust \nsafety alignment, yet these models remain vulnerable to evolving adversarial attacks, \nincluding multi-turn jailbreaks that iteratively search for successful queries. Current", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05052&hl=en&sa=X&d=12643963361954479351&ei=kGf7aPKXJIOAieoPtpDVoA0&scisig=ABGrvjITm70eJQ3DAJ41GbIUFyZv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Fewer Weights, More Problems: A Practical Attack on LLM Pruning", "first_label": ["LLM"], "second_label": [], "data": "K Egashira, R Staab, T Gloaguen, M Vero, M Vechev- arXiv preprint arXiv, 2025\nModel pruning, ie, removing a subset of model weights, has become a prominent \napproach to reducing the memory footprint of large language models (LLMs) during \ninference. Notably, popular inference engines, such as vLLM, enable users to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07985%3F&hl=en&sa=X&d=15877205037372109377&ei=kGf7aPKXJIOAieoPtpDVoA0&scisig=ABGrvjLc2zMGjcFTGp-_8sfDhRmv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Microsaccade-Inspired Probing: Positional Encoding Perturbations Reveal LLM Misbehaviours", "first_label": ["LLM"], "second_label": [], "data": "R Melo, R Abreu, CS Pasareanu- arXiv preprint arXiv:2510.01288, 2025\nWe draw inspiration from microsaccades, tiny involuntary eye movements that reveal \nhidden dynamics of human perception, to propose an analogous probing method for \nlarge language models (LLMs). Just as microsaccades expose subtle but informative", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01288&hl=en&sa=X&d=4079834350174690212&ei=kGf7aPKXJIOAieoPtpDVoA0&scisig=ABGrvjJMtJXAVeeF7NG9Bep4U4CZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "first_label": ["LLM"], "second_label": ["Agent"], "data": "VK Bonagiri, P Kumaragurum, K Nguyen, B Plaut- arXiv preprint arXiv:2510.16492, 2025\nAs Large Language Model (LLM) agents increasingly operate in complex \nenvironments with real-world consequences, their safety becomes critical. While \nuncertainty quantification is well-studied for single-turn tasks, multi-turn agentic", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16492&hl=en&sa=X&d=12122099661687534348&ei=kGf7aPKXJIOAieoPtpDVoA0&scisig=ABGrvjI4CtI_SmXhnMCPP-z7iPl7&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SoK: Taxonomy and Evaluation of Prompt Security in Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "H Hong, S Feng, N Naderloui, S Yan, J Zhang, B Liu- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have rapidly become integral to real-world \napplications, powering services across diverse sectors. However, their widespread \ndeployment has exposed critical security risks, particularly through jailbreak prompts", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15476&hl=en&sa=X&d=16332206608507819703&ei=kGf7aPKXJIOAieoPtpDVoA0&scisig=ABGrvjInhjWj4hHpDo9BRzvE6k5O&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Eliciting Secret Knowledge from Language Models", "first_label": ["LLM"], "second_label": [], "data": "B Cywiski, E Ryd, R Wang, S Rajamanoharan- arXiv preprint arXiv, 2025\nWe study secret elicitation: discovering knowledge that an AI possesses but does not \nexplicitly verbalize. As a testbed, we train three families of large language models \n(LLMs) to possess specific knowledge that they apply downstream but deny knowing\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01070%3F&hl=en&sa=X&d=17687736062767598626&ei=kGf7aPKXJIOAieoPtpDVoA0&scisig=ABGrvjLG4CCiLPxZ7-1IMATQkB8j&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Beyond SWE-Bench: A Compiler-Assisted Pipeline for Multi-language Automated Program Repair", "first_label": ["APR"], "second_label": ["Repair"], "data": "M Pineda, D Luna, M Esquivel, J Bours, J Salazar- International Conference on, 2025\nAutomated program repair (APR) research predominantly focuses on Python \nenvironments, creating significant infrastructure gaps for compiled languages like C, \nC++, and Java that dominate production systems. We present the first systematic", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-09044-7_9&hl=en&sa=X&d=9652754918189750732&ei=jmf7aKfkIIm16rQPu6Ol8AM&scisig=ABGrvjLsQlCCYsmwCJRV6mzSR0Rl&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research", "Bach Le - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Vdexplainer: Sequential decision-making and probability sampling guided statement-level explanation for vulnerability detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "W Zheng, X Su, Y Jiang, H Wei, W Tao- Computers & Security, 2025\nMost existing deep learning (DL) based vulnerability detection methods, including \npre-trained models, are coarse-grained binary classification methods that lack the \ninterpretability for detection results. Although the explanation of deep learning has", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825003591&hl=en&sa=X&d=1218753570899613844&ei=jmf7aKfkIIm16rQPu6Ol8AM&scisig=ABGrvjL3VCZPUNfODLNkXzOm9baH&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "MAVUL: Multi-Agent Vulnerability Detection via Contextual Reasoning and Interactive Refinement", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Agent", "Reasoning"], "data": "Y Li, K Joshi, X Wang, E Wong- arXiv preprint arXiv:2510.00317, 2025\nThe widespread adoption of open-source software (OSS) necessitates the mitigation \nof vulnerability risks. Most vulnerability detection (VD) methods are limited by \ninadequate contextual understanding, restrictive single-round interactions, and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.00317&hl=en&sa=X&d=577185325914480253&ei=jmf7aKfkIIm16rQPu6Ol8AM&scisig=ABGrvjIbyn7OuStXpJ3sqMy4JVsK&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language", "first_label": ["LLM", "Software Testing"], "second_label": ["Agent"], "data": "S Salva, R Taguelmimt- arXiv preprint arXiv:2509.19136, 2025\nThe use of natural language (NL) test cases for validating graphical user interface \n(GUI) applications is emerging as a promising direction to manually written \nexecutable test scripts, which are costly to develop and difficult to maintain. Recent", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19136&hl=en&sa=X&d=14763218273592887225&ei=jmf7aKfkIIm16rQPu6Ol8AM&scisig=ABGrvjJ-9d5MQo7eq8oD5l_0ZsY3&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Bach Le - new related research"]}
{"title": "An Experimental Study of Real-Life LLM-Proposed Performance Improvements", "first_label": ["LLM"], "second_label": [], "data": "L Yi, G Gay, P Leitner- arXiv preprint arXiv:2510.15494, 2025\nLarge Language Models (LLMs) can generate code, but can they generate fast \ncode? In this paper, we study this question using a dataset of 65 real-world tasks \nmined from open-source Java programs. We specifically select tasks where", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15494&hl=en&sa=X&d=10640118915085146028&ei=jmf7aKfkIIm16rQPu6Ol8AM&scisig=ABGrvjLcRUj8NSio7-ggPhAhEwVg&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "David Lo - new related research", "Bach Le - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Towards Human-interpretable Explanation in Code Clone Detection using LLM-based Post Hoc Explainer", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "T Racharak, C Ragkhitwetsagul, C Junplong- arXiv preprint arXiv, 2025\nRecent studies highlight various machine learning (ML)-based techniques for code \nclone detection, which can be integrated into developer tools such as static code \nanalysis. With the advancements brought by ML in code understanding, ML-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22978&hl=en&sa=X&d=13116222657243354012&ei=jmf7aKfkIIm16rQPu6Ol8AM&scisig=ABGrvjLcsdvC_Wkq4bjALj1X_8xA&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Local Agentic RAG-Based Information System Development for Intelligent Analysis of GitHub Code Repositories in Computer Science Education", "first_label": ["Code"], "second_label": ["Agent"], "data": "Z Hu, MM Paprotskyi, V Vysotska, L Chyrun, Y Ushenko\nThis study presents the development and evaluation of a local agent-based Retrieval-\nAugmented Generation (Agentic RAG) system designed for the intelligent analysis of \nGitHub repositories in computer science education and IT practice. The novelty of", "link": "https://scholar.google.com/scholar_url?url=https://www.mecs-press.org/ijmecs/ijmecs-v17-n5/IJMECS-V17-N5-7.pdf&hl=en&sa=X&d=15899062735032558573&ei=jmf7aKfkIIm16rQPu6Ol8AM&scisig=ABGrvjIz9ZvXb18eqWpoqNMeLmro&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "VULDA: Source Code Vulnerability Detection via Local Dependency Context Aggregation on Vulnerability-Aware Code Mapping Graph", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection", "Graph"], "data": "T Peng, L Gui, L Cai, J Tang, A Ye, F Zhu- International Conference on Information, 2025\nVulnerability detection is crucial in the field of software security. However, existing \nmethods often suffer from interference caused by redundant information and \ninsufficient cross-line semantic dependencies when handling large-scale and", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-3537-8_12&hl=en&sa=X&d=18053713641719279471&ei=jmf7aKfkIIm16rQPu6Ol8AM&scisig=ABGrvjLf83uW7I1CojVrPDivo4rn&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research", "Hong Jin Kang - new related research"]}
{"title": "ISGraphVD: Precise Vulnerability Detection for IoT Supply Chains Based on Identifier Sensitive Graph", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "Y Zhang, X Liu, Z Liu, S Li, N Li, W Niu, R Zhou, Q Zhou\nOpen-source software (OSS) is widely reused in Internet of Things (IoT) devices, \nleading to widespread N-Day vulnerabilities when outdated components remain \nunpatched. Existing methods typically encode features of different Common", "link": "https://scholar.google.com/scholar_url?url=https://songli.io/papers/ISGraphVD.pdf&hl=en&sa=X&d=1350040853715836251&ei=jmf7aKfkIIm16rQPu6Ol8AM&scisig=ABGrvjL6Gy3HcNBj_HXDJJ6tYHSa&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "LLM-Assisted Synthesis of High-Assurance C Programs", "first_label": ["LLM"], "second_label": [], "data": "P Mukherjee, M Lu, B Delaware - 2025\nWe present SYNVERa novel, general purpose synthesizer for C programs \nequipped with machine-checked proofs of correctness using the Verified Software \nToolchain. To do so, SYNVER employs two Large Language Models (LLMs): the first\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.cs.purdue.edu/homes/bendy/SynVer/synver-preprint.pdf&hl=en&sa=X&d=10034668577701533579&ei=jmf7aKfkIIm16rQPu6Ol8AM&scisig=ABGrvjJVHZL0Qe9peKRNYugenHb2&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Selecting and Combining Large Language Models for Scalable Code Clone Detection", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "M Chochlov, GA Ahmed, JV Patten, Y Han, G Lu- arXiv preprint arXiv, 2025\nSource code clones pose risks ranging from intellectual property violations to \nunintended vulnerabilities. Effective and efficient scalable clone detection, especially \nfor diverged clones, remains challenging. Large language models (LLMs) have", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15480&hl=en&sa=X&d=9943637308311023337&ei=kGf7aM7QMO2ZieoP7ueJyQk&scisig=ABGrvjKwntTHj-gYFVYkC1ZboyXO&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "CodeDiffuSe: A masked diffusion framework for structure-aware code completion and repair", "first_label": ["Code"], "second_label": ["Repair", "Generation"], "data": "A Onan, HA Alhumyani- Journal of King Saud University Computer and, 2025\nCode completion and code repair have become fundamental tasks in software \nengineering and machine learning research. However, existing large language \nmodels (LLMs) for code generation, predominantly based on autoregressive", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00237-6&hl=en&sa=X&d=7004051865866003393&ei=kGf7aM7QMO2ZieoP7ueJyQk&scisig=ABGrvjLGM1IZub3Xu-Shr7decZu_&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "QuanBench: Benchmarking Quantum Code Generation with Large Language Models", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "X Guo, M Wang, J Zhao- arXiv preprint arXiv:2510.16779, 2025\nLarge language models (LLMs) have demonstrated good performance in general \ncode generation; however, their capabilities in quantum code generation remain \ninsufficiently studied. This paper presents QuanBench, a benchmark for evaluating", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16779&hl=en&sa=X&d=17566044421726947035&ei=kGf7aM7QMO2ZieoP7ueJyQk&scisig=ABGrvjLz_dVACfzQ6yk2NfyB_EtZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Enhancing LLM-based Fault Localization with a Functionality-Aware Retrieval-Augmented Generation Framework", "first_label": ["LLM", "Fault Localization"], "second_label": ["Generation", "Localization"], "data": "X Shi, Z Li, AR Chen- arXiv preprint arXiv:2509.20552, 2025\nFault localization (FL) is a critical but time-consuming task in software debugging, \naiming to identify faulty code elements. While recent advances in large language \nmodels (LLMs) have shown promise for FL, they often struggle with complex systems", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.20552&hl=en&sa=X&d=538936030362850881&ei=kGf7aM7QMO2ZieoP7ueJyQk&scisig=ABGrvjL4cjY5kpuvtyS7TJjphFny&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Automating software size measurement from python code using language models", "first_label": ["LLM", "Code"], "second_label": [], "data": "S Tenekeci, H nl, BA Gl, D Kele, M Kk- Automated Software, 2026\nSoftware size is a key input for project planning, effort estimation, and productivity \nanalysis. While pre-trained language models have shown promise in deriving \nfunctional size from natural-language requirements, measuring size directly from", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00571-z&hl=en&sa=X&d=6975543180754084024&ei=kGf7aM7QMO2ZieoP7ueJyQk&scisig=ABGrvjLkBeMkTvtxg_tOzsUhaAY9&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research", "Bach Le - new related research", "Hong Jin Kang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "SEER: Enhancing Chain-of-Thought Code Generation through Self-Exploring Deep Reasoning", "first_label": ["Code"], "second_label": ["Generation", "Reasoning"], "data": "S Gao, C Wang, C Gao, MR Lyu- arXiv preprint arXiv:2510.17130, 2025\nCode generation, the task of creating executable programs from natural language \nrequirements, has recently seen tremendous advances through Chain-of-Thought \n(CoT) reasoning, which enables Large Language Models (LLMs) to develop high", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.17130&hl=en&sa=X&d=12693856038029798940&ei=kGf7aM7QMO2ZieoP7ueJyQk&scisig=ABGrvjKEnVA5_PAClZTm8wVsrMks&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=7&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "Programming Language Techniques for Bridging LLM Code Generation Semantic Gaps", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Y Du, C Wang, H Wang- Proceedings of the 1st ACM SIGPLAN International, 2025\nLarge Language Models have demonstrated remarkable capabilities in automated \ncode generation, yet their statistical nature and black-box characteristics create \nsignificant semantic gaps manifested through syntax errors, semantic hallucinations\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3759425.3763383&hl=en&sa=X&d=13163076018612820373&ei=kGf7aM7QMO2ZieoP7ueJyQk&scisig=ABGrvjKZmEJcfJtbZWktIe-ihR1j&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=8&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Fact-Aligned and Template-Constrained Static Analyzer Rule Enhancement with LLMs", "first_label": ["LLM"], "second_label": [], "data": "Z Jiang, M Wen, G Wen, H Jin\nStatic analyzers are vital to ensure software quality, but often produce false alarms. In \nthis paper, we focus on the challenging task, directly refining defective static \ndetection rules in the analyzer with Large Language Models to mitigate false \npositives/negatives fundamentally. This paper introduces RULEREFINER, a novel \nmulti-stage framework for static analyzer rule refinement. Specifically, \nRULEREFINER systematically employs LLMs by integrating dynamic profiling\nCites: Detecting false alarms from automatic static analysis tools: How far\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://mingwen-cs.github.io/paper/ASE-2025-Camera-Ready.pdf&hl=en&sa=X&d=3402883198820837671&ei=jmf7aJScMIeVieoP9e_euQw&scisig=ABGrvjLZYRDNOG5XepzNkwF8-j9E&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:ABGrvjL7VxrFERkDgFky-TJkXnvY&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["1 new citation to articles by Hong Jin Kang"]}
{"title": "QuickSafe: Targeted Hardening Against Memory Corruption", "first_label": [], "second_label": [], "data": "J Blaser, F Gorter, K Gleissenthall, H Bos\nDespite decades of research, memory safety solutions see limited adoption, as they \noften incur high overheads, are complex to deploy, or cover only a narrow scope of \nbugs. In this paper, we present QuickSafea targeted approach to harden programs \nagainst exploitation of known but unresolved memory errors with minimal overhead. \nQuickSafe yields a stopgap patch that is immediately available, while the bug awaits \neventual resolution. Where most existing automatic patch generators rely on\nCites: Adversarial Patch Generation for Automated Program Repair", "link": "https://scholar.google.com/scholar_url?url=https://download.vusec.net/papers/quicksafe_sp26.pdf&hl=en&sa=X&d=17008190715069772206&ei=jWf7aLiYK86E6rQPjY_jkQI&scisig=ABGrvjI2R2eX2KY0myPKh9UXtXxz&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:ABGrvjLoGmGqyBdYvoW1MFiOqEKp&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Bach Le", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "When AI Takes the Wheel: Security Analysis of Framework-Constrained Program Generation", "first_label": [], "second_label": ["Generation"], "data": "Y Liu, Z Xing, S Pan, C Tantithamthavorn- arXiv preprint arXiv:2510.16823, 2025\nIn recent years, the AI wave has grown rapidly in software development. Even novice \ndevelopers can now design and generate complex framework-constrained software \nsystems based on their high-level requirements with the help of Large Language \nModels (LLMs). However, when LLMs gradually\" take the wheel\" of software \ndevelopment, developers may only check whether the program works. They often \nmiss security problems hidden in how the generated programs are implemented. In\nCites: Thanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16823&hl=en&sa=X&d=3361222524844858675&ei=jWf7aLiYK86E6rQPjY_jkQI&scisig=ABGrvjJKedL82jrVoYHkXEQqUTEv&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:ABGrvjLoGmGqyBdYvoW1MFiOqEKp&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 new citations to articles by Thanh Le-Cong", "David Lo - new related research", "4 new citations to articles by Bach Le"]}
{"title": "Large Language Models for Software Testing: A Research Roadmap", "first_label": ["LLM", "Software Testing"], "second_label": ["Search"], "data": "C Augusto, A Bertolino, G De Angelis, F Lonetti- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) are starting to be profiled as one of the most \nsignificant disruptions in the Software Testing field. Specifically, they have been \nsuccessfully applied in software testing tasks such as generating test code, or", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25043&hl=en&sa=X&d=1208330022631398164&ei=j2f7aO6LEdWY6rQPrbXRgQY&scisig=ABGrvjLqU3HMhvF_5yODTZeYJl6a&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "SECTEST-EVAL: CAN LLMS VERIFY SECURITY IMPACTS", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "OF AVulnerability\nLarge language models (LLMs) have shown remarkable potential in cybersecurity \napplications, particularly in code vulnerability analysis for both defensive and \noffensive purposes. Hence, several benchmarks have emerged to evaluate LLMs'", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DV4YGa3V2QO&hl=en&sa=X&d=7173618316408004049&ei=j2f7aO6LEdWY6rQPrbXRgQY&scisig=ABGrvjInak7n9wHVbEieTgRavCLP&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Challenge on Optimization of Context Collection for Code Completion", "first_label": ["Code"], "second_label": ["Generation"], "data": "D Ustalov, E Bogomolov, A Bezzubov, Y Golubev- arXiv preprint arXiv, 2025\nThe rapid advancement of workflows and methods for software engineering using AI \nemphasizes the need for a systematic evaluation and analysis of their ability to \nleverage information from entire projects, particularly in large code bases. In this\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04349%3F&hl=en&sa=X&d=3126744820627406093&ei=j2f7aO6LEdWY6rQPrbXRgQY&scisig=ABGrvjKnnFFcEPzyzZuaXwbxsC1c&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "MLCPD: A Unified Multi-Language Code Parsing Dataset with Universal AST Schema", "first_label": ["Code"], "second_label": [], "data": "J Gajjar, K Subramaniakuppusamy- arXiv preprint arXiv:2510.16357, 2025\nWe introduce the MultiLang Code Parser Dataset (MLCPD), a large-scale, language-\nagnostic dataset unifying syntactic and structural representations of code across ten \nmajor programming languages. MLCPD contains over seven million parsed source \nfiles normalized under our proposed universal Abstract Syntax Tree (AST) schema, \nenabling consistent cross-language reasoning, structural learning, and multilingual \nsoftware analysis. Unlike existing corpora that focus purely on token-level code or\nCites: Vgx: Large-scale sample generation for boosting learning-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16357&hl=en&sa=X&d=15367199942385914011&ei=jmf7aISuEIeVieoP9e_euQw&scisig=ABGrvjKDVJevvyPgUO3xuKXcR50u&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:ABGrvjIL7aJF81gdGo1gERw9ebUT&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "Breaking Guardrails, Facing Walls: Insights on Adversarial AI for Defenders & Researchers", "first_label": [], "second_label": ["Search"], "data": "G Bertollo, N Bodemir, J Burgess- arXiv preprint arXiv:2510.16005, 2025\nAnalyzing 500 CTF participants, this paper shows that while participants readily \nbypassed simple AI guardrails using common techniques, layered multi-step \ndefenses still posed significant challenges, offering concrete insights for building \nsafer AI systems.\nCites: Llm agents can autonomously hack websites", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16005&hl=en&sa=X&d=4103318876950651123&ei=jmf7aISuEIeVieoP9e_euQw&scisig=ABGrvjLvjHo6vTeYA6fo5BJcMqsy&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:ABGrvjIL7aJF81gdGo1gERw9ebUT&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "SPARD: Defending Harmful Fine-Tuning Attack via Safety Projection with RelevanceDiversity Data Selection", "first_label": [], "second_label": [], "data": "AVIAS PROJECTION\nFine-tuning large language models often undermines their safety alignment, a \nproblem further amplified by harmful fine-tuning attacks in which adversarial data \nremoves safeguards and induces unsafe behaviors. We propose** SPARD**, a \ndefense framework that integrates** S** afety-** P** rojected** A** lternating \noptimization with** R** elevance-** D** iversity aware data selection. SPARD \nemploys SPAG, which optimizes alternatively between utility updates and explicit\nCites: Removing rlhf protections in gpt-4 via fine-tuning", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D81mxnkcW43&hl=en&sa=X&d=4640997185178482705&ei=jmf7aISuEIeVieoP9e_euQw&scisig=ABGrvjLFp_PSclBO8j7EWYsmM9xm&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:ABGrvjIL7aJF81gdGo1gERw9ebUT&html=&pos=2&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "MBST: a bad smells testbed for microservice systems", "first_label": ["Software Testing"], "second_label": [], "data": "Y Xing, W Yang, J Yin, D Chu, Z Tu- Cluster Computing, 2025\nPoor design in microservice architectures can lead to microservice bad smells \n(MBSs), negatively impacting system performance, reliability, and scalability. These \nlatent MBSs, if not promptly detected and eliminated, can accumulate and cause", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10586-025-05641-1&hl=en&sa=X&d=17011677757760399391&ei=j2f7aJycLb7WieoPn4GZgQE&scisig=ABGrvjJcUxc_QqmXurt4Nnxs20cf&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:ABGrvjLiNx7BmV3CtCrSb8n_Y3dH&html=&pos=1&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Security Vulnerabilities in AI-Generated Code: A Large-Scale Analysis of Public GitHub Repositories", "first_label": ["Vulnerabilities", "Code"], "second_label": [], "data": "M Schreiber, P Tippe- International Conference on Information and, 2025\nThis paper presents a comprehensive empirical analysis of security vulnerabilities in \nAI-generated code across public GitHub repositories. We collected and analyzed \n7,703 files explicitly attributed to four major AI tools: ChatGPT (91.52%), GitHub", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-3537-8_9&hl=en&sa=X&d=12380316708857381053&ei=j2f7aJycLb7WieoPn4GZgQE&scisig=ABGrvjIE3LAfntb04Xv2EJIiSupU&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:ABGrvjLiNx7BmV3CtCrSb8n_Y3dH&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Code Digital Twin: Empowering LLMs with Tacit Knowledge for Complex Software Development", "first_label": ["LLM", "Code"], "second_label": [], "data": "X Peng, C Wang- arXiv preprint arXiv:2510.16395, 2025\nRecent advances in large language models (LLMs) have demonstrated strong \ncapabilities in software engineering tasks, raising expectations of revolutionary \nproductivity gains. However, enterprise software development is largely driven by", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16395&hl=en&sa=X&d=8507888308546930595&ei=jWf7aKfRPL7WieoPn4GZgQE&scisig=ABGrvjIzSYZLgifrDAsdyamW_Ysz&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Multi Language Models for On-the-Fly Syntax Highlighting", "first_label": ["LLM"], "second_label": [], "data": "ME Palma, P Rani, HC Gall- arXiv preprint arXiv:2510.04166, 2025\nSyntax highlighting is a critical feature in modern software development \nenvironments, enhancing code readability and developer productivity. However, \ndelivering accurate highlighting in real time remains challenging for online and web", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04166%3F&hl=en&sa=X&d=2254729212502568662&ei=jWf7aKfRPL7WieoPn4GZgQE&scisig=ABGrvjIMpU0YGaMDVoPzEyw5QYUR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "RANGER--Repository-Level Agent for Graph-Enhanced Retrieval", "first_label": ["Repository-Level"], "second_label": ["Agent", "Graph"], "data": "P Shah, R Ghosh, A Singhal, D Dutta- arXiv preprint arXiv:2509.25257, 2025\nGeneral-purpose automated software engineering (ASE) includes tasks such as \ncode completion, retrieval, repair, QA, and summarization. These tasks require a \ncode retrieval system that can handle specific queries about code entities, or code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25257&hl=en&sa=X&d=3054390226051185769&ei=jWf7aKfRPL7WieoPn4GZgQE&scisig=ABGrvjIXwMPztva_GaFR6_J7qsws&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=4&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Beyond SWE-Bench: A Compiler-Assisted Pipeline for Multi-language Automated", "first_label": [], "second_label": [], "data": "D Flores-Araiza, S Hinojosa- Advances in Soft Computing: 24th Mexican, 2025\nAutomated program repair (APR) research predominantly focuses on Python \nenvironments, creating significant infrastructure gaps for compiled languages like C, \nC++, and Java that dominate production systems. We present the first systematic", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DdHqQEQAAQBAJ%26oi%3Dfnd%26pg%3DPA115%26ots%3DPJditDLKWX%26sig%3DLVyqEp5XVyAYN1xUecqQ2JjujMY&hl=en&sa=X&d=11355528957197608093&ei=jWf7aKfRPL7WieoPn4GZgQE&scisig=ABGrvjLkMI1uw-bPt3C8eSKgTu94&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=5&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "What Do They Fix? LLM-Aided Categorization of Security Patches for Critical Memory Bugs", "first_label": ["LLM", "Bug"], "second_label": [], "data": "X Li, J Pu, Y Wu, X Zou, S Zhu, Q Wu, Z Zhang, J Hsu- arXiv preprint arXiv, 2025\nOpen-source software projects are foundational to modern software ecosystems, with \nthe Linux kernel standing out as a critical exemplar due to its ubiquity and \ncomplexity. Although security patches are continuously integrated into the Linux\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.22796&hl=en&sa=X&d=5877456260761011502&ei=jWf7aKfRPL7WieoPn4GZgQE&scisig=ABGrvjIeON_T-kQB0Y1OLfGe7VuN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=6&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Cottontail: Large Language Model-Driven Concolic Execution for Highly Structured Test Input Generation", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "H Tu, S Lee, Y Li, P Chen, L Jiang, M Bhme- of the IEEE Symposium on Security, 2026\nHow can we perform concolic execution to generate highly structured test inputs for \nsystematically testing parsing programs? Existing concolic execution engines are \nsignificantly restricted by (1) input structure-agnostic path constraint selection", "link": "https://scholar.google.com/scholar_url?url=https://haoxintu.github.io/files/sp2026-cottontail.pdf&hl=en&sa=X&d=18058727110766818863&ei=kWf7aNmeAZjO6rQPk_O3wAE&scisig=ABGrvjJEdIFBYe4OAs4jVnG6s3oK&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Enhancing Code Review through Fuzzing and Likely Invariants", "first_label": ["Fuzzing", "Code Review", "Code"], "second_label": [], "data": "W Charoenwet, P Thongtanunam, VT Pham, C Treude- arXiv preprint arXiv, 2025\nMany software projects employ manual code review to gatekeep defects and \nvulnerabilities in the code before integration. However, reviewers often work under \ntime pressure and rely primarily on static inspection, leaving the dynamic aspects of", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15512&hl=en&sa=X&d=1339818209110486888&ei=kWf7aNmeAZjO6rQPk_O3wAE&scisig=ABGrvjLpix9WXdRvjqJ9pWyGQD17&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "10 new citations to articles by Abhik Roychoudhury", "Abhik Roychoudhury - new related research"]}
{"title": "Balancing Validity and Vulnerability: Knowledge-Driven Seed Generation via LLMs for Deep Learning Library Fuzzing", "first_label": ["Vulnerabilities", "LLM", "Fuzzing"], "second_label": ["Generation"], "data": "R Liao, X Yan, Z Pang, K Zhu- Applied Sciences, 2025\nFuzzing deep learning (DL) libraries is essential for uncovering security \nvulnerabilities in AI systems. Existing approaches enhance large language models \n(LLMs) with external knowledge such as bug reports to improve the quality of", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2076-3417/15/19/10396&hl=en&sa=X&d=9374413942225787882&ei=kWf7aNmeAZjO6rQPk_O3wAE&scisig=ABGrvjKhiDEIHlVEE5WVDiWRb4SH&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Large-Scale Empirical Analysis of Continuous Fuzzing: Insights from 1 Million Fuzzing Sessions", "first_label": ["Fuzzing"], "second_label": [], "data": "T Shirai, O Nourry, Y Kashiwa, K Fujiwara, Y Kamei- arXiv preprint arXiv, 2025\nSoftware vulnerabilities are constantly being reported and exploited in software \nproducts, causing significant impacts on society. In recent years, the main approach \nto vulnerability detection, fuzzing, has been integrated into the continuous integration", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16433&hl=en&sa=X&d=4720648398624229113&ei=kWf7aNmeAZjO6rQPk_O3wAE&scisig=ABGrvjLvN3fPNsFOAfS3JY64ZdkS&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "R1-MFSol: a Smart Contract Vulnerability Detection Model Based on LLM and Multi-modal Feature Fusion", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection"], "data": "H Yang, Z Hao, T Liu- International Conference on Information and, 2025\nSmart contracts are programs stored and run on blockchains, which conform to the \ndecentralized characteristics of blockchains. Contract vulnerabilities can cause \nsignificant losses to blockchains, so vulnerability detection of smart contracts is", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-3543-9_8&hl=en&sa=X&d=284873340636578689&ei=kWf7aNmeAZjO6rQPk_O3wAE&scisig=ABGrvjLvcscXOYcGH8ZsEmhiGDGM&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Assertion Messages with Large Language Models (LLMs) for Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "A Aljohani, AH Mollah, H Do- arXiv preprint arXiv:2509.19673, 2025\nAssertion messages significantly enhance unit tests by clearly explaining the \nreasons behind test failures, yet they are frequently omitted by developers and \nautomated test-generation tools. Despite recent advancements, Large Language", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19673&hl=en&sa=X&d=7084463702742822906&ei=kWf7aNmeAZjO6rQPk_O3wAE&scisig=ABGrvjLuKcuLx3UrwEBxySJvUs4t&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Human-Aligned Code Readability Assessment with Large Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "WC Oudraogo, Y Li, X Dang, P Borsukiewicz, X Zhou- arXiv preprint arXiv, 2025\nCode readability is crucial for software comprehension and maintenance, yet difficult \nto assess at scale. Traditional static metrics often fail to capture the subjective, \ncontext-sensitive nature of human judgments. Large Language Models (LLMs) offer\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16579&hl=en&sa=X&d=12659624534862037240&ei=kWf7aNmeAZjO6rQPk_O3wAE&scisig=ABGrvjL2nWFvSPDHdvoGZggKBvrJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "SIADAFIX: issue description response for adaptive program repair", "first_label": ["APR"], "second_label": ["Repair"], "data": "X Cao, N Yu- arXiv preprint arXiv:2510.16059, 2025\nWe propose utilizing fast and slow thinking to enhance the capabilities of large \nlanguage model-based agents on complex tasks such as program repair. In \nparticular, we design an adaptive program repair method based on issue description \nresponse, called SIADAFIX. The proposed method utilizes slow thinking bug fix \nagent to complete complex program repair tasks, and employs fast thinking workflow \ndecision components to optimize and classify issue descriptions, using issue\nCites: Enhancing repository-level software repair via repository-aware", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16059&hl=en&sa=X&d=5786445982665756977&ei=j2f7aMuqAvrUieoPvMbB8Qc&scisig=ABGrvjIIqgzPyIq7oRcF5nYPk0qW&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:ABGrvjKFoYpfVt7EiQsbVsLwN3n6&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["4 new citations to articles by Bach Le", "Abhik Roychoudhury - new related research"]}
{"title": "No Place to Hide: An Efficient and Accurate Backdoor Detection Tool for Ethereum ERC-20 Smart Contracts", "first_label": ["Smart Contracts", "Ethereum"], "second_label": ["Detection"], "data": "S Zhou, L Zhou, Y Tao- International Conference on Information and, 2025\nEthereum ERC-20 smart contracts are now widely utilized in various domains for \ntrust and transparent transaction process. However, ERC-20 contracts face \nsignificant security risks, particularly backdoors that can lead to severe incidents. In \nbackdoor attacks, malicious actors can exploit these vulnerabilities to perform \nunauthorized transactions, steal funds, or manipulate token balances, resulting in \nsubstantial financial losses and damaging trust of blockchain system. This paper\nCites: Smart contract development: Challenges and opportunities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-3543-9_9&hl=en&sa=X&d=1102128674100915924&ei=j2f7aMuqAvrUieoPvMbB8Qc&scisig=ABGrvjJoyKRnYkVKpZHNjKxKXUKV&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:ABGrvjKFoYpfVt7EiQsbVsLwN3n6&html=&pos=3&folt=cit", "author": ["Bach Le"], "ref": ["4 new citations to articles by Bach Le"]}
{"title": "Analyzing Compliance and Complications of Integrating Internationalized X. 509 Certificates", "first_label": [], "second_label": [], "data": "M Zhang, J Guo, Y Zhang, S Zhang, B Liu, H Zhao, X Li - 2025\nThe global PKI supports the issuance of Unicerts, which are X. 509 certificates that \nintegrate internationalized content such as IDNs and multilingual text. This \nintegration introduces complexity in Unicert issuance and usage. Past incidents \nshowed that poor Unicode handling can cause security risks, including spoofing and \nremote code execution, yet threats specific to PKI and Unicerts remain \nunderexplored. This paper presents the first large-scale study of Unicerts, examining\nCites: Large language model guided protocol fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://cypher-z.github.io/files/imc25-unicert.pdf&hl=en&sa=X&d=8749472837612451792&ei=j2f7aOWoH4GpieoPyfaRyA4&scisig=ABGrvjKB_oyCV8PpPy1Bh8fG0AAj&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "NLSaber: Enhancing Netlink Family Fuzzing via Automated Syscall Description Generation", "first_label": ["Fuzzing"], "second_label": ["Generation"], "data": "L Ma, X Lin, Z Zhang, Y Zhou\nRecently, security researchers have uncovered a significant number of high-severity \nvulnerabilities in Netlink families, posing serious threats to overall kernel security. \nDespite these risks, there are no automated methods available to effectively detect \nbugs in Netlink families. For example, Syzkallera state-of-the-art, general-purpose \nkernel fuzzerfails to achieve effective fuzzing for Netlink families because it \ndepends on manually written descriptions that are often incomplete or inaccurate. To\nCites: Smart greybox fuzzing", "link": "https://scholar.google.com/scholar_url?url=http://www.malgenomeproject.org/papers/esorics25_nlsaber.pdf&hl=en&sa=X&d=16990889969423848271&ei=j2f7aOWoH4GpieoPyfaRyA4&scisig=ABGrvjJRPkYoF9rRjymF8lMB0_jD&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "AMOS2: adaptive multi-objective seed schedule in gray-box fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "W Jiao, X Li, W Yao, Z Chen, G Zhang- The Computer Journal, 2025\nCoverage-based graybox fuzzing is one of the most effective methods for identifying \nvulnerabilities in the field of software security testing. To maximize performance, \nfuzzers need to assess the quality of seeds and make two decisions appropriately:(1) \nwhich seed (Parent test case) has more potential for fuzzing, ie the prioritization \nproblem?(2) How many new inputs (Child test cases) are generated by mutating a \nseed, ie energy schedule problem? However, existing studies do not rationally utilize\nCites: Directed greybox fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://academic.oup.com/comjnl/advance-article/doi/10.1093/comjnl/bxaf123/8294329&hl=en&sa=X&d=1040039006592745696&ei=j2f7aOWoH4GpieoPyfaRyA4&scisig=ABGrvjKV5482DJb1QdOGKhK9fiMe&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "gem5 Co-Pilot: AI Assistant Agent for Architectural Design Space Exploration", "first_label": [], "second_label": ["Agent"], "data": "Z Fu, A Manley, M Alian\nGenerative AI is increasing the productivity of software and hardware development \nacross many application domains. In this work, we utilize the power of Large \nLanguage Models (LLMs) to develop a co-pilot agent for assisting gem5 users with \nautomating design space exploration. Computer architecture design space \nexploration is complex and time-consuming, given that numerous parameter settings \nand simulation statistics must be analyzed before improving the current design. The\nCites: Design space exploration of caches using compressed traces", "link": "https://scholar.google.com/scholar_url?url=https://sarchlab.org/cams25/gem5%2520Co-Pilot%2520AI%2520Assistant%2520Agent%2520for%2520Architectural%2520Design%2520Space%2520Exploration.pdf&hl=en&sa=X&d=10460392485781722422&ei=j2f7aOWoH4GpieoPyfaRyA4&scisig=ABGrvjImL6zjYBhM2UKB1ZhFcAPG&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Curiosity-Driven Crawling Approach", "first_label": [], "second_label": [], "data": "SL Chen- Proceedings of the 7th International Conference on, 2025\nIn recent years, the widespread adoption of smart mobile devices has driven a \nsignificant increase in demand for Android apps, creating a growing need for \neffective Android app testing. One crucial method to testing Android apps is the \nautomated exploration of their GUIs to detect potential crashes. To facilitate this, we \npreviously developed ACE (Android CrawlEr), a model-based GUI testing tool for \nAndroid apps that employs a search-based algorithm to explore and test the app\nCites: Time-travel Testing of Android Apps\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DDHuQEQAAQBAJ%26oi%3Dfnd%26pg%3DPA3%26ots%3DuSBHWznsnB%26sig%3DUD6CtVV6N2-5ud4bEkDxyYm8MUw&hl=en&sa=X&d=18291278939560818470&ei=j2f7aOWoH4GpieoPyfaRyA4&scisig=ABGrvjLasSOwB6bhcfXD2H4ngPT6&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=9&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "SymbFuzz: Symbolic Execution Guided Hardware Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "SS Miftah, A Srivastava, H Kim, S Wei, K Basu- Proceedings of the 58th IEEE/ACM, 2025\nModern hardware incorporates reusable designs to reduce cost and time to market, \ninadvertently increasing exposure to security vulnerabilities. While formal verification \nand simulation-based approaches have been traditionally utilized to mitigate these", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3725843.3756131&hl=en&sa=X&d=13892451739855032330&ei=j2f7aO3xOu2ZieoP7ueJyQk&scisig=ABGrvjIckMkLWaPrI55dPwVGCMUZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "MALF: A Multi-Agent LLM Framework for Intelligent Fuzzing of Industrial Control Protocols", "first_label": ["LLM", "Fuzzing"], "second_label": ["Agent"], "data": "B Ning, X Zong, K He- arXiv preprint arXiv:2510.02694, 2025\nIndustrial control systems (ICS) are vital to modern infrastructure but increasingly \nvulnerable to cybersecurity threats, particularly through weaknesses in their \ncommunication protocols. This paper presents MALF (Multi-Agent LLM Fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02694&hl=en&sa=X&d=17402884467768873558&ei=j2f7aO3xOu2ZieoP7ueJyQk&scisig=ABGrvjKY-EhTZJxLf3FSS8GSogrU&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Minoris: Practical Out-of-Emulator Kernel Module Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Xiang, F Wang, Y Chen, Q Liu, H Wang, J Wang- IEEE Transactions on, 2025\nVulnerabilities in the Linux kernel can be exploited to perform privilege escalation \nand take over the whole system. Fuzzing has been leveraged to detect Linux kernel \nvulnerabilities during the last decade. However, existing kernel fuzzing techniques", "link": "https://scholar.google.com/scholar_url?url=http://www.malgenomeproject.org/papers/tdsc25_minoris.pdf&hl=en&sa=X&d=4018952161547770155&ei=j2f7aO3xOu2ZieoP7ueJyQk&scisig=ABGrvjJ6DkbswJoR00cuvD4KKxo6&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Extraction and Mutation at a High Level: Template-Based Fuzzing for JavaScript Engines", "first_label": ["Fuzzing"], "second_label": [], "data": "WK Wong, D Xiao, CT Lai, Y Peng, D Wu, S Wang- Proceedings of the ACM on, 2025\nJavaScript (JS) engines implement complex language semantics and optimization \nstrategies to support the dynamic nature of JS, making them difficult to test thoroughly \nand prone to subtle, security-critical bugs. Existing fuzzers often struggle to generate", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3763154&hl=en&sa=X&d=604366854830515299&ei=j2f7aO3xOu2ZieoP7ueJyQk&scisig=ABGrvjJ8_etpKvSy6Zr28o1_lt7G&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=6&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "E-FuzzEdge: Optimizing Embedded Device Security with Scalable In-Place Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "D Rusconi, O Yousef, M Picca, F Toffalini, A Lanzi- arXiv preprint arXiv:2510.01393, 2025\nIn this paper we show E-FuzzEdge, a novel fuzzing architecture targeted towards \nimproving the throughput of fuzzing campaigns in contexts where scalability is \nunavailable. E-FuzzEdge addresses the inefficiencies of hardware-in-the-loop", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01393&hl=en&sa=X&d=876126288656849057&ei=j2f7aO3xOu2ZieoP7ueJyQk&scisig=ABGrvjI29yYRKrlJ80KOjroLHXeT&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=8&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "DT4LM: Differential Testing for Reliable Language Model Updates in Classification Tasks", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "X Zuo, Y Xiao, X Cao, W Wang, JS Dong- IEEE Transactions on Software, 2025\nIn the field of Natural Language Processing (NLP), Language Models (LMs) are \nfrequently updated to enhance performance. However, these updates can introduce \nunintended regressions, cases where the updated model fails on inputs correctly", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11205851/&hl=en&sa=X&d=4279235962652410820&ei=9_D5aJOCPNWY6rQPrbXRgQY&scisig=AAZF9b_vk8ySHE8yEr_D_w4b14zI&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "1 new citation to articles by Thanh Le-Cong", "1 new citation to articles by Hong Jin Kang", "1 new citation to articles by Bach Le"]}
{"title": "Interpretable Vulnerability Detection in LLMs: A BERT-Based Approach with SHAP Explanations", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "N Ahmad, C Zhang- Computers, Materials and Continua, 2025\nSource code vulnerabilities present significant security threats, necessitating \neffective detection techniques. Rigid rule-sets and pattern matching are the \nfoundation of traditional static analysis tools, which drown developers in false", "link": "https://scholar.google.com/scholar_url?url=https://cdn.techscience.press/files/cmc/2025/TSP_CMC-85-2/TSP_CMC_67044/TSP_CMC_67044.pdf&hl=en&sa=X&d=1252818813327302141&ei=9_D5aJOCPNWY6rQPrbXRgQY&scisig=AAZF9b-4FiCmmcGvTLnyvFdif2Cb&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A systematic exploration of C-to-rust code translation based on large language models: prompt strategies and automated repair", "first_label": ["APR", "LLM", "Code"], "second_label": ["Repair", "Generation"], "data": "R Zhang, S Zhang, L Xie- Automated Software Engineering, 2026\nC is widely used in system programming due to its low-level flexibility. However, as \ndemands for memory safety and code reliability grow, Rust has become a more \nfavorable alternative owing to its modern design principles. Migrating existing C code", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00570-0&hl=en&sa=X&d=5082487858088455285&ei=9_D5aJOCPNWY6rQPrbXRgQY&scisig=AAZF9b_JL3FP7-OdYQZPYkX0tm7J&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Metamorphic Testing for Smart Contracts: A User-Behavior-Sequence-Aware Approach and Automation Tool", "first_label": ["Smart Contracts", "Software Testing"], "second_label": [], "data": "CA Sun, Y Ji, X Zheng, H Liu- IEEE Transactions on Services Computing, 2025\nSmart contracts are basically the self-executing programs on blockchain networks \nlike Ethereum. Normally managed through external user accounts, they operate via a \ntransaction-driven state transition process. Once deployed on the blockchain", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11206493/&hl=en&sa=X&d=13495408290240561529&ei=9_D5aJOCPNWY6rQPrbXRgQY&scisig=AAZF9b_Xbu6cIHpmC7X_4JGjoDOb&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Leveraging Code Cohesion Analysis to Identify Source Code Supply Chain Attacks", "first_label": ["Code"], "second_label": [], "data": "M Reuben, I Mendel, O Feldman, M Kravchik, M Guri- arXiv preprint arXiv, 2025\nSupply chain attacks significantly threaten software security with malicious code \ninjections within legitimate projects. Such attacks are very rare but may have a \ndevastating impact. Detecting spurious code injections using automated tools is", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.14778&hl=en&sa=X&d=14938838885220553189&ei=9_D5aJOCPNWY6rQPrbXRgQY&scisig=AAZF9b-0X4EKDGYd4BJpNSvC6Fjz&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "GlassWing: A Tailored Static Analysis Approach for Flutter Android Apps", "first_label": ["Static Analysis"], "second_label": [], "data": "X Zhang, Y Su, L Fan, M Cai, S Chen\nThe variety of mobile operating systems available in the market has led to the \nemergence of cross-platform frameworks, which simplify the development and \ndeployment of mobile applications across multiple platforms simultaneously. Among\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://sen-chen.github.io/img_cs/pdf/ASE2025-GlassWing%2520A%2520Tailored%2520Static%2520Analysis%2520Approach%2520for%2520Flutter%2520Android%2520Apps.pdf&hl=en&sa=X&d=3861822635221850315&ei=9_D5aJOCPNWY6rQPrbXRgQY&scisig=AAZF9b_9GeneOcBAHmgsAvkH3XdV&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "K Shehada, Y Wu, WD Feng, A Iyer, G Kumfert, Y Ding- NeurIPS 2025 Workshop on\nLarge Language Models (LLMs) have revolutionized automated program repair \n(APR) but current benchmarks like SWE-Bench predominantly focus on userspace \napplications and overlook the complexities of kernel-space debugging and repair", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DNY4wv5C39G&hl=en&sa=X&d=13284020585308537468&ei=9vD5aKyDJoGpieoPyfaRyA4&scisig=ABGrvjITGmaV0UTqgjmorBghp9Q5&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Fully automated synthetic BIM dataset generation using a deep learning-based framework", "first_label": [], "second_label": ["Generation"], "data": "X Liang, N Yabuki, T Fukuda- Automation in Construction, 2026\nBuilding information models (BIMs) are essential for efficient building operation, yet \nmost existing buildings only have two-dimensional (2D) drawings, leading to \nincreased interest in 2D-to-BIM reconstruction. To address the data scarcity", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0926580525006247&hl=en&sa=X&d=10129115388115331923&ei=9vD5aKyDJoGpieoPyfaRyA4&scisig=ABGrvjJBhLQsv_PGO0Rgwz9gdHLF&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Misactivation-Aware Stealthy Backdoor Attacks on Neural Code Understanding Models", "first_label": ["Code"], "second_label": [], "data": "X Sun, Y Xiao, L Bo, W Sun, X Liu, B Li, J Zhang- IEEE Transactions on Software, 2025\nNeural code models (NCMs) play a crucial role in helping developers solve code \nunderstanding tasks. Recent studies have exposed that NCMs are vulnerable to \nseveral security threats, among which backdoor attack is one of the toughest. It is", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11181191/&hl=en&sa=X&d=1845847614155086033&ei=9vD5aKyDJoGpieoPyfaRyA4&scisig=ABGrvjI9DNxRO77jA3vgieL6tY3m&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Semantics-Aligned, Curriculum-Driven, and Reasoning-Enhanced Vulnerability Repair Framework", "first_label": ["Vulnerabilities"], "second_label": ["Repair", "Reasoning"], "data": "C Yang, T Zhang, J Jiang, X Zhou, H Tian, J Shi- arXiv preprint arXiv, 2025\nCurrent learning-based Automated Vulnerability Repair (AVR) approaches, while \npromising, often fail to generalize effectively in real-world scenarios. Our diagnostic \nanalysis reveals three fundamental weaknesses in state-of-the-art AVR", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01002&hl=en&sa=X&d=3295364238331710726&ei=9vD5aKyDJoGpieoPyfaRyA4&scisig=ABGrvjIl8pYNpRxZZ-68eLx672oD&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=3&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation", "first_label": ["LLM", "Fault Localization"], "second_label": ["Localization"], "data": "F Liu, T Wang, L Zhang, Z Yang, J Jiang, Z Sun- arXiv preprint arXiv:2509.25676, 2025\nProviding timely and personalized guidance for students' programming assignments, \noffers significant practical value for helping students complete assignments and \nenhance their learning. In recent years, various automated Fault Localization (FL)", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25676&hl=en&sa=X&d=16831300563596066577&ei=9vD5aKyDJoGpieoPyfaRyA4&scisig=ABGrvjKOmbi2TriQ76tXIs_L9sIr&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=4&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "CG-Bench: Can Language Models Assist Call Graph Construction in the Real World?", "first_label": ["LLM", "Static Analysis"], "second_label": ["Graph"], "data": "T Yuan, W Zhang, D Chen, J Wang- Proceedings of the 1st ACM SIGPLAN, 2025\nLanguage models for coding are shifting their focus from function-level to repository-\nlevel, with complex function invocations. We introduce CG-Bench, the first manually \nconstructed benchmark that measures the ability to understand call graphs for", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3759425.3763379&hl=en&sa=X&d=11570618845570061776&ei=9vD5aKyDJoGpieoPyfaRyA4&scisig=ABGrvjJTTJMRIMAuaa7eEoue4X54&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=7&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Distilling Lightweight Language Models for C/C++ Vulnerabilities", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "Z Wei, X Yang, J Sun, Z Zhang- arXiv preprint arXiv:2510.06645, 2025\nThe increasing complexity of modern software systems exacerbates the prevalence \nof security vulnerabilities, posing risks of severe breaches and substantial economic \nloss. Consequently, robust code vulnerability detection is essential for software\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.06645&hl=en&sa=X&d=3698413128266030415&ei=9vD5aKyDJoGpieoPyfaRyA4&scisig=ABGrvjJ1fCv1MSxVF7pMC87uzV8-&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=8&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "A Multi-Language Object-Oriented Programming Benchmark for Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "S Wang, L Ding, L Shen, Y Luo, H Hu, L Zhang, F Lin- arXiv preprint arXiv, 2025\nEstablishing fair and robust benchmarks is essential for evaluating intelligent code \ngeneration by large language models (LLMs). Our survey of 35 existing benchmarks \nuncovers three major imbalances: 85.7% focus on a single programming language;", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.26111&hl=en&sa=X&d=2388658668398987935&ei=-vD5aJP3BtrZzwKX7-SYDw&scisig=ABGrvjLOMqK6KseaqrwLOyii9NBd&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "JDExtractor: an automated approach for efficient extraction of defect-related methods in Java projects", "first_label": ["Software Defect"], "second_label": [], "data": "T Liu, J Ye, W Ji- Automated Software Engineering, 2026\nHigh-quality repositories containing real-world defects are essential for developing \ndefect-related algorithms. Although plenty of defect repositories exist, they often fail \nto capture the context of inter-procedural defects, which include all methods in the", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00563-z&hl=en&sa=X&d=8201831092714916491&ei=-vD5aJP3BtrZzwKX7-SYDw&scisig=ABGrvjKyzg1BPx5ST9S9tifv_cw-&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research", "4 new citations to articles by Abhik Roychoudhury"]}
{"title": "BloomAPR: A Bloom's Taxonomy-based Framework for Assessing the Capabilities of LLM-Powered APR Solutions", "first_label": ["LLM"], "second_label": [], "data": "Y Ma, J Shin, L Da Silva, Z Ming, S Wang, F Khomh- arXiv preprint arXiv, 2025\nRecent advances in large language models (LLMs) have accelerated the \ndevelopment of AI-driven automated program repair (APR) solutions. However, these \nsolutions are typically evaluated using static benchmarks such as Defects4J and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25465&hl=en&sa=X&d=11066311399156471814&ei=-vD5aJP3BtrZzwKX7-SYDw&scisig=ABGrvjLV6fSkcBPGA5NmFimfwxQS&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "AP2O: Correcting LLM-Generated Code Errors Type by Type Like Humans via Adaptive Progressive Preference Optimization", "first_label": ["LLM", "Code"], "second_label": [], "data": "J Zhang, W Xia, H Dong, Q Lin, J Cao- arXiv preprint arXiv:2510.02393, 2025\nLLMs' code generation capabilities have yielded substantial improvements in the \neffectiveness of programming tasks. However, LLM-generated code still suffers from \ncompilation and runtime errors. Existing offline preference optimization methods", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02393&hl=en&sa=X&d=3930841886253564413&ei=-vD5aJP3BtrZzwKX7-SYDw&scisig=ABGrvjL0CxKs_FsALMWew0zkynx0&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "The Richer Representation Fallacy: Are We Just Adding Noise to LLM-based Software Vulnerability Detectors?", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "H Hanif, S Maffeis, NB Anuar\nLarge Language Models (LLMs) have established strong baselines for software \nvulnerability detection, leading to a common assumption that their performance can \nbe enhanced by augmenting them with supplementary information such as Abstract\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.doc.ic.ac.uk/~maffeis/papers/icoco25.pdf&hl=en&sa=X&d=9374945953362351896&ei=-vD5aJP3BtrZzwKX7-SYDw&scisig=ABGrvjJP7g6ze4j15IMQXWKX48ED&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "CIVS: A Collective-Intelligence Ensemble for Automated Software Vulnerability Scoring", "first_label": ["Vulnerabilities"], "second_label": [], "data": "SL Mirtaheri, R Shahbazian, V Pascucci- IEEE Access, 2025\nAutomated and accurate Common Vulnerability Scoring System (CVSS) labeling is \nrequired for quick patch processing. Large Language Models (LLMs) have shown \nimpressive capabilities in understanding and generating human language; however\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11206133.pdf&hl=en&sa=X&d=6848923925667945345&ei=-PD5aObhJPOx6rQP9IDG8Qs&scisig=AAZF9b8bU6Ipwl_gh6eLLrxGF46P&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "1 new citation to articles by Xin ZHOU"]}
{"title": "Backdoor-Powered Prompt Injection Attacks Nullify Defense Methods", "first_label": [], "second_label": [], "data": "Y Chen, H Li, Y Sui, Y Song, B Hooi- arXiv preprint arXiv:2510.03705, 2025\nWith the development of technology, large language models (LLMs) have dominated \nthe downstream natural language processing (NLP) tasks. However, because of the \nLLMs' instruction-following abilities and inability to distinguish the instructions in the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03705&hl=en&sa=X&d=9793005798347645046&ei=-fD5aIe-Js-F6rQPotzKiQ0&scisig=AAZF9b_HnZpDS0idSVQ9IazqK7ZK&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Poisoned to Aware: Fostering Backdoor Self-Awareness in LLMs", "first_label": ["LLM"], "second_label": [], "data": "G Shen, S Cheng, X Xu, Y Zhou, H Guo, Z Zhang- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) can acquire deceptive behaviors through backdoor \nattacks, where the model executes prohibited actions whenever secret triggers \nappear in the input. Existing safety training methods largely fail to address this", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05169&hl=en&sa=X&d=9405091671790165810&ei=-fD5aIe-Js-F6rQPotzKiQ0&scisig=AAZF9b8o4jJRSuUiMq-cqxdu42gl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Q Wei, T Yang, Y Wang, X Li, L Li, Z Yin, Y Zhan, T Holz- arXiv preprint arXiv, 2025\nLarge Language Model (LLM) agents use memory to learn from past interactions, \nenabling autonomous planning and decision-making in complex environments. \nHowever, this reliance on memory introduces a critical security risk: an adversary can", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02373%3F&hl=en&sa=X&d=4598414696562770679&ei=-fD5aIe-Js-F6rQPotzKiQ0&scisig=AAZF9b81TzOjaUWLDsP44BPpjuXB&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Dual-Space Smoothness for Robust and Balanced LLM Unlearning", "first_label": ["LLM"], "second_label": [], "data": "H Yan, Z Liu, M Jiang- arXiv preprint arXiv:2509.23362, 2025\nWith the rapid advancement of large language models, Machine Unlearning has \nemerged to address growing concerns around user privacy, copyright infringement, \nand overall safety. Yet state-of-the-art (SOTA) unlearning methods often suffer from", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23362&hl=en&sa=X&d=1871730686130311929&ei=-fD5aIe-Js-F6rQPotzKiQ0&scisig=AAZF9b8As51yVW8jz__d_c1PoJ_F&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "MetaBreak: Jailbreaking Online LLM Services via Special Token Manipulation", "first_label": ["LLM"], "second_label": [], "data": "W Zhu, Z Xiang, W Niu, L Guan- arXiv preprint arXiv:2510.10271, 2025\nUnlike regular tokens derived from existing text corpora, special tokens are artificially \ncreated to annotate structured conversations during the fine-tuning process of Large \nLanguage Models (LLMs). Serving as metadata of training data, these tokens play a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10271&hl=en&sa=X&d=10904776402205985786&ei=-fD5aIe-Js-F6rQPotzKiQ0&scisig=AAZF9b_F0Cun6iwf_kcQRFluBJsN&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Webcloak: Characterizing and mitigating the threats of llm-driven web agents as intelligent scrapers", "first_label": ["LLM"], "second_label": ["Agent"], "data": "X Li, T Qiu, Y Jin, L Wang, H Guo, X Jia, X Wang- Proceedings of the 2026, 2026\nThe rise of web agents powered by large language models (LLMs) is reshaping the \nlandscape of human-computer interaction, enabling users to automate complex web \ntasks with natural language commands. However, this progress introduces serious", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Xinfeng-Li-7/publication/396418425_WebCloak_Characterizing_and_Mitigating_Threats_from_LLM-Driven_Web_Agents_as_Intelligent_Scrapers/links/68ea2bc4f3032e2b4be84935/WebCloak-Characterizing-and-Mitigating-Threats-from-LLM-Driven-Web-Agents-as-Intelligent-Scrapers.pdf&hl=en&sa=X&d=11222165444201781035&ei=-fD5aIe-Js-F6rQPotzKiQ0&scisig=AAZF9b_YUPVueXaKg_vffu8We5ja&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "C Ziakas, N Loo, N Jain, A Russo- arXiv preprint arXiv:2510.07239, 2025\nAutomated red-teaming has emerged as a scalable approach for auditing Large \nLanguage Models (LLMs) prior to deployment, yet existing approaches lack \nmechanisms to efficiently adapt to model-specific vulnerabilities at inference. We", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07239%3F&hl=en&sa=X&d=7730973334197366962&ei=-fD5aIe-Js-F6rQPotzKiQ0&scisig=AAZF9b_6OS1meKBJ_r2Js8UAke4U&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Valid Stopping for LLM Generation via Empirical Dynamic Formal Lift", "first_label": ["LLM"], "second_label": ["Generation"], "data": "S Akter, IF Shihab, A Sharma- arXiv preprint arXiv:2510.06478, 2025\nWe introduce Sequential-EDFL (Empirical Dynamic Formal Lift), applying anytime-\nvalid sequential testing to language model generation stopping. Our approach tracks \ninformation lift--the log-likelihood ratio between full models and deliberately", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.06478&hl=en&sa=X&d=14932518012707883160&ei=-fD5aIe-Js-F6rQPotzKiQ0&scisig=AAZF9b9Dby7z2N2n_QBkW3Cth3vw&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Certifiable Safe RLHF: Fixed-Penalty Constraint Optimization for Safer Language Models", "first_label": ["LLM"], "second_label": [], "data": "K Pandit, S Ganguly, A Banerjee, S Angizi, A Ghosh- arXiv preprint arXiv:2510.03520, 2025\nEnsuring safety is a foundational requirement for large language models (LLMs). \nAchieving an appropriate balance between enhancing the utility of model outputs \nand mitigating their potential for harm is a complex and persistent challenge", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03520%3F&hl=en&sa=X&d=4542062984345920079&ei=-fD5aIe-Js-F6rQPotzKiQ0&scisig=AAZF9b8EWkBgbTMrAWRzGI48E_SK&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "VISOR++: Universal Visual Inputs based Steering for Large Vision Language Models", "first_label": ["LLM"], "second_label": [], "data": "R Balakrishnan, M Phute- arXiv preprint arXiv:2509.25533, 2025\nAs Vision Language Models (VLMs) are deployed across safety-critical applications, \nunderstanding and controlling their behavioral patterns has become increasingly \nimportant. Existing behavioral control methods face significant limitations: system\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25533%3F&hl=en&sa=X&d=10426105664438089802&ei=-fD5aIe-Js-F6rQPotzKiQ0&scisig=AAZF9b9t7vnaEkw3JWoCXDM-Hr5q&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "InsightQL: Advancing Human-Assisted Fuzzing with a Unified Code Database and Parameterized Query Interface", "first_label": ["Fuzzing", "Code"], "second_label": [], "data": "W Gao, R Borovica-Gajic, SK Cha, T Qiu, VT Pham- arXiv preprint arXiv:2510.04835, 2025\nFuzzing is a highly effective automated testing method for uncovering software \nvulnerabilities. Despite advances in fuzzing techniques, such as coverage-guided \ngreybox fuzzing, many fuzzers struggle with coverage plateaus caused by fuzz", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04835&hl=en&sa=X&d=7721758508651636625&ei=-PD5aMTlNbeO6rQP6NHlsQ0&scisig=AAZF9b9S6TLnsxYfSiDSKvyS6fS2&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Boosting Parallel Fuzzing with Boundary-Targeted Task Allocation and Exploration", "first_label": ["Fuzzing"], "second_label": [], "data": "H Liang, Y Guo, H Wu, Y Xia, Y Xiang, X Jin, H Peng- IEEE Transactions on, 2025\nAs software systems grow in complexity, scale, and update frequency, parallel \nfuzzing has become essential for mitigating the efficiency limitations of traditional \nfuzzing. Effective task allocation is vital in maximizing parallel fuzzing efficiency and", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11206474/&hl=en&sa=X&d=16498784007064341742&ei=-PD5aMTlNbeO6rQP6NHlsQ0&scisig=AAZF9b9B9HMIHRxTKGTTZiNfO5nO&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "4 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Survey for MQTT Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "SY Chowdhury, R Sun, B Dudley- Proceedings of the 2025 Workshop on Re-design, 2025\nMessage Queuing Telemetry Transport (MQTT) has emerged as a promising \ncommunication protocol for Internet of Things (IoT) ecosystems, enabling lightweight, \nscalable publish-subscribe messaging across resource-constrained devices. As", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3733823.3764515&hl=en&sa=X&d=13012329971672204999&ei=-PD5aMTlNbeO6rQP6NHlsQ0&scisig=AAZF9b8vgf7FG03SkoQTaHno7c8H&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "DynamiQ: Unlocking the Potential of Dynamic Task Allocation in Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "W Yan, T Murray, B Rubinstein, VT Pham- arXiv preprint arXiv:2510.04469, 2025\nWe present DynamiQ, a full-fledged and optimized successor to AFLTeam that \nsupports dynamic and adaptive parallel fuzzing. Unlike most existing approaches \nthat treat individual seeds as tasks, DynamiQ leverages structural information from", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04469&hl=en&sa=X&d=10962816615102660239&ei=-PD5aMTlNbeO6rQP6NHlsQ0&scisig=AAZF9b_5VltWA46OsWSnq5GXtqKm&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing", "first_label": ["LLM", "Fuzzing", "Bug"], "second_label": [], "data": "S Ou, Y Li, L Yu, C Wei, T Wen, Q Chen, Y Chen- IEEE Transactions on, 2025\nDeep learning (DL) frameworks serve as the backbone for a wide range of artificial \nintelligence applications. However, bugs within DL frameworks can cascade into \ncritical issues in higher-level applications, jeopardizing reliability and security. While", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/32/4359463/11201027.pdf&hl=en&sa=X&d=1422528139240657868&ei=-PD5aMTlNbeO6rQP6NHlsQ0&scisig=AAZF9b899-spy-aa2AQhyA9vfr3w&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Function Clustering-Based Fuzzing Termination: Toward Smarter Early Stopping", "first_label": ["Fuzzing"], "second_label": [], "data": "L Ding, W Yang, Y Xue\nFuzzing is a testing technique that generates a large number of inputs to cause \nprogram crashes. As software development accelerates and projects scale, the \ndemand for fuzz testing in software assurance has increased. Performing", "link": "https://scholar.google.com/scholar_url?url=https://wzyang.cn/files/FuzzingTermination.pdf&hl=en&sa=X&d=16741608997780760317&ei=-PD5aMTlNbeO6rQP6NHlsQ0&scisig=AAZF9b8PamUxP4hadUhNaXUhRS_c&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Automating software size measurement with language models: Insights from industrial case studies", "first_label": ["LLM"], "second_label": [], "data": "H nl, S Tenekeci, DE Kennouche, O Demirrs- Journal of Systems and Software, 2025\nObjective software size measurement is critical for accurate effort estimation, yet \nmany organizations avoid it due to high costs, required expertise, and time-\nconsuming manual effort. This often leads to vague predictions, poor planning, and\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225003073&hl=en&sa=X&d=5059883465057516935&ei=-PD5aMTlNbeO6rQP6NHlsQ0&scisig=AAZF9b_UuarYpBo8g6NwqQ3xVSkn&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=8&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "PIONEER: improving the robustness of student models when compressing pre-trained models of code", "first_label": ["Code"], "second_label": [], "data": "X Liu, X Liu, L Bo, X Wu, Y Yang, X Sun, F Zhou- Automated Software Engineering, 2026\nPre-trained models of code have shown significant effectiveness in a variety of \nsoftware engineering tasks, but they are difficult for local deployment due to their \nlarge size. Existing works mainly focus on compressing these large models into small", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00560-2&hl=en&sa=X&d=17836676178374949159&ei=-fD5aKytNYOAieoPtpDVoA0&scisig=ABGrvjJdD0MvEWeVdOXzGwm8Edqh&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "LLM-based Vulnerability Discovery through the Lens of Code Metrics", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": [], "data": "F Weissberg, L Pirch, E Imgrund, J Mller, T Eisenhofer- arXiv preprint arXiv, 2025\nLarge language models (LLMs) excel in many tasks of software engineering, yet \nprogress in leveraging them for vulnerability discovery has stalled in recent years. To \nunderstand this phenomenon, we investigate LLMs through the lens of classic code\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19117%3F&hl=en&sa=X&d=9123199236929215814&ei=-fD5aKytNYOAieoPtpDVoA0&scisig=ABGrvjINMq2iD3RR-wdlKRQHhs7z&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "On the Resilience of Traditional AI Algorithms Toward Poisoning Attacks for Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "L Gonzlez-Manzano, J Garcia-Alfaro- IET Information Security, 2025\nThe complexity of implementations and the interconnection of assorted systems and \ndevices facilitate the emergence of vulnerabilities. Detection systems are developed \nto fight against this security issue, being the use of artificial intelligence (AI) a", "link": "https://scholar.google.com/scholar_url?url=https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/ise2/9997989&hl=en&sa=X&d=5722794315536622997&ei=9vD5aLyePIePieoPtcvwuAc&scisig=ABGrvjLdOwLlSBpL11TJzAaXOj2f&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Repair", "Reasoning"], "data": "XC Wen, Z Lin, Y Yang, C Gao, D Ye- arXiv preprint arXiv:2510.05480, 2025\nThe exponential increase in software vulnerabilities has created an urgent need for \nautomatic vulnerability repair (AVR) solutions. Recent research has formulated AVR \nas a sequence generation problem and has leveraged large language models", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05480&hl=en&sa=X&d=17087307418542281791&ei=9vD5aLyePIePieoPtcvwuAc&scisig=ABGrvjJlsQcjOBCSZutD9pRzL3u0&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Enhancing Domain-Specific Code Completion via Collaborative Inference with Large and Small Language Models", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Yu, Z Gao, L Bao, Z Liu- ACM Transactions on Software Engineering and, 2025\nLarge language model-based code completion has demonstrated excellent \nperformance, but still encounters challenges in capturing domain-specific knowledge \nfor more precise completion within specific domains, ie, domain-specific code", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3770748&hl=en&sa=X&d=2019769577165862416&ei=9vD5aLyePIePieoPtcvwuAc&scisig=ABGrvjKO1fKaLDZwwCDDcSmDx0Da&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Improving the Efficiency of LLM Agent Systems through Trajectory Reduction", "first_label": ["LLM"], "second_label": ["Agent"], "data": "YA Xiao, P Gao, C Peng, Y Xiong- arXiv preprint arXiv:2509.23586, 2025\nMulti-turn agent systems based on Large Language Models (LLMs) have been \nincreasingly popular for software engineering tasks. While LLM agents show decent \neffectiveness, the high computational cost of input tokens due to the ever-growing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23586%3F&hl=en&sa=X&d=12596444921036280365&ei=9vD5aLyePIePieoPtcvwuAc&scisig=ABGrvjLC0C_0GltjgtJTt8p-QsJp&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "X Yin, C Ni, X Li, L Chen, G Ma, X Yang\nRecently, Large Language Models (LLMs) have gained attention for their ability to \nhandle a broad range of tasks, including unit test generation. Despite their success, \nLLMs may exhibit hallucinations when generating unit tests for focal methods or", "link": "https://scholar.google.com/scholar_url?url=https://vinci-grape.github.io/papers/Enhancing_LLM_s_Ability_to_Generate_More_Repository_Aware_Unit_Tests_Through_Precise_Context_Injection.pdf&hl=en&sa=X&d=3506872574868649515&ei=9vD5aLyePIePieoPtcvwuAc&scisig=ABGrvjKPA0zq2FXS1WyPoCr65qwT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "LLM Agents for Automated Dependency Upgrades", "first_label": ["LLM"], "second_label": ["Agent"], "data": "V Tawosi, S Alamir, X Liu, M Veloso- arXiv preprint arXiv:2510.03480, 2025\nAs a codebase expands over time, its library dependencies can become outdated \nand require updates to maintain innovation and security. However, updating a library \ncan introduce breaking changes in the code, necessitating significant developer time", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03480&hl=en&sa=X&d=6490656773391404708&ei=9vD5aLyePIePieoPtcvwuAc&scisig=ABGrvjLTI-aGv2gyB5kKiU57yoCH&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Real-VulLLM: An LLM Based Assessment Framework in the Wild", "first_label": ["LLM"], "second_label": [], "data": "R Safdar, D Mateen, ST Ali, W Hussain- arXiv preprint arXiv:2510.04056, 2025\nArtificial Intelligence (AI) and more specifically Large Language Models (LLMs) have \ndemonstrated exceptional progress in multiple areas including software engineering, \nhowever, their capability for vulnerability detection in the wild scenario and its\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04056&hl=en&sa=X&d=7464868966945655593&ei=9vD5aLyePIePieoPtcvwuAc&scisig=ABGrvjIaO4pEKfAZ4-It9iNMVajB&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Unveiling the Centralized Security Risks in Decentralized Ecosystems", "first_label": [], "second_label": [], "data": "K Yan, J Zhang, X Liu, W Diao- IEEE Transactions on Dependable and Secure, 2025\nThe decentralized ecosystem is claimed to avoid security risks caused by \ncentralization. Decentralized services, such as crypto wallets and decentralized \napplications (DApps), are purported to offer more reliable security and better protect \nuser privacy. However, our research suggests a different reality: centralized \ncomponents or scenarios are still prevalent within decentralized ecosystems, \nintroducing security risks typically associated with centralization. This work\nCites: Large language model guided protocol fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11205310/&hl=en&sa=X&d=13031482534762170477&ei=-PD5aPCSEZjO6rQPk_O3wAE&scisig=AAZF9b-s-MdFd1kuklZIFZBztZx-&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Exploring the Relationship Between Code Metrics and the Ability of Large Language Models to Solve Code Issues", "first_label": ["LLM", "Code"], "second_label": [], "data": "O Ramirez, P Ekler- 2025 IEEE 16th International Conference on Cognitive, 2025\nLarge Language Models (LLMs) are increasingly integrated into software \nengineering workflows, assisting with tasks such as code generation, unit testing, \nand bug resolution. Despite their growing use, limited research has examined how \ncode-level metrics such as Halstead complexity, maintainability index, and source \nlines of code correlate with issue resolution rates for LLM-powered agents when \nmodifying existing codebases. The paper bridges the well established field of code\nCites: AutoCodeRover: Autonomous program improvement", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11200869/&hl=en&sa=X&d=1302319353271404221&ei=-PD5aPCSEZjO6rQPk_O3wAE&scisig=AAZF9b8oUDRGKb5aJZG_jxZUVu8Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
