{"title": "On the Freshness of Pinned Dependencies in Maven", "first_label": [], "second_label": [], "data": "V Vikram, Y Agarwal, R Padhye- arXiv preprint arXiv:2510.22815, 2025\nLibrary dependencies in software ecosystems play a crucial role in the development \nof software. As newer releases of these libraries are published, developers may opt \nto pin their dependencies to a particular version. While pinning may have benefits in \nensuring reproducible builds and avoiding breaking changes, it bears larger risks in \nusing outdated dependencies that may contain bugs and security vulnerabilities. To \nunderstand the frequency and consequences of dependency pinning, we first define\nCites: Test mimicry to assess the exploitability of library vulnerabilities", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.22815&hl=en&sa=X&d=14311664418567176613&ei=qsYEacOFKM6E6rQPlNvGgAg&scisig=ABGrvjJP_9S1ymcd42-J1VlmWowS&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:ABGrvjKFoYpfVt7EiQsbVsLwN3n6&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["4 new citations to articles by Bach Le", "1 new citation to articles by Hong Jin Kang"]}
{"title": "A Pattern-Oriented Ontology and Workflow Modeling Approach for the Sui Move Programming Language", "first_label": [], "second_label": [], "data": "A Giatzis, CK Georgiadis - 2025\nSmart contracts are vulnerable to critical, design-level Business Logic Flaws (BLFs) \nthat conventional analysis tools often fail to detect. To address this semantic gap, this \nstudy introduces and validates a novel ontological framework designed to formally \nmodel the link between high-level architectural intent and low-level code. The \nmethodology involved constructing a multi-layered framework that integrates a \ncomprehensive formal ontology of the Sui Move language, a library of secure design\nCites: Smart contract development: Challenges and opportunities", "link": "https://scholar.google.com/scholar_url?url=https://www.preprints.org/frontend/manuscript/fa02820d2af029bb8810458af7dfabe3/download_pub&hl=en&sa=X&d=12875564609920459087&ei=qsYEacOFKM6E6rQPlNvGgAg&scisig=ABGrvjLkET3GdVLsK5SaQogUvENk&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:ABGrvjKFoYpfVt7EiQsbVsLwN3n6&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["4 new citations to articles by Bach Le"]}
{"title": "AgriTrustChain: A Decentralized Certification and Edaphic Data Traceability Framework with Zero-Leak for Sustainable Farming Using Blockchain", "first_label": ["Blockchain"], "second_label": [], "data": "WBS Souei, MA Hattab, L Sliman, RB Djemaa\nAgriculture relies heavily on the storage and management of Electronic Land \nRecords (ELRs), which are usually maintained in centralized datacenters and shared \namong farmers, government agencies, and soil experts. However, these traditional \nstorage methods suffer from several limitations, including risks of tampering, \nunauthorized disclosure of confidential data, and challenges in efficient data retrieval \ncaused by inconsistent formats across institutions. Centralized systems are also\nCites: Smart contract development: Challenges and opportunities", "link": "https://scholar.google.com/scholar_url?url=https://www.scitepress.org/Papers/2025/139603/139603.pdf&hl=en&sa=X&d=10252620263264823187&ei=qsYEacOFKM6E6rQPlNvGgAg&scisig=ABGrvjKmWp-kBbvwtgyqZmfJG4CF&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:ABGrvjKFoYpfVt7EiQsbVsLwN3n6&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["4 new citations to articles by Bach Le"]}
{"title": "Automated smart contract vulnerability threat modelling with STRIDE", "first_label": ["Vulnerabilities", "Smart Contracts"], "second_label": [], "data": "N Jeri, M Turkanovi\nSmart contracts are subject to critical vulnerabilities that existing tools often detect \nwithout a structured classification of threats. This article presents a heuristic \nmethodology for classifying smart contract vulnerabilities according to the STRIDE \nmodel. By combining Solidity-specific semantic patterns with manually defined \nheuristics, the system enables transparent and understandable detection of threats in \nall STRIDE categories. Our approach, implemented as an API service, processes\nCites: Smart contract development: Challenges and opportunities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ceur-ws.org/Vol-4077/paper9.pdf&hl=en&sa=X&d=3001392296087298216&ei=qsYEacOFKM6E6rQPlNvGgAg&scisig=ABGrvjIBBKeMGpsOXA3CFOcU_GPN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:ABGrvjKFoYpfVt7EiQsbVsLwN3n6&html=&pos=3&folt=cit", "author": ["Bach Le"], "ref": ["4 new citations to articles by Bach Le"]}
{"title": "Assessing the effectiveness of recent closed-source large language models in fault localization and automated program repair", "first_label": ["APR", "LLM", "Fault Localization"], "second_label": ["Repair", "Localization"], "data": "B Wang, M Deng, M Chen, Y Lin, J Zhou, JM Zhang- Automated Software, 2026\nAbstract Large Language Models (LLMs) have made significant advancements in \ncode-related tasks. In the field of automated debugging, fault localization (FL) and \nautomated program repair (APR) are two prevalent topics attracting significant", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00549-x&hl=en&sa=X&d=2170467974947906611&ei=qcYEaYjtGYGpieoP_8jXuAM&scisig=ABGrvjLjc5ZU-mipJQXt_7SuyqBd&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Quang-Cuong Bui - new related research", "David Lo - new related research", "5 new citations to articles by Abhik Roychoudhury", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "PortGPT: Towards Automated Backporting Using Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Li, Z Yu, J Song, M Xu, Y Luo, D Mu- arXiv preprint arXiv:2510.22396, 2025\nPatch backporting, the process of migrating mainline security patches to older \nbranches, is an essential task in maintaining popular open-source projects (eg, Linux \nkernel). However, manual backporting can be labor-intensive, while existing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.22396&hl=en&sa=X&d=916502372979732461&ei=qcYEaYjtGYGpieoP_8jXuAM&scisig=ABGrvjIltEMAtblhnVWg0Hijp9el&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Quang-Cuong Bui - new related research", "David Lo - new related research", "5 new citations to articles by Abhik Roychoudhury", "Xin ZHOU - new related research"]}
{"title": "LMFuzz: Program repair fuzzing based on large language models", "first_label": ["APR", "LLM", "Fuzzing"], "second_label": ["Repair"], "data": "R Lin, R Wang, G Hu, X Xu- Automated Software Engineering, 2026\nGenerating programs using large language models (LLMs) for fuzz testing has \nemerged as a significant testing methodology. While traditional fuzzers can produce \ncorrect programs, their effectiveness is limited by excessive constraints and restricted", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00568-8&hl=en&sa=X&d=16706984066078411801&ei=qcYEaYjtGYGpieoP_8jXuAM&scisig=ABGrvjLMTxGR3-Z1Hr556q7Ejx9K&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Abhik Roychoudhury - new related research", "Quang-Cuong Bui - new related research", "Hong Jin Kang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Multi Language Models for On-the-Fly Syntax Highlighting", "first_label": ["LLM"], "second_label": [], "data": "ME Palma, P Rani, HC Gall- arXiv preprint arXiv:2510.04166, 2025\nSyntax highlighting is a critical feature in modern software development \nenvironments, enhancing code readability and developer productivity. However, \ndelivering accurate highlighting in real time remains challenging for online and web\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04166%3F&hl=en&sa=X&d=2254729212502568662&ei=qcYEaYjtGYGpieoP_8jXuAM&scisig=ABGrvjIMpU0YGaMDVoPzEyw5QYUR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=3&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "SymbFuzz: Symbolic Execution Guided Hardware Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "SS Miftah, A Srivastava, H Kim, S Wei, K Basu- Proceedings of the 58th IEEE/ACM, 2025\nModern hardware incorporates reusable designs to reduce cost and time to market, \ninadvertently increasing exposure to security vulnerabilities. While formal verification \nand simulation-based approaches have been traditionally utilized to mitigate these", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3725843.3756131&hl=en&sa=X&d=13892451739855032330&ei=q8YEafSBOpSQieoPpvjD8A0&scisig=ABGrvjIckMkLWaPrI55dPwVGCMUZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "MALF: A Multi-Agent LLM Framework for Intelligent Fuzzing of Industrial Control Protocols", "first_label": ["LLM", "Fuzzing"], "second_label": ["Agent"], "data": "B Ning, X Zong, K He- arXiv preprint arXiv:2510.02694, 2025\nIndustrial control systems (ICS) are vital to modern infrastructure but increasingly \nvulnerable to cybersecurity threats, particularly through weaknesses in their \ncommunication protocols. This paper presents MALF (Multi-Agent LLM Fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02694&hl=en&sa=X&d=17402884467768873558&ei=q8YEafSBOpSQieoPpvjD8A0&scisig=ABGrvjKY-EhTZJxLf3FSS8GSogrU&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Large-Scale Empirical Analysis of Continuous Fuzzing: Insights from 1 Million Fuzzing Sessions", "first_label": ["Fuzzing"], "second_label": [], "data": "T Shirai, O Nourry, Y Kashiwa, K Fujiwara, Y Kamei- arXiv preprint arXiv, 2025\nSoftware vulnerabilities are constantly being reported and exploited in software \nproducts, causing significant impacts on society. In recent years, the main approach \nto vulnerability detection, fuzzing, has been integrated into the continuous integration", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16433&hl=en&sa=X&d=4720648398624229113&ei=q8YEafSBOpSQieoPpvjD8A0&scisig=ABGrvjLvN3fPNsFOAfS3JY64ZdkS&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Minoris: Practical Out-of-Emulator Kernel Module Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Xiang, F Wang, Y Chen, Q Liu, H Wang, J Wang- IEEE Transactions on, 2025\nVulnerabilities in the Linux kernel can be exploited to perform privilege escalation \nand take over the whole system. Fuzzing has been leveraged to detect Linux kernel \nvulnerabilities during the last decade. However, existing kernel fuzzing techniques", "link": "https://scholar.google.com/scholar_url?url=http://www.malgenomeproject.org/papers/tdsc25_minoris.pdf&hl=en&sa=X&d=4018952161547770155&ei=q8YEafSBOpSQieoPpvjD8A0&scisig=ABGrvjJ6DkbswJoR00cuvD4KKxo6&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Extraction and Mutation at a High Level: Template-Based Fuzzing for JavaScript Engines", "first_label": ["Fuzzing"], "second_label": [], "data": "WK Wong, D Xiao, CT Lai, Y Peng, D Wu, S Wang- Proceedings of the ACM on, 2025\nJavaScript (JS) engines implement complex language semantics and optimization \nstrategies to support the dynamic nature of JS, making them difficult to test thoroughly \nand prone to subtle, security-critical bugs. Existing fuzzers often struggle to generate", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3763154&hl=en&sa=X&d=604366854830515299&ei=q8YEafSBOpSQieoPpvjD8A0&scisig=ABGrvjJ8_etpKvSy6Zr28o1_lt7G&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Hong Jin Kang - new related research"]}
{"title": "E-FuzzEdge: Optimizing Embedded Device Security with Scalable In-Place Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "D Rusconi, O Yousef, M Picca, F Toffalini, A Lanzi- arXiv preprint arXiv:2510.01393, 2025\nIn this paper we show E-FuzzEdge, a novel fuzzing architecture targeted towards \nimproving the throughput of fuzzing campaigns in contexts where scalability is \nunavailable. E-FuzzEdge addresses the inefficiencies of hardware-in-the-loop", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01393&hl=en&sa=X&d=876126288656849057&ei=q8YEafSBOpSQieoPpvjD8A0&scisig=ABGrvjI29yYRKrlJ80KOjroLHXeT&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=6&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "BugPilot: Complex Bug Generation for Efficient Learning of SWE Skills", "first_label": ["Bug"], "second_label": ["Generation"], "data": "A Sonwane, I White, H Lee, M Pereira, L Caccia, M Kim- arXiv e-prints, 2025\nFigure 1: Comparison to previous SoTA results. We train FROGBOSS with our \ncollected data including our new FEATADD datasets, and FROGBOSS achieves \n54.6% pass@ 1 averaged over three seeds. With pass@ 3 we achieve a score of", "link": "https://scholar.google.com/scholar_url?url=https://microsoft.github.io/debug-gym/static/papers/BugPilot_arxiv.pdf&hl=en&sa=X&d=16262114761206686527&ei=q8YEafSBOpSQieoPpvjD8A0&scisig=ABGrvjIHGetWqaGVvo2Iya2TUNGz&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=7&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Clutch Control: An Attention-based Combinatorial Bandit for Efficient Mutation in JavaScript Engine Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "M Foley, S Maffeis, MF Rozi, T Takahashi- arXiv preprint arXiv:2510.12732, 2025\nJavaScript engines are widely used in web browsers, PDF readers, and server-side \napplications. The rise in concern over their security has led to the development of \nseveral targeted fuzzing techniques. However, existing approaches use random", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12732%3F&hl=en&sa=X&d=1368299778829400409&ei=q8YEafSBOpSQieoPpvjD8A0&scisig=ABGrvjI4CAZkWhcKOyqw3pENwwii&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=8&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "DFAFUZZ: Fuzzing for Embedded JavaScript Virtual Machines with Type-Directed DFA", "first_label": ["Fuzzing"], "second_label": [], "data": "H Lai, B Hua\nJavaScript is rapidly being deployed in securitycritical embedded domains, including \nIoT devices, edge computing, and smart automotive applications. Embedded \nJavaScript virtual machines (VMs) are critical in powering such deployments, which\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://csslab-ustc.github.io/publications/2025/js-vm-bugs.pdf&hl=en&sa=X&d=14086662969394613156&ei=q8YEafSBOpSQieoPpvjD8A0&scisig=ABGrvjIDsQUp4KqbY58bTWR9VXh_&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=9&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing", "first_label": ["LLM", "Fuzzing", "Bug"], "second_label": [], "data": "S Ou, Y Li, L Yu, C Wei, T Wen, Q Chen, Y Chen- IEEE Transactions on, 2025\nDeep learning (DL) frameworks serve as the backbone for a wide range of artificial \nintelligence applications. However, bugs within DL frameworks can cascade into \ncritical issues in higher-level applications, jeopardizing reliability and security. While", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/32/4359463/11201027.pdf&hl=en&sa=X&d=1422528139240657868&ei=q8YEabj9C7mAieoPq7Lh4A8&scisig=ABGrvjI1tTlw2XwsJvzcyylBVxMq&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Abhik Roychoudhury - new related research", "Bach Le - new related research"]}
{"title": "Bug Histories as Sources of Compiler Fuzzing Mutators", "first_label": ["Fuzzing", "Bug"], "second_label": [], "data": "L Liu, F Qin, O Legunsen, M d'Amorim- arXiv preprint arXiv:2510.07834, 2025\nBugs in compilers, which are critical infrastructure today, can have outsized negative \nimpacts. Mutational fuzzers aid compiler bug detection by systematically mutating \ncompiler inputs, ie, programs. Their effectiveness depends on the quality of the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07834&hl=en&sa=X&d=9037187058146226309&ei=q8YEabj9C7mAieoPq7Lh4A8&scisig=ABGrvjIG6zX5TgS9MStSGVHyXUtI&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "NatGVD: Natural Adversarial Example Attack towards Graph-based Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "A Rath, W Qi, Y Li, X Wang- arXiv preprint arXiv:2510.04987, 2025\nGraph-based models learn rich code graph structural information and present \nsuperior performance on various code analysis tasks. However, the robustness of \nthese models against adversarial example attacks in the context of vulnerability", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04987&hl=en&sa=X&d=16144354957589846642&ei=q8YEabj9C7mAieoPq7Lh4A8&scisig=ABGrvjKVVWD-G2UrNfBQI0a18maw&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "E2Edev: Benchmarking Large Language Models in End-to-End Software Development Task", "first_label": ["LLM"], "second_label": [], "data": "J Liu, C Huang, Z Guan, W Lei, Y Deng- arXiv preprint arXiv:2510.14509, 2025\nE2EDev comprises (i) a fine-grained set of user requirements,(ii){multiple BDD test \nscenarios with corresponding Python step implementations for each requirement}, \nand (iii) a fully automated testing pipeline built on the Behave framework. To ensure", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.14509&hl=en&sa=X&d=15900279319022234305&ei=q8YEabj9C7mAieoPq7Lh4A8&scisig=ABGrvjJ71cvauMgej6922cy2tGye&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Exploring the Power of Diffusion Large Language Models for Software Engineering: An Empirical Investigation", "first_label": ["LLM"], "second_label": [], "data": "J Zhang, T Li, X Zhang, Q Hu, B Shi- arXiv preprint arXiv:2510.04605, 2025\nAutoregressive Large Language Models (AR-LLMs) are widely used in software \nengineering (SE) but face limitations in processing code structure information and \nsuffer from high inference latency. Diffusion LLMs (DLLMs) offer a promising", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04605&hl=en&sa=X&d=10573600647646258285&ei=q8YEabj9C7mAieoPq7Lh4A8&scisig=ABGrvjL5R-YlKad_jWq6RXhc4mcD&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "DT4LM: Differential Testing for Reliable Language Model Updates in Classification Tasks", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "X Zuo, Y Xiao, X Cao, W Wang, JS Dong- IEEE Transactions on Software, 2025\nIn the field of Natural Language Processing (NLP), Language Models (LMs) are \nfrequently updated to enhance performance. However, these updates can introduce \nunintended regressions, cases where the updated model fails on inputs correctly", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11205851/&hl=en&sa=X&d=4279235962652410820&ei=q8YEabj9C7mAieoPq7Lh4A8&scisig=ABGrvjKlOHcizD46rps8GlscSi_q&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "PCRepair: A Context-Aware Template-Based Approach for Automated Program Repair", "first_label": ["APR"], "second_label": ["Repair"], "data": "H Cao, W Zhang, Y Wang, Y Chu, M Deng, Z He- International Journal of Software, 2025\nAutomated Program Repair (APR) is increasingly vital for managing the complexity of \nmodern software systems. However, current APR techniques suffer from inefficiently \nselecting repair components, resulting in suboptimal patches. To address these", "link": "https://scholar.google.com/scholar_url?url=https://www.worldscientific.com/doi/abs/10.1142/S0218194025500731&hl=en&sa=X&d=10736890690647149823&ei=q8YEabj9C7mAieoPq7Lh4A8&scisig=ABGrvjKIfDzI4FxEk_Z2oR6hTnmJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Challenge on Optimization of Context Collection for Code Completion", "first_label": ["Code"], "second_label": ["Generation"], "data": "D Ustalov, E Bogomolov, A Bezzubov, Y Golubev- arXiv preprint arXiv, 2025\nThe rapid advancement of workflows and methods for software engineering using AI \nemphasizes the need for a systematic evaluation and analysis of their ability to \nleverage information from entire projects, particularly in large code bases. In this\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04349%3F&hl=en&sa=X&d=3126744820627406093&ei=q8YEabj9C7mAieoPq7Lh4A8&scisig=ABGrvjKnnFFcEPzyzZuaXwbxsC1c&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "LLVM-Based Efficient Hybrid Cache and TCM Memory Allocation for Low-Latency", "first_label": [], "second_label": [], "data": "G Jeon, D Park- IEEE Embedded Systems Letters, 2025\nCache memory has been introduced to accelerate embedded system performance \nand is automatically managed without programmer intervention through hardware-\nbased cache controllers. However, since it operates based on typical variable access \npatterns, opportunities for complementary approaches remain. In contrast, \nScratchpad Memory (SPM) or Tightly Coupled Memory (TCM), which is closely \ncoupled with the processor core, require direct programmer control over data\nCites: WCET centric data allocation to scratchpad memory", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11218194/&hl=en&sa=X&d=17788066513205518140&ei=q8YEabrkG_XSieoP5dXGqA0&scisig=ABGrvjKzbL7-wkRATywp6IoMRO8m&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "Understanding, Localizing, and Repairing Flakiness in Web Front-End Testing", "first_label": ["Software Testing"], "second_label": ["Repair"], "data": "Y PEI - 2025\nSoftware system reliability and maintainability are threatened by flaky tests, which \nyield inconsistent results without changing the code. Due to the complexity of modern \nfront-end frameworks, dynamic content, and asynchronous behaviour, the issue is \nparticularly painful in the context of web applications. Although test 5 flakiness in \nsoftware testing is becoming more widely recognized, little is known about its precise \nforms and underlying causes in web front-end testing. This dissertation aims to\nCites: Concurrency-related flaky test detection in android apps", "link": "https://scholar.google.com/scholar_url?url=https://orbilu.uni.lu/bitstream/10993/66145/1/thesis.pdf&hl=en&sa=X&d=12084277497073420105&ei=q8YEabrkG_XSieoP5dXGqA0&scisig=ABGrvjKn7CdGLDur5cubhysGga3a&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "Improving classifier robustness", "first_label": [], "second_label": [], "data": "B Lindqvist - 2025\nAbstract Machine learning classifiers are the state-of-the-art in classification and \nincreasingly deployed in domains where safety and security are critical. Such \ndomains include banking, autonomous driving, malware detection, and cancer \ndetection. Unlike humans, machine learning classifiers can be easily fooled by \nattacks that perturb samples slightly to cause misclassifications. The use of \nvulnerable machine learning classifiers in domains without much room for error is\nCites: Fuzz Testing based Data Augmentation to Improve Robustness of\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://aaltodoc.aalto.fi/bitstreams/b6c8dc19-6efb-48ce-a374-ac34afc2d9ac/download&hl=en&sa=X&d=2406482127182207514&ei=q8YEabrkG_XSieoP5dXGqA0&scisig=ABGrvjIHa_Kki1UphNXPR_t95Yrj&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "MulVuln: Enhancing Pre-trained LMs with Shared and Language-Specific Knowledge for Multilingual Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "V Nguyen, S Nepal, X Yuan, T Wu, F Chen, C Rudolph- arXiv preprint arXiv, 2025\nSoftware vulnerabilities (SVs) pose a critical threat to safety-critical systems, driving \nthe adoption of AI-based approaches such as machine learning and deep learning \nfor software vulnerability detection. Despite promising results, most existing methods", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04397%3F&hl=en&sa=X&d=15852306161444656354&ei=rMYEafX6M_rUieoPrsHOyQk&scisig=ABGrvjK1G5x4sOA0GtoSv3NYa9I1&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Fuzzing C++ Compilers via Type-Driven Mutation", "first_label": ["Fuzzing"], "second_label": [], "data": "B Wang, C Chen, M Deng, J Chen, X Zhang, Y Lin- Proceedings of the ACM on, 2025\nC++ is a system-level programming language for modern software development, \nwhich supports multiple programming paradigms, including object-oriented, generic, \nand functional programming. The intrinsic complexity of these paradigms and their", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3763094&hl=en&sa=X&d=9567278433097235731&ei=rMYEafX6M_rUieoPrsHOyQk&scisig=ABGrvjKncNY8xjPjRhCyvL8v-_9Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "InstructRepair: Instruct Large Language Models with Rich Bug Information for Automated Program Repair", "first_label": ["APR", "LLM", "Bug"], "second_label": ["Repair"], "data": "A Fu, P Xu, J Li, B Kuang, Y Gao- IEEE Transactions on Information Forensics and, 2025\nAutomated Program Repair (APR) repairs software bugs based on buggy code \nsnippets automatically. It is instrumental in reducing the time and effort required for \nsoftware maintenance. Recently, large language models (LLMs) have been utilized", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11194216/&hl=en&sa=X&d=15287113091370652463&ei=rMYEafX6M_rUieoPrsHOyQk&scisig=ABGrvjKRQ4NA9Q2bph15_TI0m8Cp&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Preconditions and Postconditions as Design Constraints for LLM Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "L Newcomb, A Davidoff, O Ochoa- IEEE Access, 2025\nLarge Language Models (LLMs) have significantly advanced automated code \ngeneration, but current methods predominantly rely on natural language descriptions \nduring prompting. This approach encounters challenges when handling complex", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11218044.pdf&hl=en&sa=X&d=2337714649732748995&ei=rMYEafX6M_rUieoPrsHOyQk&scisig=ABGrvjKSLf-Xyz3bwoDp_ol_ElmA&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "From Defender to Devil? Unintended Risk Interactions Induced by LLM Defenses", "first_label": ["LLM"], "second_label": [], "data": "X Meng, T Cong, L Wang, W Chen, Z Li, S Guo- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have shown remarkable performance across \nvarious applications, but their deployment in sensitive domains raises significant \nconcerns. To mitigate these risks, numerous defense strategies have been proposed", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07968&hl=en&sa=X&d=16628375445005170696&ei=rMYEafuPGY-JieoP5Lz3kAI&scisig=ABGrvjJFN6fFD2JlXKrvW9Fj6lWu&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "HarmRLVR: Weaponizing Verifiable Rewards for Harmful LLM Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Liu, L Li, X Wang, J Shao- arXiv preprint arXiv:2510.15499, 2025\nRecent advancements in Reinforcement Learning with Verifiable Rewards (RLVR) \nhave gained significant attention due to their objective and verifiable reward signals, \ndemonstrating strong performance in reasoning and code generation tasks", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15499&hl=en&sa=X&d=3684055427722867634&ei=rMYEafuPGY-JieoP5Lz3kAI&scisig=ABGrvjIQtg1gf4x__eiLyp1jaShs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Pattern Enhanced Multi-Turn Jailbreaking: Exploiting Structural Vulnerabilities in Large Language Models", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Exploit"], "data": "RA Nihal, R Wen, K Nakadai, J Sakuma- arXiv preprint arXiv:2510.08859, 2025\nLarge language models (LLMs) remain vulnerable to multi-turn jailbreaking attacks \nthat exploit conversational context to bypass safety constraints gradually. These \nattacks target different harm categories (like malware generation, harassment, or", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.08859%3F&hl=en&sa=X&d=7314837639992204150&ei=rMYEafuPGY-JieoP5Lz3kAI&scisig=ABGrvjJr3ufD3FvrhCdwPmE1Is3_&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Proactive defense against LLM Jailbreak", "first_label": ["LLM"], "second_label": [], "data": "W Zhao, J Peng, D Ben-Levi, Z Yu, J Yang- arXiv preprint arXiv:2510.05052, 2025\nThe proliferation of powerful large language models (LLMs) has necessitated robust \nsafety alignment, yet these models remain vulnerable to evolving adversarial attacks, \nincluding multi-turn jailbreaks that iteratively search for successful queries. Current", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05052&hl=en&sa=X&d=12643963361954479351&ei=rMYEafuPGY-JieoP5Lz3kAI&scisig=ABGrvjITm70eJQ3DAJ41GbIUFyZv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Fewer Weights, More Problems: A Practical Attack on LLM Pruning", "first_label": ["LLM"], "second_label": [], "data": "K Egashira, R Staab, T Gloaguen, M Vero, M Vechev- arXiv preprint arXiv, 2025\nModel pruning, ie, removing a subset of model weights, has become a prominent \napproach to reducing the memory footprint of large language models (LLMs) during \ninference. Notably, popular inference engines, such as vLLM, enable users to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07985%3F&hl=en&sa=X&d=15877205037372109377&ei=rMYEafuPGY-JieoP5Lz3kAI&scisig=ABGrvjLc2zMGjcFTGp-_8sfDhRmv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Microsaccade-Inspired Probing: Positional Encoding Perturbations Reveal LLM Misbehaviours", "first_label": ["LLM"], "second_label": [], "data": "R Melo, R Abreu, CS Pasareanu- arXiv preprint arXiv:2510.01288, 2025\nWe draw inspiration from microsaccades, tiny involuntary eye movements that reveal \nhidden dynamics of human perception, to propose an analogous probing method for \nlarge language models (LLMs). Just as microsaccades expose subtle but informative", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01288&hl=en&sa=X&d=4079834350174690212&ei=rMYEafuPGY-JieoP5Lz3kAI&scisig=ABGrvjJMtJXAVeeF7NG9Bep4U4CZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "first_label": ["LLM"], "second_label": ["Agent"], "data": "VK Bonagiri, P Kumaragurum, K Nguyen, B Plaut- arXiv preprint arXiv:2510.16492, 2025\nAs Large Language Model (LLM) agents increasingly operate in complex \nenvironments with real-world consequences, their safety becomes critical. While \nuncertainty quantification is well-studied for single-turn tasks, multi-turn agentic", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.16492&hl=en&sa=X&d=12122099661687534348&ei=rMYEafuPGY-JieoP5Lz3kAI&scisig=ABGrvjI4CtI_SmXhnMCPP-z7iPl7&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM Unlearning Under the Microscope: A Full-Stack View on Methods and Metrics", "first_label": ["LLM"], "second_label": [], "data": "C Fan, C Wang, Y Huang, S Pal, S Liu- arXiv preprint arXiv:2510.07626, 2025\nMachine unlearning for large language models (LLMs) aims to remove undesired \ndata, knowledge, and behaviors (eg, for safety, privacy, or copyright) while \npreserving useful model capabilities. Despite rapid progress over the past two years", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07626%3F&hl=en&sa=X&d=2219175947074663426&ei=rMYEafuPGY-JieoP5Lz3kAI&scisig=ABGrvjJT5bdpnV9SaCOVVwX2gtdv&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Demystifying the Roles of LLM Layers in Retrieval, Knowledge, and Reasoning", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "X Song, K Wang, PX Li, L Yin, S Liu- arXiv preprint arXiv:2510.02091, 2025\nRecent studies suggest that the deeper layers of Large Language Models (LLMs) \ncontribute little to representation learning and can often be removed without \nsignificant performance loss. However, such claims are typically drawn from narrow", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02091%3F&hl=en&sa=X&d=1937934351809912348&ei=rMYEafuPGY-JieoP5Lz3kAI&scisig=ABGrvjIcqjlNfwqLU3ZuXogdd9E9&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Forgetting to Forget: Attention Sink as A Gateway for Backdooring LLM Unlearning", "first_label": ["LLM"], "second_label": [], "data": "B Shang, Y Chen, Y Zhang, B Shen, S Liu- arXiv preprint arXiv:2510.17021, 2025\nLarge language model (LLM) unlearning has become a critical mechanism for \nremoving undesired data, knowledge, or behaviors from pre-trained models while \nretaining their general utility. Yet, with the rise of open-weight LLMs, we ask: can the\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.17021&hl=en&sa=X&d=4136982877864927192&ei=rMYEafuPGY-JieoP5Lz3kAI&scisig=ABGrvjJ2KA9iqOctB2m1kEDFMr9I&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Understanding Self-Admitted Technical Debt in Test Code: An Empirical Study", "first_label": ["Code", "Software Testing"], "second_label": [], "data": "I Nakamura, Y Kashiwa, B Lin, H Iida- arXiv preprint arXiv:2510.22249, 2025\nDevelopers often opt for easier but non-optimal implementation to meet deadlines or \ncreate rapid prototypes, leading to additional effort known as technical debt to \nimprove the code later. Oftentimes, developers explicitly document the technical debt \nin code comments, referred to as Self-Admitted Technical Debt (SATD). Numerous \nresearchers have investigated the impact of SATD on different aspects of software \nquality and development processes. However, most of these studies focus on SATD\nCites: Vul4j: A dataset of reproducible java vulnerabilities geared towards\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.22249&hl=en&sa=X&d=6392396678059743151&ei=qsYEaa_bOO2ZieoP1bb86A4&scisig=ABGrvjK41L5IJOyxvescB7xhbGSR&oi=scholaralrt&hist=ylyK0_8AAAAJ:5615766320347152220:ABGrvjKrSK-QNjD1BSPBp8aOrKCw&html=&pos=0&folt=cit", "author": ["Quang-Cuong Bui"], "ref": ["1 new citation to articles by Quang-Cuong Bui"]}
{"title": "Breaking Agent Backbones: Evaluating the Security of Backbone LLMs in AI Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "J Bazinska, M Mathys, F Casucci, M Rojas-Carulla- arXiv preprint arXiv, 2025\nAI agents powered by large language models (LLMs) are being deployed at scale, \nyet we lack a systematic understanding of how the choice of backbone LLM affects \nagent security. The non-deterministic sequential nature of AI agents complicates \nsecurity modeling, while the integration of traditional software with AI components \nentangles novel LLM vulnerabilities with conventional security risks. Existing \nframeworks only partially address these challenges as they either capture specific\nCites: Adaptive attacks break defenses against indirect prompt injection", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.22620&hl=en&sa=X&d=12413555517911436052&ei=qcYEafPqLbmAieoPq7Lh4A8&scisig=ABGrvjL8ih3UDJ8x-TTaEo_Rc6lV&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:ABGrvjIL7aJF81gdGo1gERw9ebUT&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Understanding the Effects of Representation Misdirection for Large Language Model Unlearning", "first_label": ["LLM"], "second_label": [], "data": "HT Dang - 2025\nModern large language models (LLMs) are pre-trained on massive text corpora from \nthe web, including copyrighted material, toxic and sexual content, sensitive and \nprivate information, gender and political bias, and dangerous documents such as \ncybersecurity attacks and bioweapon development. As a result, LLMs can exhibit \nharmful and unwanted behaviors. The right to be forgotten emerged for LLMs as a \ntool to ensure their and our safety. Machine unlearning is an approach that aims to\nCites: Llm agents can autonomously hack websites\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://dspace.jaist.ac.jp/dspace/bitstream/10119/20045/5/paper.pdf&hl=en&sa=X&d=9879035999439932556&ei=qcYEafPqLbmAieoPq7Lh4A8&scisig=ABGrvjIEqid3kgaFI76QC-T2qbOz&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:ABGrvjIL7aJF81gdGo1gERw9ebUT&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Repair", "Reasoning"], "data": "XC Wen, Z Lin, Y Yang, C Gao, D Ye- arXiv preprint arXiv:2510.05480, 2025\nThe exponential increase in software vulnerabilities has created an urgent need for \nautomatic vulnerability repair (AVR) solutions. Recent research has formulated AVR \nas a sequence generation problem and has leveraged large language models", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.05480&hl=en&sa=X&d=17087307418542281791&ei=qsYEaeX3A-2ZieoP1bb86A4&scisig=ABGrvjJlsQcjOBCSZutD9pRzL3u0&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Source Code Guardrail: AI Driven Solution to Distinguish Critical vs. Generic Code for Enterprise LLM Security", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Sharma, A Gupta- International Conference on Provable Security, 2025\nAbstract The adoption of Large Language Models (LLMs) in businesses raises the \npossibility of inadvertent intellectual property (IP) and secret data leaks to public \nartificial intelligence systems. Organizations are using security solutions, including", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-2961-2_23&hl=en&sa=X&d=5184326828152072441&ei=qsYEaeX3A-2ZieoP1bb86A4&scisig=ABGrvjJOJG-OQ4wH-x-OhS5wRNe2&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Bach Le - new related research"]}
{"title": "TIT: A Tree-Structured Instruction Tuning Approach for LLM-Based Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "H Jiang, Y Wang, H Lin, P Zou, Z Zhou, A Jia, X Li- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have shown strong performance in automated \nsource-to-target code translation through pretraining on extensive code corpora. \nHowever, mainstream LLM-based code translation methods suffer from two critical", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.09400&hl=en&sa=X&d=13736189209612319180&ei=qsYEaeX3A-2ZieoP1bb86A4&scisig=ABGrvjLfQpVO1yEU3BC2VHg0FKp1&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "X Yin, C Ni, X Li, L Chen, G Ma, X Yang\nRecently, Large Language Models (LLMs) have gained attention for their ability to \nhandle a broad range of tasks, including unit test generation. Despite their success, \nLLMs may exhibit hallucinations when generating unit tests for focal methods or", "link": "https://scholar.google.com/scholar_url?url=https://vinci-grape.github.io/papers/Enhancing_LLM_s_Ability_to_Generate_More_Repository_Aware_Unit_Tests_Through_Precise_Context_Injection.pdf&hl=en&sa=X&d=3506872574868649515&ei=qsYEaeX3A-2ZieoP1bb86A4&scisig=ABGrvjKPA0zq2FXS1WyPoCr65qwT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research"]}
{"title": "Large Language Models for Code Editing", "first_label": ["LLM", "Code"], "second_label": [], "data": "RJ Mooney, A Shi\nPretrained language models have been shown to be effective in many \nsoftwarerelated generation tasks; however, they are not well-suited for editing tasks \nduring maintaining the software as they are not designed to reason about edits. To", "link": "https://scholar.google.com/scholar_url?url=https://users.ece.utexas.edu/~gligoric/papers/Zhang25PhD.pdf&hl=en&sa=X&d=10229569576199033599&ei=qsYEaeX3A-2ZieoP1bb86A4&scisig=ABGrvjLpWoTa-j_SG0xO2_Fs3G5S&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "LLM-Assisted Synthesis of High-Assurance C Programs", "first_label": ["LLM"], "second_label": [], "data": "P Mukherjee, M Lu, B Delaware - 2025\nWe present SYNVERa novel, general purpose synthesizer for C programs \nequipped with machine-checked proofs of correctness using the Verified Software \nToolchain. To do so, SYNVER employs two Large Language Models (LLMs): the first\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://prasitagit.github.io/papers/SynverPreprint.pdf&hl=en&sa=X&d=10034668577701533579&ei=qsYEaeX3A-2ZieoP1bb86A4&scisig=ABGrvjKedmUATdp-iuZhyQwb-bpX&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "A Study of Preconditions and Postconditions as Design Constraints for LLM Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "L Newcomb - 2025\nAbstract Large Language Models (LLMs) have significantly advanced automated \ncode generation, but current methods predominantly rely on natural language \ndescriptions. This approach encounters challenges when handling complex, class", "link": "https://scholar.google.com/scholar_url?url=https://commons.erau.edu/cgi/viewcontent.cgi%3Farticle%3D1917%26context%3Dedt&hl=en&sa=X&d=13973124336738166359&ei=rMYEabr8JtqI6rQP34HLqQY&scisig=ABGrvjLNU8FKcFxyqJA-3cEql0sU&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Does In-IDE Calibration of Large Language Models work at Scale?", "first_label": ["LLM"], "second_label": [], "data": "R Koohestani, A Sergeyuk, D Gros, C Spiess, S Titov- arXiv preprint arXiv, 2025\nThe introduction of large language models into integrated development \nenvironments (IDEs) is revolutionizing software engineering, yet it poses challenges \nto the usefulness and reliability of Artificial Intelligence-generated code. Post-hoc\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/abs/2510.22614&hl=en&sa=X&d=10380670912744146683&ei=rMYEabr8JtqI6rQP34HLqQY&scisig=ABGrvjLniSn_aRoXPTH1NGr5weOv&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Survey for MQTT Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "SY Chowdhury, R Sun, B Dudley- Proceedings of the 2025 Workshop on Re-design, 2025\nMessage Queuing Telemetry Transport (MQTT) has emerged as a promising \ncommunication protocol for Internet of Things (IoT) ecosystems, enabling lightweight, \nscalable publish-subscribe messaging across resource-constrained devices. As", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3733823.3764515&hl=en&sa=X&d=13012329971672204999&ei=fDsDacSZLZjO6rQP0cXo6Aw&scisig=ABGrvjId2cO-K_7acZfnhIhoKULY&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "DynamiQ: Unlocking the Potential of Dynamic Task Allocation in Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "W Yan, T Murray, B Rubinstein, VT Pham- arXiv preprint arXiv:2510.04469, 2025\nWe present DynamiQ, a full-fledged and optimized successor to AFLTeam that \nsupports dynamic and adaptive parallel fuzzing. Unlike most existing approaches \nthat treat individual seeds as tasks, DynamiQ leverages structural information from", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04469&hl=en&sa=X&d=10962816615102660239&ei=fDsDacSZLZjO6rQP0cXo6Aw&scisig=ABGrvjJffOk8ddKWXV2Kdd4qJSnB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Function Clustering-Based Fuzzing Termination: Toward Smarter Early Stopping", "first_label": ["Fuzzing"], "second_label": [], "data": "L Ding, W Yang, Y Xue\nFuzzing is a testing technique that generates a large number of inputs to cause \nprogram crashes. As software development accelerates and projects scale, the \ndemand for fuzz testing in software assurance has increased. Performing", "link": "https://scholar.google.com/scholar_url?url=https://wzyang.cn/files/FuzzingTermination.pdf&hl=en&sa=X&d=16741608997780760317&ei=fDsDacSZLZjO6rQP0cXo6Aw&scisig=ABGrvjJOoGioSM_8JoIy2nxjy7ve&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Exploring Data-Efficient Adaptation of Large Language Models for Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "X Jiang, Y Dong, Z Fan, Z Jin, W Jiao, G Li- ACM Transactions on Software, 2025\nAlthough Large Language Models (LLMs) have made significant progress in code \ngeneration, they still struggle with code generation tasks in specific scenarios. These \nscenarios usually necessitate the adaptation of LLMs to fulfill specific needs, but the", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3772721&hl=en&sa=X&d=2686921242856750605&ei=fDsDacSZLZjO6rQP0cXo6Aw&scisig=ABGrvjI_8WoaFiP253fyOzGjNdkw&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research", "David Lo - new related research", "Thanh Le-Cong - new related research"]}
{"title": "CG-Bench: Can Language Models Assist Call Graph Construction in the Real World?", "first_label": ["LLM", "Static Analysis"], "second_label": ["Graph"], "data": "T Yuan, W Zhang, D Chen, J Wang- Proceedings of the 1st ACM SIGPLAN, 2025\nLanguage models for coding are shifting their focus from function-level to repository-\nlevel, with complex function invocations. We introduce CG-Bench, the first manually \nconstructed benchmark that measures the ability to understand call graphs for", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3759425.3763379&hl=en&sa=X&d=11570618845570061776&ei=fDsDacSZLZjO6rQP0cXo6Aw&scisig=ABGrvjJTTJMRIMAuaa7eEoue4X54&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ABGrvjIVKizzz6QV3C-yZ03bi6pL&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Bach Le - new related research"]}
{"title": "Deepvulmatch: Learning and matching latent vulnerability representations for dual-granularity vulnerability detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "M Fu, T Le, V Nguyen, C Tantithamthavorn, D Phung- IEEE Transactions on, 2025\nDeep learning (DL) models are widely used to detect software vulnerabilities, but \nidentifying vulnerabilities at the line level remains challenging due to varied coding \nstyles and the spread of vulnerabilities across multiple lines. We observe that", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11185217/&hl=en&sa=X&d=1932042155778202107&ei=fTsDacvyM4-JieoP5Lz3kAI&scisig=ABGrvjIo1w1dYncMZqfmksUM0TlO&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "SecureBERT 2.0: Advanced Language Model for Cybersecurity Intelligence", "first_label": ["LLM"], "second_label": [], "data": "E Aghaei, S Jain, P Arun, A Sambamoorthy- arXiv preprint arXiv:2510.00240, 2025\nEffective analysis of cybersecurity and threat intelligence data demands language \nmodels that can interpret specialized terminology, complex document structures, and \nthe interdependence of natural language and source code. Encoder-only transformer", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.00240%3F&hl=en&sa=X&d=18114694566329479656&ei=fTsDacvyM4-JieoP5Lz3kAI&scisig=ABGrvjJSk6luh9bURYUYqbLBKs2u&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Multi-Language Object-Oriented Programming Benchmark for Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "S Wang, L Ding, L Shen, Y Luo, H Hu, L Zhang, F Lin- arXiv preprint arXiv, 2025\nEstablishing fair and robust benchmarks is essential for evaluating intelligent code \ngeneration by large language models (LLMs). Our survey of 35 existing benchmarks \nuncovers three major imbalances: 85.7% focus on a single programming language;", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.26111&hl=en&sa=X&d=2388658668398987935&ei=fTsDacvyM4-JieoP5Lz3kAI&scisig=ABGrvjLOMqK6KseaqrwLOyii9NBd&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "DeepCodeProbe: Evaluating Code Representation Quality in Models Trained on Code", "first_label": ["Code"], "second_label": [], "data": "V Majdinasab, A Nikanjam, F Khomh- Empirical Software Engineering, 2025\nAbstract Machine Learning models trained on code and artifacts extracted from them \n(eg, version control histories, code differences, etc.), provide invaluable assistance \nfor software engineering tasks. Despite their good performance, there exists a lack of", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10731-0&hl=en&sa=X&d=4894546859526238222&ei=fTsDacvyM4-JieoP5Lz3kAI&scisig=ABGrvjJoUaIzDkGAIgtuBvd2DHl_&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Automating software size measurement from python code using language models", "first_label": ["LLM", "Code"], "second_label": [], "data": "S Tenekeci, H nl, BA Gl, D Kele, M Kk- Automated Software, 2026\nSoftware size is a key input for project planning, effort estimation, and productivity \nanalysis. While pre-trained language models have shown promise in deriving \nfunctional size from natural-language requirements, measuring size directly from", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00571-z&hl=en&sa=X&d=6975543180754084024&ei=fTsDacvyM4-JieoP5Lz3kAI&scisig=ABGrvjLkBeMkTvtxg_tOzsUhaAY9&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Code-enabled language models can outperform reasoning models on diverse tasks", "first_label": ["LLM", "Code"], "second_label": ["Reasoning"], "data": "CE Zhang, C Colas, G Poesia, JB Tenenbaum- arXiv preprint arXiv, 2025\nReasoning models (RMs), language models (LMs) trained with reinforcement \nlearning to produce long-form natural language reasoning, have been remarkably \nsuccessful, but they still require large amounts of computation and data to train, and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.20909&hl=en&sa=X&d=7123146514276156589&ei=fTsDacvyM4-JieoP5Lz3kAI&scisig=ABGrvjIQoa2Q-NURPn1_aaML4r6b&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "FVDebug: An LLM-Driven Debugging Assistant for Automated Root Cause Analysis of Formal Verification Failures", "first_label": ["Verification", "LLM", "Bug"], "second_label": [], "data": "Y Bai, GB Hamad, CT Ho, S Suhaib, H Ren- arXiv preprint arXiv:2510.15906, 2025\nDebugging formal verification (FV) failures represents one of the most time-\nconsuming bottlenecks in modern hardware design workflows. When properties fail, \nengineers must manually trace through complex counter-examples spanning", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15906&hl=en&sa=X&d=5061588972257186492&ei=fTsDacvyM4-JieoP5Lz3kAI&scisig=ABGrvjKa6iDogxoZI1kK18hPFpKS&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=7&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "SpecAgent: A Speculative Retrieval and Forecasting Agent for Code Completion", "first_label": ["Code"], "second_label": ["Generation", "Agent"], "data": "G Ma, A Koul, Q Chen, Y Wu, S Kuhar, Y Yu- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) excel at code-related tasks but often struggle in \nrealistic software repositories, where project-specific APIs and cross-file \ndependencies are crucial. Retrieval-augmented methods mitigate this by injecting", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.17925&hl=en&sa=X&d=3299397357636031554&ei=fTsDacvyM4-JieoP5Lz3kAI&scisig=ABGrvjIOzA0E2pWK6kawREa-Eqes&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=8&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Towards LLM-Augmented Database Systems OR The Relational Model is dead! Long live the Relational Model!", "first_label": ["LLM"], "second_label": [], "data": "C Binnig\nRelational databases have powered critical systems for decades. Yet, despite their \npromises of a simple data model and an easy-to-use query language, relational \nsystems impose high overheads of using them, which are inherently rooted in the\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=http://sites.computer.org/debull/A25sep/p19.pdf&hl=en&sa=X&d=4928711554788802753&ei=fTsDacvyM4-JieoP5Lz3kAI&scisig=ABGrvjJfwIkgzzQ9-CcQ65_EKB7w&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ABGrvjI9n0QO5d8yW-K6yrd4SQQc&html=&pos=9&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Backdoor-Powered Prompt Injection Attacks Nullify Defense Methods", "first_label": [], "second_label": [], "data": "Y Chen, H Li, Y Sui, Y Song, B Hooi- arXiv preprint arXiv:2510.03705, 2025\nWith the development of technology, large language models (LLMs) have dominated \nthe downstream natural language processing (NLP) tasks. However, because of the \nLLMs' instruction-following abilities and inability to distinguish the instructions in the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03705&hl=en&sa=X&d=9793005798347645046&ei=fTsDaYLcI4m16rQPw4j56AI&scisig=ABGrvjJ2v68AhMUTz-vIWEu8QJ-h&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Genesis: Evolving Attack Strategies for LLM Web Agent Red-Teaming", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Z Zhang, J He, Y Cai, D Ye, P Zhao, R Feng, H Wang- arXiv preprint arXiv, 2025\nAs large language model (LLM) agents increasingly automate complex web tasks, \nthey boost productivity while simultaneously introducing new security risks. However, \nrelevant studies on web agent attacks remain limited. Existing red-teaming", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.18314&hl=en&sa=X&d=14799970374377988040&ei=fTsDaYLcI4m16rQPw4j56AI&scisig=ABGrvjLlUwaYV7x4iFtGtsyDIHdw&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "MetaBreak: Jailbreaking Online LLM Services via Special Token Manipulation", "first_label": ["LLM"], "second_label": [], "data": "W Zhu, Z Xiang, W Niu, L Guan- arXiv preprint arXiv:2510.10271, 2025\nUnlike regular tokens derived from existing text corpora, special tokens are artificially \ncreated to annotate structured conversations during the fine-tuning process of Large \nLanguage Models (LLMs). Serving as metadata of training data, these tokens play a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10271%3F&hl=en&sa=X&d=10904776402205985786&ei=fTsDaYLcI4m16rQPw4j56AI&scisig=ABGrvjL7g_73UHz_DwhnWsdL9iGk&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Webcloak: Characterizing and mitigating the threats of llm-driven web agents as intelligent scrapers", "first_label": ["LLM"], "second_label": ["Agent"], "data": "X Li, T Qiu, Y Jin, L Wang, H Guo, X Jia, X Wang- Proceedings of the 2026, 2026\nThe rise of web agents powered by large language models (LLMs) is reshaping the \nlandscape of human-computer interaction, enabling users to automate complex web \ntasks with natural language commands. However, this progress introduces serious", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Xinfeng-Li-7/publication/396418425_WebCloak_Characterizing_and_Mitigating_Threats_from_LLM-Driven_Web_Agents_as_Intelligent_Scrapers/links/68ea2bc4f3032e2b4be84935/WebCloak-Characterizing-and-Mitigating-Threats-from-LLM-Driven-Web-Agents-as-Intelligent-Scrapers.pdf&hl=en&sa=X&d=11222165444201781035&ei=fTsDaYLcI4m16rQPw4j56AI&scisig=ABGrvjIK6rwNOFCGhsxEhJgoFqxB&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "C Ziakas, N Loo, N Jain, A Russo- arXiv preprint arXiv:2510.07239, 2025\nAutomated red-teaming has emerged as a scalable approach for auditing Large \nLanguage Models (LLMs) prior to deployment, yet existing approaches lack \nmechanisms to efficiently adapt to model-specific vulnerabilities at inference. We", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07239%3F&hl=en&sa=X&d=7730973334197366962&ei=fTsDaYLcI4m16rQPw4j56AI&scisig=ABGrvjK7SFLw8g1qTWHeOk7VhS4x&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Investigating the Impact of Dark Patterns on LLM-Based Web Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "D Ersoy, B Lee, A Shreekumar, A Arunasalam- arXiv preprint arXiv, 2025\nAs users increasingly turn to large language model (LLM) based web agents to \nautomate online tasks, agents may encounter dark patterns: deceptive user interface \ndesigns that manipulate users into making unintended decisions. Although dark", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.18113&hl=en&sa=X&d=9332036408692793636&ei=fTsDaYLcI4m16rQPw4j56AI&scisig=ABGrvjL2GoCmABLkIStSVW1f9lld&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Securing with Dual-LLM Architecture: ChatTEDU An Open Access Chatbot's Defense", "first_label": ["LLM"], "second_label": [], "data": "H Emekci, G Budakoglu- IEEE Access, 2025\nOpen access chatbots face escalating cybersecurity risks due to adversarial \nexploitation. This paper presents the case of ChatTEDU, a dual-LLM architecture \ndesigned to protect open-access AI systems from sophisticated adversarial attacks", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11207588.pdf&hl=en&sa=X&d=8815365068079578094&ei=fTsDaYLcI4m16rQPw4j56AI&scisig=ABGrvjIotmfuTMIEf8JuZ6CJRHKR&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Categorized Privacy Neuron Editing: Addressing Heterogeneity for Privacy Leakage Mitigation in Language Models", "first_label": ["LLM"], "second_label": [], "data": "X Yang, P Wu- International Conference on Advanced Data Mining, 2025\nConventional neuron editing methods for language model privacy protection suffer \nfrom a critical limitation: uniform intervention strategies inadvertently exacerbate \ncross-category leakage via the privacy seesaw effect. Current methodologies", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-3456-2_9&hl=en&sa=X&d=16693435278691795213&ei=fTsDaYLcI4m16rQPw4j56AI&scisig=ABGrvjKw_XM3Jyi0C8HSsmMIHP4o&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SMaRT: Select, Mix, and ReinvenT-A Strategy Fusion Framework for LLM-Driven Reasoning and Planning", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "N Verma, M Bharadwaj, W Jang, H Singh, Y Wang- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have redefined complex task automation with \nexceptional generalization capabilities. Despite these advancements, state-of-the-art \nmethods rely on single-strategy prompting, missing the synergy of diverse reasoning", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.18095&hl=en&sa=X&d=6260306680531832341&ei=fTsDaYLcI4m16rQPw4j56AI&scisig=ABGrvjK3FnRszSUvTIH9jwxzNMjV&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Distribution Preference Optimization: A Fine-grained Perspective for LLM Unlearning", "first_label": ["LLM"], "second_label": [], "data": "K Qin, J Wu, J He, H Sun, Y Zhao, B Liang, Y Chang- arXiv preprint arXiv, 2025\nAs Large Language Models (LLMs) demonstrate remarkable capabilities learned \nfrom vast corpora, concerns regarding data privacy and safety are receiving \nincreasing attention. LLM unlearning, which aims to remove the influence of specific\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04773%3F&hl=en&sa=X&d=4289738586061872066&ei=fTsDaYLcI4m16rQPw4j56AI&scisig=ABGrvjIEHtN9syvv877lZhRpUUgo&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:ABGrvjLSafwX14k1S_MKjxB3BoE0&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation", "first_label": ["LLM", "Fault Localization"], "second_label": ["Localization"], "data": "F Liu, T Wang, L Zhang, Z Yang, J Jiang, Z Sun- arXiv preprint arXiv:2509.25676, 2025\nProviding timely and personalized guidance for students' programming assignments, \noffers significant practical value for helping students complete assignments and \nenhance their learning. In recent years, various automated Fault Localization (FL)", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25676&hl=en&sa=X&d=16831300563596066577&ei=ezsDadSpA_-j6rQP4cHB4A4&scisig=ABGrvjKOmbi2TriQ76tXIs_L9sIr&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ABGrvjJn3lMA7KZZZk5XPENSCuJZ&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Hong Jin Kang - new related research"]}
{"title": "A Scalable Vulnerability Detection System with Multi-View Graph Representations", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "S Dou, H Zheng, J Shan, Y Wu, D Zou, X Huang, Y Liu- ACM Transactions on, 2025\nDeep learning (DL) has been extensively utilized in source code vulnerability \ndetection due to its robust automatic feature extraction capabilities. To achieve \nscalable vulnerability scanning, some prior studies intend to process the source code", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3770075&hl=en&sa=X&d=14953216934661661615&ei=fjsDaYa5BpjO6rQP0cXo6Aw&scisig=ABGrvjIFKzTAARKmQs4FcWCEoWpB&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "LSPFuzz: Hunting Bugs in Language Servers", "first_label": ["Fuzzing", "Bug"], "second_label": [], "data": "H Zhu, S Chen, V Terragni, L Wei, J Wu, Y Liu- arXiv preprint arXiv, 2025\nThe Language Server Protocol (LSP) has revolutionized the integration of code \nintelligence in modern software development. There are approximately 300 LSP \nserver implementations for various languages and 50 editors offering LSP", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.00532&hl=en&sa=X&d=3201719160230213096&ei=fjsDaYa5BpjO6rQP0cXo6Aw&scisig=ABGrvjKlQ__ltef17HmH0t9-5iwk&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "GlassWing: A Tailored Static Analysis Approach for Flutter Android Apps", "first_label": ["Static Analysis"], "second_label": [], "data": "X Zhang, Y Su, L Fan, M Cai, S Chen\nThe variety of mobile operating systems available in the market has led to the \nemergence of cross-platform frameworks, which simplify the development and \ndeployment of mobile applications across multiple platforms simultaneously. Among", "link": "https://scholar.google.com/scholar_url?url=https://sen-chen.github.io/img_cs/pdf/ASE2025-GlassWing%2520A%2520Tailored%2520Static%2520Analysis%2520Approach%2520for%2520Flutter%2520Android%2520Apps.pdf&hl=en&sa=X&d=3861822635221850315&ei=fjsDaYa5BpjO6rQP0cXo6Aw&scisig=ABGrvjLW9rFsIjIFaUpu9DnJki-m&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "LLMs are All You Need? Improving Fuzz Testing for MOJO with Large Language Models", "first_label": ["LLM", "Fuzzing", "Software Testing"], "second_label": [], "data": "L Huang, P Zhao, H Chen- arXiv preprint arXiv:2510.10179, 2025\nThe rapid development of large language models (LLMs) has revolutionized \nsoftware testing, particularly fuzz testing, by automating the generation of diverse and \neffective test inputs. This advancement holds great promise for improving software", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.10179%3F&hl=en&sa=X&d=1799101126036134381&ei=fjsDaYa5BpjO6rQP0cXo6Aw&scisig=ABGrvjJpTzJLdPRF-_YdbFCpjP7v&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "PLSEMANTICSBENCH: Large Language Models As Programming Language Interpreters", "first_label": ["LLM"], "second_label": [], "data": "A Thimmaiah, J Zhang, J Srinivasa, JJ Li, M Gligoric- arXiv preprint arXiv:2510.03415, 2025\nAs large language models (LLMs) excel at code reasoning, a natural question arises: \ncan an LLM execute programs (ie, act as an interpreter) purely based on a \nprogramming language's formal semantics? If so, it will enable rapid prototyping of", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03415&hl=en&sa=X&d=2539578870795389971&ei=fjsDaYa5BpjO6rQP0cXo6Aw&scisig=ABGrvjLDcDk0eY78Xm7hHQxmswny&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Do Large Language Models Respect Contracts? Evaluating and Enforcing Contract-Adherence in Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "S Lim, J Hahn, H Park, SK Ko, YS Han- arXiv preprint arXiv:2510.12047, 2025\nPrevailing code generation benchmarks, such as HumanEval+ and MBPP+, primarily \nevaluate large language models (LLMs) with pass@ k on functional correctness \nusing well-formed inputs. However, they ignore a crucial aspect of real-world\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.12047&hl=en&sa=X&d=2889880949652380666&ei=fjsDaYa5BpjO6rQP0cXo6Aw&scisig=ABGrvjJFxTBnu5WvPpefIV01qBsD&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ABGrvjKDzVgVRQIlzHl67TyxXn3a&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Towards Speeding up Program Repair with Non-Autoregressive Model", "first_label": ["APR"], "second_label": ["Repair"], "data": "Z Yang, Y Pan, Z Yang, Z Yu- arXiv preprint arXiv:2510.01825, 2025\nEnlightened by the success of machine learning techniques in various application \nareas, recent years have witnessed a surge of research efforts on automatic program \nrepair (APR) using machine learning techniques. Previous machine learning-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.01825&hl=en&sa=X&d=13565386759645709244&ei=ezsDaYXKL4ePieoP-LWzqQs&scisig=ABGrvjLcaUrVIG2KVg-f03OTMEUr&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "An Experimental Study of Real-Life LLM-Proposed Performance Improvements", "first_label": ["LLM"], "second_label": [], "data": "L Yi, G Gay, P Leitner- arXiv preprint arXiv:2510.15494, 2025\nLarge Language Models (LLMs) can generate code, but can they generate fast \ncode? In this paper, we study this question using a dataset of 65 real-world tasks \nmined from open-source Java programs. We specifically select tasks where", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.15494&hl=en&sa=X&d=10640118915085146028&ei=ezsDaYXKL4ePieoP-LWzqQs&scisig=ABGrvjLcRUj8NSio7-ggPhAhEwVg&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "R2ComSync: Improving Code-Comment Synchronization with In-Context Learning and Reranking", "first_label": ["Code"], "second_label": [], "data": "Z Yang, H Lin, X Yu, JW Keung, S Liu, PYP Chan- arXiv preprint arXiv, 2025\nCode-Comment Synchronization (CCS) aims to synchronize the comments with code \nchanges in an automated fashion, thereby significantly reducing the workload of \ndevelopers during software maintenance and evolution. While previous studies have", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.21106&hl=en&sa=X&d=6172187810578117406&ei=ezsDaYXKL4ePieoP-LWzqQs&scisig=ABGrvjLLXn5ongZqlg38cJ7wwwJW&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "1 new citation to articles by Xin ZHOU"]}
{"title": "Enhanced Architecture of Structure Semantics for SyntaxAware Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "C Zhou, Z Li, H Huang, Y Xiang, F Liu, Z Hao- Software: Practice and Experience, 2025\nObjective The task of code generation aims to transform natural language \ndescriptions into corresponding target code. Among the various approaches, syntax\naware code generation has emerged as a significant approach that strives to\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.70025&hl=en&sa=X&d=17163292334780918507&ei=ezsDaYXKL4ePieoP-LWzqQs&scisig=ABGrvjIEfWSCelZJddhXkIyGi8VD&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ABGrvjKKcNTwHjDvGa19Y1_mBhEU&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "SQLAGENT: LEARNING TO EXPLORE BEFORE GEN", "first_label": [], "second_label": ["Agent"], "data": "E AS\nLarge Language Models have recently shown impressive capabilities in reasoning \nand code generation, making them promising tools for natural language interfaces to \nrelational databases. However, existing approaches often fail to generalize in \ncomplex, real-world settings due to the highly database-specific nature of SQL \nreasoning, which requires deep familiarity with unique schemas, ambiguous \nsemantics, and intricate join paths. To address this challenge, we introduce a novel\nCites: AutoCodeRover: Autonomous program improvement", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DvoLoLHms2K&hl=en&sa=X&d=3794971325233823406&ei=fDsDaeyDB9WY6rQP4IbZiQw&scisig=ABGrvjL0lopT8BtGvjNZn6vGuY_B&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
{"title": "The Journal of Systems & Software", "first_label": [], "second_label": [], "data": "Q Stivenart, D Binkley, C De Roover\nThe WebAssembly standard aims to form a portable compilation target, enabling the \ncross-platform distribution of programs written in a variety of languages. This paper \nintroduces and evaluates novel slicing approaches for WebAssembly, including \ndynamic and hybrid approaches. Given a program and a location in that program, a \nprogram slice is a reduced program that preserves the behavior at the given location. \nA static slice does so for all possible inputs, while a dynamic slice does so for a fixed\nCites: Dynamic slicing on Java bytecode traces\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://cris.vub.be/ws/portalfiles/portal/138619047/122946436.pdf&hl=en&sa=X&d=10765010399015279439&ei=fDsDaeyDB9WY6rQP4IbZiQw&scisig=ABGrvjKO6xPV_4gfU0Lx9Eavs_yI&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ABGrvjKFSuRPDpxUzNODsIIknJQT&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
{"title": "Enhancing Domain-Specific Code Completion via Collaborative Inference with Large and Small Language Models", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Yu, Z Gao, L Bao, Z Liu- ACM Transactions on Software Engineering and, 2025\nLarge language model-based code completion has demonstrated excellent \nperformance, but still encounters challenges in capturing domain-specific knowledge \nfor more precise completion within specific domains, ie, domain-specific code", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3770748&hl=en&sa=X&d=2019769577165862416&ei=ezsDaeeIGtqI6rQP34HLqQY&scisig=ABGrvjKO1fKaLDZwwCDDcSmDx0Da&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "ALMAS: an autonomous llm-based multi-agent software engineering framework", "first_label": ["LLM"], "second_label": ["Agent"], "data": "V Tawosi, K Ramani, S Alamir, X Liu- arXiv preprint arXiv:2510.03463, 2025\nMulti-agent Large Language Model (LLM) systems have been leading the way in \napplied LLM research across a number of fields. One notable area is software \ndevelopment, where researchers have advanced the automation of code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03463&hl=en&sa=X&d=6189494284468520954&ei=ezsDaeeIGtqI6rQP34HLqQY&scisig=ABGrvjJrdVeB80cic_brCTfqWIPK&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Real-VulLLM: An LLM Based Assessment Framework in the Wild", "first_label": ["LLM"], "second_label": [], "data": "R Safdar, D Mateen, ST Ali, W Hussain- arXiv preprint arXiv:2510.04056, 2025\nArtificial Intelligence (AI) and more specifically Large Language Models (LLMs) have \ndemonstrated exceptional progress in multiple areas including software engineering, \nhowever, their capability for vulnerability detection in the wild scenario and its\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04056&hl=en&sa=X&d=7464868966945655593&ei=ezsDaeeIGtqI6rQP34HLqQY&scisig=ABGrvjIaO4pEKfAZ4-It9iNMVajB&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ABGrvjJ67LyP46ziTQ2HxkaZCAOI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
