{"title": "Characterising harmful API uses and repair techniques: Insights from a systematic review", "first_label": [], "second_label": ["Repair"], "data": "L Ochoa, M Hammad, G Giray, \\xc3\\x96 Babur, K Bennin\\xc2\\xa0- Computer Science Review, 2025\nAPI use has become prevalent in current times and its purposeful management is of \nforemost importance to avoid undesired effects on client code. A plethora of studies \nfocusing on the isolated investigation of different types of harmful API uses (eg, API \nmisuse and security vulnerabilities) have been conducted before. However, a \ncomprehensive overview of possible harmful API uses is required to help both library \nand client developers on the management of implemented and used APIs. Moreover\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomatic Android deprecated-API usage update by learning from\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1574013725000097&hl=en&sa=X&d=2853008465452076343&ei=CF_SZ8iYLZuw6rQP27yHsAU&scisig=AFWwaeaLJMWXJ54HCM5AJgS2Fmcg&oi=scholaralrt&hist=apJ4fD8AAAAJ:11486195984023826531:AFWwaebYo-fw1j0PJswL-CdomZqY&html=&pos=0&folt=cit", "ref": ["1 new citation to articles by Hong Jin Kang", "5 new citations to articles by Abhik Roychoudhury"]}
{"title": "LServe: Efficient Long-sequence LLM Serving with Unified Sparse Attention", "first_label": ["Large Language Models"], "second_label": [], "data": "S Yang, J Guo, H Tang, Q Hu, G Xiao, J Tang, Y Lin\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have shown remarkable potential in processing long \nsequences, yet efficiently serving these long-context models remains challenging \ndue to the quadratic computational complexity of attention in the prefilling stage and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.14866%3F&hl=en&sa=X&d=15664006594860475276&ei=B1_SZ_eeLYC96rQP2s_YiAM&scisig=AFWwaeYz5XhtIZXaHxxrx6sNKSYk&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=0&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Safety is Not Only About Refusal: Reasoning-Enhanced Fine-tuning for Interpretable LLM Safety", "first_label": ["Large Language Models"], "second_label": [], "data": "Y Zhang, M Li, W Han, Y Yao, Z Cen, D Zhao\\xc2\\xa0- arXiv preprint arXiv:2503.05021, 2025\nLarge Language Models (LLMs) are vulnerable to jailbreak attacks that exploit \nweaknesses in traditional safety alignment, which often relies on rigid refusal \nheuristics or representation engineering to block harmful outputs. While they are\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.05021&hl=en&sa=X&d=5785695892417368823&ei=B1_SZ_eeLYC96rQP2s_YiAM&scisig=AFWwaea2MHnS_d1ERRbZdJf_zDWG&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=1&folt=rel", "ref": ["Richard Fang - new related research", "Carlos E. Jimenez - new related research"]}
{"title": "Are Your LLM-based Text-to-SQL Models Secure? Exploring SQL Injection via Backdoor Attacks", "first_label": ["Large Language Models"], "second_label": [], "data": "M Lin, H Zhang, J Lao, R Li, Y Zhou, C Yang, Y Cao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have shown state-of-the-art results in translating \nnatural language questions into SQL queries (Text-to-SQL), a long-standing \nchallenge within the database community. However, security concerns remain\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.05445&hl=en&sa=X&d=12926828222086671917&ei=B1_SZ_eeLYC96rQP2s_YiAM&scisig=AFWwaeacACDznBMcnP3WImmo3dtE&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=2&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "SecureGaze: Defending Gaze Estimation Against Backdoor Attacks", "first_label": [], "second_label": [], "data": "L Du, Y Liu, J Jia, G Lan\\xc2\\xa0- arXiv preprint arXiv:2502.20306, 2025\nGaze estimation models are widely used in applications such as driver attention \nmonitoring and human-computer interaction. While many methods for gaze \nestimation exist, they rely heavily on data-hungry deep learning to achieve high\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.20306%3F&hl=en&sa=X&d=3616193931903532449&ei=B1_SZ_eeLYC96rQP2s_YiAM&scisig=AFWwaeYrAWi-icZrK7vyLgYJbB_k&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=3&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "V2V-LLM: Vehicle-to-Vehicle Cooperative Autonomous Driving with Multi-Modal Large Language Models", "first_label": ["Large Language Models"], "second_label": [], "data": "H Chiu, R Hachiuma, CY Wang, SF Smith, YCF Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCurrent autonomous driving vehicles rely mainly on their individual sensors to \nunderstand surrounding scenes and plan for future trajectories, which can be \nunreliable when the sensors are malfunctioning or occluded. To address this\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.09980&hl=en&sa=X&d=15240013219582954077&ei=B1_SZ_eeLYC96rQP2s_YiAM&scisig=AFWwaeYlIvaPITJgQzXxI4cpjd3u&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=4&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "ASDroid: Resisting Evolving Android Malware With API Clusters Derived From Source Code", "first_label": ["Code"], "second_label": [], "data": "Q Hu, W Wang, H Song, S Guo, J Zhang, S Zhang\\xc2\\xa0- IEEE Transactions on Information\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMachine learning-based Android malware detection has consistently demonstrated \nsuperior results. However, with the continual evolution of the Android framework, the \nefficacy of the deployed models declines markedly. Existing solutions necessitate\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10884652/&hl=en&sa=X&d=11327102995599250404&ei=B1_SZ_eeLYC96rQP2s_YiAM&scisig=AFWwaeYMsBMMLEkLIoZcRuGHvBae&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=5&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Steering Large Language Models for Vulnerability Detection", "first_label": ["Vulnerabilities", "Large Language Models"], "second_label": ["Detection"], "data": "J Li, L Cui, J Zhang, H Fei, Y Chen, H Zhu\\xc2\\xa0- ICASSP 2025-2025 IEEE International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nVulnerability detection remains a critical challenge in the field of security. Many \nexisting approaches extract code representations for vulnerability detection. \nHowever, these methods often focus on the overall semantics of the code, neglecting\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/10887540/10887541/10887736.pdf&hl=en&sa=X&d=11396564186480251679&ei=B1_SZ_eeLYC96rQP2s_YiAM&scisig=AFWwaea-ECZznko97aDblsNZcgzA&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=6&folt=rel", "ref": ["Richard Fang - new related research", "Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi", "5 new citations to articles by Abhik Roychoudhury", "1 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Hakjoo Oh", "Hong Jin Kang - new related research", "Thanh Le-Cong - new related research", "Michael Fu - new related research", "Triet H. M. Le - new related research"]}
{"title": "Self-Regularization with Latent Space Explanations for Controllable LLM-based Classification", "first_label": ["Large Language Models"], "second_label": [], "data": "X Wu, W Yu, X Zhai, N Liu\\xc2\\xa0- arXiv preprint arXiv:2502.14133, 2025\nModern text classification methods heavily rely on contextual embeddings from large \nlanguage models (LLMs). Compared to human-engineered features, these \nembeddings provide automatic and effective representations for classification model\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.14133&hl=en&sa=X&d=4757495942301661489&ei=B1_SZ_eeLYC96rQP2s_YiAM&scisig=AFWwaeY4_J4wOHv0aBKN7bjXACSi&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=7&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Lume: Llm unlearning with multitask evaluations", "first_label": ["Large Language Models"], "second_label": [], "data": "A Ramakrishna, Y Wan, X Jin, KW Chang, Z Bu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nUnlearning aims to remove copyrighted, sensitive, or private content from large \nlanguage models (LLMs) without a full retraining. In this work, we develop a multi-\ntask unlearning benchmark (LUME) which features three tasks:(1) unlearn\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.15097&hl=en&sa=X&d=15431032367192817700&ei=B1_SZ_eeLYC96rQP2s_YiAM&scisig=AFWwaeYrLEcIffndgl1M7o1B_0a5&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=8&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Can LLM Watermarks Robustly Prevent Unauthorized Knowledge Distillation?", "first_label": ["Large Language Models"], "second_label": [], "data": "L Pan, A Liu, S Huang, Y Lu, X Hu, L Wen, I King\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe radioactive nature of Large Language Model (LLM) watermarking enables the \ndetection of watermarks inherited by student models when trained on the outputs of \nwatermarked teacher models, making it a promising tool for preventing unauthorized\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.11598&hl=en&sa=X&d=12264103332853854678&ei=B1_SZ_eeLYC96rQP2s_YiAM&scisig=AFWwaeZ9XviGOEemzrPnk9_AhBxL&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=9&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Can LLMs Reason About Program Semantics? A Comprehensive Evaluation of LLMs on Formal Specification Inference", "first_label": ["Large Language Models"], "second_label": [], "data": "T Le-Cong, B Le, T Murray\\xc2\\xa0- arXiv preprint arXiv:2503.04779, 2025\nLarge Language Models (LLMs) are increasingly being used to automate \nprogramming tasks. Yet, LLMs' capabilities in reasoning about program semantics \nare still inadequately studied, leaving significant potential for further exploration. This\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.04779&hl=en&sa=X&d=3289284575963255876&ei=CF_SZ9bqBJ-_6rQPzI2_uQ0&scisig=AFWwaeantBmJUlE4DeNvuO_tHZTZ&oi=scholaralrt&hist=apJ4fD8AAAAJ:6458747529493839318:AFWwaeZG0VX_uXeMAQTQBnnN-wb_&html=&pos=0&folt=art", "ref": ["Thanh Le-Cong - new articles", "Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi", "Abhik Roychoudhury - new related research", "Bach Le - new articles", "3 new citations to articles by Thanh Le-Cong", "3 new citations to articles by Bach Le"]}
{"title": "A software vulnerability detection method based on multi-modality with unified processing", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "W Cai, J Chen, J Yu, W Hu, L Gao\\xc2\\xa0- Information and Software Technology, 2025\nWith the development of the Internet and the Internet of Things, software has become \nan indispensable part, making software vulnerabilities one of the main threats to \ncomputer security. In recent years, a multitude of deep learning-based software \nvulnerability detection methods have been proposed, especially those based on \nmultimodal approaches. Although these multimodal methods have proven to be \neffective, they often treat each modality separately. We propose a novel multimodal\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLinevul: A transformer-based line-level vulnerability prediction\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nMichael Fu\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925000424&hl=en&sa=X&d=5319209508677612172&ei=B1_SZ7jvJsuZieoP9PnpkQc&scisig=AFWwaeZxHxmCJPLJLYUF5XxVdqjT&oi=scholaralrt&hist=apJ4fD8AAAAJ:4465730527138788254:AFWwaebhnVuF-27TSh32-dm_KGTR&html=&pos=0&folt=cit", "ref": ["1 new citation to articles by Michael Fu", "Michael Fu - new related research", "Triet H. M. Le - new related research"]}
{"title": "CSAFuzzer: Fuzzing smart contracts combining with static analysis", "first_label": ["Smart Contracts", "Fuzzing"], "second_label": [], "data": "J Yang, X Zhao, H Zhang, L He, S Wang, N Gou\\xc2\\xa0- Empirical Software Engineering, 2025\nSmart contracts are pivotal in blockchain technology. With enviable digital assets, \nthey have long been targeted by hackers. Unlike traditional programs, once \ndeployed, a contract cannot be modified. Therefore, it is particularly essential to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10623-3&hl=vi&sa=X&d=1763889265484170949&ei=CV_SZ5Yo56GJ6g_D17jBAQ&scisig=AFWwaebNS6CHNg-ElTjwjlSpOnOY&oi=scholaralrt&hist=apJ4fD8AAAAJ:16065687014273664109:AFWwaeYpvD7V4gPm0ywHhNT6YvSk&html=&pos=0&folt=rel", "ref": ["Hakjoo Oh - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "PromptPex: Automatic Test Generation for Language Model Prompts", "first_label": [], "second_label": ["Generation"], "data": "RK Sharma, J De Halleux, S Barke, B Zorn\\xc2\\xa0- arXiv preprint arXiv:2503.05070, 2025\nLarge language models (LLMs) are being used in many applications and prompts for \nthese models are integrated into software applications as code-like artifacts. These \nprompts behave much like traditional software in that they take inputs, generate\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.05070&hl=vi&sa=X&d=7697764794079612529&ei=CV_SZ5Yo56GJ6g_D17jBAQ&scisig=AFWwaeYr_iEdETCfR6P3Js_YYLTp&oi=scholaralrt&hist=apJ4fD8AAAAJ:16065687014273664109:AFWwaeYpvD7V4gPm0ywHhNT6YvSk&html=&pos=1&folt=rel", "ref": ["Hakjoo Oh - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi", "Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi", "Hong Jin Kang - new related research"]}
{"title": "Static Program Analysis Guided LLM Based Unit Test Generation", "first_label": ["Unit Test", "Large Language Models"], "second_label": ["Generation"], "data": "S Roychowdhury, G Sridhara, AK Raghavan, J Bose\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWe describe a novel approach to automating unit test generation for Java methods \nusing large language models (LLMs). Existing LLM-based approaches rely on \nsample usage (s) of the method to test (focal method) and/or provide the entire class\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.05394&hl=vi&sa=X&d=14336038001288964881&ei=CV_SZ5Yo56GJ6g_D17jBAQ&scisig=AFWwaeYcnkhyYkvwqJxjIbK7kgvu&oi=scholaralrt&hist=apJ4fD8AAAAJ:16065687014273664109:AFWwaeYpvD7V4gPm0ywHhNT6YvSk&html=&pos=2&folt=rel", "ref": ["Hakjoo Oh - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi", "Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi", "Hong Jin Kang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Designing a Meta-Model for the Eclipse Qrisp eDSL for High-Level Quantum Programming", "first_label": [], "second_label": [], "data": "S Bock, R Seidel, M Petric, N Tcholtchev, A Hoffmann\\xe2\\x80\\xa6\nEclipse Qrisp is a high-level programming language designed to simplify quantum \nprogramming and make it accessible to a wider range of developers and end users. \nInitially developed at Fraunhofer FOKUS and now part of the Eclipse Foundation\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.scitepress.org/Papers/2025/131210/131210.pdf&hl=vi&sa=X&d=5394239786677014881&ei=CV_SZ5Yo56GJ6g_D17jBAQ&scisig=AFWwaeZ2N87mPdDBckNUwtSnfu7Q&oi=scholaralrt&hist=apJ4fD8AAAAJ:16065687014273664109:AFWwaeYpvD7V4gPm0ywHhNT6YvSk&html=&pos=3&folt=rel", "ref": ["Hakjoo Oh - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "ROSA: Finding Backdoors with Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "D Kokkonis, M Marcozzi, E Decoux, S Zacchiroli\nA code-level backdoor is a hidden access, programmed and concealed within the \ncode of a program. For instance, hard-coded credentials planted in the code of a file \nserver application would enable maliciously logging into all deployed instances of\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nGoogle Scholar g\\xe1\\xbb\\xadi th\\xc3\\xb4ng b\\xc3\\xa1o n\\xc3\\xa0y cho b\\xe1\\xba\\xa1n v\\xc3\\xac b\\xe1\\xba\\xa1n \\xc4\\x91ang theo d\\xc3\\xb5i nh\\xe1\\xbb\\xafng b\\xc3\\xa0i vi\\xe1\\xba\\xbft m\\xe1\\xbb\\x9bi li\\xc3\\xaan quan \\xc4\\x91\\xe1\\xba\\xbfn nghi\\xc3\\xaan c\\xe1\\xbb\\xa9u c\\xe1\\xbb\\xa7a \nHakjoo Oh\n.\nLi\\xe1\\xbb\\x87t k\\xc3\\xaa c\\xe1\\xba\\xa3nh b\\xc3\\xa1o\nH\\xe1\\xbb\\xa7y th\\xc3\\xb4ng b\\xc3\\xa1o\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://binsec.github.io/assets/publications/papers/2025-icse.pdf&hl=vi&sa=X&d=13531564943831013756&ei=CV_SZ5Yo56GJ6g_D17jBAQ&scisig=AFWwaeaGFFpUlOhEdz0gAvuIoA9h&oi=scholaralrt&hist=apJ4fD8AAAAJ:16065687014273664109:AFWwaeYpvD7V4gPm0ywHhNT6YvSk&html=&pos=4&folt=rel", "ref": ["Hakjoo Oh - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "EnCus: Customizing Search Space for Automated Program Repair", "first_label": ["Automated Program Repair"], "second_label": ["Repair"], "data": "S Kim, S Jang, J Kim, J Nam\nThe primary challenge faced by Automated Program Repair (APR) techniques in \nfixing buggy programs is the search space problem. To generate a patch, APR \ntechniques must address three critical decisions: where to fix (location), how to fix\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://lifove.github.io/files/ICST_2025_EnCus.pdf&hl=en&sa=X&d=13746921339775956765&ei=CF_SZ936JJm7ieoP1NrBiQU&scisig=AFWwaeZGniVL7NTqatFPJ-6HNr8S&oi=scholaralrt&hist=apJ4fD8AAAAJ:11137134570824175991:AFWwaeZJgvZkFmSwNlRigHvrI7d8&html=&pos=0&folt=rel", "ref": ["Abhik Roychoudhury - new related research", "Michael Fu - new related research"]}
{"title": "Moneta: Ex-Vivo GPU Driver Fuzzing by Recalling In-Vivo Execution States", "first_label": ["Fuzzing"], "second_label": [], "data": "J Jung, J Jang, Y Jo, J Vinck, A Voulimeneas\\xe2\\x80\\xa6\nGraphics Processing Units (GPUs) have become an indispensable part of modern \ncomputing infrastructure. They can execute massively parallel tasks on large data \nsets and have rich user space-accessible APIs for 3D rendering and generalpurpose\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.ndss-symposium.org/wp-content/uploads/2025-218-paper.pdf&hl=en&sa=X&d=4536160784874836119&ei=CF_SZ936JJm7ieoP1NrBiQU&scisig=AFWwaeZSpFxKVjEvBs8doewhVJqc&oi=scholaralrt&hist=apJ4fD8AAAAJ:11137134570824175991:AFWwaeZJgvZkFmSwNlRigHvrI7d8&html=&pos=2&folt=rel", "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Mechanistic Understanding of Language Models in Syntactic Code Completion", "first_label": ["Code"], "second_label": ["Generation"], "data": "S Miller, D Rai, Z Yao\\xc2\\xa0- arXiv preprint arXiv:2502.18499, 2025\nRecently, language models (LMs) have shown impressive proficiency in code \ngeneration tasks, especially when fine-tuned on code-specific datasets, commonly \nknown as Code LMs. However, our understanding of the internal decision-making\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.18499&hl=en&sa=X&d=16766167717063467915&ei=CF_SZ936JJm7ieoP1NrBiQU&scisig=AFWwaeZXFo3QPd08t686n6v36dI4&oi=scholaralrt&hist=apJ4fD8AAAAJ:11137134570824175991:AFWwaeZJgvZkFmSwNlRigHvrI7d8&html=&pos=3&folt=rel", "ref": ["Abhik Roychoudhury - new related research", "Hong Jin Kang - new related research"]}
{"title": "Knowledge-Enhanced Program Repair for Data Science Code", "first_label": ["Automated Program Repair", "Code"], "second_label": ["Repair"], "data": "S Ouyang, JM Zhang, Z Sun, AM Penuela\\xc2\\xa0- arXiv preprint arXiv:2502.09771, 2025\nThis paper introduces DSrepair, a knowledge-enhanced program repair method \ndesigned to repair the buggy code generated by LLMs in the data science domain. \nDSrepair uses knowledge graph based RAG for API knowledge retrieval as well as\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.09771&hl=en&sa=X&d=3654048262265967&ei=CV_SZ7K7A5-_6rQPzI2_uQ0&scisig=AFWwaea3b7K5alddz2-3Pw0svJ0R&oi=scholaralrt&hist=apJ4fD8AAAAJ:16488056128958629805:AFWwaeZVy5biUXZBZUZeh3-Oz0_I&html=&pos=0&folt=rel", "ref": ["Bach Le - new related research", "Thanh Le-Cong - new related research", "Michael Fu - new related research"]}
{"title": "Generative fuzzer-driven vulnerability detection in the Internet of Things networks", "first_label": ["Vulnerabilities", "Fuzzing"], "second_label": ["Detection"], "data": "MT Masud, N Koroniotis, M Keshk, B Turnbull\\xe2\\x80\\xa6\\xc2\\xa0- Applied Soft Computing, 2025\nAbstract The Internet of Things (IoT) paradigm has displayed tremendous growth in \nrecent years, driving innovations such as Industry 4.0 and the creation of smart \nenvironments that enhance efficiency and asset management and enable intelligent \ndecision-making. However, these benefits come with considerable cybersecurity \nrisks due to inherent vulnerabilities within IoT ecosystems. Introducing potentially \nvulnerable IoT devices into secure environments, like smart airports, introduces new\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1568494625002844&hl=en&sa=X&d=8880446620289000715&ei=B1_SZ9iQNZGu6rQPgrKC0AY&scisig=AFWwaeZDod1Vi26Pd_cF9ImZMMM7&oi=scholaralrt&hist=apJ4fD8AAAAJ:5778505219825515303:AFWwaeaDDOggOneW-z6K3HLjAzuP&html=&pos=0&folt=cit", "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "LLMs' Reshaping of People, Processes, Products, and Society in Software Development: A Comprehensive Exploration with Early Adopters", "first_label": ["Large Language Models"], "second_label": [], "data": "B Tabarsi, H Reichert, A Limke, S Kuttal, T Barnes\\xc2\\xa0- arXiv preprint arXiv:2503.05012, 2025\nLarge language models (LLMs) like OpenAI ChatGPT, Google Gemini, and GitHub \nCopilot are rapidly gaining traction in the software industry, but their full impact on \nsoftware engineering remains insufficiently explored. Despite their growing adoption, \nthere is a notable lack of formal, qualitative assessments of how LLMs are applied in \nreal-world software development contexts. To fill this gap, we conducted semi-\nstructured interviews with sixteen early-adopter professional developers to explore\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.05012&hl=en&sa=X&d=5417932718337029689&ei=B1_SZ9iQNZGu6rQPgrKC0AY&scisig=AFWwaebeefwud2vIe7PrdeSIsl9F&oi=scholaralrt&hist=apJ4fD8AAAAJ:5778505219825515303:AFWwaeaDDOggOneW-z6K3HLjAzuP&html=&pos=1&folt=cit", "ref": ["5 new citations to articles by Abhik Roychoudhury", "3 new citations to articles by Thanh Le-Cong", "3 new citations to articles by Bach Le"]}
{"title": "SMT (LIA) Sampling with High Diversity", "first_label": [], "second_label": [], "data": "Y Lai, J Li, C Luo\\xc2\\xa0- arXiv preprint arXiv:2503.04782, 2025\nSatisfiability Modulo Linear Integer Arithmetic, SMT (LIA) for short, is pivotal across \nvarious critical domains. Previous research has primarily focused on SMT solving \ntechniques. However, in practical applications such as software and hardware \ntesting, there is a need to generate a diverse set of solutions for use as test inputs. \nWe have developed the first sampling framework that integrates local search with \nCDCL (T) techniques, named HighDiv, capable of generating a highly diverse set of\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.04782&hl=en&sa=X&d=14936674142838153132&ei=B1_SZ9iQNZGu6rQPgrKC0AY&scisig=AFWwaebSrG7pq-VHTwX6bpD6hx2p&oi=scholaralrt&hist=apJ4fD8AAAAJ:5778505219825515303:AFWwaeaDDOggOneW-z6K3HLjAzuP&html=&pos=4&folt=cit", "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "Compromising Honesty and Harmlessness in Language Models via Deception Attacks", "first_label": [], "second_label": [], "data": "L\\xc3\\x83\\xc4\\xbb Vaugrante, F Carlon, M Menke, T Hagendorff\\xc2\\xa0- arXiv preprint arXiv:2502.08301, 2025\nRecent research on large language models (LLMs) has demonstrated their ability to \nunderstand and employ deceptive behavior, even without explicit prompting. \nHowever, such behavior has only been observed in rare, specialized cases and has\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.08301&hl=en&sa=X&d=1314709450220270892&ei=B1_SZ8moIIa56rQP1a-HqQw&scisig=AFWwaebOnmwnilqF5sVkJCLG7eZp&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=0&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "TESS 2: A Large-Scale Generalist Diffusion Language Model", "first_label": [], "second_label": [], "data": "J Tae, H Ivison, S Kumar, A Cohan\\xc2\\xa0- arXiv preprint arXiv:2502.13917, 2025\nWe introduce TESS 2, a general instruction-following diffusion language model that \noutperforms contemporary instruction-tuned diffusion models, as well as matches \nand sometimes exceeds strong autoregressive (AR) models. We train TESS 2 by first\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.13917%3F&hl=en&sa=X&d=1855260706280837543&ei=B1_SZ8moIIa56rQP1a-HqQw&scisig=AFWwaeZ-HiKumWKVlqKpcJBDV9eE&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=1&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "Continual Quantization-Aware Pre-Training: When to transition from 16-bit to 1.58-bit pre-training for BitNet language models?", "first_label": [], "second_label": [], "data": "J Nielsen, P Schneider-Kamp, L Galke\\xc2\\xa0- arXiv preprint arXiv:2502.11895, 2025\nLarge language models (LLMs) require immense resources for training and \ninference. Quantization, a technique that reduces the precision of model parameters, \noffers a promising solution for improving LLM efficiency and sustainability. While post\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.11895&hl=en&sa=X&d=5315475009734524900&ei=B1_SZ8moIIa56rQP1a-HqQw&scisig=AFWwaeac1W1T5CLpz9ocqASaiX6z&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=3&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "Vldbench: Vision language models disinformation detection benchmark", "first_label": [], "second_label": ["Detection"], "data": "S Raza, A Vayani, A Jain, A Narayanan, VR Khazaie\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid rise of AI-generated content has made detecting disinformation \nincreasingly challenging. In particular, multimodal disinformation, ie, online posts-\narticles that contain images and texts with fabricated information are specially\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.11361&hl=en&sa=X&d=6632168061223988917&ei=B1_SZ8moIIa56rQP1a-HqQw&scisig=AFWwaeaTaEZpb41Gm07ps-z9VqSU&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=4&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "Language Models Can Predict Their Own Behavior", "first_label": [], "second_label": [], "data": "D Ashok, J May\\xc2\\xa0- arXiv preprint arXiv:2502.13329, 2025\nAutoregressive Language Models output text by sequentially predicting the next \ntoken to generate, with modern methods like Chain-of-Thought (CoT) prompting \nachieving state-of-the-art reasoning capabilities by scaling the number of generated\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.13329&hl=en&sa=X&d=15514504307712566951&ei=B1_SZ8moIIa56rQP1a-HqQw&scisig=AFWwaebsBF3m-dOwUfEoW7VuVtXb&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=5&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "Evaluating the Paperclip Maximizer: Are RL-Based Language Models More Likely to Pursue Instrumental Goals?", "first_label": [], "second_label": [], "data": "Y He, Y Li, J Wu, Y Sui, Y Chen, B Hooi\\xc2\\xa0- arXiv preprint arXiv:2502.12206, 2025\nAs large language models (LLMs) continue to evolve, ensuring their alignment with \nhuman goals and values remains a pressing challenge. A key concern is\\\\textit \n{instrumental convergence}, where an AI system, in optimizing for a given objective\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.12206&hl=en&sa=X&d=5833515845218376624&ei=B1_SZ8moIIa56rQP1a-HqQw&scisig=AFWwaeZB0gZ0Nl88Ufuj-qhTc1MK&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=6&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "Balcony: A Lightweight Approach to Dynamic Inference of Generative Language Models", "first_label": [], "second_label": [], "data": "B Jamialahmadi, P Kavehzadeh, M Rezagholizadeh\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeploying large language models (LLMs) in real-world applications is often hindered \nby strict computational and latency constraints. While dynamic inference offers the \nflexibility to adjust model behavior based on varying resource budgets, existing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.05005&hl=en&sa=X&d=3866827792098068074&ei=B1_SZ8moIIa56rQP1a-HqQw&scisig=AFWwaeaoZiEg0Si9J5cdK0YftJLV&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=7&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "LVLM-Compress-Bench: Benchmarking the Broader Impact of Large Vision-Language Model Compression", "first_label": [], "second_label": [], "data": "S Kundu, A Bhiwandiwalla, S Yu, P Howard, T Le\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite recent efforts in understanding the compression impact on large language \nmodels (LLMs) in terms of their downstream task performance and trustworthiness on \nrelatively simpler uni-modal benchmarks (for example, question answering, common\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.04982&hl=en&sa=X&d=16988601174909249761&ei=B1_SZ8moIIa56rQP1a-HqQw&scisig=AFWwaeYpMGr_5zjW1vGOKyO2OCDv&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=8&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "Unveiling Environmental Impacts of Large Language Model Serving: A Functional Unit View", "first_label": ["Large Language Models"], "second_label": [], "data": "Y Wu, I Hua, Y Ding\\xc2\\xa0- arXiv preprint arXiv:2502.11256, 2025\nLarge language models (LLMs) offer powerful capabilities but come with significant \nenvironmental costs, particularly in carbon emissions. Existing studies benchmark \nthese emissions but lack a standardized basis for comparison across models. To\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nCarlos E. Jimenez\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.11256&hl=en&sa=X&d=839300699424972036&ei=B1_SZ8moIIa56rQP1a-HqQw&scisig=AFWwaeYhFYoT1V_AEDvHWQ4CZ4HT&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=9&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "Shifting Perspectives: Steering Vector Ensembles for Robust Bias Mitigation in LLMs", "first_label": ["Large Language Models"], "second_label": [], "data": "Z Siddique, I Khalid, LD Turner, L Espinosa-Anke\\xc2\\xa0- arXiv preprint arXiv:2503.05371, 2025\nWe present a novel approach to bias mitigation in large language models (LLMs) by \napplying steering vectors to modify model activations in forward passes. We employ \nBayesian optimization to systematically identify effective contrastive pair datasets \nacross nine bias axes. When optimized on the BBQ dataset, our individually tuned \nsteering vectors achieve average improvements of 12.2%, 4.7%, and 3.2% over the \nbaseline for Mistral, Llama, and Qwen, respectively. Building on these promising\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.05371&hl=en&sa=X&d=3747000663560487652&ei=CF_SZ6qrGJyV6rQPpZCUsQI&scisig=AFWwaeaTAR8gvOfQ3dUKsy4cWiKk&oi=scholaralrt&hist=apJ4fD8AAAAJ:9077511576393718270:AFWwaeYjhZg9MUHEYuARvipEszZC&html=&pos=0&folt=cit", "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "No, Of Course I Can! Refusal Mechanisms Can Be Exploited Using Harmless Data", "first_label": [], "second_label": ["Exploit"], "data": "J Kazdan, L Yu, R Schaeffer, C Cundy, S Koyejo\\xe2\\x80\\xa6\\xc2\\xa0- ICLR 2025 Workshop on Building\\xc2\\xa0\\xe2\\x80\\xa6\nLeading language model (LM) providers like OpenAI and Google offer fine-tuning \nAPIs that allow customers to adapt LMs for specific use cases. To prevent misuse, \nthese LM providers implement filtering mechanisms to block harmful fine-tuning data. \nConsequently, adversaries seeking to produce unsafe LMs via these APIs must craft \nadversarial training data that are not identifiably harmful. We make three \ncontributions in this context: 1. We show that many existing attacks that use harmless\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DPKEMgfGuCD&hl=en&sa=X&d=14583508412141032895&ei=CF_SZ6qrGJyV6rQPpZCUsQI&scisig=AFWwaearq1yFX8RK9GplzmJoJ777&oi=scholaralrt&hist=apJ4fD8AAAAJ:9077511576393718270:AFWwaeYjhZg9MUHEYuARvipEszZC&html=&pos=1&folt=cit", "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Human-AI Collaboration (HAIC): The Rise of Hybrid Intelligence in Modern Software Development", "first_label": [], "second_label": [], "data": "S Medepalli\\xc2\\xa0- Journal Publication of International Research for\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware development or software engineering has certainly moved to new levels of \nexcellence with the effective syncing of artificial intelligence and human effort. This \npaper investigates the evolving impact of AI-human collaboration (hybrid \nintelligence) with a due focus on the role of AI agents and human participants in \nsoftware development. It analyzes how teams take on AI, use AI to assist in \nprogramming, collaborate on projects, resolve issues, and perform other similar\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://joirem.com/wp-content/uploads/journal/published_paper/volume-10/issue-1/J_ylZzP5pq.pdf&hl=en&sa=X&d=6994451778038483246&ei=B1_SZ8D5GZuw6rQP27yHsAU&scisig=AFWwaeYvSu4LKXufxZNripLcT7nO&oi=scholaralrt&hist=apJ4fD8AAAAJ:1878193813677419122:AFWwaebnAK6dY8A06r0yyM87AWUg&html=&pos=0&folt=cit", "ref": ["3 new citations to articles by Thanh Le-Cong", "3 new citations to articles by Bach Le"]}
{"title": "Towards cost-efficient vulnerability detection with cross-modal adversarial reprogramming", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "Z Tian, R Qiu, Y Teng, J Sun, Y Chen, L Chen\\xc2\\xa0- Journal of Systems and Software, 2025\nWhile deep learning has advanced the automatic detection of software \nvulnerabilities, current DL-based methods still face two major obstacles: the scarcity \nof vulnerable code samples and the high computational cost of training models from\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225000330&hl=en&sa=X&d=17446884386547932313&ei=CF_SZ4vTEMmpieoP4aW8iQ8&scisig=AFWwaeZtqZ9sta5N5NchBizwtudz&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=0&folt=rel", "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Poisoned Source Code Detection in Code Models", "first_label": ["Code"], "second_label": ["Detection"], "data": "E Ghannoum, M Ghafari\\xc2\\xa0- arXiv preprint arXiv:2502.13459, 2025\nDeep learning models have gained popularity for conducting various tasks involving \nsource code. However, their black-box nature raises concerns about potential risks. \nOne such risk is a poisoning attack, where an attacker intentionally contaminates the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.13459&hl=en&sa=X&d=6875396652207410319&ei=CF_SZ4vTEMmpieoP4aW8iQ8&scisig=AFWwaeZ_hcNzoEiXth4lEVB3Rdg4&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=3&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "GPT-Based Automated Induction: Vulnerability Detection in Medical Software", "first_label": ["Vulnerabilities", "Large Language Models"], "second_label": ["Detection"], "data": "L Deng, H Lei, F Khan, G Srivastava, J Chen, M Haque\\xc2\\xa0- IEEE Journal of Biomedical\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIntegrating Natural Language Processing (NLP) with Generative Pre-trained \nTransformer (GPT) models plays a pivotal role in enhancing the accuracy and \nefficiency of healthcare software, which is essential for patient safety and providing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10899829/&hl=en&sa=X&d=4257828238536637457&ei=CF_SZ4vTEMmpieoP4aW8iQ8&scisig=AFWwaebLUMgz30_kE6q-kcisdZTu&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=4&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Combining Large Language Models with Static Analyzers for Code Review Generation", "first_label": ["Large Language Models", "Code Review", "Code"], "second_label": ["Generation"], "data": "I Jaoua, OB Sghaier, H Sahraoui\\xc2\\xa0- arXiv preprint arXiv:2502.06633, 2025\nCode review is a crucial but often complex, subjective, and time-consuming activity in \nsoftware development. Over the past decades, significant efforts have been made to \nautomate this process. Early approaches focused on knowledge-based systems\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.06633&hl=en&sa=X&d=15947875415862330768&ei=CF_SZ4vTEMmpieoP4aW8iQ8&scisig=AFWwaeZNoEKeFXzps09u7HRXyGKK&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=5&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Pragmatic Reasoning improves LLM Code Generation", "first_label": ["Large Language Models", "Code"], "second_label": ["Generation"], "data": "Z Cao, S Apel, A Singla, V Demberg\\xc2\\xa0- arXiv preprint arXiv:2502.15835, 2025\nLarge Language Models (LLMs) have demonstrated impressive potential in \ntranslating natural language (NL) instructions into program code. However, user \ninstructions often contain inherent ambiguities, making it challenging for LLMs to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.15835&hl=en&sa=X&d=6927995321596801340&ei=CF_SZ4vTEMmpieoP4aW8iQ8&scisig=AFWwaebpCZ-l4eJjTQ3XaxQi2c08&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=7&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "MARIN: A Research-Centric Interface for Querying Software Artifacts on Maven Repositories", "first_label": [], "second_label": [], "data": "J D\\xc3\\xbcsing, J Chiaramonte, B Hermann\nMaven Central is the largest open repository for JVM libraries, hosting just under 15 \nmillion artifacts as of November 2024. Its popularity has made it a prime target for \nmalicious actors to upload malware or exploit vulnerabilities\\xe2\\x80\\x93one in eight open\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://sse.cs.tu-dortmund.de/storages/sse-cs/r/Publications/Preprints/marin-paper-main.pdf&hl=en&sa=X&d=14248612257349812073&ei=CF_SZ4vTEMmpieoP4aW8iQ8&scisig=AFWwaeZYlg4cHvGKIk9iDebOX8g6&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=9&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "LLM-enhanced evolutionary test generation for untyped languages", "first_label": ["Large Language Models"], "second_label": ["Generation"], "data": "R Yang, X Xu, R Wang\\xc2\\xa0- Automated Software Engineering, 2025\nDynamic programming languages, such as Python, are widely used for their flexibility \nand support for rapid development. However, the absence of explicit parameter type \ndeclarations poses significant challenges in generating automated test cases. This\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00496-7&hl=en&sa=X&d=5209764566405071124&ei=CF_SZ825M7utieoP8ref4Qo&scisig=AFWwaeZZcNNRu-1nh6WZ8bsL9w5L&oi=scholaralrt&hist=apJ4fD8AAAAJ:11631047573362457156:AFWwaeYhbBKL65h4pzyKCNru3s-R&html=&pos=1&folt=rel", "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Improving Deep Assertion Generation via Fine-Tuning Retrieval-Augmented Pre-trained Language Models", "first_label": [], "second_label": ["Generation"], "data": "Q Zhang, C Fang, Y Zheng, Y Zhang, Y Zhao, R Huang\\xe2\\x80\\xa6\\xc2\\xa0- ACM Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nUnit testing validates the correctness of the units of the software system under test \nand serves as the cornerstone in improving software quality and reliability. To reduce \nmanual efforts in writing unit tests, some techniques have been proposed to generate\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3721128&hl=en&sa=X&d=7994025115950886329&ei=B1_SZ9mZO5uoieoPksjy2Ag&scisig=AFWwaebGza7bXsWUQ2XMouPDx_vl&oi=scholaralrt&hist=apJ4fD8AAAAJ:6234092987365270793:AFWwaeZHIN6aK_iU38VPuuMoYcVu&html=&pos=2&folt=rel", "ref": ["Michael Fu - new related research"]}
{"title": "LLM Compiler: Foundation Language Models for Compiler Optimization", "first_label": ["Large Language Models"], "second_label": [], "data": "C Cummins, V Seeker, D Grubisic, B Roziere\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 34th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable capabilities across \na variety of software engineering and coding tasks. However, their application in the \ndomain of code and compiler optimization remains underexplored. Training LLMs is\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3708493.3712691&hl=en&sa=X&d=15248179687375146706&ei=B1_SZ9mZO5uoieoPksjy2Ag&scisig=AFWwaeaQLmVGmhuYPirTSRdIm2C5&oi=scholaralrt&hist=apJ4fD8AAAAJ:6234092987365270793:AFWwaeZHIN6aK_iU38VPuuMoYcVu&html=&pos=3&folt=rel", "ref": ["Michael Fu - new related research"]}
{"title": "Beyond Next Word Prediction: Developing Comprehensive Evaluation Frameworks for measuring LLM performance on real world applications", "first_label": ["Large Language Models"], "second_label": [], "data": "V Agrawal, A Chaudhury, S Agrawal\\xc2\\xa0- arXiv preprint arXiv:2503.04828, 2025\nWhile Large Language Models (LLMs) are fundamentally next-token prediction \nsystems, their practical applications extend far beyond this basic function. From \nnatural language processing and text generation to conversational assistants and \nsoftware use, LLMs have numerous use-cases, and have already acquired a \nsignificant degree of enterprise adoption. To evaluate such models, static evaluation \ndatasets, consisting of a set of prompts and their corresponding ground truths, are\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSwe-bench: Can language models resolve real-world github issues?\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.04828&hl=en&sa=X&d=16147851031426595143&ei=CV_SZ5H9AZGu6rQPgrKC0AY&scisig=AFWwaeZ28pFbfjSojGwYbu2PZqum&oi=scholaralrt&hist=apJ4fD8AAAAJ:16237994392044955269:AFWwaebaLgrVcMkfKx1Gjt1mqPQn&html=&pos=0&folt=cit", "ref": ["2 new citations to articles by Carlos E. Jimenez"]}
{"title": "Framing the Game: How Context Shapes LLM Decision-Making", "first_label": ["Large Language Models"], "second_label": [], "data": "I Robinson, J Burden\\xc2\\xa0- arXiv preprint arXiv:2503.04840, 2025\nLarge Language Models (LLMs) are increasingly deployed across diverse contexts \nto support decision-making. While existing evaluations effectively probe latent model \ncapabilities, they often overlook the impact of context framing on perceived rational \ndecision-making. In this study, we introduce a novel evaluation framework that \nsystematically varies evaluation instances across key features and procedurally \ngenerates vignettes to create highly varied scenarios. By analyzing decision-making\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSwe-bench: Can language models resolve real-world github issues?\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nCarlos E. Jimenez\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.04840&hl=en&sa=X&d=14689277467560255031&ei=CV_SZ5H9AZGu6rQPgrKC0AY&scisig=AFWwaea6_DjH4Yjny_6_D84EcwwE&oi=scholaralrt&hist=apJ4fD8AAAAJ:16237994392044955269:AFWwaebaLgrVcMkfKx1Gjt1mqPQn&html=&pos=1&folt=cit", "ref": ["2 new citations to articles by Carlos E. Jimenez"]}
