{"title": "Investigating the Vulnerability of LLM-as-a-Judge Architectures to Prompt-Injection Attacks", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "N Maloyan, B Ashinov, D Namiot\\xc2\\xa0- arXiv preprint arXiv:2505.13348, 2025\nLarge Language Models (LLMs) are increasingly employed as evaluators (LLM-as-a-\nJudge) for assessing the quality of machine-generated text. This paradigm offers \nscalability and cost-effectiveness compared to human annotation. However, the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13348&hl=en&sa=X&d=5272614435720234126&ei=cMcwaLefGsmx6rQP-rCh4AE&scisig=AAZF9b__v284anbHznTasg-AYLVM&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Evaluatiing the efficacy of LLM Safety Solutions: The Palit Benchmark Dataset", "first_label": ["LLM"], "second_label": [], "data": "S Palit, D Woods\\xc2\\xa0- arXiv preprint arXiv:2505.13028, 2025\nLarge Language Models (LLMs) are increasingly integrated into critical systems in \nindustries like healthcare and finance. Users can often submit queries to LLM-\nenabled chatbots, some of which can enrich responses with information retrieved\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13028&hl=en&sa=X&d=1273460049730580919&ei=cMcwaLefGsmx6rQP-rCh4AE&scisig=AAZF9b_-vHL06cauSDcPg_fRL8FD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "JULI: Jailbreak Large Language Models by Self-Introspection", "first_label": ["LLM"], "second_label": [], "data": "J Wang, Z Hu, D Wagner\\xc2\\xa0- arXiv preprint arXiv:2505.11790, 2025\nLarge Language Models (LLMs) are trained with safety alignment to prevent \ngenerating malicious content. Although some attacks have highlighted vulnerabilities \nin these safety-aligned LLMs, they typically have limitations, such as necessitating\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11790&hl=en&sa=X&d=3926434229328693064&ei=cMcwaLefGsmx6rQP-rCh4AE&scisig=AAZF9b9nZiBnexyosm99TRU_ULp7&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Wang, W Wang, S Wang, Z Li, Z Ji, Z Lyu, D Wu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Large Language Models (LLMs) has led to the \nemergence of Multi-Agent Systems (MAS) to perform complex tasks through \ncollaboration. However, the intricate nature of MAS, including their architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12442&hl=en&sa=X&d=8825331941370095164&ei=cMcwaLefGsmx6rQP-rCh4AE&scisig=AAZF9b_j6hKF2Zy8dNMOx-tobM6E&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "first_label": ["LLM"], "second_label": [], "data": "G Chen, F Song, Z Zhao, X Jia, Y Liu, Y Qiao, W Zhang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreak attacks to Large audio-language models (LALMs) are studied recently, but \nthey achieve suboptimal effectiveness, applicability, and practicability, particularly, \nassuming that the adversary can fully manipulate user prompts. In this work, we first\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14103&hl=en&sa=X&d=12355582258955555442&ei=cMcwaLefGsmx6rQP-rCh4AE&scisig=AAZF9b84twuHlVXU1hPFciKO3AfT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SPIRIT: Patching Speech Language Models against Jailbreak Attacks", "first_label": ["LLM"], "second_label": [], "data": "A Djanibekov, N Mukhituly, K Inui, H Aldarmaki\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSpeech Language Models (SLMs) enable natural interactions via spoken \ninstructions, which more effectively capture user intent by detecting nuances in \nspeech. The richer speech signal introduces new security risks compared to text\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13541&hl=en&sa=X&d=14264422034074649514&ei=cMcwaLefGsmx6rQP-rCh4AE&scisig=AAZF9b_cqBc09Ng0S0WhdfXSIHSr&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Bullying the Machine: How Personas Increase LLM Vulnerability", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "Z Xu, U Sanghi, M Kankanhalli\\xc2\\xa0- arXiv preprint arXiv:2505.12692, 2025\nLarge Language Models (LLMs) are increasingly deployed in interactions where \nthey are prompted to adopt personas. This paper investigates whether such persona \nconditioning affects model safety under bullying, an adversarial manipulation that\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12692&hl=en&sa=X&d=3130006781540917286&ei=cMcwaLefGsmx6rQP-rCh4AE&scisig=AAZF9b_aZXNRBIY5lJUtsG2cllBY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Disambiguation in Conversational Question Answering in the Era of LLM: A Survey", "first_label": ["LLM"], "second_label": [], "data": "MM Tanjim, Y In, X Chen, VS Bursztyn, RA Rossi\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAmbiguity remains a fundamental challenge in Natural Language Processing (NLP) \ndue to the inherent complexity and flexibility of human language. With the advent of \nLarge Language Models (LLMs), addressing ambiguity has become even more\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12543&hl=en&sa=X&d=10098855731850359041&ei=cMcwaLefGsmx6rQP-rCh4AE&scisig=AAZF9b-vOVUAwttokXYr2ZwaP0ql&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Shots to Stories: LLM-Assisted Video Editing with Unified Language Representations", "first_label": ["LLM"], "second_label": [], "data": "Y Li, H Xu, F Tian\\xc2\\xa0- arXiv preprint arXiv:2505.12237, 2025\nLarge Language Models (LLMs) and Vision-Language Models (VLMs) have \ndemonstrated remarkable reasoning and generalization capabilities in video \nunderstanding; however, their application in video editing remains largely\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12237&hl=en&sa=X&d=10505763597250854428&ei=cMcwaLefGsmx6rQP-rCh4AE&scisig=AAZF9b90gQPI6R4RwX9k19MeWwCR&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Steering the CensorShip: Uncovering Representation Vectors for LLM\" Thought\" Control", "first_label": ["LLM"], "second_label": [], "data": "H Cyberey, D Evans\\xc2\\xa0- arXiv preprint arXiv:2504.17130, 2025\nLarge language models (LLMs) have transformed the way we access information. \nThese models are often tuned to refuse to comply with requests that are considered \nharmful and to produce responses that better align with the preferences of those who\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.17130&hl=en&sa=X&d=15371871009015193723&ei=cMcwaLefGsmx6rQP-rCh4AE&scisig=AAZF9b8EW3QbsTc18pFbrVjbazAC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Fixing 7,400 Bugs for 1$: Cheap Crash-Site Program Repair", "first_label": ["APR", "Bug"], "second_label": ["Repair"], "data": "H Zheng, I Shumailov, T Fan, A Hall, M Payer\\xc2\\xa0- arXiv preprint arXiv:2505.13103, 2025\nThe rapid advancement of bug-finding techniques has led to the discovery of more \nvulnerabilities than developers can reasonably fix, creating an urgent need for \neffective Automated Program Repair (APR) methods. However, the complexity of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13103&hl=en&sa=X&d=13398758609778638920&ei=cMcwaIXGFOfRieoP8p3muQQ&scisig=AAZF9b-mwPS59VllzciyI8t93968&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "Bach Le - new related research", "Hong Jin Kang - new related research", "Thanh Le-Cong - new related research", "David Lo - new related research", "7 new citations to articles by Abhik Roychoudhury", "3 new citations to articles by Xin ZHOU"]}
{"title": "Adversarial Reasoning for Repair Based on Inferred Program Intent", "first_label": [], "second_label": ["Repair", "Reasoning"], "data": "H Ye, AZH Yang, C Hu, Y Wang, T Zhang, CL Goues\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomated program repair (APR) has shown promising results, particularly with the \nuse of neural networks. Currently, most APR tools focus on code transformations \nspecified by test suites, rather than reasoning about the program intent and the high\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13008&hl=en&sa=X&d=69655204533362550&ei=cMcwaIXGFOfRieoP8p3muQQ&scisig=AAZF9b8GEF76NVs7pjmf0XUNAGB8&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=1&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "2 new citations to articles by Bach Le", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "7 new citations to articles by Abhik Roychoudhury"]}
{"title": "EffiBench-X: A Multi-Language Benchmark for Measuring Efficiency of LLM-Generated Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "Y Qing, B Zhu, M Du, Z Guo, TY Zhuo, Q Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nExisting code generation benchmarks primarily evaluate functional correctness, with \nlimited focus on code efficiency and often restricted to a single language like Python. \nTo address this gap, we introduce EffiBench-X, the first multi-language benchmark\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13004&hl=en&sa=X&d=12028887143426091594&ei=cMcwaNnxC-WBieoP0PLYiAU&scisig=AAZF9b8YAoU1OnIvBgJUbMPYVZ2h&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Hong Jin Kang - new related research", "David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Identifying Root Cause of bugs by Capturing Changed Code Lines with Relational Graph Neural Networks", "first_label": ["Code", "Bug"], "second_label": ["Detection", "Graph"], "data": "J Zhang, S Guo, H Li, C Li, Y Chai, R Chen\\xc2\\xa0- arXiv preprint arXiv:2505.00990, 2025\nThe Just-In-Time defect prediction model helps development teams improve software \nquality and efficiency by assessing whether code changes submitted by developers \nare likely to introduce defects in real-time, allowing timely identification of potential\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.00990&hl=en&sa=X&d=17996198631274398381&ei=cMcwaKONHeWBieoP0PLYiAU&scisig=AAZF9b_S66ntoRzUw7soStgrJChb&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Stateful Analysis and Fuzzing of Commercial Baseband Firmware", "first_label": ["Fuzzing"], "second_label": [], "data": "A Ranjbar, T Yang, K Tu, S Khalilollahi, SR Hussain\\xc2\\xa0- 2025 IEEE Symposium on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBaseband firmware plays a critical role in cellular communication, yet its proprietary, \nclosed-source nature and complex, stateful processing logic make systematic \nsecurity testing challenging. Existing methods often fail to account for the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://syed-rafiul-hussain.github.io/wp-content/uploads/2025/05/Loris_baseband_fuzzing_sp25.pdf&hl=en&sa=X&d=12942867024371270911&ei=cMcwaKONHeWBieoP0PLYiAU&scisig=AAZF9b-Ze-vPOALeUo-ikpj0sFws&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "LLM-assisted Bug Identification and Correction for Verilog HDL", "first_label": ["LLM", "Bug"], "second_label": [], "data": "K Qayyum, CK Jha, S Ahmadi-Pour, M Hassan\\xe2\\x80\\xa6\\xc2\\xa0- ACM Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs technology continues to advance, it becomes increasingly integrated into daily life \nfacilitating complex tasks across a range of environments. While some applications \nsuch as smartphones and smartwatches are less critical, others like healthcare\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3733237&hl=en&sa=X&d=17416623168000537614&ei=cMcwaKONHeWBieoP0PLYiAU&scisig=AAZF9b8EupnBeyQszHacv5cfujCQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "An Empirical Study of Multi-Language Security Patches in Open Source Software", "first_label": [], "second_label": [], "data": "S Sun, Y Xing, G Zou, X Wang, K Sun\nVulnerabilities in software repositories written in multiple programming languages \npresent a major challenge to modern software quality assurance, especially those \nresulting from interactions between different languages. Existing static and dynamic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://yunlongxing.github.io/publications/dimva25_Empirical.pdf&hl=en&sa=X&d=10326866748066170289&ei=cMcwaKONHeWBieoP0PLYiAU&scisig=AAZF9b-FrAQMzcNeCYBMoioph8Ze&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "On-Policy Optimization with Group Equivalent Preference for Multi-Programming Language Understanding", "first_label": [], "second_label": [], "data": "H Wu, R Ming, J Gao, H Zhao, X Chen, Y Yang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) achieve remarkable performance in code generation \ntasks. However, a significant performance disparity persists between popular \nprogramming languages (eg, Python, C++) and others. To address this capability\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12723&hl=en&sa=X&d=13717591830345234396&ei=cMcwaKONHeWBieoP0PLYiAU&scisig=AAZF9b-Rv548ZrJGZne-1MZyXh7v&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Benchmarking and Revisiting Code Generation Assessment: A Mutation-Based Approach", "first_label": ["Code"], "second_label": ["Generation"], "data": "L Wang, T Li, X Xie, Y Zhi, J Wang, C Shen\\xc2\\xa0- arXiv preprint arXiv:2505.06880, 2025\nCode Large Language Models (CLLMs) have exhibited outstanding performance in \nprogram synthesis, attracting the focus of the research community. The evaluation of \nCLLM's program synthesis capability has generally relied on manually curated\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.06880&hl=en&sa=X&d=14741036642597810521&ei=cMcwaKONHeWBieoP0PLYiAU&scisig=AAZF9b-XtwkjbmK5M8jMYEwh_fbQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "EVALOOP: Assessing LLM Robustness in Programming from a Self-consistency Perspective", "first_label": ["LLM"], "second_label": [], "data": "S Fang, W Ding, B Xu\\xc2\\xa0- arXiv preprint arXiv:2505.12185, 2025\nAssessing the programming capabilities of Large Language Models (LLMs) is crucial \nfor their effective use in software engineering. Current evaluations, however, \npredominantly measure the accuracy of generated code on static benchmarks, \nneglecting the critical aspect of model robustness during programming tasks. While \nadversarial attacks offer insights on model robustness, their effectiveness is limited \nand evaluation could be constrained. Current adversarial attack methods for\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAdversarial attacks on code models with discriminative graph\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12185&hl=en&sa=X&d=10000522040676713077&ei=cMcwaI-GELeC6rQP9sj2mQ8&scisig=AAZF9b9hKHunVPRN-AH800zkjV73&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le", "David Lo - new related research"]}
{"title": "On the Applicability of Code Language Models to Scientific Computing Programs", "first_label": ["LLM", "Code"], "second_label": [], "data": "Q Zhao, F Liu, X Long, C Wu, L Zhang\\xc2\\xa0- IEEE Transactions on Software Engineering, 2025\nScientific Computing Programming Languages (SCPLs), like MATLAB and R, are \npopular and widely used for computational mathematics. In recent years, pre-trained \ncode language models (CLMs) have automated many code-related tasks, covering\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10977820/&hl=en&sa=X&d=15239791575915616252&ei=cMcwaMTHDqm7ieoP1JuLsA8&scisig=AAZF9b_lsWqv_Sky29QCVRfDTuma&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Context-Enhanced Vulnerability Detection Based on Large Language Model", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "Y Yang, B Xu, X Gao, H Sun\\xc2\\xa0- arXiv preprint arXiv:2504.16877, 2025\nVulnerability detection is a critical aspect of software security. Accurate detection is \nessential to prevent potential security breaches and protect software systems from \nmalicious attacks. Recently, vulnerability detection methods leveraging deep\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.16877&hl=en&sa=X&d=18311446874543132824&ei=cMcwaMTHDqm7ieoP1JuLsA8&scisig=AAZF9b8vxEu3pMo1vQ7vVJj2XwJH&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Exploring Fine-Grained Bug Report Categorization with Large Language Models and Prompt Engineering: An Empirical Study", "first_label": ["LLM", "Bug"], "second_label": [], "data": "A Koyuncu\\xc2\\xa0- ACM Transactions on Software Engineering and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAccurate classification of issues is essential for effective project management and \ntimely responses, as the volume of issue reports continues to grow. Manual \nclassification is labor-intensive and error-prone, necessitating automated solutions\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3736408&hl=en&sa=X&d=1221326668322558367&ei=cMcwaPi2EZ-mieoPoOrjuQU&scisig=AAZF9b94qGcVVVtNwHBRf1PSh6nk&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Success is in the Details: Evaluate and Enhance Details Sensitivity of Code LLMs through Counterfactuals", "first_label": ["LLM", "Code"], "second_label": [], "data": "X Luo, Q Zhu, Z Zhang, M Xu, T Cheng, Y Wang, Z Chu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode Sensitivity refers to the ability of Code LLMs to recognize and respond to \ndetails changes in problem descriptions. While current code benchmarks and \ninstruction data focus on difficulty and diversity, sensitivity is overlooked. We first\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14597&hl=en&sa=X&d=3060624652656954460&ei=cMcwaPi2EZ-mieoPoOrjuQU&scisig=AAZF9b_0rbuD18fQZ1qyyZ10pqAd&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Automated Vulnerability Discovery Generative AI in Offensive Security", "first_label": ["Vulnerabilities"], "second_label": [], "data": "M Alauthman, A Almomani, S Aoudi, A Al-Qerem\\xe2\\x80\\xa6\\xc2\\xa0- \\xe2\\x80\\xa6\\xc2\\xa0Risks Produced by\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis chapter investigates how generative AI techniques transform offensive security. \nIt explores automated methods that identify software flaws, generate targeted \nexploits, and support penetration testers in analyzing systems. Emphasis is placed\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.igi-global.com/chapter/automated-vulnerability-discovery-generative-ai-in-offensive-security/378288&hl=en&sa=X&d=6142877101358339902&ei=cMcwaPi2EZ-mieoPoOrjuQU&scisig=AAZF9b900jvcuzxSKRS8GTRV_VL2&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Automated Vulnerability Discovery Generative Al", "first_label": ["Vulnerabilities"], "second_label": [], "data": "A Al-Qerem, A Aldweesh\\xc2\\xa0- \\xe2\\x80\\xa6\\xc2\\xa0Cybersecurity Risks Produced by Generative AI, 2025\nThis chapter investigates how generative Al techniques transform offensive security. \nIt explores automated methods that identify software flaws, generate targeted \nexploits, and support penetration testers in analyzing systems. Emphasis is placed\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DzORbEQAAQBAJ%26oi%3Dfnd%26pg%3DPA309%26ots%3DVbsP-qp8xv%26sig%3D1IZyz9DVbXZoKPRRB-NIS6_DQWo&hl=en&sa=X&d=17594705992911668952&ei=cMcwaPi2EZ-mieoPoOrjuQU&scisig=AAZF9b9pqFy2tqVqR-JKv6Zb1gXz&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Selective Code Generation for Functional Guarantees", "first_label": ["Code"], "second_label": ["Generation"], "data": "J Jeong, T Kim, S Park\\xc2\\xa0- arXiv preprint arXiv:2505.13553, 2025\nLarge language models (LLMs) show human-level performance and their \nspecialized descendants, code generation models, play core roles in solving \ncomplex tasks, including mathematical reasoning and software development. On the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13553&hl=en&sa=X&d=10618887701165566141&ei=cMcwaPi2EZ-mieoPoOrjuQU&scisig=AAZF9b88mIfSM5NIHQuMquWHVKnm&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Manifesto from Dagstuhl Perspectives Workshop 24452--Reframing Technical Debt", "first_label": [], "second_label": [], "data": "P Avgeriou, I Ozkaya, H Koziolek, Z Codabux, N Ernst\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis is the Dagstuhl Perspectives Workshop 24452 manifesto on Reframing \nTechnical Debt. The manifesto begins with a one-page summary of Values, Beliefs, \nand Principles. It then elaborates on each Value, Belief, and Principle to explain their\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13009&hl=en&sa=X&d=13515691248470767835&ei=cMcwaPi2EZ-mieoPoOrjuQU&scisig=AAZF9b_-qPhAs9uhZovsiWcLcd4a&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "SVA-ICL: Improving LLM-based Software Vulnerability Assessment via In-Context Learning and Information Fusion", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "C Gao, X Chen, G Zhang\\xc2\\xa0- arXiv preprint arXiv:2505.10008, 2025\nContext: Software vulnerability assessment (SVA) is critical for identifying, evaluating, \nand prioritizing security weaknesses in software applications. Objective: Despite the \nincreasing application of large language models (LLMs) in various software\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.10008&hl=en&sa=X&d=1264413811272727540&ei=cMcwaOfaG4PFieoPyOahgAU&scisig=AAZF9b8ALX06m_riBYkcPk3CfsTb&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "CLEVER: A Curated Benchmark for Formally Verified Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "A Thakur, J Lee, G Tsoukalas, M Sistla, M Zhao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWe introduce ${\\\\rm C {\\\\small LEVER}} $, a high-quality, curated benchmark of 161 \nproblems for end-to-end verified code generation in Lean. Each problem consists of \n(1) the task of generating a specification that matches a held-out ground-truth\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13938&hl=en&sa=X&d=11192071992810668718&ei=cMcwaOfaG4PFieoPyOahgAU&scisig=AAZF9b-C-NTbh5R9b-swAyggAxAH&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "RTL++: Graph-enhanced LLM for RTL Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation", "Graph"], "data": "M Akyash, K Azar, H Kamali\\xc2\\xa0- arXiv preprint arXiv:2505.13479, 2025\nAs hardware design complexity escalates, there is an urgent need for advanced \nautomation in electronic design automation (EDA). Traditional register transfer level \n(RTL) design methods are manual, time-consuming, and prone to errors. While\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13479&hl=en&sa=X&d=6042755301333836943&ei=cMcwaOfaG4PFieoPyOahgAU&scisig=AAZF9b91iYjfy-c_GO2nFCC4zu2K&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Guided Search Strategies in Non-Serializable Environments with Applications to Software Engineering Agents", "first_label": [], "second_label": ["Agent", "Search"], "data": "K Zainullina, A Golubev, M Trofimova, S Polezhaev\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have recently achieved remarkable results in \ncomplex multi-step tasks, such as mathematical reasoning and agentic software \nengineering. However, they often struggle to maintain consistent performance across \nmultiple solution attempts. One effective approach to narrow the gap between \naverage-case and best-case performance is guided test-time search, which explores \nmultiple solution paths to identify the most promising one. Unfortunately, effective\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13652&hl=en&sa=X&d=16639264652215845731&ei=cMcwaIOGE_ynieoPhK2buAM&scisig=AAZF9b8rosT55wzCqZ8cohQw-jIG&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "An Automated Blackbox Noncompliance Checker for QUIC Server Implementations", "first_label": [], "second_label": [], "data": "KK Ang, G Farrelly, C Pope, DC Ranasinghe\\xc2\\xa0- arXiv preprint arXiv:2505.12690, 2025\nWe develop QUICtester, an automated approach for uncovering non-compliant \nbehaviors in the ratified QUIC protocol implementations (RFC 9000/9001). \nQUICtester leverages active automata learning to abstract the behavior of a QUIC \nimplementation into a finite state machine (FSM) representation. Unlike prior \nnoncompliance checking methods, to help uncover state dependencies on event \ntiming, QUICtester introduces the idea of state learning with event timing variations\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12690&hl=en&sa=X&d=4685541144643323507&ei=cMcwaIOGE_ynieoPhK2buAM&scisig=AAZF9b987F0IhMXLHOwmMTOqWaqI&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "From LLMs to Randomness: Analyzing Program Input Efficacy with Resource and Language Metrics", "first_label": ["LLM"], "second_label": [], "data": "G Black, E Yocam, V Vaidyan, G Comert, Y Wang\\xc2\\xa0- IEEE Access, 2025\nSecurity-focused program testing typically focuses on crash detection and code \ncoverage while overlooking additional system behaviors that can impact program \nconfidentiality and availability. To address this gap, we propose a statistical \nframework that combines embedding-based anomaly detection, resource usage \nmetrics, and resource-state distance measures to systematically profile software \nbehaviors beyond traditional coverage-based methods. Leveraging over 5 million\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFuzzing: Challenges and Reflections\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11006641.pdf&hl=en&sa=X&d=18274979556241197973&ei=cMcwaIOGE_ynieoPhK2buAM&scisig=AAZF9b8kBdUN_IJqKKkeBSLHiFuo&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "Understanding the Sneaky Patterns of Pop-up Windows in the Mobile Ecosystem", "first_label": [], "second_label": [], "data": "D Wu, Y Nan, S Wang, J Wang, L Li, X Wang\\xc2\\xa0- arXiv preprint arXiv:2505.12056, 2025\nIn mobile applications, Pop-up window (PoW) plays a crucial role in improving user \nexperience, guiding user actions, and delivering key information. Unfortunately, the \nexcessive use of PoWs severely degrades the user experience. These PoWs often \nsneakily mislead users in their choices, employing tactics that subtly manipulate \ndecision-making processes. In this paper, we provide the first in-depth study on the \nSneaky patterns in the mobile ecosystem. Our research first highlights five distinct\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTime-travel Testing of Android Apps\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12056&hl=en&sa=X&d=16052199622639594585&ei=cMcwaIOGE_ynieoPhK2buAM&scisig=AAZF9b_rQ0aUIDzZ_5nB_pjqshQV&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "Bringing fuzzing capabilities to the Genode Framework", "first_label": ["Fuzzing"], "second_label": [], "data": "S Meier - 2025\nThe Genode OS framework represents a novel operating system architecture that \nhas been developed to address the challenges posed by complexity. It is an open-\nsource tool kit for building highly secure componentbased operating systems and its \nfunctionality extends across a wide range of devices, from those intended for use in \nembedded systems to those designed for dynamic general-purpose computing. \nDespite Genode's selfcharacterisation as a security-oriented operating system, it is\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCoverage-based greybox fuzzing as markov chain\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://silasmeier.ch/master_thesis/Bringing_Fuzzing_Capabilites_to_the_Genode_Framework.pdf&hl=en&sa=X&d=14511365399994014207&ei=cMcwaIOGE_ynieoPhK2buAM&scisig=AAZF9b9rtZ3uMiuOs-End2tKBmdX&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "CHIMERA: Fuzzing P4 Network Infrastructure for Multi-Plane Bug Detection and Vulnerability Discovery", "first_label": ["Vulnerabilities", "Fuzzing", "Bug"], "second_label": ["Detection"], "data": "J Kim, DJ Tian, BE Ujcich\\xc2\\xa0- 2025 IEEE Symposium on Security and Privacy (SP), 2025\nProgrammable network data planes, such as P4, offer flexibility in defining network \nforwarding behavior. However, such programmability introduces a new attack \nsurface for bugs and security vulnerabilities. Most P4 security research has focused\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://kjw6855.github.io/assets/pdf/sp25_kim_chimera.pdf&hl=en&sa=X&d=6094077905886690143&ei=cMcwaKOOFtHSieoP4tatoQU&scisig=AAZF9b86dvBdClyFEIFpgKdNzAJ4&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Revisiting Defects4J for Fault Localization in Diverse Development Scenarios", "first_label": ["Fault Localization", "Software Defect"], "second_label": ["Localization"], "data": "MN Rafi, AR Chen, THP Chen, S Wang\nDefects4J stands out as a leading benchmark dataset for software testing research, \nproviding a controlled environment to study real bugs from prominent open-source \nsystems. While Defects4J provides a clean and valuable dataset, we aim to explore\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://petertsehsun.github.io/papers/MSR25_Defects4j.pdf&hl=en&sa=X&d=17769356187159404178&ei=cMcwaKOOFtHSieoP4tatoQU&scisig=AAZF9b9Jow3u953pAdt-vrSlDqrb&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Forewarned is Forearmed: A Survey on Large Language Model-based Agents in Autonomous Cyberattacks", "first_label": ["LLM"], "second_label": ["Agent"], "data": "M Xu, J Fan, X Huang, C Zhou, J Kang, D Niyato\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the continuous evolution of Large Language Models (LLMs), LLM-based agents \nhave advanced beyond passive chatbots to become autonomous cyber entities \ncapable of performing complex tasks, including web browsing, malicious code and \ndeceptive content generation, and decision-making. By significantly reducing the \ntime, expertise, and resources, AI-assisted cyberattacks orchestrated by LLM-based \nagents have led to a phenomenon termed Cyber Threat Inflation, characterized by a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection and repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12786&hl=en&sa=X&d=5089822906395003663&ei=cMcwaITUGNyZieoP4ti52Q4&scisig=AAZF9b-0xl4uFh8D1fX1kOA-bKoS&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["3 new citations to articles by Xin ZHOU", "6 new citations to articles by Richard Fang"]}
{"title": "Do Code LLMs Do Static Analysis?", "first_label": ["LLM", "Code", "Static Analysis"], "second_label": [], "data": "CY Su, C McMillan\\xc2\\xa0- arXiv preprint arXiv:2505.12118, 2025\nThis paper investigates code LLMs' capability of static analysis during code \nintelligence tasks such as code summarization and generation. Code LLMs are now \nhousehold names for their abilities to do some programming tasks that have \nheretofore required people. The process that people follow to do programming tasks \nhas long been understood to require static analysis. For example, human \nprogrammers navigate the call graph of large programs to comprehend the different\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaExploring Parameter-Efficient Fine-Tuning Techniques for Code\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12118&hl=en&sa=X&d=1588101499003976139&ei=cMcwaITUGNyZieoP4ti52Q4&scisig=AAZF9b_BbsCh-WUpc8HvOPjR0t-y&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["3 new citations to articles by Xin ZHOU"]}
{"title": "EVA: Red-Teaming GUI Agents via Evolving Indirect Prompt Injection", "first_label": [], "second_label": ["Agent"], "data": "Y Lu, T Ju, M Zhao, X Ma, Y Guo, ZS Zhang\\xc2\\xa0- arXiv preprint arXiv:2505.14289, 2025\nAs multimodal agents are increasingly trained to operate graphical user interfaces \n(GUIs) to complete user tasks, they face a growing threat from indirect prompt \ninjection, attacks in which misleading instructions are embedded into the agent's \nvisual environment, such as popups or chat messages, and misinterpreted as part of \nthe intended task. A typical example is environmental injection, in which GUI \nelements are manipulated to influence agent behavior without directly modifying the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAdaptive attacks break defenses against indirect prompt injection\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14289&hl=en&sa=X&d=16078611100021680803&ei=cMcwaISXDdqX6rQP0Kmy0QM&scisig=AAZF9b_L3wIXA3whGse7NRJcxI6N&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["6 new citations to articles by Richard Fang"]}
{"title": "Safe Delta: Consistently Preserving Safety when Fine-Tuning LLMs on Diverse Datasets", "first_label": ["LLM"], "second_label": [], "data": "N Lu, S Liu, J Wu, W Chen, Z Zhang, YS Ong, Q Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have shown great potential as general-purpose AI \nassistants across various domains. To fully leverage this potential in specific \napplications, many companies provide fine-tuning API services, enabling users to \nupload their own data for LLM customization. However, fine-tuning services \nintroduce a new safety threat: user-uploaded data, whether harmful or benign, can \nbreak the model's alignment, leading to unsafe outputs. Moreover, existing defense\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12038&hl=en&sa=X&d=11004474244674046700&ei=cMcwaISXDdqX6rQP0Kmy0QM&scisig=AAZF9b8rI7QyhYZq2MBRUtZ3eJeU&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=2&folt=cit", "author": ["Richard Fang"], "ref": ["6 new citations to articles by Richard Fang"]}
{"title": "Automated Profile Inference with Language Model Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Y Du, Z Li, B Ding, Y Li, H Xiao, J Zhou, N Li\\xc2\\xa0- arXiv preprint arXiv:2505.12402, 2025\nImpressive progress has been made in automated problem-solving by the \ncollaboration of large language models (LLMs) based agents. However, these \nautomated capabilities also open avenues for malicious applications. In this paper, \nwe study a new threat that LLMs pose to online pseudonymity, called automated \nprofile inference, where an adversary can instruct LLMs to automatically scrape and \nextract sensitive personal attributes from publicly visible user activities on\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12402&hl=en&sa=X&d=3098044590675759444&ei=cMcwaISXDdqX6rQP0Kmy0QM&scisig=AAZF9b_VFVTNesGvipUIGp2Ayfnv&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=3&folt=cit", "author": ["Richard Fang"], "ref": ["6 new citations to articles by Richard Fang"]}
{"title": "MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem", "first_label": ["LLM"], "second_label": ["Agent"], "data": "F Liu, Z Yang, C Liu, T Song, X Gao, H Liu\\xc2\\xa0- arXiv preprint arXiv:2505.14148, 2025\nMathematical modeling is a cornerstone of scientific discovery and engineering \npractice, enabling the translation of real-world problems into formal systems across \ndomains such as physics, biology, and economics. Unlike mathematical reasoning, \nwhich assumes a predefined formulation, modeling requires open-ended problem \nanalysis, abstraction, and principled formalization. While Large Language Models \n(LLMs) have shown strong reasoning capabilities, they fall short in rigorous model\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14148&hl=en&sa=X&d=3052781000511687798&ei=cMcwaISXDdqX6rQP0Kmy0QM&scisig=AAZF9b8jSgczWE3UNkaupWwf4NV0&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=4&folt=cit", "author": ["Richard Fang"], "ref": ["6 new citations to articles by Richard Fang"]}
{"title": "Safety Subspaces are Not Distinct: A Fine-Tuning Case Study", "first_label": [], "second_label": [], "data": "K Ponkshe, S Shah, R Singhal, P Vepakomma\\xc2\\xa0- arXiv preprint arXiv:2505.14185, 2025\nLarge Language Models (LLMs) rely on safety alignment to produce socially \nacceptable responses. This is typically achieved through instruction tuning and \nreinforcement learning from human feedback. However, this alignment is known to \nbe brittle: further fine-tuning, even on benign or lightly contaminated data, can \ndegrade safety and reintroduce harmful behaviors. A growing body of work suggests \nthat alignment may correspond to identifiable geometric directions in weight space\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14185&hl=en&sa=X&d=8896531855132265957&ei=cMcwaISXDdqX6rQP0Kmy0QM&scisig=AAZF9b8zIJ0U5rhDxwMqHE3xvznx&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=5&folt=cit", "author": ["Richard Fang"], "ref": ["6 new citations to articles by Richard Fang"]}
{"title": "Proactive Debugging of Memory Leakage Bugs in Single Page Web Applications", "first_label": ["Bug"], "second_label": [], "data": "A Shahoor, S Abdyldayev, H Hong, J Yi, D Kim\\xc2\\xa0- IEEE Transactions on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeveloping modern web applications often relies on web-based application \nframeworks such as React, Vue. js, and Angular. Although the frameworks accelerate \nthe development of web applications with several useful and predefined\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11006504/&hl=en&sa=X&d=16291541763448082091&ei=XUsvaNbZJ_SM6rQP27_9oAg&scisig=AAZF9b_wP8w2u2xQZYbzpsqmP7bd&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "2 new citations to articles by Abhik Roychoudhury", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "Improving Assembly Code Performance with Large Language Models via Reinforcement Learning", "first_label": ["LLM", "Code"], "second_label": [], "data": "A Wei, T Suresh, H Tan, Y Xu, G Singh, K Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have demonstrated strong performance across a \nwide range of programming tasks, yet their potential for code optimization remains \nunderexplored. This work investigates whether LLMs can optimize the performance\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11480&hl=en&sa=X&d=12653631255298440844&ei=XUsvaNbZJ_SM6rQP27_9oAg&scisig=AAZF9b-UOQsbenDivhIB7ogyV68r&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "David Lo - new related research", "Abhik Roychoudhury - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Think Twice Before You Act: Enhancing Agent Behavioral Safety with Thought Correction", "first_label": [], "second_label": ["Agent"], "data": "C Jiang, X Pan, M Yang\\xc2\\xa0- arXiv preprint arXiv:2505.11063, 2025\nLLM-based autonomous agents possess capabilities such as reasoning, tool \ninvocation, and environment interaction, enabling the execution of complex multi-\nstep tasks. The internal reasoning process, ie, thought, of behavioral trajectory\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11063&hl=en&sa=X&d=18357706901376478503&ei=XUsvaNaEN5e6ieoP887W2QY&scisig=AAZF9b_3JvezeDRhiIseCUpdvIxh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "aiXamine: LLM Safety and Security Simplified", "first_label": ["LLM"], "second_label": [], "data": "F Deniz, D Popovic, Y Boshmaf, E Jeong, M Ahmad\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nEvaluating Large Language Models (LLMs) for safety and security remains a \ncomplex task, often requiring users to navigate a fragmented landscape of ad hoc \nbenchmarks, datasets, metrics, and reporting formats. To address this challenge, we\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.14985&hl=en&sa=X&d=1653724166156179673&ei=XUsvaNaEN5e6ieoP887W2QY&scisig=AAZF9b9vEQF_GlIdZVlXNUHpd5mQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Cracking SQL Barriers: An LLM-based Dialect Transaltion System", "first_label": ["LLM"], "second_label": [], "data": "W Zhou, Y Gao, X Zhou, G Li\\xc2\\xa0- Proc. ACM Manag. Data, 2025\nAuthors' Contact Information: Wei Zhou, Shanghai Jiao Tong University, China, \nweizhoudb@ gmail. com; Yuyang Gao, Tsinghua University, China, 21373016@ \nbuaa. edu. cn; Xuanhe Zhou, Shanghai Jiao Tong University, China, zhouxh@ cs\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dbgroup.cs.tsinghua.edu.cn/ligl/SIGMOD25-CrackSQL.pdf&hl=en&sa=X&d=824223224836212020&ei=XUsvaNaEN5e6ieoP887W2QY&scisig=AAZF9b-rtjCRZ8P3fMzchSuEoMwi&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "HEXGEN-TEXT2SQL: Optimizing LLM Inference Request Scheduling for Agentic Text-to-SQL Workflow", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Y Peng, Y Jiang, C Wang, B Yuan\\xc2\\xa0- arXiv preprint arXiv:2505.05286, 2025\nRecent advances in leveraging the agentic paradigm of large language models \n(LLMs) utilization have significantly enhanced Text-to-SQL capabilities, enabling \nusers without specialized database expertise to query data intuitively. However\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.05286&hl=en&sa=X&d=6377650197552909211&ei=XUsvaNaEN5e6ieoP887W2QY&scisig=AAZF9b9Va6kgrSVNrXeD16t3wPYc&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Hidden Ghost Hand: Unveiling Backdoor Vulnerabilities in MLLM-Powered Mobile GUI Agents", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Agent"], "data": "P Cheng, H Hu, Z Wu, Z Wu, T Ju, Z Zhang, G Liu\nGraphical user interface (GUI) agents powered by multimodal large language \nmodels (MLLMs) have shown greater promise for human-interaction. However, it \nintroduces a crucial yet unexplored security vulnerability: backdoor attacks. In this\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Pengzhou-Cheng/publication/391851149_Hidden_Ghost_Hand_Unveiling_Backdoor_Vulnerabilities_in_MLLM-Powered_Mobile_GUI_Agents/links/682a03d5df0e3f544f552aca/Hidden-Ghost-Hand-Unveiling-Backdoor-Vulnerabilities-in-MLLM-Powered-Mobile-GUI-Agents.pdf&hl=en&sa=X&d=14818498633339702555&ei=XUsvaNaEN5e6ieoP887W2QY&scisig=AAZF9b874adHLUPSvJX_cdb_rpyu&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SQLGenie: A practical LLM based system for reliable and efficient SQL generation", "first_label": ["LLM"], "second_label": ["Generation"], "data": "P Ghosh, A Jain, P Yenigalla - 2025\nAbstract Large Language Models (LLMs) enable natural language to SQL \nconversion, allowing users to query databases without SQL expertise. However, \ngenerating accurate, efficient queries is challenging due to ambiguous intent\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.amazon.science/publications/sqlgenie-a-practical-llm-based-system-for-reliable-and-efficient-sql-generation&hl=en&sa=X&d=3455872540350512164&ei=XUsvaNaEN5e6ieoP887W2QY&scisig=AAZF9b-Git6_1seeZbd43QWZG6Zk&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Measuring the impact of predictive models on the software project: A cost, service time, and risk evaluation of a metric-based defect severity prediction model", "first_label": ["Software Defect"], "second_label": [], "data": "R Sadam\\xc2\\xa0- Automated Software Engineering, 2025\nIn a critical software system, the testers have to spend an enormous amount of time \nand effort maintaining the software due to the continuous occurrence of defects. To \nreduce the time and effort of a tester, prior works in the literature are limited to using \ndocumented defect reports to automatically predict the severity of the defective \nsoftware modules. In contrast, in this work, we propose a metric-based software \ndefect severity prediction (SDSP) model that is built using a decision-tree\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomatic program repair\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00519-3&hl=en&sa=X&d=6645964614234177920&ei=XUsvaJTgL5mD6rQPm8iIuAU&scisig=AAZF9b8lhGrqpVBpHtU1FvsXTL5x&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury", "3 new citations to articles by Bach Le"]}
{"title": "Is Compression Really Linear with Code Intelligence?", "first_label": ["Code"], "second_label": [], "data": "X Luo, S Xuyang, T Cheng, Z Chu, H Li, S Huang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nUnderstanding the relationship between data compression and the capabilities of \nLarge Language Models (LLMs) is crucial, especially in specialized domains like \ncode intelligence. Prior work posited a linear relationship between compression and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11441&hl=en&sa=X&d=2948005725115524385&ei=XUsvaMWnLeqUieoPwK6m6A8&scisig=AAZF9b_9SPr8Gy-RG0EI510WaeIg&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "StRuCom: A Novel Dataset of Structured Code Comments in Russian", "first_label": ["Code"], "second_label": [], "data": "M Dziuba, V Malykh\\xc2\\xa0- arXiv preprint arXiv:2505.11026, 2025\nStructured code comments in docstring format are essential for code comprehension \nand maintenance, but existing machine learning models for their generation perform \npoorly for Russian compared to English. To bridge this gap, we present StRuCom\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11026&hl=en&sa=X&d=17484164301514067363&ei=XUsvaMWnLeqUieoPwK6m6A8&scisig=AAZF9b_tEFsrfYRmhxGTZEx07Jpo&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Understanding and Characterizing Obfuscated Funds Transfers in Ethereum Smart Contracts", "first_label": ["Smart Contracts", "Ethereum"], "second_label": [], "data": "Z Sheng, TK Quang, S Wang, S Duan, K Li, Y Duan\\xc2\\xa0- arXiv preprint arXiv:2505.11320, 2025\nScam contracts on Ethereum have rapidly evolved alongside the rise of DeFi and \nNFT ecosystems, utilizing increasingly complex code obfuscation techniques to \navoid early detection. This paper systematically investigates how obfuscation\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11320&hl=en&sa=X&d=14756795732277610496&ei=XUsvaMWnLeqUieoPwK6m6A8&scisig=AAZF9b9jFsIDq1sf-N8hOCapNzRS&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "It's payback time! Developing a strategy to resolve technical debt", "first_label": [], "second_label": [], "data": "J Ruissalo, T Rinta-Kahila, E Penttinen\\xc2\\xa0- Journal of Information Technology Teaching\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs companies seek to exploit the full potential of various information systems to \nreach their strategic goals, they must balance the system-maintenance obligations \nthat arise through the systems' development and use. As evolution brings new\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://journals.sagepub.com/doi/pdf/10.1177/20438869251338319&hl=en&sa=X&d=9318993517760731053&ei=XUsvaMWnLeqUieoPwK6m6A8&scisig=AAZF9b9xGMCafm3Ih_Yja1rirpbJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Fuzzing Space Communication Protocols", "first_label": ["Fuzzing"], "second_label": [], "data": "S Havermans, L Baumg\\xc3\\xa4rtner, J Roberts, M Wallum\\xe2\\x80\\xa6\nSpace systems are critical assets and protecting them against cyberattacks is a \nparamount challenge that has received limited attention. In particular, it is \nfundamental to secure spacecraft communications by identifying and removing\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://software.imdea.org/~juanca/papers/spacefuzz_spacesec25.pdf&hl=en&sa=X&d=964000194933772866&ei=XUsvaJPYMsmx6rQP-rCh4AE&scisig=AAZF9b9To-YtFkNH0V2NeHA65cZP&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "The Price of AI Assistance: The Undermining Effect of AI-Generated Code on Developers' Procedural Knowledge", "first_label": ["Code"], "second_label": [], "data": "C Diebel, M Goutier, M Adam, A Benlian - 2025\nThe emergence of advanced large language models enables artificial intelligence \n(AI) based agents to assist developers in writing computer code to an unprecedented \nextent. Due to this development, AI-based agents have become integral to \ndevelopers' daily workflows. While ongoing enhancements in the code quality \nprovided by AI-based agents aim to improve developers' productivity, it is far from \nclear how that development affects developers' knowledge of how to write functional\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://aisel.aisnet.org/ecis2025/cog_hbis/cog_hbis/2/&hl=en&sa=X&d=13658656158013585690&ei=XUsvaKbuK-W16rQPsqVy&scisig=AAZF9b-yG1vcm6AphYfza7fcMiW3&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le", "1 new citation to articles by Thanh Le-Cong"]}
{"title": "The Role of ChatGPT in Reducing Storage, Energy, and Scalability Overheads in Blockchain\\xe2\\x80\\x90Based Healthcare Systems", "first_label": ["LLM", "Blockchain"], "second_label": [], "data": "N Almusallam, M Hasnain\\xc2\\xa0- Transactions on Emerging Telecommunications\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nOpen artificial intelligence (AI) applications, including ChatGPT, are gaining \nrecognition across diverse research domains, including healthcare, due to their \neffective handling of inquiries related to AI implementation in healthcare. Despite the \ngrowing use of blockchain technology in healthcare systems, existing research \nstruggles with storage limitations, computational efficiency, and scalability issues. \nTherefore, an optimized approach is required to address these critical challenges\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/ett.70151&hl=en&sa=X&d=9626339749352580268&ei=XUsvaKbuK-W16rQPsqVy&scisig=AAZF9b_FkdisJCQssJWgT7BTt4Fy&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "LLMs unlock new paths to monetizing exploits", "first_label": ["LLM"], "second_label": ["Exploit"], "data": "N Carlini, M Nasr, E Debenedetti, B Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWe argue that Large language models (LLMs) will soon alter the economics of \ncyberattacks. Instead of attacking the most commonly used software and monetizing \nexploits by targeting the lowest common denominator among victims, LLMs enable \nadversaries to launch tailored attacks on a user-by-user basis. On the exploitation \nfront, instead of human attackers manually searching for one difficult-to-identify bug \nin a product with millions of users, LLMs can find thousands of easy-to-identify bugs\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11449&hl=en&sa=X&d=746565809597179017&ei=XUsvaIGCKauM6rQPsd_4QA&scisig=AAZF9b8UnciL5nDD3sESiIwqKbOg&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "A Survey on the Safety and Security Threats of Computer-Using Agents: JARVIS or Ultron?", "first_label": [], "second_label": ["Agent"], "data": "A Chen, Y Wu, J Zhang, S Yang, J Huang, K Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecently, AI-driven interactions with computing devices have advanced from basic \nprototype tools to sophisticated, LLM-based systems that emulate human-like \noperations in graphical user interfaces. We are now witnessing the emergence \nof\\\\emph {Computer-Using Agents}(CUAs), capable of autonomously performing \ntasks such as navigating desktop applications, web pages, and mobile apps. \nHowever, as these agents grow in capability, they also introduce novel safety and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.10924&hl=en&sa=X&d=5877649385047604221&ei=XUsvaIGCKauM6rQPsd_4QA&scisig=AAZF9b9yzUjLMDI8dPdRFYVZIeS7&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Let the Trial Begin: A Mock-Court Approach to Vulnerability Detection using LLM-Based Agents", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Agent"], "data": "R Widyasari, M Weyssow, IC Irsan, HW Ang, F Liauw\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDetecting vulnerabilities in source code remains a critical yet challenging task, \nespecially when benign and vulnerable functions share significant similarities. In this \nwork, we introduce VulTrial, a courtroom-inspired multi-agent framework designed to\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.10961&hl=en&sa=X&d=3932794314184783932&ei=XUsvaIK_KoPFieoPyOahgAU&scisig=AAZF9b-EMspdm-y3IxVqsZ8hpAwp&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "1 new citation to articles by Xin ZHOU", "Hong Jin Kang - new articles", "Quang-Cuong Bui - new related research"]}
{"title": "PRIMG: Efficient LLM-driven Test Generation Using Mutant Prioritization", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "MS Bouafif, M Hamdaqa, E Zulkoski\\xc2\\xa0- arXiv preprint arXiv:2505.05584, 2025\nMutation testing is a widely recognized technique for assessing and enhancing the \neffectiveness of software test suites by introducing deliberate code mutations. \nHowever, its application often results in overly large test suites, as developers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.05584%3F&hl=en&sa=X&d=11403797073407320761&ei=XUsvaNHnOeG86rQP8bDQeA&scisig=AAZF9b_8rRCKKaF4lP39iEYsaKlR&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Towards Test Generation from Task Description for Mobile Testing with Multi-modal Reasoning", "first_label": ["Software Testing"], "second_label": ["Generation", "Reasoning"], "data": "H Huynh, H Phung, H Pham, TN Nguyen, V Nguyen\\xc2\\xa0- arXiv preprint arXiv:2504.15917, 2025\nIn Android GUI testing, generating an action sequence for a task that can be replayed \nas a test script is common. Generating sequences of actions and respective test \nscripts from task goals described in natural language can eliminate the need for\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.15917&hl=en&sa=X&d=9616274488732027894&ei=XUsvaNHnOeG86rQP8bDQeA&scisig=AAZF9b-YoPXsj2SdHvqVcNuNLCSX&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "\" I Would Have Written My Code Differently'': Beginners Struggle to Understand LLM-Generated Code", "first_label": ["LLM", "Code", "Code Change"], "second_label": [], "data": "Y Zi, L Li, A Guha, CJ Anderson, MQ Feldman\\xc2\\xa0- arXiv preprint arXiv:2504.19037, 2025\nLarge language models (LLMs) are being increasingly adopted for programming \nwork. Prior work shows that while LLMs accelerate task completion for professional \nprogrammers, beginning programmers struggle to prompt models effectively\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.19037&hl=en&sa=X&d=14079919503875004701&ei=XUsvaNHnOeG86rQP8bDQeA&scisig=AAZF9b9RnARU6UknVFP-nOgEl0zB&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
