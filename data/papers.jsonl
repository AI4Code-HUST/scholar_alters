{"title": "Enhancing High-Quality Code Generation in Large Language Models with Comparative Prefix-Tuning", "first_label": ["Large Language Models", "Code"], "second_label": ["Generation"], "data": "Y Jiang, Y Zhang, L Lu, C Treude, X Su, S Huang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have been widely adopted in commercial code \ncompletion engines, significantly enhancing coding efficiency and productivity. \nHowever, LLMs may generate code with quality issues that violate coding standards \nand best practices, such as poor code style and maintainability, even when the code \nis functionally correct. This necessitates additional effort from developers to improve \nthe code, potentially negating the efficiency gains provided by LLMs. To address this\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.09020&hl=en&sa=X&d=274986171076802173&ei=dQraZ8-GHKOD6rQPt-Ce6A4&scisig=AFWwaea-q7yfbqCfb2mRj_yZrJ7q&oi=scholaralrt&hist=apJ4fD8AAAAJ:1878193813677419122:AFWwaebnAK6dY8A06r0yyM87AWUg&html=&pos=0&folt=cit", "ref": ["1 new citation to articles by Thanh Le-Cong", "Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi", "3 new citations to articles by Bach Le", "Hong Jin Kang - new related research"]}
{"title": "CASTLE: Benchmarking Dataset for Static Code Analyzers and LLMs towards CWE Detection", "first_label": ["Large Language Models", "Code"], "second_label": ["Detection"], "data": "RA Dubniczky, KZ Horv\\xc3\\xa1t, T Bisztray, MA Ferrag\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIdentifying vulnerabilities in source code is crucial, especially in critical software \ncomponents. Existing methods such as static analysis, dynamic analysis, formal \nverification, and recently Large Language Models are widely used to detect security\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.09433&hl=en&sa=X&d=11258824252715647139&ei=dQraZ5PeI4C96rQP2s_YiAM&scisig=AFWwaeaw-NMlXSIjGeLPHmbzxDl0&oi=scholaralrt&hist=apJ4fD8AAAAJ:6234092987365270793:AFWwaeZHIN6aK_iU38VPuuMoYcVu&html=&pos=0&folt=rel", "ref": ["Michael Fu - new related research", "Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi", "Triet H. M. Le - new related research"]}
{"title": "GPT-Based Automated Induction: Vulnerability Detection in Medical Software", "first_label": ["Vulnerabilities", "Large Language Models"], "second_label": ["Detection"], "data": "L Deng, H Lei, F Khan, G Srivastava, J Chen, M Haque\\xc2\\xa0- IEEE Journal of Biomedical\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIntegrating Natural Language Processing (NLP) with Generative Pre-trained \nTransformer (GPT) models plays a pivotal role in enhancing the accuracy and \nefficiency of healthcare software, which is essential for patient safety and providing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10899829/&hl=en&sa=X&d=4257828238536637457&ei=dQraZ5PeI4C96rQP2s_YiAM&scisig=AFWwaebLUMgz30_kE6q-kcisdZTu&oi=scholaralrt&hist=apJ4fD8AAAAJ:6234092987365270793:AFWwaeZHIN6aK_iU38VPuuMoYcVu&html=&pos=1&folt=rel", "ref": ["Michael Fu - new related research"]}
{"title": "Boosting Code-line-level Defect Prediction with Spectrum Information and Causality Analysis", "first_label": ["Code"], "second_label": [], "data": "S Sun, Y Li, L Chen, Y Zhou, J Zhao\\xc2\\xa0- 2025 IEEE/ACM 47th International Conference\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode-line-level defect prediction (CLDP) is an effective technique to incorporate \ncomprehensive measures for buggy line identification to optimize efforts in Software \nQuality Assurance activities. Most CLDP methods either consider the textual\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a776/251mHGVkul2&hl=en&sa=X&d=4505598638938137522&ei=dQraZ5PeI4C96rQP2s_YiAM&scisig=AFWwaeaqGaPklQzwN1JlkJyBVkEo&oi=scholaralrt&hist=apJ4fD8AAAAJ:6234092987365270793:AFWwaeZHIN6aK_iU38VPuuMoYcVu&html=&pos=2&folt=rel", "ref": ["Michael Fu - new related research"]}
{"title": "Multilabel classification for defect prediction in software engineering", "first_label": [], "second_label": [], "data": "J Pachouly, S Ahirrao, K Kotecha, A Kulkarni\\xe2\\x80\\xa6\\xc2\\xa0- Scientific Reports, 2025\nWith advancements in software development and artificial intelligence, defect \nprediction has gradually become an essential component of the software \ndevelopment lifecycle. Historically, defect prediction has been considered a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.nature.com/articles/s41598-025-93242-8&hl=en&sa=X&d=1640757485281526631&ei=dQraZ5PeI4C96rQP2s_YiAM&scisig=AFWwaeYT-FrQpGzNW-iGrF7LR5bT&oi=scholaralrt&hist=apJ4fD8AAAAJ:6234092987365270793:AFWwaeZHIN6aK_iU38VPuuMoYcVu&html=&pos=3&folt=rel", "ref": ["Michael Fu - new related research"]}
{"title": "ESfix: An Embedded Program Repair Tool for Effective Removal of Concurrency Defects", "first_label": ["Automated Program Repair"], "second_label": ["Repair"], "data": "J Zhao, Y Wu, Y Fu, S Liu\\xc2\\xa0- Entropy, 2025\nEmbedded programs are not only inseparable from our daily lives but are also widely \nused in aerospace, medical devices, and other fields that require very high security \nand stability. The uncertainty and randomness of the large amount of data generated\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/1099-4300/27/3/294&hl=en&sa=X&d=9453366221456951826&ei=dQraZ5PeI4C96rQP2s_YiAM&scisig=AFWwaebvW1SrRy8iWc3ITgSg92Uo&oi=scholaralrt&hist=apJ4fD8AAAAJ:6234092987365270793:AFWwaeZHIN6aK_iU38VPuuMoYcVu&html=&pos=4&folt=rel", "ref": ["Michael Fu - new related research", "Thanh Le-Cong - new related research", "Hakjoo Oh - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi", "3 new citations to articles by Bach Le", "5 new citations to articles by Abhik Roychoudhury"]}
{"title": "Mechanistic Understanding of Language Models in Syntactic Code Completion", "first_label": ["Code"], "second_label": ["Generation"], "data": "S Miller, D Rai, Z Yao\\xc2\\xa0- arXiv preprint arXiv:2502.18499, 2025\nRecently, language models (LMs) have shown impressive proficiency in code \ngeneration tasks, especially when fine-tuned on code-specific datasets, commonly \nknown as Code LMs. However, our understanding of the internal decision-making\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.18499&hl=en&sa=X&d=16766167717063467915&ei=dQraZ5PeI4C96rQP2s_YiAM&scisig=AFWwaeZXFo3QPd08t686n6v36dI4&oi=scholaralrt&hist=apJ4fD8AAAAJ:6234092987365270793:AFWwaeZHIN6aK_iU38VPuuMoYcVu&html=&pos=5&folt=rel", "ref": ["Michael Fu - new related research", "Thanh Le-Cong - new related research", "Richard Fang - new related research", "Bach Le - new related research"]}
{"title": "Bugfix: a standard language, database schema and repository for research on bugs and automatic program repair", "first_label": ["Automated Program Repair", "Bug"], "second_label": ["Repair"], "data": "V Kananchuk, I Mustafin, B Meyer\\xc2\\xa0- arXiv preprint arXiv:2502.15599, 2025\nAutomatic Program Repair (APR) is a brilliant idea: when detecting a bug, also \nprovide suggestions for correcting the program. Progress towards that goal is \nhindered by the absence of a common frame of reference for the multiplicity of APR\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nMichael Fu\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.15599&hl=en&sa=X&d=10642094292575353027&ei=dQraZ5PeI4C96rQP2s_YiAM&scisig=AFWwaebYZkmLIso9Pt-1zoBNSzF7&oi=scholaralrt&hist=apJ4fD8AAAAJ:6234092987365270793:AFWwaeZHIN6aK_iU38VPuuMoYcVu&html=&pos=6&folt=rel", "ref": ["Michael Fu - new related research", "Thanh Le-Cong - new related research", "Bach Le - new related research"]}
{"title": "Transformer-based knowledge distillation for explainable intrusion detection system", "first_label": [], "second_label": ["Detection"], "data": "ALN Nadiah, A Alamri, A Aljuhani, P Kumar\\xc2\\xa0- Computers & Security, 2025\nThe rapid expansion of IoT networks has increased the risk of cyber threats, making \nintrusion detection systems (IDS) critical for maintaining security. However, most of \nthe existing IDS rely on computationally intensive deep learning architectures, \nrendering them unsuitable for IoT environments with limited resources. Additionally, \nexisting IDS approaches, including those using Knowledge Distillation (KD), often fail \nto capture the complex temporal dependencies and contextual relationships inherent\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaVulexplainer: A transformer-based hierarchical distillation for\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825001063&hl=en&sa=X&d=8947319397925336291&ei=dQraZ8uPH5uoieoPksjy2Ag&scisig=AFWwaeZutJ_GNLiq_JGEWLs4VFlg&oi=scholaralrt&hist=apJ4fD8AAAAJ:4465730527138788254:AFWwaebhnVuF-27TSh32-dm_KGTR&html=&pos=0&folt=cit", "ref": ["2 new citations to articles by Michael Fu"]}
{"title": "A Study on Vulnerability Explanation Using Large Language Models", "first_label": ["Vulnerabilities", "Large Language Models"], "second_label": [], "data": "LB Germano, JC Duarte\nIn the quickly advancing field of software development, addressing vulnerabilities \nwith robust security measures is essential. While much research has focused on \nvulnerability detection using Large Language Models (LLMs), limited attention has \nbeen given to generating actionable explanations. This study explores the capability \nof LLMs to explain vulnerabilities in Java code, structuring outputs into four \ndimensions: why the vulnerability exists, its dangers, how it can be exploited, and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaVulRepair: a T5-based automated software vulnerability repair\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nMichael Fu\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.scitepress.org/Papers/2025/133792/133792.pdf&hl=en&sa=X&d=9722690209273363407&ei=dQraZ8uPH5uoieoPksjy2Ag&scisig=AFWwaeb_SAORfoFtHhYW9UO3VhPg&oi=scholaralrt&hist=apJ4fD8AAAAJ:4465730527138788254:AFWwaebhnVuF-27TSh32-dm_KGTR&html=&pos=1&folt=cit", "ref": ["2 new citations to articles by Michael Fu", "Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Large Language Models-Aided Program Debloating", "first_label": ["Large Language Models"], "second_label": [], "data": "B Lin, S Wang, Y Qin, L Chen, X Mao\\xc2\\xa0- arXiv preprint arXiv:2503.08969, 2025\nAs software grows in complexity to accommodate diverse features and platforms, \nsoftware bloating has emerged as a significant challenge, adversely affecting \nperformance and security. However, existing approaches inadequately address the \ndual objectives of debloating: maintaining functionality by preserving essential \nfeatures and enhancing security by reducing security issues. Specifically, current \nsoftware debloating techniques often rely on input-based analysis, using user inputs\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDetecting false alarms from automatic static analysis tools: How far\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.08969&hl=en&sa=X&d=13482712823570075551&ei=dQraZ9buLJyV6rQPpZCUsQI&scisig=AFWwaeYnZnqZ4gdydijvHgZ-_-hx&oi=scholaralrt&hist=apJ4fD8AAAAJ:11486195984023826531:AFWwaebYo-fw1j0PJswL-CdomZqY&html=&pos=0&folt=cit", "ref": ["1 new citation to articles by Hong Jin Kang", "Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi", "Thanh Le-Cong - new related research", "Bach Le - new related research", "Hong Jin Kang - new related research", "5 new citations to articles by Abhik Roychoudhury"]}
{"title": "Iterative Generation of Adversarial Example for Deep Code Models", "first_label": ["Code"], "second_label": ["Generation"], "data": "L Huang, W Sun, M Yan\\xc2\\xa0- 2025 IEEE/ACM 47th International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeep code models are vulnerable to adversarial attacks, making it possible for \nsemantically identical inputs to trigger different responses. Current black-box attack \nmethods typically prioritize the impact of identifiers on the model based on custom\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a623/251mG3BFrPi&hl=vi&sa=X&d=7520291134619695633&ei=dQraZ6KfK4WlieoP3KvqcQ&scisig=AFWwaea13g41tqbDlO07DzoT9B5e&oi=scholaralrt&hist=apJ4fD8AAAAJ:11355862984917483435:AFWwaeZvT_NNWQMu4_zZrEW644gW&html=&pos=1&folt=rel", "ref": ["Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "LLMs Meet Library Evolution: Evaluating Deprecated API Usage in LLM-based Code Completion", "first_label": ["Large Language Models", "Code"], "second_label": ["Generation"], "data": "C Wang, K Huang, J Zhang, Y Feng, L Zhang, Y Liu\\xe2\\x80\\xa6\\xc2\\xa0- 2025 IEEE/ACM 47th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs), pre-trained or fine-tuned on large code corpora, \nhave shown effectiveness in generating code completions. However, in LLM-based \ncode completion, LLMs may struggle to use correct and up-to-date Application\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a781/251mHK5tjdC&hl=vi&sa=X&d=4291983748355056793&ei=dQraZ6KfK4WlieoP3KvqcQ&scisig=AFWwaebbFgNB42GTnyK8DsY5wt9u&oi=scholaralrt&hist=apJ4fD8AAAAJ:11355862984917483435:AFWwaeZvT_NNWQMu4_zZrEW644gW&html=&pos=2&folt=rel", "ref": ["Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "LocAgent: Graph-Guided LLM Agents for Code Localization", "first_label": ["Large Language Models", "Code"], "second_label": ["Agent"], "data": "Z Chen, X Tang, G Deng, F Wu, J Wu, Z Jiang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode localization--identifying precisely where in a codebase changes need to be \nmade--is a fundamental yet challenging task in software maintenance. Existing \napproaches struggle to efficiently navigate complex codebases when identifying\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.09089&hl=vi&sa=X&d=276668227003209980&ei=dQraZ6KfK4WlieoP3KvqcQ&scisig=AFWwaebAyR-svanElQXWQmPvdLUQ&oi=scholaralrt&hist=apJ4fD8AAAAJ:11355862984917483435:AFWwaeZvT_NNWQMu4_zZrEW644gW&html=&pos=5&folt=rel", "ref": ["Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi", "6 new citations to articles by Carlos E. Jimenez"]}
{"title": "LWDIFF: An LLM-Assisted Differential Testing Framework for WebAssembly Runtimes", "first_label": ["Large Language Models"], "second_label": [], "data": "S Zhou, J Wang, H Ye, H Zhou, C Le Goues, X Luo\\xc2\\xa0- 2025 IEEE/ACM 47th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAbstract WebAssembly (Wasm) runtimes execute Wasm programs, a popular low-\nlevel language for efficiently executing high-level languages in browsers, with broad \napplications across diverse domains. The correctness of those runtimes is critical for\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a769/251mHCEMl6U&hl=vi&sa=X&d=6266582449620129308&ei=dQraZ6KfK4WlieoP3KvqcQ&scisig=AFWwaeaMcPDBhbw2sYmWRYl-nU1e&oi=scholaralrt&hist=apJ4fD8AAAAJ:11355862984917483435:AFWwaeZvT_NNWQMu4_zZrEW644gW&html=&pos=6&folt=rel", "ref": ["Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Fixing Large Language Models' Specification Misunderstanding for Better Code Generation", "first_label": ["Large Language Models", "Code"], "second_label": ["Generation"], "data": "Z Tian, J Chen, X Zhang\\xc2\\xa0- 2025 IEEE/ACM 47th International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode generation is to automatically generate source code conforming to a given \nprogramming specification, which has received extensive attention especially with \nthe development of large language models (LLMs). Due to the inherent difficulty of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a645/251mGiigD6g&hl=vi&sa=X&d=6513233471596826292&ei=dQraZ6KfK4WlieoP3KvqcQ&scisig=AFWwaeZmcxfmdYd6h7xTEhek9ReT&oi=scholaralrt&hist=apJ4fD8AAAAJ:11355862984917483435:AFWwaeZvT_NNWQMu4_zZrEW644gW&html=&pos=7&folt=rel", "ref": ["Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "HumanEvo: An Evolution-aware Benchmark for More Realistic Evaluation of Repository-level Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "D Zheng, Y Wang, E Shi, R Zhang, Y Ma, H Zhang\\xe2\\x80\\xa6\\xc2\\xa0- 2025 IEEE/ACM 47th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nTo evaluate the repository-level code generation capabilities of Large Language \nModels (LLMs) in complex real-world software development scenarios, many \nevaluation methods have been developed. These methods typically leverage\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nGoogle Scholar g\\xe1\\xbb\\xadi th\\xc3\\xb4ng b\\xc3\\xa1o n\\xc3\\xa0y cho b\\xe1\\xba\\xa1n v\\xc3\\xac b\\xe1\\xba\\xa1n \\xc4\\x91ang theo d\\xc3\\xb5i nh\\xe1\\xbb\\xafng b\\xc3\\xa0i vi\\xe1\\xba\\xbft m\\xe1\\xbb\\x9bi li\\xc3\\xaan quan \\xc4\\x91\\xe1\\xba\\xbfn nghi\\xc3\\xaan c\\xe1\\xbb\\xa9u c\\xe1\\xbb\\xa7a \nXin ZHOU\n.\nLi\\xe1\\xbb\\x87t k\\xc3\\xaa c\\xe1\\xba\\xa3nh b\\xc3\\xa1o\nH\\xe1\\xbb\\xa7y th\\xc3\\xb4ng b\\xc3\\xa1o\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a764/251mHzzKizu&hl=vi&sa=X&d=934346741216220072&ei=dQraZ6KfK4WlieoP3KvqcQ&scisig=AFWwaeZ5ZCNBU_T4R6gc8YxvLX3n&oi=scholaralrt&hist=apJ4fD8AAAAJ:11355862984917483435:AFWwaeZvT_NNWQMu4_zZrEW644gW&html=&pos=9&folt=rel", "ref": ["Xin ZHOU - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Pragmatic Reasoning improves LLM Code Generation", "first_label": ["Large Language Models", "Code"], "second_label": ["Generation"], "data": "Z Cao, S Apel, A Singla, V Demberg\\xc2\\xa0- arXiv preprint arXiv:2502.15835, 2025\nLarge Language Models (LLMs) have demonstrated impressive potential in \ntranslating natural language (NL) instructions into program code. However, user \ninstructions often contain inherent ambiguities, making it challenging for LLMs to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.15835&hl=en&sa=X&d=6927995321596801340&ei=dQraZ_GXLsCSieoPoa_pwQc&scisig=AFWwaebpCZ-l4eJjTQ3XaxQi2c08&oi=scholaralrt&hist=apJ4fD8AAAAJ:11631047573362457156:AFWwaeYhbBKL65h4pzyKCNru3s-R&html=&pos=4&folt=rel", "ref": ["Thanh Le-Cong - new related research"]}
{"title": "CodeSwift: Accelerating LLM Inference for Efficient Code Generation", "first_label": ["Large Language Models", "Code"], "second_label": ["Generation"], "data": "Q Zhao, L Zhang, F Liu, X Lian, Q Meng, Z Jiao, Z Zhou\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode generation is a latency-sensitive task that demands high timeliness, but the \nautoregressive decoding mechanism of Large Language Models (LLMs) leads to \npoor inference efficiency. Existing LLM inference acceleration methods mainly focus\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.17139&hl=en&sa=X&d=12309021167084800557&ei=dQraZ_GXLsCSieoPoa_pwQc&scisig=AFWwaebM1YnN4NurSD2BsoIiHS26&oi=scholaralrt&hist=apJ4fD8AAAAJ:11631047573362457156:AFWwaeYhbBKL65h4pzyKCNru3s-R&html=&pos=5&folt=rel", "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Improving Graph Learning-Based Fault Localization with Tailored Semi-supervised Learning", "first_label": ["Fault Localization"], "second_label": [], "data": "C LI, HUI LI, Z LI, M PAN, X LI - 2025\nAuthors' Contact Information: Chun Li, Nanjing University, State Key Laboratory for \nNovel Software Technology, Nanjing, China, chunli@ smail. nju. edu. cn; Hui Li, \nSamsung Electronics (China) R&D Centre, Nanjing, China, hui. li@ samsung. com;\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://pppppkun.github.io/files/fse25.pdf&hl=en&sa=X&d=3684507761350432065&ei=dQraZ_GXLsCSieoPoa_pwQc&scisig=AFWwaeaCU1iGZOL3wdyrA6_vPx0l&oi=scholaralrt&hist=apJ4fD8AAAAJ:11631047573362457156:AFWwaeYhbBKL65h4pzyKCNru3s-R&html=&pos=6&folt=rel", "ref": ["Thanh Le-Cong - new related research", "Hakjoo Oh - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Unveiling Privacy Risks in LLM Agent Memory", "first_label": ["Large Language Models"], "second_label": ["Agent"], "data": "B Wang, W He, P He, S Zeng, Z Xiang, Y Xing, J Tang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Model (LLM) agents have become increasingly prevalent across \nvarious real-world applications. They enhance decision-making by storing private \nuser-agent interactions in the memory module for demonstrations, introducing new\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.13172&hl=en&sa=X&d=1205784360742732283&ei=dQraZ628IPCj6rQPm8WmmQg&scisig=AFWwaebxlZzBMwyVDWpxNWr57ygF&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=0&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "ELBA-Bench: An Efficient Learning Backdoor Attacks Benchmark for Large Language Models", "first_label": ["Large Language Models"], "second_label": [], "data": "X Liu, S Liang, M Han, Y Luo, A Liu, X Cai, Z He, D Tao\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGenerative large language models are crucial in natural language processing, but \nthey are vulnerable to backdoor attacks, where subtle triggers compromise their \nbehavior. Although backdoor attacks against LLMs are constantly emerging, existing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.18511&hl=en&sa=X&d=2326898847250844616&ei=dQraZ628IPCj6rQPm8WmmQg&scisig=AFWwaeYsxLaPZ35g7ZwCcXLowDSz&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=1&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Geneshift: Impact of different scenario shift on Jailbreaking LLM", "first_label": ["Large Language Models"], "second_label": [], "data": "T Wu, Z Xue, Y Liu, J Zhang, B Hooi, SK Ng\\xc2\\xa0- ICLR 2025 Workshop on Foundation Models in\\xc2\\xa0\\xe2\\x80\\xa6\nJailbreak attacks, which aim to cause LLMs to perform unrestricted behaviors, have \nbecome a critical and challenging direction in AI safety. Despite achieving the \npromising attack success rate using dictionary-based evaluation, existing jailbreak\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DyQ4gkBJcGm&hl=en&sa=X&d=14386066076658480190&ei=dQraZ628IPCj6rQPm8WmmQg&scisig=AFWwaea9y_szA1KiiVRfPOcYQZKy&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=2&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Language Models Can See Better: Visual Contrastive Decoding For LLM Multimodal Reasoning", "first_label": ["Large Language Models"], "second_label": [], "data": "Y Pang, B Yang, H Tu, Y Cao, Z Zhang\\xc2\\xa0- \\xe2\\x80\\xa6\\xc2\\xa02025-2025 IEEE International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAlthough Large Language Models (LLMs) excel in reasoning and generation for \nlanguage tasks, they are not specifically designed for multimodal challenges. \nTraining Multimodal Large Language Models (MLLMs), however, is resource\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.11751&hl=en&sa=X&d=11065919914523651369&ei=dQraZ628IPCj6rQPm8WmmQg&scisig=AFWwaeafJ9hHibn9FVw6fdjz4t5T&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=3&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "LLM Compiler: Foundation Language Models for Compiler Optimization", "first_label": ["Large Language Models"], "second_label": [], "data": "C Cummins, V Seeker, D Grubisic, B Roziere\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 34th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable capabilities across \na variety of software engineering and coding tasks. However, their application in the \ndomain of code and compiler optimization remains underexplored. Training LLMs is\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3708493.3712691&hl=en&sa=X&d=15248179687375146706&ei=dQraZ628IPCj6rQPm8WmmQg&scisig=AFWwaeaQLmVGmhuYPirTSRdIm2C5&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=4&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "EAGER-LLM: Enhancing Large Language Models as Recommenders through Exogenous Behavior-Semantic Integration", "first_label": ["Large Language Models"], "second_label": [], "data": "M Hong, Y Xia, Z Wang, J Zhu, Y Wang, S Cai, X Yang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are increasingly leveraged as foundational \nbackbones in the development of advanced recommender systems, offering \nenhanced capabilities through their extensive knowledge and reasoning. Existing llm\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.14735&hl=en&sa=X&d=426769658566315280&ei=dQraZ628IPCj6rQPm8WmmQg&scisig=AFWwaeYh4wl6YqJyh-StysItru7m&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=5&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "PersGuard: Preventing Malicious Personalization via Backdoor Attacks on Pre-trained Text-to-Image Diffusion Models", "first_label": [], "second_label": [], "data": "X Liu, X Jia, Y Xun, H Zhang, X Cao\\xc2\\xa0- arXiv preprint arXiv:2502.16167, 2025\nDiffusion models (DMs) have revolutionized data generation, particularly in text-to-\nimage (T2I) synthesis. However, the widespread use of personalized generative \nmodels raises significant concerns regarding privacy violations and copyright\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/abs/2502.16167&hl=en&sa=X&d=4329161943110226749&ei=dQraZ628IPCj6rQPm8WmmQg&scisig=AFWwaeafrJsvZfvDQ-TQGz6g7XVq&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=6&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "Class-Conditional Neural Polarizer: A Lightweight and Effective Backdoor Defense by Purifying Poisoned Features", "first_label": [], "second_label": [], "data": "M Zhu, S Wei, H Zha, B Wu\\xc2\\xa0- arXiv preprint arXiv:2502.18520, 2025\nRecent studies have highlighted the vulnerability of deep neural networks to \nbackdoor attacks, where models are manipulated to rely on embedded triggers \nwithin poisoned samples, despite the presence of both benign and trigger\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.18520&hl=en&sa=X&d=6105536655339044814&ei=dQraZ628IPCj6rQPm8WmmQg&scisig=AFWwaeYurmmbkgOuiDkmd6ofPMWA&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=8&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "C^ 2 ATTACK: Towards Representation Backdoor on CLIP via Concept Confusion", "first_label": [], "second_label": [], "data": "L Hu, J Liao, W Lyu, S Fu, T Huang, S Yang, G Hu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBackdoor attacks pose a significant threat to deep learning models, enabling \nadversaries to embed hidden triggers that manipulate the behavior of the model \nduring inference. Traditional backdoor attacks typically rely on inserting explicit\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.09095&hl=en&sa=X&d=13446138486998005752&ei=dQraZ628IPCj6rQPm8WmmQg&scisig=AFWwaeamdX8DB8jytHU_2yJfgBZs&oi=scholaralrt&hist=apJ4fD8AAAAJ:4513401344136555010:AFWwaea8pA4W9ESmXpw9yvMxc7-7&html=&pos=9&folt=rel", "ref": ["Richard Fang - new related research"]}
{"title": "TIVER: Identifying Adaptive Versions of C/C++ Third-Party Open-Source Components Using a Code Clustering Technique", "first_label": ["Code"], "second_label": ["Detection"], "data": "Y Choi, S Woo\\xc2\\xa0- 2025 IEEE/ACM 47th International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nReusing third-party open-source software (OSS) provides many benefits but can \nexpose the entire system to risks owing to propagated vulnerabilities. While tracking \nthe versions of OSS components can help prevent threats, existing approaches \ntypically map a single version to a reused OSS codebase. This coarse-grained \nmethod fails to address multiple versions of code that coexist within the codebase, \nresulting in ineffective OSS management. Additionally, effectively identifying\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nTr\\xc3\\xadch d\\xe1\\xba\\xabn: \\xe2\\x80\\xaaCENTRIS: A precise and scalable approach for identifying\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nGoogle Scholar g\\xe1\\xbb\\xadi th\\xc3\\xb4ng b\\xc3\\xa1o n\\xc3\\xa0y cho b\\xe1\\xba\\xa1n v\\xc3\\xac b\\xe1\\xba\\xa1n \\xc4\\x91ang theo d\\xc3\\xb5i nh\\xe1\\xbb\\xafng l\\xe1\\xbb\\x9di tr\\xc3\\xadch d\\xe1\\xba\\xabn m\\xe1\\xbb\\x9bi trong c\\xc3\\xa1c b\\xc3\\xa0i vi\\xe1\\xba\\xbft c\\xe1\\xbb\\xa7a \nHakjoo Oh\n.\nLi\\xe1\\xbb\\x87t k\\xc3\\xaa c\\xe1\\xba\\xa3nh b\\xc3\\xa1o\nH\\xe1\\xbb\\xa7y th\\xc3\\xb4ng b\\xc3\\xa1o\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a725/251mHaekWuk&hl=vi&sa=X&d=15669055506051126098&ei=dQraZ7XPMdSyieoPy4i_oQo&scisig=AFWwaeaah1VsiYSCriwpXTgKOvzk&oi=scholaralrt&hist=apJ4fD8AAAAJ:13534924455939102554:AFWwaeZN-y-gtbFtywJ0Xio3nYxl&html=&pos=0&folt=cit", "ref": ["1 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Hakjoo Oh"]}
{"title": "NumScout: Unveiling Numerical Defects in Smart Contracts using LLM-Pruning Symbolic Execution", "first_label": ["Smart Contracts", "Large Language Models"], "second_label": [], "data": "J Chen, Z Shao, S Yang, Y Shen, Y Wang, T Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, the Ethereum platform has witnessed a proliferation of smart \ncontracts, accompanied by exponential growth in total value locked (TVL). High-TVL \nsmart contracts often require complex numerical computations, particularly in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.10041&hl=vi&sa=X&d=6960500453180123266&ei=dQraZ_T1NKOD6rQPt-Ce6A4&scisig=AFWwaeYP5hfmn9pjGBEQ7VGMFyRA&oi=scholaralrt&hist=apJ4fD8AAAAJ:16065687014273664109:AFWwaeYpvD7V4gPm0ywHhNT6YvSk&html=&pos=1&folt=rel", "ref": ["Hakjoo Oh - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "PacDroid: A Pointer-Analysis-Centric Framework for Security Vulnerabilities in Android Apps", "first_label": ["Vulnerabilities"], "second_label": [], "data": "M Chen, T Tan, M Pan, Y Li\\xc2\\xa0- 2025 IEEE/ACM 47th International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGeneral frameworks such as FlowDroid, IccTA, P/Taint, Amandroid, and DroidSafe \nhave significantly advanced the development of static analysis tools for Android \nsecurity by providing fundamental facilities for them. However, while these\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a744/251mHmpnWtW&hl=vi&sa=X&d=17163892210997669487&ei=dQraZ_T1NKOD6rQPt-Ce6A4&scisig=AFWwaebd1Izw3RG_Em5DraTgn4Gk&oi=scholaralrt&hist=apJ4fD8AAAAJ:16065687014273664109:AFWwaeYpvD7V4gPm0ywHhNT6YvSk&html=&pos=2&folt=rel", "ref": ["Hakjoo Oh - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi", "Hong Jin Kang - new related research"]}
{"title": "Automated Test Generation For Smart Contracts via On-Chain Test Case Augmentation and Migration", "first_label": ["Smart Contracts"], "second_label": ["Generation"], "data": "J Zhang, J Chen, J Grundy, J Gao, Y Wang, T Chen\\xe2\\x80\\xa6\\xc2\\xa0- 2025 IEEE/ACM 47th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nPre-deployment testing has become essential to ensure the functional correctness of \nsmart contracts. However, since smart contracts are stateful programs integrating \nmany different functionalities, manually writing test cases to cover all potential\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a633/251mGaCfjY4&hl=vi&sa=X&d=9107351715224870129&ei=dQraZ_T1NKOD6rQPt-Ce6A4&scisig=AFWwaeZOuSM97UsUuINbE5jMD_PG&oi=scholaralrt&hist=apJ4fD8AAAAJ:16065687014273664109:AFWwaeYpvD7V4gPm0ywHhNT6YvSk&html=&pos=3&folt=rel", "ref": ["Hakjoo Oh - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "TopSeed: Learning Seed Selection Strategies for Symbolic Execution from Scratch", "first_label": [], "second_label": [], "data": "J Lee, S Cha\\xc2\\xa0- 2025 IEEE/ACM 47th International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWe present TopSeed, a new approach that automatically selects optimal seeds to \nenhance symbolic execution. Recently, the performance of symbolic execution has \nsignificantly improved through various state-of-the-art techniques, including search\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a632/251mG9WwhQA&hl=vi&sa=X&d=4367630789830598339&ei=dQraZ_T1NKOD6rQPt-Ce6A4&scisig=AFWwaeaTxlj-dDdn7-AWJv77Ovhw&oi=scholaralrt&hist=apJ4fD8AAAAJ:16065687014273664109:AFWwaeYpvD7V4gPm0ywHhNT6YvSk&html=&pos=4&folt=rel", "ref": ["Hakjoo Oh - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "No Harness, No Problem: Oracle-guided Harnessing for Auto-generating C API Fuzzing Harnesses", "first_label": ["Fuzzing"], "second_label": [], "data": "G Sherman, S Nagy\\xc2\\xa0- 2025 IEEE/ACM 47th International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLibrary APIs are used by virtually every modern application and system, making them \namong today's most security-critical software. In recent years, library bug-finding \nefforts have overwhelmingly adopted the powerful testing strategy of coverage\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a775/251mHGjRraw&hl=vi&sa=X&d=14099560217111377398&ei=dQraZ_T1NKOD6rQPt-Ce6A4&scisig=AFWwaea2-KF729Z4_Pfnqd_I-2C7&oi=scholaralrt&hist=apJ4fD8AAAAJ:16065687014273664109:AFWwaeYpvD7V4gPm0ywHhNT6YvSk&html=&pos=5&folt=rel", "ref": ["Hakjoo Oh - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi", "Abhik Roychoudhury - new related research"]}
{"title": "A System-Level Testing Framework for Automated Assessment of Programming Assignments Allowing Students Object-Oriented Design Freedom", "first_label": [], "second_label": [], "data": "V Terragni, N Giacaman\nAutomated assessment of programming assignments is essential in software \nengineering education, especially for large classes where manual grading is \nimpractical. While static analysis can evaluate code style and syntax correctness, it\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://valerio-terragni.github.io/assets/pdf/terragni-icstEdu-2025.pdf&hl=vi&sa=X&d=9843236759681985112&ei=dQraZ_T1NKOD6rQPt-Ce6A4&scisig=AFWwaeYlmIot4fQq-Bgna_aXNgpq&oi=scholaralrt&hist=apJ4fD8AAAAJ:16065687014273664109:AFWwaeYpvD7V4gPm0ywHhNT6YvSk&html=&pos=7&folt=rel", "ref": ["Hakjoo Oh - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "Lightweight Concolic Testing via Path-Condition Synthesis for Deep Learning Libraries", "first_label": [], "second_label": [], "data": "S Kim, Y Kim, D Park, Y Jeon, J Yi, M Kim\\xc2\\xa0- 2025 IEEE/ACM 47th International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMany techniques have been recently developed for testing deep learning (DL) \nlibraries. Although these techniques have effectively improved API and code \ncoverage and detected unknown bugs, they rely on blackbox fuzzing for input\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.jooyongyi.com/papers/ICSE25.pdf&hl=vi&sa=X&d=10264194252454271239&ei=dQraZ_T1NKOD6rQPt-Ce6A4&scisig=AFWwaeY1z_V3GkFVvQ4yKrS6-u2H&oi=scholaralrt&hist=apJ4fD8AAAAJ:16065687014273664109:AFWwaeYpvD7V4gPm0ywHhNT6YvSk&html=&pos=8&folt=rel", "ref": ["Hakjoo Oh - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi", "Hong Jin Kang - new related research"]}
{"title": "Detecting Reentrancy Vulnerabilities for Solidity Smart Contracts with Contract Standards-Based Rules", "first_label": ["Vulnerabilities", "Smart Contracts"], "second_label": ["Detection"], "data": "J Cai, J Chen, T Zhang, X Luo, X Sun, B Li\\xc2\\xa0- IEEE Transactions on Information\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe reentrancy vulnerability is one of the most notorious vulnerabilities of smart \ncontracts. It enables attackers to hijack the control flow of a smart contract by invoking \na function as the entry point and then re-invoking a function as the reentry point\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nGoogle Scholar g\\xe1\\xbb\\xadi th\\xc3\\xb4ng b\\xc3\\xa1o n\\xc3\\xa0y cho b\\xe1\\xba\\xa1n v\\xc3\\xac b\\xe1\\xba\\xa1n \\xc4\\x91ang theo d\\xc3\\xb5i nh\\xe1\\xbb\\xafng b\\xc3\\xa0i vi\\xe1\\xba\\xbft m\\xe1\\xbb\\x9bi li\\xc3\\xaan quan \\xc4\\x91\\xe1\\xba\\xbfn nghi\\xc3\\xaan c\\xe1\\xbb\\xa9u c\\xe1\\xbb\\xa7a \nHakjoo Oh\n.\nLi\\xe1\\xbb\\x87t k\\xc3\\xaa c\\xe1\\xba\\xa3nh b\\xc3\\xa1o\nH\\xe1\\xbb\\xa7y th\\xc3\\xb4ng b\\xc3\\xa1o\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10926491/&hl=vi&sa=X&d=14342854464858374059&ei=dQraZ_T1NKOD6rQPt-Ce6A4&scisig=AFWwaeYCbOhhoFL6t_fljne4UToU&oi=scholaralrt&hist=apJ4fD8AAAAJ:16065687014273664109:AFWwaeYpvD7V4gPm0ywHhNT6YvSk&html=&pos=9&folt=rel", "ref": ["Hakjoo Oh - nghi\u00ean c\u1ee9u li\u00ean quan m\u1edbi"]}
{"title": "How Do Multimodal Large Language Models Handle Complex Multimodal Reasoning? Placing Them in An Extensible Escape Game", "first_label": ["Large Language Models"], "second_label": [], "data": "Z Wang, Y Dong, F Luo, M Ruan, Z Cheng, C Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancing of Multimodal Large Language Models (MLLMs) has spurred \ninterest in complex multimodal reasoning tasks in the real-world and virtual \nenvironment, which require coordinating multiple abilities, including visual \nperception, visual reasoning, spatial awareness, and target deduction. However, \nexisting evaluations primarily assess the final task completion, often degrading \nassessments to isolated abilities such as visual grounding and visual question\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSwe-agent: Agent-computer interfaces enable automated software\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.10042&hl=en&sa=X&d=12439053581098274854&ei=dQraZ-_NNpuw6rQP27yHsAU&scisig=AFWwaeb_NBWnQ-riONpWIPmTQg5y&oi=scholaralrt&hist=apJ4fD8AAAAJ:16237994392044955269:AFWwaebaLgrVcMkfKx1Gjt1mqPQn&html=&pos=0&folt=cit", "ref": ["6 new citations to articles by Carlos E. Jimenez"]}
{"title": "DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation", "first_label": ["Large Language Models", "Code"], "second_label": ["Generation"], "data": "W Hu, J Duan, C Wei, L Zhang, Y Zhang, K Xu\\xc2\\xa0- arXiv preprint arXiv:2503.10452, 2025\nThe rapid advancement of large language models (LLMs) has significantly improved \ntheir performance in code generation tasks. However, existing code benchmarks \nremain static, consisting of fixed datasets with predefined problems. This makes them \nvulnerable to memorization during training, where LLMs recall specific test cases \ninstead of generalizing to new problems, leading to data contamination and \nunreliable evaluation results. To address these issues, we introduce DynaCode, a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSwe-bench: Can language models resolve real-world github issues?\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.10452&hl=en&sa=X&d=18434869581405978931&ei=dQraZ-_NNpuw6rQP27yHsAU&scisig=AFWwaebhO12LDpcDZViapqHz_1ND&oi=scholaralrt&hist=apJ4fD8AAAAJ:16237994392044955269:AFWwaebaLgrVcMkfKx1Gjt1mqPQn&html=&pos=2&folt=cit", "ref": ["6 new citations to articles by Carlos E. Jimenez"]}
{"title": "Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning Large Language Models", "first_label": ["Large Language Models"], "second_label": [], "data": "Q Chen, L Qin, J Liu, D Peng, J Guan, P Wang, M Hu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent advancements in reasoning with large language models (RLLMs), such as \nOpenAI-O1 and DeepSeek-R1, have demonstrated their impressive capabilities in \ncomplex domains like mathematics and coding. A central factor in their success lies \nin the application of long chain-of-thought (Long CoT) characteristics, which enhance \nreasoning abilities and enable the solution of intricate problems. However, despite \nthese developments, a comprehensive survey on Long CoT is still lacking, limiting\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSwe-bench: Can language models resolve real-world github issues?\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.09567&hl=en&sa=X&d=12289179072091147983&ei=dQraZ-_NNpuw6rQP27yHsAU&scisig=AFWwaeYQ1AKbt9oF4BFdkU_z-tqe&oi=scholaralrt&hist=apJ4fD8AAAAJ:16237994392044955269:AFWwaebaLgrVcMkfKx1Gjt1mqPQn&html=&pos=3&folt=cit", "ref": ["6 new citations to articles by Carlos E. Jimenez"]}
{"title": "Compute Optimal Scaling of Skills: Knowledge vs Reasoning", "first_label": [], "second_label": [], "data": "N Roberts, N Chatterji, S Narang, M Lewis, D Hupkes\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nScaling laws are a critical component of the LLM development pipeline, most \nfamously as a way to forecast training decisions such as' compute-optimally'trading-\noff parameter count and dataset size, alongside a more recent growing list of other \ncrucial decisions. In this work, we ask whether compute-optimal scaling behaviour \ncan be skill-dependent. In particular, we examine knowledge and reasoning-based \nskills such as knowledge-based QA and code generation, and we answer this\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSwe-bench: Can language models resolve real-world github issues?\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.10061&hl=en&sa=X&d=11932281003332524670&ei=dQraZ-_NNpuw6rQP27yHsAU&scisig=AFWwaebFs4rdQL8V4sVDD2UBRmui&oi=scholaralrt&hist=apJ4fD8AAAAJ:16237994392044955269:AFWwaebaLgrVcMkfKx1Gjt1mqPQn&html=&pos=4&folt=cit", "ref": ["6 new citations to articles by Carlos E. Jimenez"]}
{"title": "Factorio Learning Environment", "first_label": [], "second_label": [], "data": "J Hopkins, M Bakler, A Khan\\xc2\\xa0- arXiv preprint arXiv:2503.09617, 2025\nLarge Language Models (LLMs) are rapidly saturating existing benchmarks, \nnecessitating new open-ended evaluations. We introduce the Factorio Learning \nEnvironment (FLE), based on the game of Factorio, that tests agents in long-term \nplanning, program synthesis, and resource optimization. FLE provides exponentially \nscaling challenges--from basic automation to complex factories processing millions \nof resource units per second. We provide two settings:(1) lab-play consisting of eight\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSwe-bench: Can language models resolve real-world github issues?\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nCarlos E. Jimenez\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.09617&hl=en&sa=X&d=11011603862727183121&ei=dQraZ-_NNpuw6rQP27yHsAU&scisig=AFWwaebYF3SRGtOqTnnYTgGwQBIu&oi=scholaralrt&hist=apJ4fD8AAAAJ:16237994392044955269:AFWwaebaLgrVcMkfKx1Gjt1mqPQn&html=&pos=5&folt=cit", "ref": ["6 new citations to articles by Carlos E. Jimenez"]}
{"title": "Efficient Federated Fine-Tuning of Large Language Models with Layer Dropout", "first_label": ["Large Language Models"], "second_label": [], "data": "S Wang, J Liu, H Xu, J Yan, X Gao\\xc2\\xa0- arXiv preprint arXiv:2503.10217, 2025\nFine-tuning plays a crucial role in enabling pre-trained LLMs to evolve from general \nlanguage comprehension to task-specific expertise. To preserve user data privacy, \nfederated fine-tuning is often employed and has emerged as the de facto paradigm. \nHowever, federated fine-tuning is prohibitively inefficient due to the tension between \nLLM complexity and the resource constraint of end devices, incurring unaffordable \nfine-tuning overhead. Existing literature primarily utilizes parameter-efficient fine\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaWhen Fine-Tuning LLMs Meets Data Privacy: An Empirical Study\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.10217&hl=en&sa=X&d=11075601728272533371&ei=dQraZ7qiKJ-_6rQPzI2_uQ0&scisig=AFWwaeanQrbKQejvX5kogEEytecQ&oi=scholaralrt&hist=apJ4fD8AAAAJ:10695555881282652625:AFWwaeakbu5Ta3HmdjfVean1AXL4&html=&pos=0&folt=cit", "ref": ["3 new citations to articles by Bach Le"]}
{"title": "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs", "first_label": [], "second_label": [], "data": "A Abouelenin, A Ashfaq, A Atkinson, H Awadalla\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWe introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable language \nand multimodal models. Phi-4-Mini is a 3.8-billion-parameter language model \ntrained on high-quality web and synthetic data, significantly outperforming recent\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.01743%3F&hl=en&sa=X&d=1080021729655208449&ei=dQraZ-TBHZuw6rQP27yHsAU&scisig=AFWwaeZMnVxRBi2ctuK9FSJVQwyR&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=0&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "Reinforced Diffuser for Red Teaming Large Vision-Language Models", "first_label": [], "second_label": [], "data": "R Wang, X Zheng, X Wang, C Wang, X Ma\\xc2\\xa0- arXiv preprint arXiv:2503.06223, 2025\nThe rapid advancement of large Vision-Language Models (VLMs) has raised \nsignificant safety concerns, particularly regarding their vulnerability to jailbreak \nattacks. While existing research primarily focuses on VLMs' susceptibility to harmful\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.06223&hl=en&sa=X&d=10511149449596864280&ei=dQraZ-TBHZuw6rQP27yHsAU&scisig=AFWwaeYy58SFxfq_z39Cm9leB-EZ&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=1&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "Capturing Nuanced Preferences: Preference-Aligned Distillation for Small Language Models", "first_label": [], "second_label": [], "data": "Y Gu, J Li, S Huang, X Zou, Z Li, X Hu\\xc2\\xa0- arXiv preprint arXiv:2502.14272, 2025\nAligning small language models (SLMs) with human values typically involves \ndistilling preference knowledge from large language models (LLMs). However, \nexisting distillation methods model preference knowledge in teacher LLMs by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.14272&hl=en&sa=X&d=3283888565285721117&ei=dQraZ-TBHZuw6rQP27yHsAU&scisig=AFWwaeacCk5hYRYI-fAwtLN-1pFN&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=2&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "Safechain: Safety of language models with long chain-of-thought reasoning capabilities", "first_label": [], "second_label": [], "data": "F Jiang, Z Xu, Y Li, L Niu, Z Xiang, B Li, BY Lin\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nEmerging large reasoning models (LRMs), such as DeepSeek-R1 models, leverage \nlong chain-of-thought (CoT) reasoning to generate structured intermediate steps, \nenhancing their reasoning capabilities. However, long CoT does not inherently\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.12025%3F&hl=en&sa=X&d=11794055058332912936&ei=dQraZ-TBHZuw6rQP27yHsAU&scisig=AFWwaeZIkep8RWr0oJ-gto7S9nZK&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=3&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "Adversary-Aware DPO: Enhancing Safety Alignment in Vision Language Models via Adversarial Training", "first_label": [], "second_label": [], "data": "F Weng, J Lou, J Feng, M Huang, W Wang\\xc2\\xa0- arXiv preprint arXiv:2502.11455, 2025\nSafety alignment is critical in pre-training large language models (LLMs) to generate \nresponses aligned with human values and refuse harmful queries. Unlike LLM, the \ncurrent safety alignment of VLMs is often achieved with post-hoc safety fine-tuning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.11455&hl=en&sa=X&d=14199852315052579694&ei=dQraZ-TBHZuw6rQP27yHsAU&scisig=AFWwaeaQdgo38ob0HLeDPQrlflMZ&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=4&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "Following the Autoregressive Nature of LLM Embeddings via Compression and Alignment", "first_label": ["Large Language Models"], "second_label": [], "data": "J Deng, Z Jiang, L Pang, L Chen, K Xu, Z Wei, H Shen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nA new trend uses LLMs as dense text encoders via contrastive learning. However, \nsince LLM embeddings predict the probability distribution of the next token, they are \ninherently generative and distributive, conflicting with contrastive learning, which\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.11401&hl=en&sa=X&d=5106071575990121675&ei=dQraZ-TBHZuw6rQP27yHsAU&scisig=AFWwaeZbBDaqVX9ZcIUYqZxcu6rk&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=5&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "ALinFiK: Learning to Approximate Linearized Future Influence Kernel for Scalable Third-Parity LLM Data Valuation", "first_label": ["Large Language Models"], "second_label": [], "data": "Y Pan, H Lin, Y Ran, J Chen, X Yu, W Zhao, D Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) heavily rely on high-quality training data, making \ndata valuation crucial for optimizing model performance, especially when working \nwithin a limited budget. In this work, we aim to offer a third-party data valuation\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.01052&hl=en&sa=X&d=6331837210289932637&ei=dQraZ-TBHZuw6rQP27yHsAU&scisig=AFWwaea2pohDgJbloKIzQaluufUF&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=6&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "ChatReID: Open-ended Interactive Person Retrieval via Hierarchical Progressive Tuning for Vision Language Models", "first_label": [], "second_label": [], "data": "K Niu, H Yu, M Zhao, T Fu, S Yi, W Lu, B Li, X Qian\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nPerson re-identification (Re-ID) is a critical task in human-centric intelligent systems, \nenabling consistent identification of individuals across different camera views using \nmulti-modal query information. Recent studies have successfully integrated LVLMs\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.19958&hl=en&sa=X&d=10791693987736030937&ei=dQraZ-TBHZuw6rQP27yHsAU&scisig=AFWwaeYKLydze2o3z4XHrHXHjdao&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=7&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "FR-Spec: Accelerating Large-Vocabulary Language Models via Frequency-Ranked Speculative Sampling", "first_label": [], "second_label": [], "data": "W Zhao, T Pan, X Han, Y Zhang, A Sun, Y Huang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSpeculative sampling has emerged as an important technique for accelerating the \nauto-regressive generation process of large language models (LLMs) by utilizing a \ndraft-then-verify mechanism to produce multiple tokens per forward pass. While state\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.14856&hl=en&sa=X&d=4250945624494244927&ei=dQraZ-TBHZuw6rQP27yHsAU&scisig=AFWwaeYRHIy0HLbCZ0oP5bnAdlsn&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=8&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "InfiR: Crafting Effective Small Language Models and Multimodal Small Language Models in Reasoning", "first_label": [], "second_label": [], "data": "C Xie, S Cai, W Wang, P Li, Z Sang, K Yang, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) and Multimodal Large Language Models (MLLMs) \nhave made significant advancements in reasoning capabilities. However, they still \nface challenges such as high computational demands and privacy concerns. This\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nCarlos E. Jimenez\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2502.11573&hl=en&sa=X&d=2040677933085995796&ei=dQraZ-TBHZuw6rQP27yHsAU&scisig=AFWwaeZDYD_mnYjLxJYKHWP3K2QX&oi=scholaralrt&hist=apJ4fD8AAAAJ:3096313017463695374:AFWwaeb8R4GEV1B4xk_Cz2b6H7gj&html=&pos=9&folt=rel", "ref": ["Carlos E. Jimenez - new related research"]}
{"title": "KNighter: Transforming Static Analysis with LLM-Synthesized Checkers", "first_label": ["Large Language Models"], "second_label": [], "data": "C Yang, Z Zhao, Z Xie, H Li, L Zhang\\xc2\\xa0- arXiv preprint arXiv:2503.09002, 2025\nStatic analysis is a powerful technique for bug detection in critical systems like \noperating system kernels. However, designing and implementing static analyzers is \nchallenging, time-consuming, and typically limited to predefined bug patterns. While \nlarge language models (LLMs) have shown promise for static analysis, directly \napplying them to scan large codebases remains impractical due to computational \nconstraints and contextual limitations. We present KNighter, the first approach that\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nTr\\xc3\\xadch d\\xe1\\xba\\xabn: \\xe2\\x80\\xaaLarge language model for vulnerability detection: Emerging results\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.09002&hl=vi&sa=X&d=15643934552074292819&ei=dQraZ9mLMI-j6rQPlMHcuAk&scisig=AFWwaeb6V7qERn3_LuvEYvObZk8F&oi=scholaralrt&hist=apJ4fD8AAAAJ:11724652424841979500:AFWwaeb06hHZ-3j7Bb1sOMTsP9ed&html=&pos=0&folt=cit", "ref": ["2 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Xin ZHOU"]}
{"title": "Artificial Intelligence and Learning English in Difficult Circumstances: Implications of Self-Determination Theory for Making-up the Learning Process", "first_label": [], "second_label": [], "data": "I Fatima, M Rashid, M Saqib, N Khan\\xc2\\xa0- Journal of Arts and Linguistics Studies, 2025\nA new era of AI has provided many opportunities, including new learnings and the \nmake-up of the learning process. AI has not only given birth to innovation in the \nmasses but has also transformed ways of learning. The English language requires \nproper attention and practice in Pakistan as it is the language of global perspectives. \nThe study is conducted to understand how to make-up the English language learning \nprocess as there are many issues in public schools, including attendance and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nTr\\xc3\\xadch d\\xe1\\xba\\xabn: \\xe2\\x80\\xaaAnswer Summarization for Technical Queries: Benchmark and\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nGoogle Scholar g\\xe1\\xbb\\xadi th\\xc3\\xb4ng b\\xc3\\xa1o n\\xc3\\xa0y cho b\\xe1\\xba\\xa1n v\\xc3\\xac b\\xe1\\xba\\xa1n \\xc4\\x91ang theo d\\xc3\\xb5i nh\\xe1\\xbb\\xafng l\\xe1\\xbb\\x9di tr\\xc3\\xadch d\\xe1\\xba\\xabn m\\xe1\\xbb\\x9bi trong c\\xc3\\xa1c b\\xc3\\xa0i vi\\xe1\\xba\\xbft c\\xe1\\xbb\\xa7a \nXin ZHOU\n.\nLi\\xe1\\xbb\\x87t k\\xc3\\xaa c\\xe1\\xba\\xa3nh b\\xc3\\xa1o\nH\\xe1\\xbb\\xa7y th\\xc3\\xb4ng b\\xc3\\xa1o\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://jals.miard.org/index.php/jals/article/download/255/210&hl=vi&sa=X&d=7210064429966108541&ei=dQraZ9mLMI-j6rQPlMHcuAk&scisig=AFWwaeY_G8qZRd9CgrJ3QnXrTkNm&oi=scholaralrt&hist=apJ4fD8AAAAJ:11724652424841979500:AFWwaeb06hHZ-3j7Bb1sOMTsP9ed&html=&pos=1&folt=cit", "ref": ["2 l\u1eddi tr\u00edch d\u1eabn m\u1edbi \u0111\u1ebfn b\u00e0i vi\u1ebft c\u1ee7a Xin ZHOU"]}
{"title": "Manual Prompt Engineering is Not Dead: A Case Study on Large Language Models for Code Vulnerability Detection with DSPy", "first_label": ["Vulnerabilities", "Large Language Models", "Code"], "second_label": ["Detection"], "data": "F Trad, A Chehab\\xc2\\xa0- 2025 8th International Conference on Data Science\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomated prompt engineering tools have recently emerged as a promising solution \nto simplify the traditional man-ual task of crafting prompts for large language models \n(LLMs). This study investigates whether such tools can fully replace manual prompt\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10908746/&hl=en&sa=X&d=5315185820890395558&ei=dQraZ_-PJZm7ieoP1NrBiQU&scisig=AFWwaeb1X7i5BNQkTn_MCK7RZ9Ck&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=1&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "LLM-enhanced evolutionary test generation for untyped languages", "first_label": ["Large Language Models"], "second_label": ["Generation"], "data": "R Yang, X Xu, R Wang\\xc2\\xa0- Automated Software Engineering, 2025\nDynamic programming languages, such as Python, are widely used for their flexibility \nand support for rapid development. However, the absence of explicit parameter type \ndeclarations poses significant challenges in generating automated test cases. This\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00496-7&hl=en&sa=X&d=5209764566405071124&ei=dQraZ_-PJZm7ieoP1NrBiQU&scisig=AFWwaeZZcNNRu-1nh6WZ8bsL9w5L&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=2&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "An Empirical Study on the Relationship Between Defects and Source Code's Unnaturalness", "first_label": ["Code"], "second_label": [], "data": "Y Jiang, H Liu, J Liu, Y Zhang, W Ji, H Zhong, L Zhang\\xc2\\xa0- ACM Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nNatural languages are \\xe2\\x80\\x9cnatural\\xe2\\x80\\x9d in that texts in natural languages are repetitive and \npredictable. Recent research indicates that programming languages share similar \ncharacteristics (naturalness), with source code displaying patterns of repetition and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3718083&hl=en&sa=X&d=7306116860520413653&ei=dQraZ_-PJZm7ieoP1NrBiQU&scisig=AFWwaeYhQXymsslwMKE9PXdq4Ud6&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=4&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Variable Renaming-Based Adversarial Test Generation for Code Model: Benchmark and Enhancement", "first_label": ["Code"], "second_label": ["Generation"], "data": "J Wen, Q Hu, Y Guo, M Cordy, Y Le Traon\\xc2\\xa0- ACM Transactions on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRobustness testing is essential for evaluating deep learning models, particularly \nunder unforeseen circumstances. Adversarial test generation, a fundamental \napproach in robustness testing, is prevalent in computer vision and natural language\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3723353&hl=en&sa=X&d=1519110496960002262&ei=dQraZ_-PJZm7ieoP1NrBiQU&scisig=AFWwaebV3O6PCE8R7KSSBObW8rXz&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=5&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "Test Amplification for REST APIs Using\" Out-of-the-box\" Large Language Models", "first_label": ["Large Language Models"], "second_label": [], "data": "T Bardakci, S Demeyer, M Beyazit\\xc2\\xa0- arXiv preprint arXiv:2503.10306, 2025\nREST APIs are an indispensable building block in today's cloud-native applications, \nso testing them is critically important. However, writing automated tests for such \nREST APIs is challenging because one needs strong and readable tests that\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.10306&hl=en&sa=X&d=1764624563322102127&ei=dQraZ_-PJZm7ieoP1NrBiQU&scisig=AFWwaebWWp27u4P7gFq2x2stAX0V&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=6&folt=rel", "ref": ["Hong Jin Kang - new related research"]}
{"title": "ClozeMaster: Fuzzing Rust Compiler by Harnessing LLMs for Infilling Masked Real Programs", "first_label": ["Large Language Models", "Fuzzing"], "second_label": [], "data": "H Gao, Y Yang, M Sun, J Wu, Y Zhou, B Xu\\xc2\\xa0- 2025 IEEE/ACM 47th International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nEnsuring the reliability of the Rust compiler is of paramount importance, given \nincreasing adoption of Rust for critical systems development, due to its emphasis on \nmemory and thread safety. However, generating valid test programs for the Rust\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a712/251mH1NLq1y&hl=en&sa=X&d=651262875265378413&ei=dQraZ_-PJZm7ieoP1NrBiQU&scisig=AFWwaeaMXR7oPpxlJlJqdN4vFwMg&oi=scholaralrt&hist=apJ4fD8AAAAJ:8900472388513427833:AFWwaeZM7Y6I9R2ROVLnk31jdyVz&html=&pos=7&folt=rel", "ref": ["Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Empirical Investigation of Key Enablers for Secure DevOps Practices", "first_label": [], "second_label": [], "data": "MA Akbar, AA Alsanad\\xc2\\xa0- IEEE Access, 2025\nDevSecOps integrates security practices from development to operations in the \nsearch for faster and more secure responses to business needs. DevSecOps is an \napproach based on the 4 pillars of the CAMS model (culture, measurement\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/10820123/10916576.pdf&hl=en&sa=X&d=14388644433580888125&ei=dQraZ4igM9mlieoPir2teA&scisig=AFWwaeYU9xrsUktqAbd3usqmTKSB&oi=scholaralrt&hist=apJ4fD8AAAAJ:15725322226479601129:AFWwaeYp-8wbw5OHTjoCHLP43E0V&html=&pos=1&folt=rel", "ref": ["Triet H. M. Le - new related research"]}
{"title": "Integrating Time Series Anomaly Detection into DevOps Workflows", "first_label": [], "second_label": ["Detection"], "data": "G K\\xc3\\xa5n\\xc3\\xa5hols, S Hasan, PE Strandberg\\xc2\\xa0- IEEE Access, 2025\nAnomaly detection in the monitoring systems of DevOps environments is crucial for \nensuring system reliability, preventing downtime, and maintaining the efficiency of \ncontinuous integration and continuous deployment pipelines. Artificial Intelligence\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/10924143.pdf&hl=en&sa=X&d=15848826380236741217&ei=dQraZ4igM9mlieoPir2teA&scisig=AFWwaeZmjZOBSBpGJH15kxEVQpVN&oi=scholaralrt&hist=apJ4fD8AAAAJ:15725322226479601129:AFWwaeYp-8wbw5OHTjoCHLP43E0V&html=&pos=2&folt=rel", "ref": ["Triet H. M. Le - new related research"]}
{"title": "The road to Sustainable DevOps", "first_label": [], "second_label": [], "data": "DA Herati, MC Aderne, F Kon\\xc2\\xa0- arXiv preprint arXiv:2503.08845, 2025\nThis manuscript focuses on the environmental, social, and individual sustainability \ndimensions within the modern software development lifecycle, aiming to establish a \nholistic approach termed Sustainable DevOps (SusDevOps). Moving beyond the\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nTriet H. M. Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.08845&hl=en&sa=X&d=10429861686899533735&ei=dQraZ4igM9mlieoPir2teA&scisig=AFWwaea74gOYpdypoCtHdEiJ7KTL&oi=scholaralrt&hist=apJ4fD8AAAAJ:15725322226479601129:AFWwaeYp-8wbw5OHTjoCHLP43E0V&html=&pos=3&folt=rel", "ref": ["Triet H. M. Le - new related research"]}
{"title": "ICSQuartz: Scan Cycle-Aware and Vendor-Agnostic Fuzzing for Industrial Control Systems", "first_label": ["Fuzzing"], "second_label": [], "data": "C Villa, C Doumanidis, H Lamri, PHN Rajput\\xe2\\x80\\xa6\nIndustrial Control Systems (ICS) ensure the automation and safe operation of critical \nindustry, energy, and commerce processes. Despite its importance, ICS code often \ncannot be evaluated as rigorously as software on traditional computing platforms, as\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.ndss-symposium.org/wp-content/uploads/2025-795-paper.pdf&hl=en&sa=X&d=10524862650214833634&ei=dQraZ5HcKeOO6rQPq9iPqQQ&scisig=AFWwaeZZ_2ARI6V22CenXEygxr-a&oi=scholaralrt&hist=apJ4fD8AAAAJ:11137134570824175991:AFWwaeZJgvZkFmSwNlRigHvrI7d8&html=&pos=0&folt=rel", "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Snowplow: Effective Kernel Fuzzing with a Learned White-box Test Mutator", "first_label": ["Fuzzing"], "second_label": [], "data": "S Gong, R Wang, D Alt\\xc4\\xb1nb\\xc3\\xbcken, P Fonseca, P Maniatis - 2025\nKernel fuzzers rely heavily on program mutation to automatically generate new test \nprograms based on existing ones. In particular, program mutation can alter the test's \ncontrol and data flow inside the kernel by inserting new system calls, changing the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://sishuaigong.github.io/pdf/asplos25-snowplow.pdf&hl=en&sa=X&d=1525548876762051891&ei=dQraZ5HcKeOO6rQPq9iPqQQ&scisig=AFWwaeYhlLgOV_U4w2jfk052O3uX&oi=scholaralrt&hist=apJ4fD8AAAAJ:11137134570824175991:AFWwaeZJgvZkFmSwNlRigHvrI7d8&html=&pos=3&folt=rel", "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Poster: FuzzLGen: Logical Seed Generation for Smart Contract Fuzzing via LLM-based Agents and Program Analysis", "first_label": ["Smart Contracts", "Large Language Models", "Fuzzing"], "second_label": ["Generation", "Agent"], "data": "S Ji, M Xu, J Wu, J Dong\nSmart contracts play a pivotal role in blockchain applications but are increasingly \ntargeted by attackers, resulting in significant financial losses. As their adoption grows \nacross various industries, ensuring their security has become more important than\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.ndss-symposium.org/wp-content/uploads/2025-poster-23.pdf&hl=en&sa=X&d=16053450712575666137&ei=dQraZ5HcKeOO6rQPq9iPqQQ&scisig=AFWwaeY0MIVvxTjziPH4D5in5TpN&oi=scholaralrt&hist=apJ4fD8AAAAJ:11137134570824175991:AFWwaeZJgvZkFmSwNlRigHvrI7d8&html=&pos=4&folt=rel", "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Ratte: Fuzzing for Miscompilations in Multi-Level Compilers Using Composable Semantics", "first_label": ["Fuzzing"], "second_label": [], "data": "P Yu, N Wu, AF Donaldson - 2025\nMulti-level intermediate representation (MLIR) is a rapidly growing compiler \nframework, with its defining feature being an ecosystem of modular language \nfragments called dialects. Specifying dialect semantics and validating dialect\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.doc.ic.ac.uk/~afd/papers/2025/ASPLOS-Ratte.pdf&hl=en&sa=X&d=2019974718744086328&ei=dQraZ5HcKeOO6rQPq9iPqQQ&scisig=AFWwaeaxX8iJzmc1p4D9ISFbKJuw&oi=scholaralrt&hist=apJ4fD8AAAAJ:11137134570824175991:AFWwaeZJgvZkFmSwNlRigHvrI7d8&html=&pos=5&folt=rel", "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Do Compilers Break Constant-time Guarantees?", "first_label": [], "second_label": [], "data": "L Gerlach, R Pietsch, M Schwarz\nSide-channel attacks are a significant concern for the implementation of \ncryptographic algorithms. Data-oblivious programming is a discipline that helps \nmitigate side-channel attacks by preventing data leakage over side channels. \nHowever, due to various optimizations in modern compilers, data-obliviousness \ncannot be guaranteed in high-level languages. This work investigates to which \nextent compiler optimizations violate data-obliviousness. To this end, we present\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBinary Rewriting without Control Flow Recovery\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=http://www.misc0110.net/files/docc_fc25.pdf&hl=en&sa=X&d=14250414356843338348&ei=dQraZ--AIsmpieoP4aW8iQ8&scisig=AFWwaeYX71bVnkVQ6nTia61z6U_B&oi=scholaralrt&hist=apJ4fD8AAAAJ:5778505219825515303:AFWwaeaDDOggOneW-z6K3HLjAzuP&html=&pos=0&folt=cit", "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "JBFuzz: Jailbreaking LLMs Efficiently and Effectively Using Fuzzing", "first_label": ["Large Language Models", "Fuzzing"], "second_label": [], "data": "V Gohil\\xc2\\xa0- arXiv preprint arXiv:2503.08990, 2025\nLarge language models (LLMs) have shown great promise as language \nunderstanding and decision making tools, and they have permeated various aspects \nof our everyday life. However, their widespread availability also comes with novel \nrisks, such as generating harmful, unethical, or offensive content, via an attack called \njailbreaking. Despite extensive efforts from LLM developers to align LLMs using \nhuman feedback, they are still susceptible to jailbreak attacks. To tackle this issue\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCoverage-based greybox fuzzing as markov chain\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.08990&hl=en&sa=X&d=4217026592049764402&ei=dQraZ--AIsmpieoP4aW8iQ8&scisig=AFWwaeY3qgXizdHVw4w1VwbWD_or&oi=scholaralrt&hist=apJ4fD8AAAAJ:5778505219825515303:AFWwaeaDDOggOneW-z6K3HLjAzuP&html=&pos=3&folt=cit", "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "GCFuzz: An Intelligent Method for Generating IoT Protocols Test Cases Using GAN with CVAE", "first_label": ["Fuzzing"], "second_label": [], "data": "H Peng, Z Ding\\xc2\\xa0- Attacks and Defenses for the Internet-of-Things: 7th\\xc2\\xa0\\xe2\\x80\\xa6\nThe importance of Internet of Things (IoT) systems security cannot be ignored, \nparticularly in the realm of communication. IoT protocols serve as standards for \ncommunication and interaction among devices in IoT environments. This paper \nenhances IoT security by identifying and exposing protocol vulnerabilities through \nfuzzing, a cru-cial method for discovering security flaws. Traditional generation-\nbased fuzzers require reverse engineering to understand protocol grammar and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAFLNet: a greybox fuzzer for network protocols\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DdC1OEQAAQBAJ%26oi%3Dfnd%26pg%3DPA107%26ots%3DxkjvDfbfg-%26sig%3Dlr_dswDdJgsL1MkV3jiXeE83dk0&hl=en&sa=X&d=5274784969656779645&ei=dQraZ--AIsmpieoP4aW8iQ8&scisig=AFWwaeYZLlUKNndQ9ySzzT6sA2PO&oi=scholaralrt&hist=apJ4fD8AAAAJ:5778505219825515303:AFWwaeaDDOggOneW-z6K3HLjAzuP&html=&pos=4&folt=cit", "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Survey on Trustworthy LLM Agents: Threats and Countermeasures", "first_label": ["Large Language Models"], "second_label": ["Agent"], "data": "M Yu, F Meng, X Zhou, S Wang, J Mao, L Pang, T Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the rapid evolution of Large Language Models (LLMs), LLM-based agents and \nMulti-agent Systems (MAS) have significantly expanded the capabilities of LLM \necosystems. This evolution stems from empowering LLMs with additional modules \nsuch as memory, tools, environment, and even other agents. However, this \nadvancement has also introduced more complex issues of trustworthiness, which \nprevious research focused solely on LLMs could not cover. In this survey, we\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.09648&hl=en&sa=X&d=10432425910303948303&ei=dQraZ5LwJrutieoP8ref4Qo&scisig=AFWwaeaewJys2IukQeo7oV2YeA2Q&oi=scholaralrt&hist=apJ4fD8AAAAJ:9077511576393718270:AFWwaeYjhZg9MUHEYuARvipEszZC&html=&pos=0&folt=cit", "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "AgentDAM: Privacy Leakage Evaluation for Autonomous Web Agents", "first_label": [], "second_label": ["Agent"], "data": "A Zharmagambetov, C Guo, I Evtimov, M Pavlova\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM-powered AI agents are an emerging frontier with tremendous potential to \nincrease human productivity. However, empowering AI agents to take action on their \nuser's behalf in day-to-day tasks involves giving them access to potentially sensitive \nand private information, which leads to a possible risk of inadvertent privacy leakage \nwhen the agent malfunctions. In this work, we propose one way to address that \npotential risk, by training AI agents to better satisfy the privacy principle of data\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2503.09780&hl=en&sa=X&d=12860650719968363446&ei=dQraZ5LwJrutieoP8ref4Qo&scisig=AFWwaeYFBb7XwAGVIFrdP1Ee_Ubb&oi=scholaralrt&hist=apJ4fD8AAAAJ:9077511576393718270:AFWwaeYjhZg9MUHEYuARvipEszZC&html=&pos=1&folt=cit", "ref": ["2 new citations to articles by Richard Fang"]}
