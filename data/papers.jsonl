{"title": "Large Language Models for Multilingual Vulnerability Detection: How Far Are We?", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "H Shu, M Fu, J Yu, D Wang, C Tantithamthavorn\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nVarious deep learning-based approaches utilizing pre-trained language models \n(PLMs) have been proposed for automated vulnerability detection. With recent \nadvancements in large language models (LLMs), several studies have begun\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07503&hl=en&sa=X&d=16921324525434229917&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b_NVmGqeviNJG8TX3MzY9vb&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "2 new citations to articles by Xin ZHOU"]}
{"title": "Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Reasoning"], "data": "XC Wen, Y Yang, C Gao, Y Xiao, D Ye\\xc2\\xa0- arXiv preprint arXiv:2506.07390, 2025\nLarge language models (LLMs) demonstrate considerable proficiency in numerous \ncoding-related tasks; however, their capabilities in detecting software vulnerabilities \nremain limited. This limitation primarily stems from two factors:(1) the absence of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07390&hl=en&sa=X&d=10299031030894150274&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b8vcpW_SfG5zRJX336Xr84s&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "2 new citations to articles by Xin ZHOU"]}
{"title": "UCP: a unified framework for code generation with pseudocode-based multi-task learning and reinforcement alignment", "first_label": ["Code"], "second_label": ["Generation"], "data": "Y Wen, Z Cui, Y Liu, Z Zhang, J Zhou, L Tang\\xc2\\xa0- The Journal of Supercomputing, 2025\nPre-trained large language models (LLMs) have been widely applied to natural \nlanguage-based code generation. However, because code generation tasks are \nhighly sensitive to structured information and exhibit diverse logical forms, directly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11227-025-07487-1&hl=en&sa=X&d=264978427275781755&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b8HnhQLRB1NFzaWU0iyGBfI&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research", "Bach Le - new related research"]}
{"title": "Adversarial Attack Classification and Robustness Testing for Large Language Models for Code", "first_label": ["LLM", "Code", "Software Testing"], "second_label": [], "data": "Y Liu, A Foundjem, F Khomh, H Li\\xc2\\xa0- arXiv preprint arXiv:2506.07942, 2025\nLarge Language Models (LLMs) have become vital tools in software development \ntasks such as code generation, completion, and analysis. As their integration into \nworkflows deepens, ensuring robustness against vulnerabilities especially those\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07942&hl=en&sa=X&d=10411796502631711196&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b-eMQpfZUdxJwBqS5XD673H&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation", "Reasoning"], "data": "C Deng, YD Tsai, GT Liu, Z Yu, H Ren\\xc2\\xa0- arXiv preprint arXiv:2506.05566, 2025\nRecent advances in large language models (LLMs) have enabled near-human \nperformance on software coding benchmarks, but their effectiveness in RTL code \ngeneration remains limited due to the scarcity of high-quality training data. While\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05566&hl=en&sa=X&d=12705396645248113526&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b_ry1MNtEw3XIAjhRirpsJ9&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Li, J Ding, C Peng, B Zhao, X Gao, H Gao, X Gu\\xc2\\xa0- arXiv preprint arXiv:2506.05692, 2025\nThe code generation capabilities of large language models (LLMs) have emerged as \na critical dimension in evaluating their overall performance. However, prior research \nhas largely overlooked the security risks inherent in the generated code. In this work\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05692&hl=en&sa=X&d=5492650506064335063&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b_VqkMkad8wzoS_QoQNt7_G&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "Bach Le - new related research"]}
{"title": "DesignBench: A Comprehensive Benchmark for MLLM-based Front-end Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Xiao, M Wang, MH Lam, Y Wan, J Liu, Y Huo, MR Lyu\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMultimodal Large Language Models (MLLMs) have demonstrated remarkable \ncapabilities in automated front-end engineering, eg, generating UI code from visual \ndesigns. However, existing front-end UI code generation benchmarks have the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.06251&hl=en&sa=X&d=17951328836556884213&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b9zlbZwsJl10-fahiXKUBZ3&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "An LLM Agent for Functional Bug Detection in Network Protocols", "first_label": ["LLM", "Bug"], "second_label": ["Detection", "Agent"], "data": "M Zheng, C Wang, X Liu, J Guo, S Feng, X Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.00714, 2025\nFunctional correctness is critical for ensuring the reliability and security of network \nprotocol implementations. Functional bugs, instances where implementations \ndiverge from behaviors specified in RFC documents, can lead to severe\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00714&hl=en&sa=X&d=14025741833580725532&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b8vkBixnPr2fRq2ZYFDK47O&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A Framework for Creating Non-Regressive Test Cases via Branch Consistency Analysis Driven by Descriptions", "first_label": ["Software Testing"], "second_label": [], "data": "Y Zhang, P Xue, Z Yang, X Ren, X Li, L Wu, J Zhao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomated test-generation research overwhelmingly assumes the correctness of \nfocal methods, yet practitioners routinely face non-regression scenarios where the \nfocal method may be defective. A baseline evaluation of EvoSuite and two leading\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07486&hl=en&sa=X&d=12300473129148860276&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b8EYaZUm5p8en4HDg1pCFjV&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "To Protect the LLM Agent Against the Prompt Injection Attack with Polymorphic Prompt", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Z Wang, N Nagaraja, L Zhang, H Bahsi, P Patil, P Liu\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM agents are widely used as agents for customer support, content generation, and \ncode assistance. However, they are vulnerable to prompt injection attacks, where \nadversarial inputs manipulate the model's behavior. Traditional defenses like input\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05739&hl=en&sa=X&d=8621477909179484491&ei=qkVMaL2kNbXCieoP_vz9iAU&scisig=AAZF9b-p03ag5mevr_Qw6WxvJKN1&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Beyond Surface Similarity: Evaluating LLM-Based Test Refactorings with Structural and Semantic Awareness", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "WC Ou\\xc3\\xa9draogo, Y Li, X Dang, X Zhou, A Koyuncu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly employed to automatically refactor \nunit tests, aiming to enhance readability, naming, and structural clarity while \npreserving functional behavior. However, evaluating such refactorings remains\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.06767&hl=en&sa=X&d=6563163690120506226&ei=qkVMaM3lMKalieoP4J3H2A8&scisig=AAZF9b9xD9hAdx6dPyiL2w3mENFA&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Neuro-Symbolic Reinforcement Learning for Context-Aware Decision Making in Safe Autonomous Vehicles", "first_label": [], "second_label": [], "data": "P Muniyandy, TDYAB El, DDNPD Ebiary\nAutonomous vehicles need to be equipped with smart, understandable, and context-\naware decision-making frameworks to drive safely within crowded environments. \nCurrent deep learning approaches tend to generalize poorly, lack transparency, and \nperform inadequately in dealing with uncertainty within dynamic city environments. \nTowards overcoming these deficiencies, this study suggests a new hybrid approach \nthat combines Neuro-Symbolic reasoning with a Convolutional Neural Network\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSurveying neuro-symbolic approaches for reliable artificial\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Janjhyam-Ramesh/publication/392377131_Neuro-Symbolic_Reinforcement_Learning_for_Context-Aware_Decision_Making_in_Safe_Autonomous_Vehicles/links/6847abd6df0e3f544f5dee53/Neuro-Symbolic-Reinforcement-Learning-for-Context-Aware-Decision-Making-in-Safe-Autonomous-Vehicles.pdf&hl=en&sa=X&d=4583605719457932112&ei=qkVMaI6uMr2W6rQPjI6v-QY&scisig=AAZF9b9r5v_YzoexIy5EAyH_B1m5&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["1 new citation to articles by Hong Jin Kang"]}
{"title": "Deployability-Centric Infrastructure-as-Code Generation: An LLM-based Iterative Framework", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "T Zhang, S Pan, Z Zhang, Z Xing, X Sun\\xc2\\xa0- arXiv preprint arXiv:2506.05623, 2025\nInfrastructure-as-Code (IaC) generation holds significant promise for automating \ncloud infrastructure provisioning. Recent advances in Large Language Models \n(LLMs) present a promising opportunity to democratize IaC development by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05623&hl=en&sa=X&d=4489224540223539289&ei=q0VMaMKVAYqIieoPrumR8AU&scisig=AAZF9b8IIvUBCWLOE3kaL0BXAX6G&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "IntenTest: Stress Testing for Intent Integrity in API-Calling LLM Agents", "first_label": ["LLM", "Software Testing"], "second_label": ["Agent"], "data": "S Feng, X Xu, X Chen, K Zhang, SY Ahmed, Z Su\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM agents are increasingly deployed to automate real-world tasks by invoking APIs \nthrough natural language instructions. While powerful, they often suffer from \nmisinterpretation of user intent, leading to the agent's actions that diverge from the \nuser's intended goal, especially as external toolkits evolve. Traditional software \ntesting assumes structured inputs and thus falls short in handling the ambiguity of \nnatural language. We introduce IntenTest, an API-centric stress testing framework\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07524&hl=en&sa=X&d=5483501088938509317&ei=qkVMaI-sL-Ws6rQPpf7X-Aw&scisig=AAZF9b8ToxhJhlHy6Z6YJ25UePxA&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang", "6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Information-Theoretic Detection of Unusual Source Code Changes", "first_label": ["Code", "Code Change"], "second_label": ["Detection"], "data": "A Torres, S Baltes, C Treude, M Wagner\\xc2\\xa0- arXiv preprint arXiv:2506.06508, 2025\nThe code base of software projects evolves essentially through inserting and \nremoving information to and from the source code. We can measure this evolution \nvia the elements of information-tokens, words, nodes-of the respective representation\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.06508&hl=en&sa=X&d=16408897699757615593&ei=q0VMaMz3Asy8ieoP89mfwQY&scisig=AAZF9b9hxGcjnj0zZ77CRsYy74NR&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Exploring Fine-Grained Bug Report Categorization with Large Language Models and Prompt Engineering: An Empirical Study", "first_label": ["LLM", "Bug"], "second_label": [], "data": "A Koyuncu\\xc2\\xa0- ACM Transactions on Software Engineering and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAccurate classification of issues is essential for effective project management and \ntimely responses, as the volume of issue reports continues to grow. Manual \nclassification is labor-intensive and error-prone, necessitating automated solutions\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3736408&hl=en&sa=X&d=1221326668322558367&ei=q0VMaMz3Asy8ieoP89mfwQY&scisig=AAZF9b94qGcVVVtNwHBRf1PSh6nk&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Dynamic graph contrastive learning based on learnable view generators", "first_label": [], "second_label": ["Graph"], "data": "M Zhu, L Qiu, W Zhao\\xc2\\xa0- Knowledge-Based Systems, 2025\nDynamic graph representation learning aims to capture graphs' evolving structure \nand properties by learning embedded representations of nodes and edges over time. \nGraph self-supervised learning, particularly graph contrastive learning, has garnered \nsignificant attention recently. However, existing dynamic graph contrastive learning \nmethods are vulnerable to data distribution imbalances, leading to model overfitting \non active nodes and edges, and they are also prone to capturing meaningless\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaToward the analysis of graph neural networks\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950705125008913&hl=en&sa=X&d=10908481830653854755&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b9MycfNw-D9zP9uf2FqAtGZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le", "1 new citation to articles by Thanh Le-Cong"]}
{"title": "Decentralized certificate issuance and verification system using Ethereum blockchain technology", "first_label": ["Verification", "Ethereum", "Blockchain"], "second_label": [], "data": "TR Sree\\xc2\\xa0- Journal of Network and Computer Applications, 2025\nThe increasing prevalence of fraudulent and inefficient centralized certificate systems \nposes significant challenges across various sectors, undermining trust and hindering \nefficient verification processes. This paper aims to overcome these difficulties by \noffering a decentralized certificate issuance and verification system based on \nEthereum blockchain technology and Goerli testnet. It is developed to provide a \nreliable and transparent way to create and validate credentials in various industries\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1084804525000876&hl=en&sa=X&d=15636684545320754745&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b_IC195LBTc1nY7SaUriyQu&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "Cybersecurity Challenges in Blockchain-Based Accounting Systems", "first_label": ["Blockchain"], "second_label": [], "data": "AL Paul\nBlockchain technology has emerged as a transformative force in the realm of digital \naccounting, promising transparency, immutability, and decentralized verification. As \naccounting systems increasingly migrate to blockchain-based infrastructures, they \nencounter a new class of cybersecurity threats. While blockchain offers improved \ntrust and integrity of financial records, it is not impervious to vulnerabilities. This \npaper explores the primary cybersecurity challenges in blockchain-based accounting\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Anthony-Paul-2/publication/392519552_Cybersecurity_Challenges_in_Blockchain-Based_Accounting_Systems/links/6846c8d6df0e3f544f5dbbf1/Cybersecurity-Challenges-in-Blockchain-Based-Accounting-Systems.pdf&hl=en&sa=X&d=14753631704336139104&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b8-We9Baae8zAtvYnbluxur&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "The Influence of Digital Governance Tools on Public Investment Strategies", "first_label": [], "second_label": [], "data": "AL Paul\nDigital governance tools have increasingly become critical instruments in shaping \nand optimizing public investment strategies globally. This paper examines how \ndigital platforms, data analytics, blockchain technology, and e-governance systems \ninfluence decision-making, transparency, efficiency, and accountability in public \ninvestment. By integrating case studies and empirical data, this study highlights the \ntransformative impact of digital governance on public sector financial planning and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Anthony-Paul-2/publication/392519391_The_Influence_of_Digital_Governance_Tools_on_Public_Investment_Strategies/links/6846cb07d1054b0207fac047/The-Influence-of-Digital-Governance-Tools-on-Public-Investment-Strategies.pdf&hl=en&sa=X&d=14107208868790362796&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b-FOaezUIcBesA_xcD22LX-&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=3&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "Digital Twins in Auditing: A Technological Leap for Real-Time Financial Monitoring", "first_label": [], "second_label": [], "data": "AL Paul\nThe auditing profession is undergoing a transformative shift driven by rapid \nadvancements in digital technologies. Digital twin technology, a virtual \nrepresentation of physical systems that updates in real-time, is emerging as a \npromising innovation to enhance auditing processes, particularly in financial \nmonitoring. This paper explores the potential of digital twins to revolutionize auditing \nby enabling continuous, real-time oversight of financial data, thereby improving the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Anthony-Paul-2/publication/392519545_Digital_Twins_in_Auditing_A_Technological_Leap_for_Real-Time_Financial_Monitoring/links/6846c806df0e3f544f5dbbdc/Digital-Twins-in-Auditing-A-Technological-Leap-for-Real-Time-Financial-Monitoring.pdf&hl=en&sa=X&d=25655615642885322&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b_zUlFTE6Q31iPStek7j4o3&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=4&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "Technological Innovations and Their Role in Enhancing Transparency in Public Sector Budgeting", "first_label": [], "second_label": [], "data": "AL Paul\nTransparency in public sector budgeting is critical for accountable governance, \nefficient resource allocation, and strengthening public trust. Technological \ninnovations, especially digital tools and systems, have increasingly become pivotal \nin transforming public budgeting processes by improving openness, accuracy, and \ncitizen engagement. This paper explores the range of technological innovations \nshaping transparency in public sector budgeting, including blockchain, big data\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Anthony-Paul-2/publication/392519205_Technological_Innovations_and_Their_Role_in_Enhancing_Transparency_in_Public_Sector_Budgeting/links/6846c995d1054b0207fabfea/Technological-Innovations-and-Their-Role-in-Enhancing-Transparency-in-Public-Sector-Budgeting.pdf&hl=en&sa=X&d=7642411289453450086&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b8iCzXCAeUdcHC1uN1WHAWu&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=5&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "The Integration of Robotic Process Automation (RPA) in Corporate Accounting: Efficiency vs. Compliance", "first_label": [], "second_label": [], "data": "AL Paul\nAbstract Robotic Process Automation (RPA) has become a transformative force in \ncorporate accounting, enabling organizations to enhance operational efficiency by \nautomating repetitive and rule-based tasks. While RPA promises significant benefits \nsuch as cost savings, improved accuracy, and faster processing times, its integration \nraises important compliance and governance concerns. This article examines the \ndual impact of RPA on corporate accounting, analyzing how firms can leverage\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Anthony-Paul-2/publication/392519398_The_Integration_of_Robotic_Process_Automation_RPA_in_Corporate_Accounting_Efficiency_vs_Compliance/links/6846cd158a76251f22ec69b3/The-Integration-of-Robotic-Process-Automation-RPA-in-Corporate-Accounting-Efficiency-vs-Compliance.pdf&hl=en&sa=X&d=8575867070192944103&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b8V9d_IBbaiXJf07fpd1JcJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=6&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "Auditing in the Age of the Metaverse: Challenges and Opportunities", "first_label": [], "second_label": [], "data": "R Ajax\nThe emergence of the Metaverse\\xe2\\x80\\x94a convergence of immersive technologies, \ndecentralized digital platforms, and virtual economies\\xe2\\x80\\x94is redefining the landscape \nof corporate operations, financial transactions, and regulatory oversight. As \nbusinesses increasingly engage in virtual real estate, digital assets, and \nblockchainenabled ecosystems, the auditing profession faces an inflection point. \nThis paper explores the transformative impact of the Metaverse on auditing, focusing\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Raymond-Ajax/publication/392519430_Auditing_in_the_Age_of_the_Metaverse_Challenges_and_Opportunities/links/6846c6b6df0e3f544f5dbbb7/Auditing-in-the-Age-of-the-Metaverse-Challenges-and-Opportunities.pdf&hl=en&sa=X&d=11506361248134588570&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b-mtpSvDOOTIUcEC1MV0xot&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=7&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "Blockchain Technology and Its Impact on Investor Behavior and Market Sensitivity", "first_label": ["Blockchain"], "second_label": [], "data": "R Ajax\nBlockchain technology, as a decentralized and distributed ledger system, has rapidly \nevolved from a niche innovation underpinning cryptocurrencies to a disruptive force \nreshaping global financial markets. This paper critically examines the extensive \nimpact of blockchain on investor behavior and market sensitivity by integrating \ninsights from behavioral finance, market microstructure, and emerging blockchain \napplications. Blockchain's core attributes\\xe2\\x80\\x94transparency, immutability, and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Raymond-Ajax/publication/392519192_Blockchain_Technology_and_Its_Impact_on_Investor_Behavior_and_Market_Sensitivity/links/6846c584d1054b0207fabf42/Blockchain-Technology-and-Its-Impact-on-Investor-Behavior-and-Market-Sensitivity.pdf&hl=en&sa=X&d=4598368271639172027&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b_pm_uXqNI9sZnvTgnxWeym&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=8&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "Assessing the Impact of FinTech Innovations on Private and Public Investment Sensitivity", "first_label": [], "second_label": [], "data": "R Ajax\nThe accelerating rise of Financial Technology (FinTech) has introduced \ntransformative changes across global financial markets, impacting how both private \nentities and public institutions make investment decisions. This research investigates \nthe extent to which FinTech innovations\\xe2\\x80\\x94such as blockchain, peer-to-peer lending, \ndigital advisory services, and decentralized finance\\xe2\\x80\\x94affect the sensitivity of private \nand public investments to macroeconomic indicators, including interest rates\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Raymond-Ajax/publication/392518908_Assessing_the_Impact_of_FinTech_Innovations_on_Private_and_Public_Investment_Sensitivity/links/6846c485df0e3f544f5dbb78/Assessing-the-Impact-of-FinTech-Innovations-on-Private-and-Public-Investment-Sensitivity.pdf&hl=en&sa=X&d=13839664669455761442&ei=qkVMaPPqM86r6rQP3rzY-QM&scisig=AAZF9b_0KX6ScY2YVXBqXIPDhk-z&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=9&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le"]}
{"title": "Agent4Vul: multimodal LLM agents for smart contract vulnerability detection", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection", "Agent"], "data": "W Jie, W Qiu, H Yang, M Guo, X Huang, T Lei, Q Zhang\\xe2\\x80\\xa6\\xc2\\xa0- Science China Information\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSmart contract vulnerabilities have emerged as a significant threat to blockchain \nsystem security under the Web 3.0 ecosystem. According to recent research, large \nlanguage models (LLMs) have demonstrated immense potential in smart contract\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=http://scis.scichina.com/en/2025/160101.pdf&hl=en&sa=X&d=2236818715129249300&ei=qkVMaLKoOL_N6rQPzuHnkAg&scisig=AAZF9b8B05xE_kt2qfr8AdX4qU1X&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=3&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Evaluating LLMs Effectiveness in Detecting and Correcting Test Smells: An Empirical Study", "first_label": ["LLM", "Software Testing"], "second_label": ["Detection"], "data": "EG Santana Jr, JPS Junior, EP Almeida, I Ahmed\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nTest smells indicate poor development practices in test code, reducing \nmaintainability and reliability. While developers often struggle to prevent or refactor \nthese issues, existing tools focus primarily on detection rather than automated\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07594&hl=en&sa=X&d=9420305687673894867&ei=qkVMaLKoOL_N6rQPzuHnkAg&scisig=AAZF9b9BvLiiGG9H_DI2P6brMLCH&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=5&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "SWE-Dev: Building Software Engineering Agents with Training and Inference Scaling", "first_label": [], "second_label": ["Agent"], "data": "H Wang, Z Hou, Y Wei, J Tang, Y Dong\\xc2\\xa0- arXiv preprint arXiv:2506.07636, 2025\nLarge language models (LLMs) have advanced rapidly from conversational problem \nsolving to addressing real-world tasks involving tool use, such as software \nengineering (SWE). Recent LLM-powered toolkits, such as OpenAI Codex and \nCursor, have offered end-to-end automation of the software development process. \nHowever, building effective SWE agents remains challenging due to the lack of high-\nquality training data and effective test cases. To address this issue, we present SWE\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07636&hl=en&sa=X&d=11131145750035336718&ei=qkVMaNPwNqKr6rQPlpCs6Q0&scisig=AAZF9b-KipotiAFWL0ISr76hyMZy&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research"]}
{"title": "CP-Bench: Evaluating Large Language Models for Constraint Modelling", "first_label": ["LLM"], "second_label": [], "data": "K Michailidis, D Tsouros, T Guns\\xc2\\xa0- arXiv preprint arXiv:2506.06052, 2025\nCombinatorial problems are present in a wide range of industries. Constraint \nProgramming (CP) is a well-suited problem-solving paradigm, but its core process, \nnamely constraint modelling, is a bottleneck for wider adoption. Aiming to alleviate \nthis bottleneck, recent studies have explored using Large Language Models (LLMs) \nas modelling assistants, transforming combinatorial problem descriptions to \nexecutable constraint models, similar to coding assistants. However, the existing\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.06052&hl=en&sa=X&d=6142141515041502582&ei=qkVMaNPwNqKr6rQPlpCs6Q0&scisig=AAZF9b_8uOW0NJbL4CH57_toiNGB&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Does It Run and Is That Enough? Revisiting Text-to-Chart Generation with a Multi-Agent Approach", "first_label": [], "second_label": ["Generation", "Agent"], "data": "J Ford, A Rios\\xc2\\xa0- arXiv preprint arXiv:2506.06175, 2025\nLarge language models can translate natural-language chart descriptions into \nrunnable code, yet approximately 15\\\\% of the generated scripts still fail to execute, \neven after supervised fine-tuning and reinforcement learning. We investigate \nwhether this persistent error rate stems from model limitations or from reliance on a \nsingle-prompt design. To explore this, we propose a lightweight multi-agent pipeline \nthat separates drafting, execution, repair, and judgment, using only an off-the-shelf\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.06175&hl=en&sa=X&d=8866180754591147613&ei=qkVMaNPwNqKr6rQPlpCs6Q0&scisig=AAZF9b9fHFvja6mIFZHI_GxaIfcG&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "CAFault: Enhance Fault Injection Technique in Practical Distributed Systems via Abundant Fault-Dependent Configurations.", "first_label": [], "second_label": [], "data": "Y Chen, F Ma, Y Zhou, Z Yan, Y Jiang\nTo ensure high reliability and availability, distributed systems are designed to be \nresilient to various faults in complex environments. Fault injection techniques are \ncommonly used to test whether a distributed system can correctly handle different \npotential faults. However, existing fault injection testing is typically performed under a \nfixed default configuration, overlooking the impact of varying configurations (which \ncan differ in real-world applications) on testing execution paths. This results in many\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaGreybox fuzzing of distributed systems\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=http://www.wingtecher.com/themes/WingTecherResearch/assets/papers/paper_from_25/CAFault_ATC25.pdf&hl=en&sa=X&d=2762221814591141395&ei=qkVMaNPwNqKr6rQPlpCs6Q0&scisig=AAZF9b9Uh0jF7NeR0Ohy6c6j7llS&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Human Side of Smart Contract Fuzzing: An Empirical Study", "first_label": ["Smart Contracts", "Fuzzing"], "second_label": [], "data": "G Qiao, PP Paul\\xc2\\xa0- arXiv preprint arXiv:2506.07389, 2025\nSmart contract (SC) fuzzing is a critical technique for detecting vulnerabilities in \nblockchain applications. However, its adoption remains challenging for practitioners \ndue to fundamental differences between SCs and traditional software systems. In this \nstudy, we investigate the challenges practitioners face when adopting SC fuzzing \ntools by conducting an inductive content analysis of 381 GitHub issues from two \nwidely used SC fuzzers: Echidna and Foundry. Furthermore, we conducted a user\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaStateful Greybox Fuzzing\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07389&hl=en&sa=X&d=987875138291859575&ei=qkVMaNPwNqKr6rQPlpCs6Q0&scisig=AAZF9b_6teo9n12SCXA1fbQcy514&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Enhancing Graph Based Models for Automatic Program Repair", "first_label": ["APR"], "second_label": ["Repair", "Graph"], "data": "V Singh, J Srivastava\\xc2\\xa0- International Conference on Soft Computing and its\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware development teams are confronted with substantial problems when it \ncomes to software flaws, which can result in reduced user experience, compromised \nsecurity, and lower reliability. For software systems to be robust and mitigated\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-88039-1_20&hl=en&sa=X&d=4498114304407797139&ei=qkVMaK_bLfiJ6rQPkqSymQY&scisig=AAZF9b9LrBdztlF3BnOO33ftE2p4&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Yuan, Y Xu, J Shi, P Zhou, L Sun\\xc2\\xa0- arXiv preprint arXiv:2505.23561, 2025\nModel merging for Large Language Models (LLMs) directly fuses the parameters of \ndifferent models finetuned on various tasks, creating a unified model for multi-domain \ntasks. However, due to potential vulnerabilities in models available on open-source\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23561&hl=en&sa=X&d=6617189016454156514&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b-hKaNf3ql6GqPXtJeaxsCC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "PandaGuard: Systematic Evaluation of LLM Safety in the Era of Jailbreaking Attacks", "first_label": ["LLM"], "second_label": [], "data": "G Shen, D Zhao, L Feng, X He, J Wang, S Shen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have achieved remarkable capabilities but remain \nvulnerable to adversarial prompts known as jailbreaks, which can bypass safety \nalignment and elicit harmful outputs. Despite growing efforts in LLM safety research\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13862&hl=en&sa=X&d=7957433049052051517&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b8uuohndjng7lcz2CFokw4p&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based Backdoor Attacks for Jailbreaking Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "J Kong, H Fang, X Yang, K Gao, B Chen, ST Xia\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSupervised fine-tuning (SFT) aligns large language models (LLMs) with human \nintent by training them on labeled task-specific data. Recent studies have shown that \nmalicious attackers can inject backdoors into these models by embedding triggers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17601%3F&hl=en&sa=X&d=14932585774719166007&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b-bRcbQ7r2VSTXuEVUTZE69&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack", "first_label": ["LLM"], "second_label": [], "data": "S Cappelletti, T Poppi, S Poppi, ZX Yong\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly evaluated on multiple-choice \nquestion answering (MCQA) tasks using* first-token probability*(FTP), which selects \nthe answer option whose initial token has the highest likelihood. While efficient, FTP\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15323%3F&hl=en&sa=X&d=5513891085179250670&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b8ts6vJnVnPKgZRZk2J59vT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Lifelong Safety Alignment for Language Models", "first_label": ["LLM"], "second_label": [], "data": "H Wang, Z Qin, Y Zhao, C Du, M Lin, X Wang, T Pang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLMs have made impressive progress, but their growing capabilities also expose \nthem to highly flexible jailbreaking attacks designed to bypass safety alignment. \nWhile many existing defenses focus on known types of attacks, it is more critical to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20259%3F&hl=en&sa=X&d=16834372085988299596&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b9d_59vHSVRWjToyCIlG2f5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "PS Pandey, S Simko, K Pelrine, Z Jin\\xc2\\xa0- arXiv preprint arXiv:2505.16789, 2025\nAs large language models gain popularity, their vulnerability to adversarial attacks \nremains a primary concern. While fine-tuning models on domain-specific datasets is \noften employed to improve model performance, it can introduce vulnerabilities within\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16789%3F&hl=en&sa=X&d=9827187220639785834&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b-hRa3CIybDfceUhaRlecWD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution", "first_label": [], "second_label": [], "data": "J Guo, X Wen, W Jiang, C Huang, J Li, H Li\\xc2\\xa0- arXiv preprint arXiv:2505.15308, 2025\nWith the widespread application of super-resolution (SR) in various fields, \nresearchers have begun to investigate its security. Previous studies have \ndemonstrated that SR models can also be subjected to backdoor attacks through\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15308&hl=en&sa=X&d=13335437674086498390&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b8WmdvUXiuzvPutlRNCBmNP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "An Embarrassingly Simple Defense Against LLM Abliteration Attacks", "first_label": ["LLM"], "second_label": [], "data": "HA Shairah, HAAK Hammoud, B Ghanem, G Turkiyyah\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are typically aligned to comply with safety guidelines \nby refusing harmful instructions. A recent attack, termed abliteration, isolates and \nsuppresses the single latent direction most responsible for refusal behavior, enabling\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19056&hl=en&sa=X&d=3737202939224050048&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b8QKV5yRTnfm0WbZVG9RAGO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Poison in the Well: Feature Embedding Disruption in Backdoor Attacks", "first_label": [], "second_label": [], "data": "Z Feng, J Chen, C Zhou, Y Pu, Q Li, S Ji\\xc2\\xa0- arXiv preprint arXiv:2505.19821, 2025\nBackdoor attacks embed malicious triggers into training data, enabling attackers to \nmanipulate neural network behavior during inference while maintaining high \naccuracy on benign inputs. However, existing backdoor attacks face limitations\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19821&hl=en&sa=X&d=8217579378668490954&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b89XZjYdu_nSk8rXx0clM5e&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Backdoor Attack on Vision Language Models with Stealthy Semantic Manipulation", "first_label": ["LLM"], "second_label": [], "data": "Z Zhong, Z Sun, Y Liu, X He, G Tao\\xc2\\xa0- arXiv preprint arXiv:2506.07214, 2025\nVision Language Models (VLMs) have shown remarkable performance, but are also \nvulnerable to backdoor attacks whereby the adversary can manipulate the model's \noutputs through hidden triggers. Prior attacks primarily rely on single-modality\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07214&hl=en&sa=X&d=13852487448298011741&ei=qkVMaITaPKy16rQPz_Hl2Qs&scisig=AAZF9b_pfJDrPo270Aj4VCR1rEcM&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Language Models and Cybersecurity-Applications and Current Limits", "first_label": ["LLM"], "second_label": [], "data": "M Boffa - 2025\nThis thesis explores the intersection of AI and cybersecurity at a time of \nunprecedented technological acceleration. As AI reshapes expectations and \ncapabilities, cyberattacks are also becoming faster, more sophisticated, and \nwidespread. The risk of outpacing security experts is real and demands innovative \nsolutions. In this context, modern AI models, with Large Language Models (LLMs) \nspearheading, offer a promising path forward.\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://tesidottorato.depositolegale.it/bitstream/20.500.14242/210987/1/converted_final_version_thesis.pdf&hl=en&sa=X&d=6212026622236604058&ei=IJdKaPnQILXCieoP_vz9iAU&scisig=AAZF9b_lGqcZOdIDNXNhYPH6L38Z&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang"]}
{"title": "A Mining-Software-Repository study on deprecated API usages in open-source Java software applications", "first_label": [], "second_label": [], "data": "P Cassieri, S Romano, G Scanniello\\xc2\\xa0- Information and Software Technology, 2025\nAbstract Context: A deprecated API (Application Programming Interface) is an API \nthat its original developers no longer recommend using. Although deprecated APIs \n(ie, deprecated fields, methods, and classes) are still implemented, they are likely to \nbe removed in future implementations. Consequently, developers are advised \nagainst using deprecated APIs in newly written code and are encouraged to update \nexisting code to remove any deprecated API usage. Objective: We aimed to gather\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAndroEvolve: Automated Android API update with data flow\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925001211&hl=en&sa=X&d=1236854347499644314&ei=IJdKaNfrIeWs6rQPpf7X-Aw&scisig=AAZF9b_uqvwK9xd-zBoe5gmSzD10&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang"]}
{"title": "PatchScope\\xe2\\x80\\x93A Modular Tool for Annotating and Analyzing Contributions", "first_label": [], "second_label": [], "data": "J Nar\\xc4\\x99bski, M Fejzer, K Stencel, P Przymus\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nPatchScope is a modular framework for analyzing software contributions through \nautomatic code annotation, offering insights beyond traditional metrics. At its core, a \nflexible automatic code annotator labels source code lines based on customizable \nrules, categorizing changes such as documentation, testing, or code updates. \nLeveraging these annotations, PatchScope generates reports with actionable \ninsights for team evaluation and expertise identification. With applications in\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBugsinpy: a database of existing bugs in python programs to\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3713081.3731727&hl=en&sa=X&d=14958408935962562814&ei=IJdKaNfrIeWs6rQPpf7X-Aw&scisig=AAZF9b84KYorDxZvUqZZh6671UUK&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang"]}
{"title": "Can Large Language Models Verify System Software? A Case Study Using FSCQ as a Benchmark", "first_label": ["LLM"], "second_label": [], "data": "J Qin, A Du, D Zhang, M Lentz, D Zhuo\\xc2\\xa0- Proceedings of the 2025 Workshop on Hot\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have demonstrated remarkable coding capabilities. \nThey excel in code synthesis benchmarks across diverse domains and have become \nubiquitous in coding tools. Recently, they have also shown promise in generating\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713082.3730382&hl=en&sa=X&d=13785804118675261186&ei=IJdKaLyTKL_N6rQPzuHnkAg&scisig=AAZF9b8mi85OzbiS7sYulDU8fXJ3&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Xin ZHOU - new related research"]}
{"title": "Trailblazer: Practical End-to-end Web API Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "L Pan, S Cohney, T Murray, VT Pham\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThere are two key challenges in automatically testing web APIs:(a) determine where \nto send API requests and (b) identify how to make a valid payload for a given \nrequest. Both challenges are sometimes addressed by the presence of a machine\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3713081.3731717&hl=en&sa=X&d=13250706246401116236&ei=IJdKaLyTKL_N6rQPzuHnkAg&scisig=AAZF9b_zw8u8QNIWTDFuexbyX64v&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "10 new citations to articles by Abhik Roychoudhury", "Hong Jin Kang - new related research"]}
{"title": "On the Applicability of Benford's Law to Detect Saturation in Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "J Lee, H Lee, S Park, SK Cha\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nKnowing when a fuzzing campaign has reached saturation is crucial for practitioners \nto avoid unnecessarily lengthy campaigns without missing bugs within given \nresources. Unfortunately, existing solutions for determining the saturation point rely\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3713081.3731723&hl=en&sa=X&d=16464785359231774820&ei=IJdKaLyTKL_N6rQPzuHnkAg&scisig=AAZF9b8eVAPEPAehw4HTvQMR6bO8&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Personalized Fuzzing: A Case Study with the FANDANGO Fuzzer on a GNSS Module (Short Paper)", "first_label": ["Fuzzing"], "second_label": [], "data": "S Neuhaus, JAZ Amaya, A Zeller\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFuzzing is a widely used technique for uncovering vulnerabilities in software \nsystems, but traditional fuzzers often struggle with generating valid and meaningful \ntest cases for complex input formats. Grammar-based fuzzers address this issue by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3713081.3731722&hl=en&sa=X&d=5954195594365474187&ei=IJdKaLyTKL_N6rQPzuHnkAg&scisig=AAZF9b8Ap7FR5u6u22s4hMsvZiwq&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "10 new citations to articles by Abhik Roychoudhury", "Hong Jin Kang - new related research"]}
{"title": "KRAKEN: Program-Adaptive Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A ZHOU, H HUANG, C ZHANG - 2025\nDespite numerous advances, most existing fuzzers still require more than 24 hours to \nthoroughly test the target programs to achieve satisfactory code coverage or bug \ndetection results [7, 32, 42, 64]. Recently, as cloud-based computing and multicore\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://seviezhou.github.io/files/kraken.pdf&hl=en&sa=X&d=6944396394299119143&ei=IJdKaLyTKL_N6rQPzuHnkAg&scisig=AAZF9b9QILhkfV1b1x87AW8NkoEo&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FuseApplyBench: Multilingual Benchmark for Trustworthy Code Edit Applying Task", "first_label": ["Code"], "second_label": [], "data": "M Liang, Q Zhang, Z Zuo, S Zheng, D Chen, W Jiang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 34th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the rise of Language Models (LMs) and Large Language Models (LLMs), their \npotential for code editing (CE) has gained attention. An approach is to have LLMs \ngenerate draft code modifications, which are then refined by smaller LMs in further \nCode Editing Apply (CEA). However, CEA is error-prone, and existing benchmarks \ndo not systematically evaluate LLM performance in handling these issues. We \nintroduce FuseApplyBench, a benchmark designed to evaluate LLM performance\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3713081.3732929&hl=en&sa=X&d=7791836070318800823&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b9Diar8Ol3LPSrd8Qng2dXJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research", "Xin ZHOU - new related research"]}
{"title": "NexuSym: Marrying symbolic path finders with large language models", "first_label": ["LLM"], "second_label": [], "data": "J Wang, P Yu, Y Qin, Y Jiang, Y Yao, X Ma\\xc2\\xa0- Automated Software Engineering, 2025\nSymbolic execution is a powerful technique for automated test case generation, \nensuring comprehensive coverage of potential scenarios. However, it often struggles \nwith complex, deep paths due to path explosion. Conversely, large language models \n(LLMs) utilize vast training data to generate test cases that can uncover intricate \nprogram behaviors that symbolic execution might miss. Despite their complementary \nstrengths, integrating the systematic nature of symbolic execution with the creative\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00529-1&hl=en&sa=X&d=16869342251625094567&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b8d53DxM9ykrfgWfU25iopx&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "David Lo - new related research"]}
{"title": "The Havoc Paradox in Generator-Based Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A Li, M Huang, V Vikram, C Lemieux, R Padhye\\xc2\\xa0- ACM Transactions on Software\\xc2\\xa0\\xe2\\x80\\xa6\nParametric generators combine coverage-guided and generator-based fuzzing for \ntesting programs requiring structured inputs. They function as decoders that \ntransform arbitrary byte sequences into structured inputs, allowing mutations on byte \nsequences to map directly to mutations on structured inputs, without requiring \nspecialized mutators. However, this technique is prone to the havoc effect, where \nsmall mutations on the byte sequence cause large, destructive mutations to the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaExplainable fuzzer evaluation\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3742894&hl=en&sa=X&d=13479173031349752511&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b-pGEgKiMnReuBmCg6m-DNm&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Hong Jin Kang - new related research"]}
{"title": "\\xe7\\x89\\xa9\\xe8\\x81\\x94\\xe7\\xbd\\x91\\xe8\\xae\\xbe\\xe5\\xa4\\x87\\xe5\\x9b\\xba\\xe4\\xbb\\xb6\\xe8\\x87\\xaa\\xe5\\x8a\\xa8\\xe5\\x8c\\x96\\xe6\\xbc\\x8f\\xe6\\xb4\\x9e\\xe6\\x8c\\x96\\xe6\\x8e\\x98\\xe6\\x8a\\x80\\xe6\\x9c\\xaf\\xe7\\xa0\\x94\\xe7\\xa9\\xb6\\xe7\\xbb\\xbc\\xe8\\xbf\\xb0.", "first_label": [], "second_label": [], "data": "\\xe5\\x88\\x98\\xe8\\x88\\xaa\\xe5\\xa4\\xa9\\xef\\xbc\\x8c \\xe7\\x94\\x98\\xe6\\xb0\\xb4\\xe6\\xbb\\x94\\xef\\xbc\\x8c \\xe5\\xbc\\xa0\\xe8\\xb6\\x85\\xef\\xbc\\x8c \\xe5\\xbc\\xa0\\xe7\\xba\\xa2\\xe6\\x97\\x97\\xef\\xbc\\x8c \\xe5\\xad\\x99\\xe6\\x96\\x87\\xe5\\x8e\\x9a\\xef\\xbc\\x8c \\xe9\\xab\\x98\\xe5\\xad\\x90\\xe8\\x81\\xaa\\xef\\xbc\\x8c \\xe8\\xb5\\xb5\\xe6\\x95\\x8f\\xe2\\x80\\xa6\\xc2\\xa0- Chinese Journal of Network\\xc2\\xa0\\xe2\\x80\\xa6, 2025\n\\xe9\\x9a\\x8f\\xe7\\x9d\\x80\\xe7\\x89\\xa9\\xe8\\x81\\x94\\xe7\\xbd\\x91\\xe6\\x8a\\x80\\xe6\\x9c\\xaf\\xe7\\x9a\\x84\\xe5\\xb9\\xbf\\xe6\\xb3\\x9b\\xe5\\xba\\x94\\xe7\\x94\\xa8, \\xe7\\x89\\xa9\\xe8\\x81\\x94\\xe7\\xbd\\x91\\xe8\\xae\\xbe\\xe5\\xa4\\x87\\xe7\\x88\\x86\\xe7\\x82\\xb8\\xe5\\xbc\\x8f\\xe5\\xa2\\x9e\\xe9\\x95\\xbf. \\xe8\\xbf\\x91\\xe5\\xb9\\xb4\\xe6\\x9d\\xa5, \\xe7\\x89\\xa9\\xe8\\x81\\x94\\xe7\\xbd\\x91\\xe8\\xae\\xbe\\xe5\\xa4\\x87\\xe5\\xaf\\xbc\\xe8\\x87\\xb4\\xe7\\x9a\\x84\\xe5\\xae\\x89\\xe5\\x85\\xa8\n\\xe4\\xba\\x8b\\xe4\\xbb\\xb6\\xe9\\xa2\\x91\\xe5\\x8f\\x91, \\xe4\\xbd\\xbf\\xe5\\xbe\\x97\\xe7\\x89\\xa9\\xe8\\x81\\x94\\xe7\\xbd\\x91\\xe8\\xae\\xbe\\xe5\\xa4\\x87\\xe5\\xae\\x89\\xe5\\x85\\xa8\\xe7\\xa0\\x94\\xe7\\xa9\\xb6\\xe6\\x88\\x90\\xe4\\xb8\\xba\\xe7\\x83\\xad\\xe7\\x82\\xb9. \\xe9\\xa6\\x96\\xe5\\x85\\x88, \\xe5\\xaf\\xb9\\xe7\\x89\\xa9\\xe8\\x81\\x94\\xe7\\xbd\\x91\\xe8\\xae\\xbe\\xe5\\xa4\\x87\\xe5\\x9b\\xba\\xe4\\xbb\\xb6\\xe7\\x9a\\x84\\xe5\\xae\\x89\\xe5\\x85\\xa8\\xe7\\x89\\xb9\\xe6\\x80\\xa7(\\xe5\\x8c\\x85\\xe6\\x8b\\xac\n\\xe9\\xbb\\x91\\xe7\\x9b\\x92\\xe7\\x89\\xb9\\xe6\\x80\\xa7, \\xe7\\xbd\\x91\\xe7\\xbb\\x9c\\xe7\\x89\\xb9\\xe6\\x80\\xa7\\xe5\\x92\\x8c\\xe5\\xae\\x9a\\xe5\\x88\\xb6\\xe5\\x8c\\x96\\xe7\\x89\\xb9\\xe6\\x80\\xa7) \\xe8\\xbf\\x9b\\xe8\\xa1\\x8c\\xe4\\xba\\x86\\xe6\\xb7\\xb1\\xe5\\x85\\xa5\\xe5\\x89\\x96\\xe6\\x9e\\x90, \\xe8\\xbf\\x99\\xe4\\xba\\x9b\\xe7\\x89\\xb9\\xe6\\x80\\xa7\\xe7\\xbb\\x99\\xe8\\x87\\xaa\\xe5\\x8a\\xa8\\xe5\\x8c\\x96\\xe6\\xbc\\x8f\\xe6\\xb4\\x9e\\xe6\\x8c\\x96\\xe6\\x8e\\x98\\xe5\\xb8\\xa6\\xe6\\x9d\\xa5\\xe4\\xba\\x86\n\\xe6\\x96\\xb0\\xe7\\x9a\\x84\\xe6\\x8c\\x91\\xe6\\x88\\x98. \\xe5\\x9b\\xba\\xe4\\xbb\\xb6\\xe4\\xbb\\xa3\\xe7\\xa0\\x81\\xe9\\x97\\xad\\xe6\\xba\\x90, \\xe8\\xbf\\x90\\xe8\\xa1\\x8c\\xe7\\x8e\\xaf\\xe5\\xa2\\x83\\xe5\\xb0\\x81\\xe9\\x97\\xad, \\xe7\\xbd\\x91\\xe7\\xbb\\x9c\\xe4\\xba\\xa4\\xe4\\xba\\x92\\xe5\\xa4\\x8d\\xe6\\x9d\\x82, \\xe8\\xbd\\xaf\\xe7\\xa1\\xac\\xe4\\xbb\\xb6\\xe9\\xab\\x98\\xe5\\xba\\xa6\\xe5\\xae\\x9a\\xe5\\x88\\xb6\\xe5\\x8c\\x96, \n\\xe8\\xbf\\x99\\xe4\\xba\\x9b\\xe9\\x83\\xbd\\xe5\\xa2\\x9e\\xe5\\x8a\\xa0\\xe4\\xba\\x86\\xe5\\x9b\\xba\\xe4\\xbb\\xb6\\xe5\\xae\\x89\\xe5\\x85\\xa8\\xe5\\x88\\x86\\xe6\\x9e\\x90\\xe7\\x9a\\x84\\xe9\\x9a\\xbe\\xe5\\xba\\xa6. \\xe9\\x92\\x88\\xe5\\xaf\\xb9\\xe8\\xbf\\x99\\xe4\\xba\\x9b\\xe6\\x8c\\x91\\xe6\\x88\\x98, \\xe7\\xa0\\x94\\xe7\\xa9\\xb6\\xe4\\xba\\xba\\xe5\\x91\\x98\\xe7\\xa0\\x94\\xe5\\x8f\\x91\\xe4\\xba\\x86\\xe4\\xb8\\x80\\xe7\\xb3\\xbb\\xe5\\x88\\x97\\xe8\\xa7\\xa3\\xe5\\x86\\xb3\\xe6\\x96\\xb9\\xe6\\xa1\\x88. \n\\xe9\\x80\\x9a\\xe8\\xbf\\x87\\xe5\\xaf\\xb9\\xe7\\x8e\\xb0\\xe6\\x9c\\x89\\xe6\\x96\\x87\\xe7\\x8c\\xae\\xe8\\xbf\\x9b\\xe8\\xa1\\x8c\\xe7\\xbb\\xbc\\xe5\\x90\\x88\\xe5\\x88\\x86\\xe6\\x9e\\x90, \\xe4\\xbb\\x8e\\xe9\\xbb\\x91\\xe7\\x9b\\x92\\xe6\\xa8\\xa1\\xe7\\xb3\\x8a\\xe6\\xb5\\x8b\\xe8\\xaf\\x95, \\xe7\\x81\\xb0\\xe7\\x9b\\x92\\xe6\\xa8\\xa1\\xe7\\xb3\\x8a\\xe6\\xb5\\x8b\\xe8\\xaf\\x95, \\xe9\\x9d\\x99\\xe6\\x80\\x81\\xe7\\xa8\\x8b\\xe5\\xba\\x8f\\xe5\\x88\\x86\\xe6\\x9e\\x90\\xe5\\x92\\x8c\\xe5\\x9b\\xba\\xe4\\xbb\\xb6\\xe9\\x87\\x8d\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://search.ebscohost.com/login.aspx%3Fdirect%3Dtrue%26profile%3Dehost%26scope%3Dsite%26authtype%3Dcrawler%26jrnl%3D2096109X%26AN%3D185234143%26h%3D5HmMjO9hoXcpFWuC8jIFtTMXoM9wM8DrKwPiND9neg2rEtFq3daCsPzC6PvPi8AqJ95fvHEa3TGwTsFRFCCCoA%253D%253D%26crl%3Dc&hl=en&sa=X&d=15048786083317320872&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b9VnHuXL8dCmPQxjw_lYY87&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "High-Trigger Fuzz Testing for Microarchitectural Speculative Execution Vulnerability", "first_label": ["Vulnerabilities", "Fuzzing", "Software Testing"], "second_label": [], "data": "C Lu, S Luo, L Pan\\xc2\\xa0- Computers & Security, 2025\nMicroarchitectural speculative execution vulnerabilities can be utilized to steal \nprivate information and even bypass some defensive programming measures in the \ncode. The difficulty in detecting this vulnerability is ensuring a high triggering \nfrequency of speculative execution. However, existing methods randomly generate \ntest programs with high uncertainty, which lack dependencies relationship between \ncode lines required by speculative execution, resulting in low trigger rates of\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaoo7: Low-overhead defense against spectre attacks via program\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825002561&hl=en&sa=X&d=2804449662848039497&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b_p2fLZckYZuyuFUxzvXkCJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Behind the Hot Fix: Demystifying Hot Fixing Industrial Practices at Z\\xc3\\xbchlke and Beyond", "first_label": [], "second_label": [], "data": "C Hanna, D Elliman, W Emmerich, F Sarro, J Petke - 2025\nRushing a hot fix and having it fail can severely damage a software company's \nreputation, impacting user satisfaction and future business opportunities. Ensuring \nbest practices for emergency bug handling is critical, yet the process remains elusive \nin the industry. We are the first to conduct a study to gain insights on hot fixing \nindustrial practices. We surveyed 24 employees of Z\\xc3\\xbchlke, a midsized IT company \nspecializing in providing software engineering services to clients from different\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTrust Enhancement Issues in Program Repair\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://discovery.ucl.ac.uk/id/eprint/10209388/1/Industrial_Views_on_Hot_Fixing_Software__Open_Questionnaire.pdf&hl=en&sa=X&d=12216522735855445826&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b-I50VB1J436_apVfKuqu6G&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "ParRP: Enabling Space Isolation in Caches with Shared Data", "first_label": [], "second_label": [], "data": "X Wang, R Pellizzoni, H Patel\\xc2\\xa0- 2025 IEEE 31st Real-Time and Embedded\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis work presents an approach to isolate cache space while supporting shared \ndata. Enabling shared data caching is challenging because it causes interference \nmaking it unsuitable for real-time multicores. Unlike prior works, we aim to introduce \nisolation, but our approach enables caching of shared data, and promotes isolated \ncache analysis for individual cores. The crux behind our approach is that shared data \nisolation can be achieved by partitioning the replacement information instead of the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTiming analysis of concurrent programs running on shared cache\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11018778/&hl=en&sa=X&d=14127514159853511929&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b8DN3s9Xje00xC0bLTL0erl&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Exploring Prompt Patterns for Effective Vulnerability Repair in Real-World Code by Large Language Models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Repair"], "data": "Y Luo, B Li, A Singhal, P Tseng, L Zhang, Q Zou, X Sun\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 2025\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown promise in automating code \nvulnerability repair, but their effectiveness in handling real-world code remains \nlimited. This paper investigates the capability of LLMs, in repairing vulnerabilities and \nproposes a systematic approach to enhance their performance through specialized \nprompt engineering. Through extensive evaluation of 5,826 code samples, we found \nthat while LLMs successfully repair vulnerabilities in simple cases, they struggle with\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCodeflaws: a programming competition benchmark for evaluating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3716815.3729010&hl=en&sa=X&d=11942114562078715389&ei=IJdKaKGvJqKr6rQPlpCs6Q0&scisig=AAZF9b_IuH7nZURJP7EbJyXnPdcG&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=9&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "Generating Secure Artificial Intelligence Model Source Code: A Reinforcement Learning Approach", "first_label": ["Code"], "second_label": [], "data": "A Kathikar, B Lazarine, Y Gao, A Shah, S Samtani\\xc2\\xa0- 2025 IEEE Security and Privacy\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe increasing adoption of open-source AI models has introduced critical security \nrisks, as vulnerabilities in AI model source code propagate through the software \nsupply chain. This study presents a reinforcement learning (RL) based framework for\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/spw/2025/664300a265/27k6oIZ3FxC&hl=en&sa=X&d=10624097985797953024&ei=IJdKaNn7JM6r6rQP3rzY-QM&scisig=AAZF9b9DaVhE-p5iCpq9n7L8tTVj&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents", "first_label": ["LLM", "Code"], "second_label": ["Agent", "Reasoning"], "data": "K Hariharan, U Girit, A Wang, J Andreas\\xc2\\xa0- arXiv preprint arXiv:2506.00172, 2025\nBenchmarks for large language models (LLMs) have predominantly assessed short-\nhorizon, localized reasoning. Existing long-horizon suites (eg SWE-bench) rely on \nmanually curated issues, so expanding or tuning difficulty demands expensive\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00172&hl=en&sa=X&d=7723120566071680437&ei=IJdKaNn7JM6r6rQP3rzY-QM&scisig=AAZF9b-MEatAoZUO5Dw1f9NQmtaH&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "BECAAC: A Blockchain and Edge Computing-Assisted Access Control Scheme for Medical Data Sharing", "first_label": ["Blockchain"], "second_label": [], "data": "K Zhao, Z Bao, Y Zhang, H Lei\\xc2\\xa0- IEEE Internet of Things Journal, 2025\nSecuring the sharing of medical data has become a critical issue in the field of \nmedical informatics. Although existing IoMT-based medical data sharing systems \nprioritize data security, anonymity, and operational efficiency during transmission, \nthey still exhibit significant shortcomings in preventing unauthorized access and \nestablishing effective accountability mechanisms. Therefore, a solution is urgently \nneeded to ensure fine-grained access control and accountability during data sharing\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11025815/&hl=en&sa=X&d=8257800659657886567&ei=IJdKaJi7I72W6rQPjI6v-QY&scisig=AAZF9b-9SLHS5u1fhMXgsrtlpqb2&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["1 new citation to articles by Bach Le"]}
{"title": "Evaluatiing the efficacy of LLM Safety Solutions: The Palit Benchmark Dataset", "first_label": ["LLM"], "second_label": [], "data": "S Palit, D Woods\\xc2\\xa0- arXiv preprint arXiv:2505.13028, 2025\nLarge Language Models (LLMs) are increasingly integrated into critical systems in \nindustries like healthcare and finance. Users can often submit queries to LLM-\nenabled chatbots, some of which can enrich responses with information retrieved\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13028%3F&hl=en&sa=X&d=1273460049730580919&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b9ByON4eaZyjRTpM1-cA_zU&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Ip leakage attacks targeting llm-based multi-agent systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Wang, W Wang, S Wang, Z Li, Z Ji, Z Lyu, D Wu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Large Language Models (LLMs) has led to the \nemergence of Multi-Agent Systems (MAS) to perform complex tasks through \ncollaboration. However, the intricate nature of MAS, including their architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12442&hl=en&sa=X&d=8825331941370095164&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b_j6hKF2Zy8dNMOx-tobM6E&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning", "first_label": ["LLM"], "second_label": [], "data": "P Yang, Q Wang, Z Huang, T Liu, C Zhang, B Han\\xc2\\xa0- arXiv preprint arXiv:2505.11953, 2025\nLoss reweighting has shown significant benefits for machine unlearning with large \nlanguage models (LLMs). However, their exact functionalities are left unclear and the \noptimal strategy remains an open question, thus impeding the understanding and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11953%3F&hl=en&sa=X&d=10115741309441283535&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b_qGRbxQa3QaxEAOlNnGTTW&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Ripple Effect: On Unforeseen Complications of Backdoor Attacks", "first_label": [], "second_label": [], "data": "R Zhang, Y Shen, H Li, W Jiang, H Chen, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent research highlights concerns about the trustworthiness of third-party Pre-\nTrained Language Models (PTLMs) due to potential backdoor attacks. These \nbackdoored PTLMs, however, are effective only for specific pre-defined downstream\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11586&hl=en&sa=X&d=15157304470732077928&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b997v4XRj8-KVQslhBMZvqE&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "first_label": ["LLM"], "second_label": [], "data": "G Chen, F Song, Z Zhao, X Jia, Y Liu, Y Qiao, W Zhang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreak attacks to Large audio-language models (LALMs) are studied recently, but \nthey achieve suboptimal effectiveness, applicability, and practicability, particularly, \nassuming that the adversary can fully manipulate user prompts. In this work, we first\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14103&hl=en&sa=X&d=12355582258955555442&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b84twuHlVXU1hPFciKO3AfT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Securing AI Agents with Information-Flow Control", "first_label": [], "second_label": ["Agent"], "data": "M Costa, B K\\xc3\\xb6pf, A Kolluri, A Paverd, M Russinovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI agents become increasingly autonomous and capable, ensuring their security \nagainst vulnerabilities such as prompt injection becomes critical. This paper explores \nthe use of information-flow control (IFC) to provide security guarantees for AI agents\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23643%3F&hl=en&sa=X&d=4534448032257376326&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b-ruPZ7fbYUs0K6HirRZr2z&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "sudoLLM: On Multi-role Alignment of Language Models", "first_label": ["LLM"], "second_label": [], "data": "S Saha, A Chaturvedi, J Mahapatra, U Garain\\xc2\\xa0- arXiv preprint arXiv:2505.14607, 2025\nUser authorization-based access privileges are a key feature in many safety-critical \nsystems, but have thus far been absent from the large language model (LLM) realm. \nIn this work, drawing inspiration from such access control systems, we introduce\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14607&hl=en&sa=X&d=17656541914978309178&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b8_EqIyi95cbbheLEpLAFw7&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadDepth: Backdoor Attacks Against Monocular Depth Estimation in the Physical World", "first_label": [], "second_label": [], "data": "J Guo, L Zhou, Z Wang, J He, Q Song, A Chen, W Jiang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, deep learning-based Monocular Depth Estimation (MDE) models \nhave been widely applied in fields such as autonomous driving and robotics. \nHowever, their vulnerability to backdoor attacks remains unexplored. To fill the gap in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16154%3F&hl=en&sa=X&d=5415910119131408953&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b_P0jMEgHvYQo3O-kEno08o&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "P He, Y Xing, S Dong, J Li, Z Dai, X Tang, H Liu, H Xu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis paper argues that a comprehensive vulnerability analysis is essential for \nbuilding trustworthy Large Language Model-based Multi-Agent Systems (LLM-MAS). \nThese systems, which consist of multiple LLM-powered agents working\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.01245&hl=en&sa=X&d=2053462704520065028&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b_Rn4q6OeIutC2KAxU8lQwB&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Variance-Based Defense Against Blended Backdoor Attacks", "first_label": [], "second_label": [], "data": "S Aseervatham, A Kerzazi, Y Bennani\\xc2\\xa0- arXiv preprint arXiv:2506.01444, 2025\nBackdoor attacks represent a subtle yet effective class of cyberattacks targeting AI \nmodels, primarily due to their stealthy nature. The model behaves normally on clean \ndata but exhibits malicious behavior only when the attacker embeds a specific trigger\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.01444&hl=en&sa=X&d=9260748938123526683&ei=IJdKaI_yKsOr6rQP277P8QY&scisig=AAZF9b9XaYcfgGaLkEqjewL_RjNC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
