{"title": "Today's Cat Is Tomorrow's Dog: Accounting for Time-Based Changes in the Labels of ML Vulnerability Detection Approaches", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "R Paramitha, Y Feng, F Massacci\\xc2\\xa0- arXiv preprint arXiv:2506.11939, 2025\nVulnerability datasets used for ML testing implicitly contain retrospective information. \nWhen tested on the field, one can only use the labels available at the time of training \nand testing (eg seen and assumed negatives). As vulnerabilities are discovered\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11939&hl=en&sa=X&d=7396654833478791244&ei=RKFUaJ-OOL2W6rQPs9Oj8A8&scisig=AAZF9b8RSR_Fu6-_XddqhzZfeQAS&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "David Lo - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "On the value of imbalance loss functions in enhancing deep learning-based vulnerability detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "X Ma, Y He, J Keung, C Tan, C Ma, W Hu, F Li\\xc2\\xa0- Expert Systems with Applications, 2025\nSoftware vulnerability detection is crucial in software engineering and information \nsecurity, and deep learning has been demonstrated to be effective in this domain. \nHowever, the class imbalance issue, where non-vulnerable code snippets vastly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0957417425021232&hl=en&sa=X&d=15544835357902509315&ei=RKFUaJ-OOL2W6rQPs9Oj8A8&scisig=AAZF9b9BqwLA-nDXnXXJORrWdJSz&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=1&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "AST2CVCode: A New Benchmark Dataset for Source Code Generation on Computer Vision Applications", "first_label": ["Code"], "second_label": ["Generation"], "data": "WS Alshehri, SK Jarraya, AA Allinjawi\\xc2\\xa0- International Conference on Advanced\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBenchmark datasets are important in evaluating various methods for source code \ngeneration tasks. In this paper, we present AST2CVCode, a new benchmark dataset \nto enhance deep learning models for source code generation. AST2CVCode is\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-91337-2_46&hl=en&sa=X&d=15545214955806460595&ei=RKFUaJ-OOL2W6rQPs9Oj8A8&scisig=AAZF9b-xEY_Bo700rs_NZO5gdshG&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "Xin ZHOU - new related research"]}
{"title": "Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Zheng, X Qian, H Zhou, S Yang, Y He, S Jana\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models (LMs) show promise for vulnerability detection but struggle with \nlong, real-world code due to sparse and uncertain vulnerability locations. These \nissues, exacerbated by token limits, often cause models to miss vulnerability-related\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17460&hl=en&sa=X&d=9334848497739178959&ei=RKFUaIKaL9GM6rQPs-LTyAw&scisig=AAZF9b_EDz61GJXVBfE-c2mGro5g&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "SoK: Automated Vulnerability Repair: Methods, Tools, and Assessments", "first_label": ["Vulnerabilities"], "second_label": ["Repair"], "data": "Y Hu, Z Li, K Shu, S Guan, D Zou, S Xu, B Yuan, H Jin\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe increasing complexity of software has led to the steady growth of vulnerabilities. \nVulnerability repair investigates how to fix software vulnerabilities. Manual \nvulnerability repair is labor-intensive and time-consuming because it relies on\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11697&hl=en&sa=X&d=1586849492069727877&ei=RKFUaIKaL9GM6rQPs-LTyAw&scisig=AAZF9b-UwcDKYGCv86RM_879inEm&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "David Lo - new related research", "1 new citation to articles by Quang-Cuong Bui", "4 new citations to articles by Abhik Roychoudhury", "2 new citations to articles by Xin ZHOU"]}
{"title": "Code Researcher: Deep Research Agent for Large Systems Code and Commit History", "first_label": ["Code"], "second_label": ["Agent", "Search"], "data": "R Singh, S Joel, A Mehrotra, N Wadhwa, RB Bairi\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Model (LLM)-based coding agents have shown promising results \non coding benchmarks, but their effectiveness on systems code remains \nunderexplored. Due to the size and complexities of systems code, making changes\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11060&hl=en&sa=X&d=7875177951630700932&ei=RKFUaIKaL9GM6rQPs-LTyAw&scisig=AAZF9b-QocjibKVRH9ufl5cBXRDX&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "4 new citations to articles by Abhik Roychoudhury", "5 new citations to articles by Abhik Roychoudhury"]}
{"title": "Retrieval-Augmented Code Review Comment Generation", "first_label": ["Code Review", "Code"], "second_label": ["Generation"], "data": "H Hong, J Baik\\xc2\\xa0- arXiv preprint arXiv:2506.11591, 2025\nAutomated code review comment generation (RCG) aims to assist developers by \nautomatically producing natural language feedback for code changes. Existing \napproaches are primarily either generation-based, using pretrained language\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11591&hl=en&sa=X&d=15885059784306332833&ei=RKFUaJ6NNYOuieoPyIM7&scisig=AAZF9b-1WT7RGxAC1bABTNtyDxhD&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "2 new citations to articles by Xin ZHOU", "Hong Jin Kang - new related research"]}
{"title": "code_transformed: The Influence of Large Language Models on Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "Y Xu, S Huang, M Geng, Y Wan, X Shi, D Chen\\xc2\\xa0- arXiv preprint arXiv:2506.12014, 2025\nCoding remains one of the most fundamental modes of interaction between humans \nand machines. With the rapid advancement of Large Language Models (LLMs), code \ngeneration capabilities have begun to significantly reshape programming practices\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12014&hl=en&sa=X&d=13040724238197518006&ei=RKFUaJ6NNYOuieoPyIM7&scisig=AAZF9b83Wh5hHvcdqJElON6kZQVk&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "TRITAG RECOMMENDER: A HYBRID APPROACH TO STACK OVERFLOW TAG PREDICTION USING TRANSFORMERS AND KEYWORD EXTRACTION", "first_label": [], "second_label": [], "data": "M KOLLA, SRAO BURAGA, SB KOMMINA, J KAVITHA\\xe2\\x80\\xa6\\xc2\\xa0- Journal of Theoretical and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCommunity question-answering (CQA) platforms offer new opportunities for users to \nshare knowledge online. Tags are added to data on these platforms to define, \nclassify, and discover the information. Accurate tags help find users to answer the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=http://www.jatit.org/volumes/Vol103No11/34Vol103No11.pdf&hl=en&sa=X&d=16074818835293450120&ei=RKFUaJ6NNYOuieoPyIM7&scisig=AAZF9b-U-bF0qqrAUMeRq1J-2uFd&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Invocable APIs derived from NL2SQL datasets for LLM Tool-Calling Evaluation", "first_label": ["LLM"], "second_label": [], "data": "B Elder, A Murthi, J Kang, AR Naik, K Kate, K Basu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are routinely deployed as agentic systems, with \naccess to tools that interact with live environments to accomplish tasks. In enterprise \ndeployments these systems need to interact with API collections that can be\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11266&hl=en&sa=X&d=12367842913750027747&ei=RKFUaJ6NNYOuieoPyIM7&scisig=AAZF9b92WAoZBXEDjoawXtjdB18D&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Leveraging GPT-4 for Vulnerability-Witnessing Unit Test Generation", "first_label": ["Vulnerabilities", "LLM", "Software Testing"], "second_label": ["Generation"], "data": "G Antal, D B\\xc3\\xa1n, M Isztin, R Ferenc, P Heged\\xc5\\xb1s\\xc2\\xa0- arXiv preprint arXiv:2506.11559, 2025\nIn the life-cycle of software development, testing plays a crucial role in quality \nassurance. Proper testing not only increases code coverage and prevents \nregressions but it can also ensure that any potential vulnerabilities in the software\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11559&hl=en&sa=X&d=10425241990739887145&ei=RKFUaJ6NNYOuieoPyIM7&scisig=AAZF9b_oNjI4ryy2xEdrHuArFTne&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Using Large Language Models to Support the Workflow of Differential Testing", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "AK Vajjala, AK Vajjala, C Badea, C Bird, J D'Souza\\xe2\\x80\\xa6 - 2025\nMany software development teams use differential testing as a quality gate in their \nrelease process. Differential testing\\xe2\\x80\\x94namely, comparing behavioral differences \nbetween a system in production and a system in test\\xe2\\x80\\x94is a laborious process to label\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.arunkv.com/HTML/assets/img/DiffViewer.pdf&hl=en&sa=X&d=15946148542503293941&ei=RKFUaJ6NNYOuieoPyIM7&scisig=AAZF9b_fJeY6V8bEK2zoUrBfuSX_&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Technical Debt of Software Projects Based on Merge Code Comments", "first_label": ["Code"], "second_label": [], "data": "MHM de Ara\\xc3\\xbajo, C Costa, A Font\\xc3\\xa3o\\xc2\\xa0- Journal of Software Engineering Research and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDevelopers use code comments for a variety of reasons, such as explaining code, \ndocumenting specifications, communicating with other developers, and highlighting \nupcoming tasks. Software projects with minimal documentation often have a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://journals-sol.sbc.org.br/index.php/jserd/article/view/4801&hl=en&sa=X&d=15287621864696684133&ei=RKFUaJ6NNYOuieoPyIM7&scisig=AAZF9b-nmzp_DNqMpArU9G9Z06ag&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Future of AI4SE: From Code Generation to Software Engineering?", "first_label": ["Code"], "second_label": ["Generation"], "data": "B Ray\nThe rise of AI-driven code generation tools like GitHub CoPilot, Cursor AI, etc., have \nrevolutionized software development by automating routine tasks and accelerating \ncoding processes. However, a gap persists between generated code and real-world\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11025797/&hl=en&sa=X&d=17394308342072499366&ei=RKFUaJ6NNYOuieoPyIM7&scisig=AAZF9b_kl7V6hb61yEgNb_oOBYUn&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software Security Tasks", "first_label": ["LLM"], "second_label": ["Agent"], "data": "H Lee, Z Zhang, H Lu, L Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.11791, 2025\nRigorous security-focused evaluation of large language model (LLM) agents is \nimperative for establishing trust in their safe deployment throughout the software \ndevelopment lifecycle. However, existing benchmarks largely rely on synthetic \nchallenges or simplified vulnerability datasets that fail to capture the complexity and \nambiguity encountered by security engineers in practice. We introduce SEC-bench, \nthe first fully automated benchmarking framework for evaluating LLM agents on\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11791&hl=en&sa=X&d=15722802865144390580&ei=RKFUaNbUMKy16rQPzoCEgAc&scisig=AAZF9b-9NAzBCCk4Ce9hZT-DdJn5&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang"]}
{"title": "Security Degradation in Iterative AI Code Generation--A Systematic Analysis of the Paradox", "first_label": ["Code"], "second_label": ["Generation"], "data": "S Shukla, H Joshi, R Syed\\xc2\\xa0- arXiv preprint arXiv:2506.11022, 2025\nThe rapid adoption of Large Language Models (LLMs) for code generation has \ntransformed software development, yet little attention has been given to how security \nvulnerabilities evolve through iterative LLM feedback. This paper analyzes security \ndegradation in AI-generated code through a controlled experiment with 400 code \nsamples across 40 rounds of\" improvements\" using four distinct prompting strategies. \nOur findings show a 37.6% increase in critical vulnerabilities after just five iterations\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11022&hl=en&sa=X&d=15590425410352158374&ei=RKFUaOXlLdzM6rQPmJLS4Q8&scisig=AAZF9b_VXlhpI6ykkgcE0TrNTLEU&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 new citation to articles by Thanh Le-Cong", "3 new citations to articles by Bach Le"]}
{"title": "DepState: Detecting Synchronization Failure Bugs in Distributed Database Management Systems", "first_label": ["Bug"], "second_label": ["Detection"], "data": "C FANG, JIE LIANG, Z WU, J FU, Z JIA, C HUANG\\xe2\\x80\\xa6 - 2025\nDepState: Detecting Synchronization Failure Bugs in Distributed Database \nManagement Systems ISSTA088: 3 is difficult, as these changes must align with \ndynamic conditions within the cluster. Moreover, the expansive state space \ncomplicates generating sequences that could trigger issues, as many \nsynchronization failures only appear under specific timing and execution conditions. \nIn order to address these challenges, DepState is introduced as a fuzzing framework\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaGreybox fuzzing of distributed systems\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://leopard-lab.github.io/paper/ISSTA2025-CundiFang.pdf&hl=en&sa=X&d=6932913758994464876&ei=RKFUaM_XNuWs6rQPkO7OyQk&scisig=AAZF9b_7ijSFvXXG42589UTLbPlY&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "GNN-Attention Framework for Efficient Test Path Coverage in Software Testing Using Control Flow Graphs", "first_label": ["Software Testing", "Static Analysis"], "second_label": ["Graph"], "data": "NK Musham, R Pushpakumar\nTraditional test-generating methodologies are unsuccessful in modern software \nengineering because of path explosion, redundancy, and inadequate failure \ndetection, which are caused by the dynamic behaviour and complexity of systems. In \norder to optimise test pathways from Control Flow Graphs (CFGs), this study offers a \nnovel deep learning strategy that combines attention processes with Graph Neural \nNetworks (GNNs). More fault discovery with fewer test cases is made possible by the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart greybox fuzzing\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Pushpakumar-Ranganathan/publication/392698812_GNN-Attention_Framework_for_Efficient_Test_Path_Coverage_in_Software_Testing_Using_Control_Flow_Graphs/links/684e5c517869fe75c5594541/GNN-Attention-Framework-for-Efficient-Test-Path-Coverage-in-Software-Testing-Using-Control-Flow-Graphs.pdf&hl=en&sa=X&d=17530488658865760384&ei=RKFUaM_XNuWs6rQPkO7OyQk&scisig=AAZF9b8g--1nnoW2PTIWxkfulxSA&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Visualization Task Taxonomy to Understand the Fuzzing Internals", "first_label": ["Fuzzing"], "second_label": [], "data": "S Kummita, M Miao, E Bodden, S Wei\\xc2\\xa0- ACM Transactions on Software Engineering\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGreybox fuzzing is used extensively in research and practice. There are umpteen \npublications that improve greybox fuzzing. However, to what extent do these \nimprovements affect the internal components or internals of a given fuzzer is not yet\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3718346&hl=en&sa=X&d=6310038100822609560&ei=RKFUaLzROc6r6rQPxrLf-As&scisig=AAZF9b_Ue_jmzHRI425oDGHolQub&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Enhancing Differential Fuzzing of Cryptographic Libraries with Sustainable Hybrid Fuzzing and Crypto-Specific Mutation", "first_label": ["Fuzzing"], "second_label": ["Graph"], "data": "J Jung, T Kwon\\xc2\\xa0- International Conference on Information Security and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCryptographic libraries are essential to any system, safeguarding privacy and \nprotecting data from cyber threats. However, the structured input requirements and \nthe inherent complexity of cryptographic algorithms pose significant challenges in\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-96-5566-3_10&hl=en&sa=X&d=14719529796060879387&ei=RKFUaLzROc6r6rQPxrLf-As&scisig=AAZF9b_d0WK4xjxLqOMKsY7N6-eb&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Smart Public Finance: Leveraging AI to Optimize Government Expenditures and Investments", "first_label": [], "second_label": [], "data": "AL Paul\nEffective management of government expenditures and investments is crucial for \npromoting sustainable economic growth and ensuring public welfare. Traditional \npublic finance methods face challenges such as inefficiencies, limited transparency, \nand difficulties in forecasting due to complex economic environments. Artificial \nIntelligence (AI) offers transformative potential to enhance government financial \nmanagement through advanced data analytics, predictive modeling, fraud detection\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Anthony-Paul-2/publication/392705944_Smart_Public_Finance_Leveraging_AI_to_Optimize_Government_Expenditures_and_Investments/links/684e74b1df3fa4286a40cdd6/Smart-Public-Finance-Leveraging-AI-to-Optimize-Government-Expenditures-and-Investments.pdf&hl=en&sa=X&d=633677533021131115&ei=RKFUaJ-TMvfWieoP1-jt-QU&scisig=AAZF9b-Xq19gJpr-jgFTw_h3i96r&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "Policy Readiness for Tech-Driven Auditing and Public Finance Systems in Low-Income Economies", "first_label": [], "second_label": [], "data": "R Ajax\nThe integration of technology into auditing and public finance systems presents a \ntransformative opportunity for enhancing transparency, accountability, and efficiency \nin government operations. However, in low-income economies, the success of such \ndigital transformations hinges significantly on policy readiness. This paper critically \nexamines the current state of policy preparedness for tech-driven auditing and \nfinancial oversight systems in low-income countries. Drawing from global\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Raymond-Ajax/publication/392706129_Policy_Readiness_for_Tech-Driven_Auditing_and_Public_Finance_Systems_in_Low-Income_Economies/links/684e790f7869fe75c55948a8/Policy-Readiness-for-Tech-Driven-Auditing-and-Public-Finance-Systems-in-Low-Income-Economies.pdf&hl=en&sa=X&d=4157875617578753773&ei=RKFUaJ-TMvfWieoP1-jt-QU&scisig=AAZF9b9kPlbMyKbRPYJZ0mCfCfZf&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR)| 979-8-3315-0183-9/25/$31.00\\xc2\\xa9 2025 IEEE| DOI: 10.1109/MSR66628\\xc2\\xa0\\xe2\\x80\\xa6", "first_label": [], "second_label": [], "data": "A Abdellatif, I Abdelmadjid, S Abedu, S Abid, I Adaji\\xe2\\x80\\xa6\nAuthor Index Page 1 Author Index Abdellatif, Ahmad 349, 359 Abdelmadjid, Idriss 846 \n\\r\\nAbedu, Samuel 255 Abid, Shamsa 478 Adaji, Ifeoma 606 Adewole, Folajinmi 750 \n\\r\\nAdnan, Ahmed 86 Ahmed, Faiz 750 Ahmed, Iftekhar 686 Ahmed, Nafisa 199 Ahmed\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/11025548/11025536/11025798.pdf&hl=en&sa=X&d=1771036948474416193&ei=RaFUaP-GBdzM6rQPmJLS4Q8&scisig=AAZF9b9NnoTJO1mCPuLCpRMK1vk2&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Identifying Helpful Context for LLM-based Vulnerability Repair: A Preliminary Study", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Repair"], "data": "G Antal, B Bogenf\\xc3\\xbcrst, R Ferenc, P Heged\\xc5\\xb1s\\xc2\\xa0- arXiv preprint arXiv:2506.11561, 2025\nRecent advancements in large language models (LLMs) have shown promise for \nautomated vulnerability detection and repair in software systems. This paper \ninvestigates the performance of GPT-4o in repairing Java vulnerabilities from a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11561&hl=en&sa=X&d=18395494134633245315&ei=RaFUaNq_A6u26rQPmuu-OA&scisig=AAZF9b9hEecaGcZAuBlwTMvwXjql&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Investigating the Relationship Between Quality and Prompt Specificity in Source Code Generation by LLM", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "L Nomoto, H Takuma\\xc2\\xa0- Computer and Information Science and Engineering, 2025\nIn this study aims to provide a methodology for generating source code based on \nnatural language prompts and analyze the impact of detailed development \ndocumentation on the quality of software constructed using the generated source\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-82606-1_7&hl=en&sa=X&d=17639593866163138761&ei=RaFUaNq_A6u26rQPmuu-OA&scisig=AAZF9b8qv1mMhYUFuJPYX35c_Usl&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "PandaGuard: Systematic Evaluation of LLM Safety in the Era of Jailbreaking Attacks", "first_label": ["LLM"], "second_label": [], "data": "G Shen, D Zhao, L Feng, X He, J Wang, S Shen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have achieved remarkable capabilities but remain \nvulnerable to adversarial prompts known as jailbreaks, which can bypass safety \nalignment and elicit harmful outputs. Despite growing efforts in LLM safety research\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13862&hl=en&sa=X&d=7957433049052051517&ei=RaFUaIDjAdSWieoP9obCkQw&scisig=AAZF9b8uuohndjng7lcz2CFokw4p&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift", "first_label": ["LLM"], "second_label": [], "data": "S Liang, J Liang, T Pang, C Du, A Liu, M Zhu, X Cao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInstruction tuning enhances large vision-language models (LVLMs) but increases \ntheir vulnerability to backdoor attacks due to their open design. Unlike prior studies in \nstatic settings, this paper explores backdoor attacks in LVLM instruction tuning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.pdf&hl=en&sa=X&d=5142527777954789704&ei=RaFUaIDjAdSWieoP9obCkQw&scisig=AAZF9b_Zz7b9xsyiBVRqo7nDX3YO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, M Dras, U Naseem\\xc2\\xa0- arXiv preprint arXiv:2506.02442, 2025\nThis paper presents a systematic evaluation of Large Language Models'(LLMs) \nbehavior on long-tail distributed (encrypted) texts and their safety implications. We \nintroduce a two-dimensional framework for assessing LLM safety:(1) instruction\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02442&hl=en&sa=X&d=15102350404536711280&ei=RaFUaIDjAdSWieoP9obCkQw&scisig=AAZF9b_4gGVOvmiHUrKGvn2E4Vhh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack", "first_label": ["LLM"], "second_label": [], "data": "S Cappelletti, T Poppi, S Poppi, ZX Yong\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly evaluated on multiple-choice \nquestion answering (MCQA) tasks using* first-token probability*(FTP), which selects \nthe answer option whose initial token has the highest likelihood. While efficient, FTP\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15323%3F&hl=en&sa=X&d=5513891085179250670&ei=RaFUaIDjAdSWieoP9obCkQw&scisig=AAZF9b8ts6vJnVnPKgZRZk2J59vT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems", "first_label": ["LLM"], "second_label": ["Agent", "Search"], "data": "X Li, J Chen, X Fang, S Ding, H Duan, Q Liu, K Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown remarkable capabilities in solving \ndiverse tasks. However, their proficiency in iteratively optimizing complex solutions \nthrough learning from previous feedback remains insufficiently explored. To bridge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10764&hl=en&sa=X&d=1134890120116902745&ei=RaFUaIDjAdSWieoP9obCkQw&scisig=AAZF9b8s_mGNSGwzfKFs6o2hgsbd&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Evaluatiing the efficacy of LLM Safety Solutions: The Palit Benchmark Dataset", "first_label": ["LLM"], "second_label": [], "data": "S Palit, D Woods\\xc2\\xa0- arXiv preprint arXiv:2505.13028, 2025\nLarge Language Models (LLMs) are increasingly integrated into critical systems in \nindustries like healthcare and finance. Users can often submit queries to LLM-\nenabled chatbots, some of which can enrich responses with information retrieved\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13028%3F&hl=en&sa=X&d=1273460049730580919&ei=RaFUaIDjAdSWieoP9obCkQw&scisig=AAZF9b9ByON4eaZyjRTpM1-cA_zU&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents", "first_label": ["LLM", "Code"], "second_label": ["Agent", "Reasoning"], "data": "K Hariharan, U Girit, A Wang, J Andreas\\xc2\\xa0- arXiv preprint arXiv:2506.00172, 2025\nBenchmarks for large language models (LLMs) have predominantly assessed short-\nhorizon, localized reasoning. Existing long-horizon suites (eg SWE-bench) rely on \nmanually curated issues, so expanding or tuning difficulty demands expensive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00172&hl=en&sa=X&d=7723120566071680437&ei=RaFUaIDjAdSWieoP9obCkQw&scisig=AAZF9b-MEatAoZUO5Dw1f9NQmtaH&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Design Patterns for Securing LLM Agents against Prompt Injections", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Beurer-Kellner, BBAM Cre\\xc5\\xa3u, E Debenedetti\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI agents powered by Large Language Models (LLMs) become increasingly \nversatile and capable of addressing a broad spectrum of tasks, ensuring their \nsecurity has become a critical challenge. Among the most pressing threats are\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08837%3F&hl=en&sa=X&d=2124308329893910985&ei=RaFUaIDjAdSWieoP9obCkQw&scisig=AAZF9b_-0v3jQvYQnBMGXbIp-l3k&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution", "first_label": [], "second_label": [], "data": "J Guo, X Wen, W Jiang, C Huang, J Li, H Li\\xc2\\xa0- arXiv preprint arXiv:2505.15308, 2025\nWith the widespread application of super-resolution (SR) in various fields, \nresearchers have begun to investigate its security. Previous studies have \ndemonstrated that SR models can also be subjected to backdoor attacks through\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15308&hl=en&sa=X&d=13335437674086498390&ei=RaFUaIDjAdSWieoP9obCkQw&scisig=AAZF9b8WmdvUXiuzvPutlRNCBmNP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "first_label": ["LLM"], "second_label": [], "data": "G Chen, F Song, Z Zhao, X Jia, Y Liu, Y Qiao, W Zhang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreak attacks to Large audio-language models (LALMs) are studied recently, but \nthey achieve suboptimal effectiveness, applicability, and practicability, particularly, \nassuming that the adversary can fully manipulate user prompts. In this work, we first\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14103&hl=en&sa=X&d=12355582258955555442&ei=RaFUaIDjAdSWieoP9obCkQw&scisig=AAZF9b84twuHlVXU1hPFciKO3AfT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Training Language Models to Generate Quality Code with Program Analysis Feedback", "first_label": ["LLM", "Code"], "second_label": [], "data": "F Yao, Z Wang, L Liu, J Cui, L Zhong, X Fu, H Mai\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode generation with large language models (LLMs), often termed vibe coding, is \nincreasingly adopted in production but fails to ensure code quality, particularly in \nsecurity (eg, SQL injection vulnerabilities) and maintainability (eg, missing type\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22704&hl=en&sa=X&d=13720297852295427429&ei=0hpTaOizIKalieoP6s6swAY&scisig=AAZF9b9qU1hJff-ona5ynwmi0w3O&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Your Agent Can Defend Itself against Backdoor Attacks", "first_label": [], "second_label": ["Agent"], "data": "L Changjiang, L Jiacheng, C Bochuan, C Jinghui\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite their growing adoption across domains, large language model (LLM)-\npowered agents face significant security risks from backdoor attacks during training \nand fine-tuning. These compromised agents can subsequently be manipulated to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08336&hl=en&sa=X&d=9281612337423238890&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b8EnIakTDvZQGsyv1duPVA5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Adversarial Preference Learning for Robust LLM Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Wang, P Wang, C Xi, B Tang, J Zhu, W Wei, C Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern language models often rely on Reinforcement Learning from Human \nFeedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to \nadversarial attacks due to three key limitations:(1) the inefficiency and high cost of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24369%3F&hl=en&sa=X&d=11526575995055803369&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b_ilBi9AMSJoKPXxHc_hWg5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Yuan, Y Xu, J Shi, P Zhou, L Sun\\xc2\\xa0- arXiv preprint arXiv:2505.23561, 2025\nModel merging for Large Language Models (LLMs) directly fuses the parameters of \ndifferent models finetuned on various tasks, creating a unified model for multi-domain \ntasks. However, due to potential vulnerabilities in models available on open-source\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23561&hl=en&sa=X&d=6617189016454156514&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b-hKaNf3ql6GqPXtJeaxsCC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based Backdoor Attacks for Jailbreaking Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "J Kong, H Fang, X Yang, K Gao, B Chen, ST Xia\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSupervised fine-tuning (SFT) aligns large language models (LLMs) with human \nintent by training them on labeled task-specific data. Recent studies have shown that \nmalicious attackers can inject backdoors into these models by embedding triggers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17601%3F&hl=en&sa=X&d=14932585774719166007&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b-bRcbQ7r2VSTXuEVUTZE69&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge", "first_label": ["LLM"], "second_label": [], "data": "S Li, C Xu, J Wang, X Gong, C Chen, J Zhang, J Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable intelligence across \nvarious tasks, which has inspired the development and widespread adoption of LLM-\nas-a-Judge systems for automated model testing, such as red teaming and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09443&hl=en&sa=X&d=2052322274134661445&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b9u9cyhYi06xXXt37CLZpdh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Syntactic paraphrase-based synthetic data generation for backdoor attacks against Chinese language models", "first_label": ["LLM"], "second_label": ["Generation"], "data": "M Hu, Y Yang, D Pan, Z Guo, L Xiao, D Lin, S Zhao\\xc2\\xa0- Information Fusion, 2025\nAbstract Language Models (LMs) have shown significant advancements in various \nNatural Language Processing (NLP) tasks. However, recent studies indicate that \nLMs are particularly susceptible to malicious backdoor attacks, where attackers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S156625352500449X&hl=en&sa=X&d=11939540759867308872&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b_omHEFDqgnSwVne_pfKwnY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Lifelong Safety Alignment for Language Models", "first_label": ["LLM"], "second_label": [], "data": "H Wang, Z Qin, Y Zhao, C Du, M Lin, X Wang, T Pang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLMs have made impressive progress, but their growing capabilities also expose \nthem to highly flexible jailbreaking attacks designed to bypass safety alignment. \nWhile many existing defenses focus on known types of attacks, it is more critical to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20259%3F&hl=en&sa=X&d=16834372085988299596&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b9d_59vHSVRWjToyCIlG2f5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "PS Pandey, S Simko, K Pelrine, Z Jin\\xc2\\xa0- arXiv preprint arXiv:2505.16789, 2025\nAs large language models gain popularity, their vulnerability to adversarial attacks \nremains a primary concern. While fine-tuning models on domain-specific datasets is \noften employed to improve model performance, it can introduce vulnerabilities within\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16789%3F&hl=en&sa=X&d=9827187220639785834&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b-hRa3CIybDfceUhaRlecWD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "An Embarrassingly Simple Defense Against LLM Abliteration Attacks", "first_label": ["LLM"], "second_label": [], "data": "HA Shairah, HAAK Hammoud, B Ghanem, G Turkiyyah\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are typically aligned to comply with safety guidelines \nby refusing harmful instructions. A recent attack, termed abliteration, isolates and \nsuppresses the single latent direction most responsible for refusal behavior, enabling\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19056&hl=en&sa=X&d=3737202939224050048&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b8QKV5yRTnfm0WbZVG9RAGO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring", "first_label": ["LLM"], "second_label": [], "data": "Y Li, Q Sheng, Y Yang, X Zhang, J Cao\\xc2\\xa0- arXiv preprint arXiv:2506.09996, 2025\nThough safety alignment has been applied to most large language models (LLMs), \nLLM service providers generally deploy a subsequent moderation as the external \nsafety guardrail in real-world products. Existing moderators mainly practice a\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09996&hl=en&sa=X&d=8967671192696781749&ei=0hpTaNvAMOWs6rQPkO7OyQk&scisig=AAZF9b-I099JquXawda445fWweEs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Malo in the Code Jungle: Explainable Fault Localization for Decentralized Applications", "first_label": ["Fault Localization", "Code"], "second_label": ["Localization"], "data": "H Zhang, J Wu, Z Wu, Z Chen, D Lin, J Chen, Y Zhou\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDecentralized applications (DApps) have long been sitting ducks for hackers due to \ntheir valuable cryptocurrency assets, exposing them to various security risks. When a \nDApp is attacked, promptly identifying faults is crucial to minimizing financial losses\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11034691/&hl=en&sa=X&d=7651709202352945146&ei=0hpTaJ_6IeWs6rQPkO7OyQk&scisig=AAZF9b8cw1Hmz_K4wN9ajW1PUmQk&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Enhancing vulnerability repair through the extraction and matching of repair patterns", "first_label": ["Vulnerabilities"], "second_label": ["Repair"], "data": "X Cao, J Wang, P Wu\\xc2\\xa0- Journal of Systems and Software, 2025\nThe application of deep learning models in software vulnerability repair is \nincreasingly crucial. However, current deep learning-based vulnerability repair \nmodels primarily rely on implicit learning when generating patches, making it \nchallenging to effectively reuse existing repair patterns for new vulnerabilities. \nAdditionally, while introducing large-scale external data helps leverage historical \nexperience, it often leads to information redundancy and increased computational\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaEmpirical study on synthesis engines for semantics-based program\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225001967&hl=en&sa=X&d=13017805190019539176&ei=0hpTaOe-I72W6rQPs9Oj8A8&scisig=AAZF9b-4HC3uxcHqQKRh9Jh9LlMi&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le", "David Lo - new related research", "1 new citation to articles by Quang-Cuong Bui", "2 new citations to articles by Xin ZHOU", "5 new citations to articles by Abhik Roychoudhury"]}
{"title": "BLOKZ\\xc4\\xb0NC\\xc4\\xb0R TEKNOLOJ\\xc4\\xb0S\\xc4\\xb0 VE AKILLI S\\xc3\\x96ZLE\\xc5\\x9eMELER\\xc4\\xb0N ULUSLARARASI T\\xc4\\xb0CARETTE KULLANILAB\\xc4\\xb0L\\xc4\\xb0RL\\xc4\\xb0\\xc4\\x9e\\xc4\\xb0N\\xc4\\xb0N HUKUK VE EKONOM\\xc4\\xb0 EKSEN\\xc4\\xb0NDE ANAL\\xc4\\xb0Z\\xc4\\xb0", "first_label": [], "second_label": [], "data": "AA KARAYEL\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar?cluster=17024255858295271479&hl=en&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le"]}
{"title": "Mind the Gap: A Readability-Aware Metric for Test Code Complexity", "first_label": ["Code", "Software Testing"], "second_label": [], "data": "WC Ou\\xc3\\xa9draogo, Y Li, X Dang, X Zhou, A Koyuncu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomatically generated unit tests-from search-based tools like EvoSuite or LLMs-\nvary significantly in structure and readability. Yet most evaluations rely on metrics like \nCyclomatic Complexity and Cognitive Complexity, designed for functional code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.06764&hl=en&sa=X&d=8031478776401773975&ei=0hpTaKzhJ6Kr6rQP49vTsAY&scisig=AAZF9b-NjCZivc__tn99Kq7Xgxd6&oi=scholaralrt&hist=ylyK0_8AAAAJ:9162293956065397449:AAZF9b-XLYhOpfmwS_vhRk8lFc-r&html=&pos=0&folt=art", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new articles"]}
{"title": "Beyond Surface Similarity: Evaluating LLM-Based Test Refactorings with Structural and Semantic Awareness", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "WC Ou\\xc3\\xa9draogo, Y Li, X Dang, X Zhou, A Koyuncu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly employed to automatically refactor \nunit tests, aiming to enhance readability, naming, and structural clarity while \npreserving functional behavior. However, evaluating such refactorings remains\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.06767&hl=en&sa=X&d=6563163690120506226&ei=0hpTaKzhJ6Kr6rQP49vTsAY&scisig=AAZF9b9xD9hAdx6dPyiL2w3mENFA&oi=scholaralrt&hist=ylyK0_8AAAAJ:9162293956065397449:AAZF9b-XLYhOpfmwS_vhRk8lFc-r&html=&pos=1&folt=art", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new articles"]}
{"title": "2025 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)| 979-8-3315-2615-3/25/$31.00\\xc2\\xa9 2025 IEEE| DOI: 10.1109\\xc2\\xa0\\xe2\\x80\\xa6", "first_label": ["LLM", "Code"], "second_label": [], "data": "I Adewuyi, S Alamir, I Al Azher, H Alhoori, G An\\xe2\\x80\\xa6\nAuthor Index Page 1 Author Index Adewuyi, Israel 88 Alamir, Salwa 49 Al Azher, Ibrahim \n\\r\\n137 Alhoori, Hamed 137 An, Gabin 17, 120 Arefin, Md Fahim 80 Athale, Mihir 169 \n\\r\\nBabkin, Petr 49 Bartholf, Michael 177 Beger, Claas 128 Bhatele, Abhinav 193 Brunelle\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11028216/&hl=en&sa=X&d=8985289990599930919&ei=0hpTaKiVJs6r6rQPxrLf-As&scisig=AAZF9b9YD7Ag3FCp_aht3SXe7nc2&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A Hybrid Analysis-Based Construction Method for Tainted Control Flow Graphs of Binary Programs", "first_label": ["Static Analysis"], "second_label": ["Graph"], "data": "H Xie, X Li, Z Shen\\xc2\\xa0- 2025 8th World Conference on Computing and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, control flow graphs (CFGs) have gained increasing prominence in \nbinary vulnerability detection due to their comprehensive representation of a \nprogram's execution paths. However, traditional methods for constructing CFGs often \nencounter significant challenges, such as limited precision in static analysis and high \nruntime overhead in dynamic analysis. To address these limitations, this paper \nproposes a novel hybrid approach that combines static taint analysis with dynamic\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAssessing generalizability of codebert\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11028008/&hl=en&sa=X&d=2323627711953533258&ei=0hpTaKKKL6y16rQPzoCEgAc&scisig=AAZF9b911nwzTo2_R_SZDdV7BFt4&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "Adaptive header identification and unsupervised clustering strategy for enhanced protocol reverse engineering", "first_label": [], "second_label": [], "data": "M Zhu, C Gu, X Zhang, Q Yuan, M Ju, G Zhang, X Chen\\xc2\\xa0- Expert Systems with\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nProtocol reverse engineering is critical for ensuring network security and \nunderstanding proprietary communication mechanisms. Most traditional network \ntrace-based methods face challenges such as high computational complexity, \nexcessive memory usage, and sensitivity to payload variations. In this paper, we \npropose a method that integrates adaptive message header recognition with \nunsupervised clustering strategies for protocol reverse engineering. Utilizing mean\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBLEEM: Packet Sequence Oriented Fuzzing for Protocol\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S095741742502086X&hl=en&sa=X&d=1649016524055649226&ei=0hpTaJucKe2rieoPk6bG-Qo&scisig=AAZF9b_s7bLi5aGjWRMXbckOPvZC&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "ASC-Hook: Efficient System Call Interception for ARM", "first_label": [], "second_label": [], "data": "Y Shen, M Xie, T Wu, W Zhang, R Wang, G Zhang\\xc2\\xa0- Proceedings of the 26th ACM\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSystem call interception is essential for tools that modify or monitor application \nbehavior. However, current system call interception solutions on ARM platforms still \nface challenges related to performance and completeness. This paper introduces \nASC-Hook, an efficient and comprehensive binary rewriting framework specifically \ndesigned for intercepting system calls on ARM architectures. ASC-Hook tackles two \ncritical challenges: the misalignment of the target address caused by directly\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBinary Rewriting without Control Flow Recovery\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3735452.3735524&hl=en&sa=X&d=2744921428114210080&ei=0hpTaJucKe2rieoPk6bG-Qo&scisig=AAZF9b-XmZhXSWPcPOmcbaggfq-u&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "Isolating Noisy Labelled Test Cases in Human-in-the-Loop Oracle Learning", "first_label": ["Software Testing"], "second_label": [], "data": "CG Kapugama\\xc2\\xa0- 2025 International Research Conference on Smart\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIncorrectly labelled test cases can adversely affect the training process of human-in-\nthe-loop oracle learning techniques. This paper introduces ISONOISE, a technique \ndesigned to identify such mislabelled test cases introduced during human-in-the-\nloop oracle learning. This technique can be applied to programs taking numeric \ninputs. Given a compromised automatic test oracle and its training test suite, \nISONOISE first isolates the test cases suspected of being mislabelled. This task is\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSemantic Program Repair Using a Reference Implementation\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11030983/&hl=en&sa=X&d=4802306526262104356&ei=0hpTaJucKe2rieoPk6bG-Qo&scisig=AAZF9b_ZAfdCbgDd2dTtMKH4zIQr&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "RIMFuzz: real-time impact-aware mutation for library API fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "X Wang, L Zhao\\xc2\\xa0- Journal of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs libraries merely expose APIs to developers rather than directly handling user \ninput, applying fuzzing to libraries requires fuzz drivers to help process fuzzer-\nprovided input and invoke APIs. To reduce manual effort and avoid reliance on\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00050-1&hl=en&sa=X&d=11566396351270247841&ei=0hpTaNqsLNGM6rQPs-LTyAw&scisig=AAZF9b9NzGapAGT-Gt26V3wejXNn&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
