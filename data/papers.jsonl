{"title": "Detecting adversarial examples in object detection: positive and negative representation approach", "first_label": [], "second_label": ["Detection"], "data": "H Zhang, JX Guo, GY Wang, JS Ding, Q Hang\\xc2\\xa0- Journal of Electronic Imaging, 2025\nThe susceptibility of deep neural networks to adversarial examples remains a \nsignificant hurdle, particularly within the realm of object detection. Given the unique \nnature of tasks in the field of object detection, many existing adversarial example \ndetection methods designed for image classification are not directly applicable. To \naddress this challenge, we propose the object detection positive and negative \ndetector. This framework identifies adversarial instances by capitalizing on the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFuzz Testing based Data Augmentation to Improve Robustness of\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging/volume-34/issue-3/033012/Detecting-adversarial-examples-in-object-detection--positive-and-negative/10.1117/1.JEI.34.3.033012.short&hl=en&sa=X&d=13234837455614183696&ei=Ti4jaK3dHdetieoP4ty46AU&scisig=AAZF9b_N8T5QB3Y4qIFfPMA9nHWP&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": [], "ref": ["1 new citation to articles by Abhik Roychoudhury"]}
{"title": "A Novel Vulnerability\\xe2\\x80\\x90Detection Method Based on the Semantic Features of Source Code and the LLVM Intermediate Representation", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "J Chen, J Zhou, W Lin, D Towey, S Cai, H Chen\\xe2\\x80\\xa6\\xc2\\xa0- Journal of Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the increasingly frequent attacks on software systems, software security is an \nissue that must be addressed. Within software security, automated detection of \nsoftware vulnerabilities is an important subject. Most existing vulnerability detectors\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.70026&hl=en&sa=X&d=17964738228929246437&ei=Ti4jaNqaIOG_6rQP0ufy2AQ&scisig=AAZF9b-fOqArk69UMYZIdEpS4_PV&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": [], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Security Vulnerabilities in Docker Images: A Cross-Tag Study of Application Dependencies", "first_label": ["Vulnerabilities"], "second_label": [], "data": "HM Nasrabadi, E Constantinou, A Serebrenik\\xc2\\xa0- 41 IEEE International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDocker containers are widely used in modern enterprise applications and cloud \nenvironments for their efficiency, portability, and rapid deployment. As a leading \ncontainerization technology, Docker enables applications to be stored as images\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://research.tue.nl/en/publications/security-vulnerabilities-in-docker-images-a-cross-tag-study-of-ap&hl=en&sa=X&d=15159198155389120694&ei=Ti4jaNqaIOG_6rQP0ufy2AQ&scisig=AAZF9b_eExaD9ygAu2z1qke4_-qR&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=1&folt=rel", "author": [], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Text-image fusion template for large language model assisted crowdsourcing test aggregation", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "Y Zhu, S Yu, Z Zong, Y Wang, Y Zhao, Z Chen\\xc2\\xa0- Journal of Systems and Software, 2025\nMobile crowdsourced testing leverages a varied group to enhance software quality \nthrough screenshots and text feedback. Examining the multitude of reports is tedious \nbut crucial, often necessitating a combined analysis of both visual and textual \ninformation. However, professionals employ detailed judgment beyond mere \nsimilarity, which poses a challenge given the limited textual data and abundance of \nimages in the reports. We introduce a framework that guides large language models\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaActive semi-supervised defect categorization\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225001463&hl=en&sa=X&d=15316154416519783590&ei=Ti4jaPvjGrOi6rQPvJGpyAE&scisig=AAZF9b-TURB3-Fo9GHV_9oGhYJ4d&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["1 new citation to articles by Bach Le"]}
{"title": "TeeDFuzzer: Fuzzing Trusted Execution Environment", "first_label": ["Fuzzing"], "second_label": [], "data": "S Wen, L Xu, L Tian, S Liu, Y Ding\\xc2\\xa0- Electronics, 2025\nThe Trusted Execution Environment (TEE) is crucial for safeguarding the ecosystem \nof embedded systems. It uses isolation to minimize the TCB (Trusted Computing \nBase) and protect sensitive software. It is vital because devices handle vast\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2079-9292/14/8/1674&hl=en&sa=X&d=17000003502334375443&ei=Ti4jaOnCIZCk6rQPifv7-Aw&scisig=AAZF9b_cWX7Aqu8F3yi_nJDEp3Ce&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": [], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "HScheduler: An execution history-based seed scheduling strategy for hardware fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "Z Guo, Y Lv, N Cui, L Chen, G Shi\\xc2\\xa0- Computers & Security, 2025\nThe recent emergence of hardware fuzzing has introduced significant advancements \nin hardware verification. However, the lack of an efficient seed (input for fuzzing) \nscheduling mechanism severely affects its performance. In this paper, we propose\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825001671&hl=en&sa=X&d=7181585585593368656&ei=Ti4jaOnCIZCk6rQPifv7-Aw&scisig=AAZF9b-MdMTIsACs-TsLu7a4u5O5&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": [], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Fuzzing Space Communication Protocols", "first_label": ["Fuzzing"], "second_label": [], "data": "S Havermans, L Baumg\\xc3\\xa4rtner, J Roberts, M Wallum\\xe2\\x80\\xa6\nSpace systems are critical assets and protecting them against cyberattacks is a \nparamount challenge that has received limited attention. In particular, it is \nfundamental to secure spacecraft communications by identifying and removing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://software.imdea.org/~juanca/papers/spacefuzz_spacesec25.pdf&hl=en&sa=X&d=964000194933772866&ei=Ti4jaOnCIZCk6rQPifv7-Aw&scisig=AAZF9b9To-YtFkNH0V2NeHA65cZP&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": [], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Revisiting Defects4J for Fault Localization in Diverse Development Scenarios", "first_label": ["Fault Localization"], "second_label": ["Localization"], "data": "MN Rafi, AR Chen, THP Chen, S Wang\nDefects4J stands out as a leading benchmark dataset for software testing research, \nproviding a controlled environment to study real bugs from prominent open-source \nsystems. While Defects4J provides a clean and valuable dataset, we aim to explore\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://petertsehsun.github.io/papers/MSR25_Defects4j.pdf&hl=en&sa=X&d=17769356187159404178&ei=Ti4jaOnCIZCk6rQPifv7-Aw&scisig=AAZF9b9Jow3u953pAdt-vrSlDqrb&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": [], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Leveraging Open-Source LLMs for Zero-Shot Vulnerability Detection: A Comparative Analysis", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "N Capuano, V Carletti, P Foggia, G Parrella, M Vento\\xc2\\xa0- International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid expansion of the Internet of Things (IoT) has brought significant security \nchallenges, primarily due to vulnerabilities in the firmware of IoT and network \ndevices, which is predominantly written in low-level programming languages such as\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-87775-9_2&hl=en&sa=X&d=8724089268434184607&ei=Ti4jaJGyHO2h6rQPp8GU8As&scisig=AAZF9b-ahkowI222f9SeGE9jq2lb&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Leveraging Large Language Models for Autonomous Cyber Defense: Insights from CAGE-2 Simulations", "first_label": ["LLM"], "second_label": [], "data": "H Mohammadi, JJ Davis, M Kiely\\xc2\\xa0- IEEE Intelligent Systems, 2025\nThe ability of large language models (LLMs) to interpret and generate human-like \ntext, along with their inbuilt knowledge and reasoning skills, has opened the door for \nmany new applications. We develop a novel LLM agent as an autonomous cyber \ndefender and benchmark it using the CAGE-2 public challenge which evaluates \nsubmitted agents in a simulated network. The agent uses a pre-trained LLM to \ninterpret a text description of the challenge and choose the best defensive action\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/10991969/&hl=en&sa=X&d=10380008895875736264&ei=Ti4jaL-NGIKwieoP1bHc0Q8&scisig=AAZF9b-E8qI1xVPG4CNCGI4xhmlC&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang"]}
{"title": "AdaSteer: Your Aligned LLM is Inherently an Adaptive Jailbreak Defender", "first_label": ["LLM"], "second_label": [], "data": "W Zhao, J Guo, Y Hu, Y Deng, A Zhang, X Sui, X Han\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite extensive efforts in safety alignment, large language models (LLMs) remain \nvulnerable to jailbreak attacks. Activation steering offers a training-free defense \nmethod but relies on fixed steering coefficients, resulting in suboptimal protection\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.09466&hl=en&sa=X&d=2341918032029788356&ei=Ti4jaIz2I5DIieoPn6y1iAQ&scisig=AAZF9b9dXN1_uIfPnb7IOrZzW5G0&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Controlnet: A firewall for rag-based llm system", "first_label": ["LLM"], "second_label": [], "data": "H Yao, H Shi, Y Chen, Y Jiang, C Wang, Z Qin, K Ren\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRetrieval-Augmented Generation (RAG) has significantly enhanced the factual \naccuracy and domain adaptability of Large Language Models (LLMs). This \nadvancement has enabled their widespread deployment across sensitive domains\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.09593&hl=en&sa=X&d=17184153539705524448&ei=Ti4jaIz2I5DIieoPn6y1iAQ&scisig=AAZF9b88t3nlCEsBuOgOJE_lA75N&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SaRO: Enhancing LLM Safety through Reasoning-based Alignment", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "Y Mou, Y Luo, S Zhang, W Ye\\xc2\\xa0- arXiv preprint arXiv:2504.09420, 2025\nCurrent safety alignment techniques for large language models (LLMs) face two key \nchallenges:(1) under-generalization, which leaves models vulnerable to novel \njailbreak attacks, and (2) over-alignment, which leads to the excessive refusal of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.09420&hl=en&sa=X&d=5520993791348679153&ei=Ti4jaIz2I5DIieoPn6y1iAQ&scisig=AAZF9b-3MYoxky6Y_jhi6SNm_6ld&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "aiXamine: LLM Safety and Security Simplified", "first_label": ["LLM"], "second_label": [], "data": "F Deniz, D Popovic, Y Boshmaf, E Jeong, M Ahmad\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nEvaluating Large Language Models (LLMs) for safety and security remains a \ncomplex task, often requiring users to navigate a fragmented landscape of ad hoc \nbenchmarks, datasets, metrics, and reporting formats. To address this challenge, we\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.14985&hl=en&sa=X&d=1653724166156179673&ei=Ti4jaIz2I5DIieoPn6y1iAQ&scisig=AAZF9b9vEQF_GlIdZVlXNUHpd5mQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Asking language models how to represent data for fine-tuning", "first_label": [], "second_label": [], "data": "U Singh, A Singha, A Awasthi, A Kanade, S Gulwani\\xe2\\x80\\xa6\nAbstract Language models are often used for tasks involving structured data like \ntables and graphs, but there is no general approach for choosing the best format to \nrepresent such data across different tasks for fine-tuning. In this study, we show how\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://usneek1.github.io/assets/asking.pdf&hl=en&sa=X&d=13984562773318642189&ei=Ti4jaIz2I5DIieoPn6y1iAQ&scisig=AAZF9b-s07zN-8HMhBQFZ4oHp_Y7&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Recommender Systems Approaches for Software Defect Prediction: A Comparative Study", "first_label": [], "second_label": [], "data": "AR Rhazi, O Banouar, F Toure, S Raghay\nDefects prediction is an important step in the software development life cycle. \nProjects involving thousands of classes require the writing of unit tests for a \nsignificant number of classes, which is a costly and timeconsuming process. Some\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.scitepress.org/Papers/2025/132117/132117.pdf&hl=en&sa=X&d=12480493164327529792&ei=Ti4jaJ6yJaiY6rQP-t2FkAQ&scisig=AAZF9b8oAsz0Gr-gEr4ISHPFSsuH&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "The Hidden Risks of LLM-Generated Web Application Code: A Security-Centric Evaluation of Code Generation Capabilities in Large Language Models", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "S Dora, D Lunkad, N Aslam, S Venkatesan, SK Shukla\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Large Language Models (LLMs) has enhanced software \ndevelopment processes, minimizing the time and effort required for coding and \nenhancing developer productivity. However, despite their potential benefits, code\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.20612&hl=en&sa=X&d=2400369794392823668&ei=Ti4jaJ6yJaiY6rQP-t2FkAQ&scisig=AAZF9b9C-RcBvcwWJaniVCK62X8q&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "CBGF: Callback Coverage Guided Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "H Hwang, D Moon\\xc2\\xa0- IEEE Access, 2025\nCallback functions are widely used across programming languages, libraries, and \noperating systems. While offering flexible software design, these mechanisms \nintroduce inherently complex execution flows that can serve as potential attack\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/10965623.pdf&hl=en&sa=X&d=3130441307734811739&ei=Ti4jaMT8Jo2Z6rQP8OTB4AI&scisig=AAZF9b_FLqC17adWphONw1LQxaLM&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "VLM-Fuzz: Vision Language Model Assisted Recursive Depth-first Search Exploration for Effective UI Testing of Android Apps", "first_label": ["Fuzzing", "Software Testing"], "second_label": ["Search"], "data": "BF Demissie, YN Tun, LK Shar, M Ceccato\\xc2\\xa0- arXiv preprint arXiv:2504.11675, 2025\nTesting Android apps effectively requires a systematic exploration of the app's \npossible states by simulating user interactions and system events. While existing \napproaches have proposed several fuzzing techniques to generate various text\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.11675&hl=en&sa=X&d=1988321903897613415&ei=Ti4jaMT8Jo2Z6rQP8OTB4AI&scisig=AAZF9b97gghXTQnt2wHdcBD6wIbH&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Bug Triaging Based on Transformer Models Utilizing Commit Messages", "first_label": ["Bug", "Commit Message"], "second_label": [], "data": "FR Arnob, RH Mollik, P Goyal\\xc2\\xa0- The 22nd International Conference on Information\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBug triaging is a crucial process in software maintenance that involves assigning bug \nreports to the appropriate developers for resolution. Automated bug triaging \neliminates the need for manual assignment by leveraging machine learning (ML)\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DOkBcEQAAQBAJ%26oi%3Dfnd%26pg%3DPA354%26ots%3DSlNk16jIP7%26sig%3DcCfVyoodfpFmnHhll7_Zy8hgFk8&hl=en&sa=X&d=3921988087650022089&ei=Ti4jaMT8Jo2Z6rQP8OTB4AI&scisig=AAZF9b_a1xfM3VcrPfcHIGd3_zq7&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "StatePre: A Large Language Model-Based State-Handling Method for Network Protocol Fuzzing", "first_label": ["LLM", "Fuzzing"], "second_label": [], "data": "Y Zhang, K Zhu, J Peng, Y Lu, Q Chen, Z Li\\xc2\\xa0- Electronics, 2025\nAs essential components for communication, network protocol programs are highly \nsecurity-critical, making it crucial to identify their vulnerabilities. Fuzzing is one of the \nmost popular software vulnerability discovery techniques, being highly efficient and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2079-9292/14/10/1931&hl=en&sa=X&d=627385219736855262&ei=Ti4jaMT8Jo2Z6rQP8OTB4AI&scisig=AAZF9b8UGqCLjsKWT4IzOOpbHV9F&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Tracking the Moving Target: A Framework for Continuous Evaluation of LLM Test Generation in Industry", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "M Azanza, BP Lamancha, E Pizarro\\xc2\\xa0- arXiv preprint arXiv:2504.18985, 2025\nLarge Language Models (LLMs) have shown great potential in automating software \ntesting tasks, including test generation. However, their rapid evolution poses a critical \nchallenge for companies implementing DevSecOps-evaluations of their effectiveness\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.18985&hl=en&sa=X&d=11270287798222660984&ei=Ti4jaMT8Jo2Z6rQP8OTB4AI&scisig=AAZF9b9r8T9GXEDqDvEqnD2WCP-S&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Quality Evaluation of Large Language Models Generated Unit Tests: Influence of Structured Output", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "DM Zapkus, A Slotkien\\xc4\\x97\\xc2\\xa0- Lietuvos magistrant\\xc5\\xb3 informatikos ir IT tyrimai, 2025\nUnit testing is critical in software quality assurance, and large language models \n(LLMs) offer an approach to automate this process. This paper evaluates the quality \nof unit tests generated by large language models using structured output prompts\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.zurnalai.vu.lt/open-series/article/download/41912/39319/116522%23page%3D282&hl=en&sa=X&d=6338104554955403980&ei=Ti4jaMT8Jo2Z6rQP8OTB4AI&scisig=AAZF9b-KrZs8C9mHgzjXB5HFGCfk&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Using Historical Information for Fuzzing JavaScript Engines", "first_label": ["Fuzzing"], "second_label": [], "data": "BG de Oliveira, AT Endo, SR Vergilio\nJavaScript is a programming language commonly used to add interactivity and \ndynamic functionality to websites. It is a high-level, dynamically-typed language, well-\nsuited for building complex, client-side applications and supporting server-side\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.scitepress.org/Papers/2025/134177/134177.pdf&hl=en&sa=X&d=12017355669252469211&ei=Ti4jaMT8Jo2Z6rQP8OTB4AI&scisig=AAZF9b_j7bAjZmSfoWjcVwV7Oa3C&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Understanding Industry Perspectives of Static Application Security Testing (SAST) Evaluation", "first_label": ["Software Testing", "Static Analysis"], "second_label": [], "data": "Y LI, P YAO, KAN YU, C WANG, Y YE, S LI, M LUO\\xe2\\x80\\xa6 - 2025\n\\xe2\\x80\\xa2 RQ1: What are the reasons practitioners use SAST benchmarks and their concerns \nabout SAST evaluation goals? Specifically, we intend to investigate under which \nevaluation scenario (s) benchmarks are required and practitioners' expectations of\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://chengpeng-wang.github.io/publications/FSE2025.pdf&hl=en&sa=X&d=5976459075001011235&ei=Ti4jaMT8Jo2Z6rQP8OTB4AI&scisig=AAZF9b8rsVGudJCoBFzKKDHse-pZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Can Long-Context Language Models Solve Repository-Level Code Generation?", "first_label": ["Code"], "second_label": ["Generation"], "data": "Y PENG, ZZ Wang, D Fried\\xc2\\xa0- LTI Student Research Symposium 2025\nWith the advance of real-world tasks that necessitate increasingly long contexts, \nrecent language models (LMs) have begun to support longer context windows. One \nparticularly complex task is repository-level code generation, where retrieval\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DpmcWo9DtDw&hl=en&sa=X&d=13063763947226413069&ei=Ti4jaIjcFo2Z6rQP8OTB4AI&scisig=AAZF9b9atphr1WTCjx4gTyjUat33&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Everything You Wanted to Know About LLM-based Vulnerability Detection But Were Afraid to Ask", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "Y Li, X Li, H Wu, M Xu, Y Zhang, X Cheng, F Xu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models are a promising tool for automated vulnerability detection, \nthanks to their success in code generation and repair. However, despite widespread \nadoption, a critical question remains: Are LLMs truly effective at detecting real-world\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.13474&hl=en&sa=X&d=3576198370349911873&ei=Ti4jaLixGZaM6rQPmLK18A4&scisig=AAZF9b_knlGBPGica-ikm1KSsK8J&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
