{"title": "The Question Neighbourhood Approach for Systematic Evaluation of Code-Generating LLMs", "first_label": ["LLM", "Code"], "second_label": [], "data": "S Honarvar, M Rei, A Donaldson- IEEE Transactions on Software Engineering, 2025\nWe present the concept of a question neighbourhood for systematically evaluating \ninstruction-tuned large language models (LLMs) for code generation via a new \nbenchmark, Turbulence. Turbulence consists of a large set of natural language", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11175086/&hl=en&sa=X&d=12331338329639325411&ei=Kr_XaKHVAsnXieoPvqrN8Qs&scisig=AAZF9b8Ies8RuQhW4d_WHfainK40&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language", "first_label": ["LLM", "Software Testing"], "second_label": ["Agent"], "data": "S Salva, R Taguelmimt- arXiv preprint arXiv:2509.19136, 2025\nThe use of natural language (NL) test cases for validating graphical user interface \n(GUI) applications is emerging as a promising direction to manually written \nexecutable test scripts, which are costly to develop and difficult to maintain. Recent", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19136&hl=en&sa=X&d=14763218273592887225&ei=Kr_XaKHVAsnXieoPvqrN8Qs&scisig=AAZF9b-UHW8cguy7BjMGIC6z7CK9&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "2 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research", "Thanh Le-Cong - new related research"]}
{"title": "LLM-based Vulnerability Discovery through the Lens of Code Metrics", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": [], "data": "F Weissberg, L Pirch, E Imgrund, J Mller, T Eisenhofer- arXiv preprint arXiv, 2025\nLarge language models (LLMs) excel in many tasks of software engineering, yet \nprogress in leveraging them for vulnerability discovery has stalled in recent years. To \nunderstand this phenomenon, we investigate LLMs through the lens of classic code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19117&hl=en&sa=X&d=9123199236929215814&ei=Kr_XaKHVAsnXieoPvqrN8Qs&scisig=AAZF9b9NYfbk81y_m-4rkRbLeJNM&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "Richard Fang - new related research", "David Lo - new related research", "Thanh Le-Cong - new related research"]}
{"title": "A Two-Stage Framework Integrating Prompt Learning and Fine-Tuning for Code Summarization", "first_label": ["Code"], "second_label": [], "data": "X Sun, S Lv, W Wan, Y Qin, G Hu- International Conference on Artificial Neural, 2025\nSource code summarization automates the generation of natural comments, \nenhancing efficiency in software development and maintenance. With the \nemergence of large language models (LLMs), significant progress has been made in", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-04549-2_24&hl=en&sa=X&d=10692364299398052856&ei=Kr_XaKHVAsnXieoPvqrN8Qs&scisig=AAZF9b8xi2Iw8kWBWVSILvm4_TwI&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "SR-Eval: Evaluating LLMs on Code Generation under Stepwise Requirement Refinement", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Z Zhan, S Gao, R Hu, C Gao- arXiv preprint arXiv:2509.18808, 2025\nLarge language models (LLMs) have achieved remarkable progress in code \ngeneration. However, existing benchmarks mainly formalize the task as a static, \nsingle-turn problem, overlooking the stepwise requirement changes and iterative", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18808&hl=en&sa=X&d=14162583223826256111&ei=Kr_XaKHVAsnXieoPvqrN8Qs&scisig=AAZF9b_T6fIKaT-uWP6LDsRQQhRF&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "OSATG-GPT: Instruction-Tuning Large Language Models with Open-Source Atomic Tasks in GitHub", "first_label": ["LLM"], "second_label": [], "data": "F Han, L Ma, F Bi, Y Wang, M You, W Wang, J Peng- Expert Systems with, 2025\nAcross numerous application scenarios in Natural Language Processing (NLP), \nLarge Language Models (LLMs) have demonstrated exceptional capabilities in text \ncomprehension and generation. These models exhibit significant potential across", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0957417425034347&hl=en&sa=X&d=10572613471784520706&ei=Kr_XaKHVAsnXieoPvqrN8Qs&scisig=AAZF9b-FcEMG2-uR0o8kT9-BQScY&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "Evaluating the Source Code Review Performance of LLM-based AI Chatbots", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "T Kakimoto, H Inayoshi, H Uwano, A Monden\nSource code review plays a critical role in ensuring software quality by identifying \nbugs early in the development process. Although recent studies have explored the \nuse of large language models (LLMs) for tasks such as vulnerability detection and\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Akito-Monden/publication/395728251_Evaluating_the_Source_Code_Review_Performance_of_LLM-based_AI_Chatbots/links/68d2399868064a19c0b971f7/Evaluating-the-Source-Code-Review-Performance-of-LLM-based-AI-Chatbots.pdf&hl=en&sa=X&d=15470312918337070369&ei=Kr_XaKHVAsnXieoPvqrN8Qs&scisig=AAZF9b-tyw2eYIWihY9d7dojU-qG&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Toward efficient vibe coding: An LLM-based agent for low-code software development", "first_label": ["LLM", "Code"], "second_label": ["Agent"], "data": "N Malamas, E Tsardoulias, K Panayiotou- Journal of Computer, 2025\nAbstract The Software Engineering (SE) domain increasingly adopts low-code and \nno-code approaches to simplify application development and deployment. Two \ndominant paradigms have emerged in this space: Model-driven Engineering (MDE), \nleveraging Domain-specific Languages (DSLs) to abstract implementation and \nreduce the knowledge and expertise required, and LLM-based vibe coding, where \ndevelopers interact with Large Language Models (LLMs) using natural language\nCites: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S259011842500053X&hl=en&sa=X&d=14193155343073234717&ei=Jr_XaIWpO-vD6rQP-pzPsQ4&scisig=AAZF9b-LMPQ2q6J-9eobpharqYge&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 new citation to articles by Thanh Le-Cong", "3 new citations to articles by Bach Le"]}
{"title": "WeMu: Effective and Scalable Emulation of Microarchitectural Weird Machines", "first_label": [], "second_label": [], "data": "D Vanspauwen, KU DistriNet, LA Daniel, J Van Bulck\nAbstract Recent research on Microarchitectural Weird Machines (WMs) has shown \nthat microarchitectural optimization features, originally exploited for data exfiltration, \ncan also facilitate hidden computation. Emerging WMs, enabled by dedicated \ncompilers, have become increasingly practical, evading conventional analysis tools \nby executing complex cryptographic algorithms and unpacking malware entirely \nwithin the microarchitectural domain. To address the lack of defensive capabilities\nCites: oo7: Low-overhead defense against spectre attacks via program\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://vanbulck.net/files/uasc26-wemu.pdf&hl=en&sa=X&d=11417229871611200833&ei=KL_XaI3nLqSgieoPmvLA-Ac&scisig=AAZF9b86FUlK5wIkmbZ4jhFfJu4x&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
{"title": "ArchiteCAD: a large-scale architectural CAD dataset for symbol spotting towards CAD-to-BIM conversion", "first_label": [], "second_label": [], "data": "Q Zhao, L Zhou, Y Wang, P Wang, Q Li- International Journal on Document Analysis, 2025\nAbstract Building Information Modeling (BIM) is integral to the Architecture, \nEngineering, Construction and Operations (AECO) industry, facilitating efficient \nproject management and lifecycle maintenance. However, obtaining BIM models for", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10032-025-00557-3&hl=en&sa=X&d=7550212691038930422&ei=J7_XaLDLD-ak6rQP4M2KgAY&scisig=AAZF9b8s4a37jGaRnsYUhdnheJNR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models", "first_label": ["LLM", "Bug", "Repository-Level"], "second_label": [], "data": "J Liu, Z Liu, Z Cheng, M He, X Shi, Y Guo, X Zhu, Y Guo- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have exhibited significant proficiency in code \ndebugging, especially in automatic program repair, which may substantially reduce \nthe time consumption of developers and enhance their efficiency. Significant\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04078%3F&hl=en&sa=X&d=12419661760319839544&ei=J7_XaLDLD-ak6rQP4M2KgAY&scisig=AAZF9b8SHef7li0_lXitWcja8LI-&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Improving Software Defect Detection with LSTM-Based Semantic Modeling and Class Imbalance Handling", "first_label": ["Software Defect"], "second_label": ["Detection"], "data": "H Andrade, N Pombo, S Pais- IEEE Open Journal of the Computer Society, 2025\nSoftware Defect Prediction (SDP) plays a vital role in maintaining software quality, \nespecially as modern systems grow in size and complexity. Traditional SDP models \nthat rely on static code metrics often fail to capture the semantic and contextual \nrelationships inherent in source code, limiting their prediction accuracy and ability to \ngeneralize across projects. In this study, we propose a Deep Learning (DL)-based \napproach that combines Long Short-Term Memory (LSTM) networks with semantic\nCites: Benchmarking Large Language Models for Multi-Language", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/8782664/9024218/11175486.pdf&hl=en&sa=X&d=9555248039218663585&ei=KL_XaOOEA8asieoPpPjngQI&scisig=AAZF9b9b1_M5cgKwrTlgRQcKrwb0&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang", "2 new citations to articles by Xin ZHOU"]}
{"title": "CoRaCMG: Contextual Retrieval-Augmented Framework for Commit Message Generation", "first_label": ["Commit Message"], "second_label": ["Generation"], "data": "B Xiong, L Zhang, C Wang, P Liang- arXiv preprint arXiv:2509.18337, 2025\nCommit messages play a key role in documenting the intent behind code changes. \nHowever, they are often low-quality, vague, or incomplete, limiting their usefulness. \nCommit Message Generation (CMG) aims to automatically generate descriptive \ncommit messages from code diffs to reduce developers' effort and improve message \nquality. Although recent advances in LLMs have shown promise in automating CMG, \ntheir performance remains limited. This paper aims to enhance CMG performance by\nCites: Cc2vec: Distributed representations of code changes", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18337&hl=en&sa=X&d=15529871488308136613&ei=KL_XaOOEA8asieoPpPjngQI&scisig=AAZF9b83TNlhuoSOkfEGOwe9NMXv&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang"]}
{"title": "Learning Resource Center, Jiangsu College of Engineering and Technology; School of Information Science and Technology, Nantong University", "first_label": [], "second_label": [], "data": "Y Fan, XIA Hongling\n. \n, , \n. \n,  \n(prediction based on data augmentation, PDA) . PDA , \n,  4 . \nCites: Cc2vec: Distributed representations of code changes\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ngzke.cbpt.cnki.net/portal/journal/portal/client/paper/b0c24bd5a0fce0534e51952aa7416cf0&hl=en&sa=X&d=16235849338654281840&ei=KL_XaOOEA8asieoPpPjngQI&scisig=AAZF9b_zipgKxI4KAFY0FFN-_los&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang"]}
{"title": "Locus: Agentic Predicate Synthesis for Directed Fuzzing", "first_label": ["Fuzzing"], "second_label": ["Agent"], "data": "J Zhu, C Shen, Z Li, J Yu, Y Chen, K Pei- arXiv preprint arXiv:2508.21302, 2025\nDirected fuzzing aims to find program inputs that lead to specified target program \nstates. It has broad applications, such as debugging system crashes, confirming \nreported bugs, and generating exploits for potential vulnerabilities. This task is\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21302&hl=en&sa=X&d=2138932734315377454&ei=Kr_XaJTIDp6sieoPwu_ngQ4&scisig=AAZF9b9iXz21pxlN8QAQ_QbeooKc&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Detection of security smells in IaC scripts through semantics-aware code and language processing", "first_label": ["Code"], "second_label": ["Detection"], "data": "A War, AA Rawass, AK Kabore, J Samhi, J Klein- arXiv preprint arXiv, 2025\nInfrastructure as Code (IaC) automates the provisioning and management of IT \ninfrastructure through scripts and tools, streamlining software deployment. Prior \nstudies have shown that IaC scripts often contain recurring security", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18790&hl=en&sa=X&d=1329338443620150235&ei=KL_XaMrRPOvD6rQP-pzPsQ4&scisig=AAZF9b9fvPQ3UZ03xSIuiTX5fpid&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=1&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Security smells in infrastructure as code: a taxonomy update beyond the seven sins", "first_label": ["Code"], "second_label": [], "data": "A War, SLB Nikiema, J Samhi, J Klein, TF Bissyande- arXiv preprint arXiv, 2025\nInfrastructure as Code (IaC) has become essential for modern software \nmanagement, yet security flaws in IaC scripts can have severe consequences, as \nexemplified by the recurring exploits of Cloud Web Services. Prior work has", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18761&hl=en&sa=X&d=4584619337256832365&ei=KL_XaMrRPOvD6rQP-pzPsQ4&scisig=AAZF9b87fl3YPXxXEp2VEu21mnOM&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Vulnerability Detection in Solidity Smart Contracts via Machine Learning: A Qualitative Analysis", "first_label": ["Vulnerabilities", "Smart Contracts"], "second_label": ["Detection"], "data": "D Ressi, A Span, L Benetollo, M Bugliesi, C Piazza- Blockchain: Research and, 2025\nSmart contracts are central to most blockchain applications, from financial \ntransactions to supply chain management. However, their adoption is hindered by \nsecurity vulnerabilities that can result in significant financial losses. Most vulnerability\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S2096720925001174&hl=en&sa=X&d=2151998906183719167&ei=KL_XaMrRPOvD6rQP-pzPsQ4&scisig=AAZF9b838SuJ8zfdDwRNltkfkdiB&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=3&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "2 new citations to articles by Xin ZHOU"]}
{"title": "Safe and Effective Post-Fine-tuning Alignment in Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "M Jiang, Y Yang, X Xie, P Ke, G Liu- Knowledge-Based Systems, 2025\nFine-tuning is critical to customizing Large Language Models (LLMs) in various \napplications, but it inevitably disrupts the safety alignment of the models. Current \nalignment methods tackle harmful fine-tuning challenges but frequently compromise \nmodel usefulness, resulting in unsatisfactory downstream task performance. To \naddress this issue, we propose a Safe and Effective post-fine-tuning Alignment (SEA) \nfrom a knowledge disentanglement perspective. SEA introduces a novel two-level\nCites: Removing rlhf protections in gpt-4 via fine-tuning", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S095070512501562X&hl=en&sa=X&d=9680225592681546011&ei=J7_XaNKiIJXP6rQPo4LniQU&scisig=AAZF9b_4Aqi8lJbTDoFQwa4yTUWn&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Beekeeper: Accelerating Honeypot Analysis with LLM-driven Feedback", "first_label": ["LLM"], "second_label": [], "data": "N Ilg, D Germek, P Duplys, M Menth- IEEE Access, 2025\nHoneypots are decoy resources intended to entice adversaries and collect threat \nintelligence in the process. The amount and quality of the collected insights strongly \ncorrelate with the honeypot's credibility to the adversary. However, the development \nof medium to high interaction honeypots, so, environments that offer at minimum a \nshell to the attacker, is laborious and complex. Additionally, getting feedback on a \nhoneypot is often expensive and time-consuming, slowing down development and\nCites: Llm agents can autonomously hack websites\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11175384.pdf&hl=en&sa=X&d=10963313873632792203&ei=J7_XaNKiIJXP6rQPo4LniQU&scisig=AAZF9b9Y5QfsbgUHObnBpBtzTRq7&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Paladin: Defending LLM-enabled Phishing Emails with a New Trigger-Tag Paradigm", "first_label": ["LLM"], "second_label": [], "data": "Y Pang, W Meng, X Liao, T Wang- arXiv preprint arXiv:2509.07287, 2025\nWith the rapid development of large language models, the potential threat of their \nmalicious use, particularly in generating phishing content, is becoming increasingly \nprevalent. Leveraging the capabilities of LLMs, malicious users can synthesize", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.07287&hl=en&sa=X&d=841142860163656335&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b9zUiVve_NVtg5_7UjR-gXJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Backdoor Attacks and Defenses in Computer Vision Domain: A Survey", "first_label": [], "second_label": [], "data": "BH Abbasi, Y Zhang, L Zhang, S Gao- arXiv preprint arXiv:2509.07504, 2025\nBackdoor (trojan) attacks embed hidden, controllable behaviors into machine-\nlearning models so that models behave normally on benign inputs but produce \nattacker-chosen outputs when a trigger is present. This survey reviews the rapidly", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.07504&hl=en&sa=X&d=3269854252125827141&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b9hUL9vDNoEXnWcZIb5H3Bf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Leveraging CVAE Encoding for Backdoor Attacks in Few-Shot Learning with Prototypical Networks", "first_label": [], "second_label": [], "data": "Q Yan, S Liang, A Ullah- IEEE Transactions on Dependable and Secure, 2025\nFew-shot learning (FSL) has demonstrated tremendous potential when challenged \nwith limited training data, but the assessment of its vulnerability to backdoor attacks is \nstill at an early stage. However, recent research revealed this deep learning", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11152502/&hl=en&sa=X&d=6687930075784700670&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b9ptsbEWBr80FGSyzcZR2Er&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Prototype-Guided Robust Learning against Backdoor Attacks", "first_label": [], "second_label": [], "data": "W Guo, M Pintor, A Demontis, B Biggio- arXiv preprint arXiv:2509.08748, 2025\nBackdoor attacks poison the training data to embed a backdoor in the model, \ncausing it to behave normally on legitimate inputs but maliciously when specific \ntrigger signals appear. Training a benign model from a dataset poisoned by", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.08748&hl=en&sa=X&d=9079518275239981489&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b8nbcMJrz3EP9De5YM82FpF&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Exploit Tool Invocation Prompt for Tool Behavior Hijacking in LLM-Based Agentic System", "first_label": ["LLM"], "second_label": ["Agent", "Exploit"], "data": "Y Liu, Y Xie, M Luo, Z Liu, Z Zhang, K Zhang, Z Li- arXiv preprint arXiv, 2025\nLLM-based agentic systems leverage large language models to handle user queries, \nmake decisions, and execute external tools for complex tasks across domains like \nchatbots, customer service, and software engineering. A critical component of these", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05755%3F&hl=en&sa=X&d=7380962265010499197&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b_WNN5iEJzU4LQ3fLBGGpF6&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Oyster-I: Beyond Refusal--Constructive Safety Alignment for Responsible Language Models", "first_label": ["LLM"], "second_label": [], "data": "R Duan, J Liu, X Jia, S Zhao, R Cheng, F Wang, C Wei- arXiv preprint arXiv, 2025\nLarge language models (LLMs) typically deploy safety mechanisms to prevent \nharmful content generation. Most current approaches focus narrowly on risks posed \nby malicious actors, often framing risks as adversarial events and relying on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01909%3F&hl=en&sa=X&d=6590160868100905669&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b8p2pmNGwnqdehrNy547NkZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Jailbreak Attack with Multimodal Virtual Scenario Hypnosis for Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "X Shi, S Chen, G Zhang, W Wei, Y Li, Z Fan, J Liu- Pattern Recognition, 2025\nDue to the inherent vulnerabilities of large Vision-Language Models (VLMs), security \ngovernance has emerged as a critical concern, particularly given the risks posed by \nnoisy and biased training data as well as adversarial attacks, including data", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0031320325010520&hl=en&sa=X&d=18404876866865125967&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b9xJx3YOX0I9CBN24pCw_YG&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Why language models hallucinate", "first_label": ["LLM"], "second_label": [], "data": "AT Kalai, O Nachum, SS Vempala, E Zhang- arXiv preprint arXiv:2509.04664, 2025\nLike students facing hard exam questions, large language models sometimes guess \nwhen uncertain, producing plausible yet incorrect statements instead of admitting \nuncertainty. Such\" hallucinations\" persist even in state-of-the-art systems and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04664&hl=en&sa=X&d=17470905045322269269&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b9-xvJdrsXYLi4Kkc78fX8P&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Adversarial Bug Reports as a Security Risk in Language Model-Based Automated Program Repair", "first_label": ["APR", "LLM", "Bug"], "second_label": ["Repair"], "data": "P Przymus, A Happe, J Cito- arXiv preprint arXiv:2509.05372, 2025\nLarge Language Model (LLM)-based Automated Program Repair (APR) systems are \nincreasingly integrated into modern software development workflows, offering \nautomated patches in response to natural language bug reports. However, this\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05372&hl=en&sa=X&d=17856431439942945890&ei=Kb_XaLGyM-ak6rQP4M2KgAY&scisig=AAZF9b9iNtxXJTJlEQXG_3JYQbs1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A Decade of Blockchain in Finance: Bibliometric Analysis and Research Directions", "first_label": ["Blockchain"], "second_label": ["Search"], "data": "K Harish Kumar- Journal of Business and Social Sciences, 2025\nBlockchain technology has rapidly emerged as a transformative force across sectors \nsuch as healthcare, supply chains, energy, and voting systems. Its decentralized, \ntransparent, and secure architecture improves efficiency, enhances trust, and \nreduces costs. Among these domains, finance has experienced the greatest \ndisruption, with blockchain reshaping banking by fostering transparency, security, \nand efficiency. This study presents a bibliometric analysis of blockchain in finance\nCites: Smart contract development: Challenges and opportunities", "link": "https://scholar.google.com/scholar_url?url=http://eprints.intimal.edu.my/2186/1/jobss2025_9.pdf&hl=en&sa=X&d=10616597400148191896&ei=KL_XaLOCEpCq6rQPzKzJyAY&scisig=AAZF9b8gAs4suTcLPzezisu9FGf-&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "ChopChop: a Programmable Framework for Semantically Constraining the Output of Language Models", "first_label": ["LLM"], "second_label": [], "data": "S Nagy, T Zhou, N Polikarpova, L D'Antoni- arXiv preprint arXiv:2509.00360, 2025\nLanguage models (LMs) can generate code, but cannot guarantee its correctness--\nproducing outputs that often violate type safety, program invariants, or semantic \nequivalence. Constrained decoding offers a solution by restricting generation to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.00360&hl=en&sa=X&d=15761961036894749958&ei=KL_XaL7PIMmk6rQPwcXzuAc&scisig=AAZF9b9gFg_U0FktMXuQ5DX2sTxT&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Generic Adversarial Smart Contract Detection with Semantics and Uncertainty-Aware LLM", "first_label": ["Smart Contracts", "LLM"], "second_label": ["Detection"], "data": "Y Liu, X Su, H Wu, S Li, Y Cheng, F Xu, S Zhong- arXiv preprint arXiv:2509.18934, 2025\nAdversarial smart contracts, mostly on EVM-compatible chains like Ethereum and \nBSC, are deployed as EVM bytecode to exploit vulnerable smart contracts typically \nfor financial gains. Detecting such malicious contracts at the time of deployment is an", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18934&hl=en&sa=X&d=13248780610884419900&ei=KL_XaL7PIMmk6rQPwcXzuAc&scisig=AAZF9b8ZyuD68cpLgk5pKTuBk84S&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Security Evaluation of Android apps in budget African Mobile Devices", "first_label": [], "second_label": [], "data": "A Diallo, A Diop, AK Kabore, J Samhi, A Pilgun- arXiv preprint arXiv, 2025\nAndroid's open-source nature facilitates widespread smartphone accessibility, \nparticularly in price-sensitive markets. System and vendor applications that come pre-\ninstalled on budget Android devices frequently operate with elevated privileges, yet\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.18800&hl=en&sa=X&d=6613736328542570603&ei=KL_XaL7PIMmk6rQPwcXzuAc&scisig=AAZF9b9YjkOqw5_ynkAveNeMK2j4&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Benchmarking and Studying the LLM-based Code Review", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "Z Zeng, R Shi, K Han, Y Li, K Sun, Y Wang, Z Yu, R Xie- arXiv preprint arXiv, 2025\nAutomated Code Review (ACR) is crucial for software quality, yet existing \nbenchmarks often fail to reflect real-world complexities, hindering the evaluation of \nmodern Large Language Models (LLMs). Current benchmarks frequently focus on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01494&hl=en&sa=X&d=9924101107475937857&ei=J7_XaOuuMNq06rQPy6vVkAI&scisig=AAZF9b9CW-Ez1-ukRHGu-p7F6_IT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "first_label": ["LLM"], "second_label": ["Agent"], "data": "T Lindenbauer, I Slinko, L Felder, E Bogomolov- arXiv preprint arXiv, 2025\nLarge Language Model (LLM)-based agents solve complex tasks through iterative \nreasoning, exploration, and tool-use, a process that can result in long, expensive \ncontext histories. While state-of-the-art Software Engineering (SE) agents like\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21433&hl=en&sa=X&d=3778813371369713554&ei=J7_XaOuuMNq06rQPy6vVkAI&scisig=AAZF9b8vjKgLLO8JtQg2HjxwaIIj&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "PromeFuzz: A Knowledge-Driven Approach to Fuzzing Harness Generation with Large Language Models", "first_label": ["LLM", "Fuzzing"], "second_label": ["Generation"], "data": "Y Liu, J Deng, X Jia, Y Wang, M Wang, L Huang, T Wei\nFuzzing has long been recognized as an effective technique for uncovering security \nvulnerabilities by automatically generating and executing a diverse set of inputs [2, 3, \n6, 8, 14, 15, 18, 20, 24, 26, 30, 32, 34, 46, 52, 53, 55, 58]. Traditional fuzzing tools", "link": "https://scholar.google.com/scholar_url?url=https://pvz122.github.io/pdf/25-promefuzz.pdf&hl=en&sa=X&d=12396611312661296556&ei=Kb_XaNyDDZu1ieoPmM6V8Q0&scisig=AAZF9b-wSitwHBsEc3RIko2Rlc5c&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Fuzzing JavaScript Engines by Fusing JavaScript and WebAssembly", "first_label": ["Fuzzing"], "second_label": [], "data": "J Lin, C Luo, M Zhang, L Lin, P Li, C Qian - 2026\nJavaScript engines are a fundamental part of modern browsers, and many efforts \nhave been invested in testing them to enhance their security. However, the \nincorporation of WebAssembly into JavaScript engines introduces new attack\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://peng-hui.github.io/data/paper/icse26:mad-eye.pdf&hl=en&sa=X&d=7025301240690243176&ei=Kb_XaNyDDZu1ieoPmM6V8Q0&scisig=AAZF9b87H2l6opoFTjGi99T54n3u&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
