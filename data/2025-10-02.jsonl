{"title": "Exploit Tool Invocation Prompt for Tool Behavior Hijacking in LLM-Based Agentic System", "first_label": ["LLM"], "second_label": ["Agent", "Exploit"], "data": "Y Liu, Y Xie, M Luo, Z Liu, Z Zhang, K Zhang, Z Li- arXiv preprint arXiv, 2025\nLLM-based agentic systems leverage large language models to handle user queries, \nmake decisions, and execute external tools for complex tasks across domains like \nchatbots, customer service, and software engineering. A critical component of these", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05755%3F&hl=en&sa=X&d=7380962265010499197&ei=jtrdaIfIJMSz6rQPyKGw-Ag&scisig=AAZF9b_WNN5iEJzU4LQ3fLBGGpF6&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Paladin: Defending LLM-enabled Phishing Emails with a New Trigger-Tag Paradigm", "first_label": ["LLM"], "second_label": [], "data": "Y Pang, W Meng, X Liao, T Wang- arXiv preprint arXiv:2509.07287, 2025\nWith the rapid development of large language models, the potential threat of their \nmalicious use, particularly in generating phishing content, is becoming increasingly \nprevalent. Leveraging the capabilities of LLMs, malicious users can synthesize", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.07287&hl=en&sa=X&d=841142860163656335&ei=jtrdaIfIJMSz6rQPyKGw-Ag&scisig=AAZF9b9zUiVve_NVtg5_7UjR-gXJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Leveraging CVAE Encoding for Backdoor Attacks in Few-Shot Learning with Prototypical Networks", "first_label": [], "second_label": [], "data": "Q Yan, S Liang, A Ullah- IEEE Transactions on Dependable and Secure, 2025\nFew-shot learning (FSL) has demonstrated tremendous potential when challenged \nwith limited training data, but the assessment of its vulnerability to backdoor attacks is \nstill at an early stage. However, recent research revealed this deep learning", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11152502/&hl=en&sa=X&d=6687930075784700670&ei=jtrdaIfIJMSz6rQPyKGw-Ag&scisig=AAZF9b9ptsbEWBr80FGSyzcZR2Er&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Prototype-Guided Robust Learning against Backdoor Attacks", "first_label": [], "second_label": [], "data": "W Guo, M Pintor, A Demontis, B Biggio- arXiv preprint arXiv:2509.08748, 2025\nBackdoor attacks poison the training data to embed a backdoor in the model, \ncausing it to behave normally on legitimate inputs but maliciously when specific \ntrigger signals appear. Training a benign model from a dataset poisoned by", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.08748&hl=en&sa=X&d=9079518275239981489&ei=jtrdaIfIJMSz6rQPyKGw-Ag&scisig=AAZF9b8nbcMJrz3EP9De5YM82FpF&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Oyster-I: Beyond Refusal--Constructive Safety Alignment for Responsible Language Models", "first_label": ["LLM"], "second_label": [], "data": "R Duan, J Liu, X Jia, S Zhao, R Cheng, F Wang, C Wei- arXiv preprint arXiv, 2025\nLarge language models (LLMs) typically deploy safety mechanisms to prevent \nharmful content generation. Most current approaches focus narrowly on risks posed \nby malicious actors, often framing risks as adversarial events and relying on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01909%3F&hl=en&sa=X&d=6590160868100905669&ei=jtrdaIfIJMSz6rQPyKGw-Ag&scisig=AAZF9b8p2pmNGwnqdehrNy547NkZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Jailbreak Attack with Multimodal Virtual Scenario Hypnosis for Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "X Shi, S Chen, G Zhang, W Wei, Y Li, Z Fan, J Liu- Pattern Recognition, 2025\nDue to the inherent vulnerabilities of large Vision-Language Models (VLMs), security \ngovernance has emerged as a critical concern, particularly given the risks posed by \nnoisy and biased training data as well as adversarial attacks, including data", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0031320325010520&hl=en&sa=X&d=18404876866865125967&ei=jtrdaIfIJMSz6rQPyKGw-Ag&scisig=AAZF9b9xJx3YOX0I9CBN24pCw_YG&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Why language models hallucinate", "first_label": ["LLM"], "second_label": [], "data": "AT Kalai, O Nachum, SS Vempala, E Zhang- arXiv preprint arXiv:2509.04664, 2025\nLike students facing hard exam questions, large language models sometimes guess \nwhen uncertain, producing plausible yet incorrect statements instead of admitting \nuncertainty. Such\" hallucinations\" persist even in state-of-the-art systems and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04664&hl=en&sa=X&d=17470905045322269269&ei=jtrdaIfIJMSz6rQPyKGw-Ag&scisig=AAZF9b9-xvJdrsXYLi4Kkc78fX8P&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Adversarial Bug Reports as a Security Risk in Language Model-Based Automated Program Repair", "first_label": ["APR", "LLM", "Bug"], "second_label": ["Repair"], "data": "P Przymus, A Happe, J Cito- arXiv preprint arXiv:2509.05372, 2025\nLarge Language Model (LLM)-based Automated Program Repair (APR) systems are \nincreasingly integrated into modern software development workflows, offering \nautomated patches in response to natural language bug reports. However, this", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05372&hl=en&sa=X&d=17856431439942945890&ei=jtrdaIfIJMSz6rQPyKGw-Ag&scisig=AAZF9b9iNtxXJTJlEQXG_3JYQbs1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Cut Costs, Not Accuracy: LLM-Powered Data Processing with Guarantees", "first_label": ["LLM"], "second_label": [], "data": "S Zeighami, S Shankar, A Parameswaran- arXiv preprint arXiv:2509.02896, 2025\nLarge Language Models (LLMs) are being increasingly used as a building block in \ndata systems to process large text datasets. To do so, LLM model providers offer \nmultiple LLMs with different sizes, spanning various cost-quality trade-offs when", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.02896%3F&hl=en&sa=X&d=17574372354989562785&ei=jtrdaIfIJMSz6rQPyKGw-Ag&scisig=AAZF9b-DvnVUyd5iBucpFadx2SoL&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "EchoLeak: The First Real-World Zero-Click Prompt Injection Exploit in a Production LLM System", "first_label": ["LLM"], "second_label": ["Exploit"], "data": "P Reddy, AS Gujral- arXiv preprint arXiv:2509.10540, 2025\nLarge language model (LLM) assistants are increasingly integrated into enterprise \nworkflows, raising new security concerns as they bridge internal and external data \nsources. This paper presents an in-depth case study of EchoLeak (CVE-2025\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.10540%3F&hl=en&sa=X&d=3830339454672368349&ei=jtrdaIfIJMSz6rQPyKGw-Ag&scisig=AAZF9b-2-nfVtjM51-72VPmeR1Yc&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models", "first_label": ["LLM", "Bug", "Repository-Level"], "second_label": [], "data": "J Liu, Z Liu, Z Cheng, M He, X Shi, Y Guo, X Zhu, Y Guo- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have exhibited significant proficiency in code \ndebugging, especially in automatic program repair, which may substantially reduce \nthe time consumption of developers and enhance their efficiency. Significant\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04078%3F&hl=en&sa=X&d=12419661760319839544&ei=jNrdaL2QCJXP6rQP9ZK58Q0&scisig=AAZF9b8SHef7li0_lXitWcja8LI-&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Generating Software Architectural Model from Source Code Using Module Clustering", "first_label": ["Code"], "second_label": [], "data": "B Arasteh, SS Sefati, H Kusetogullari, F Kiani- Symmetry, 2025\nSoftware maintenance is one of the most expensive phases in software \ndevelopment, especially when complex source code is the only available artifact. \nClustering software modules and generating a structured architectural model can\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2073-8994/17/9/1523&hl=en&sa=X&d=9037379356857496352&ei=jNrdaKWYLISb6rQPt9iYgAM&scisig=AAZF9b-K0RiHQ1pE7QZ3IUfLNE6M&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Aligning Requirement for Large Language Model's Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Z Tian, J Chen- arXiv preprint arXiv:2509.01313, 2025\nCode generation refers to the automatic generation of source code based on a given \nprogramming specification, which has garnered significant attention particularly with \nthe advancement of large language models (LLMs). However, due to the inherent", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01313&hl=en&sa=X&d=13370697676538068499&ei=jtrdaJSmPPKOieoP85S7oQk&scisig=AAZF9b9B7L937IdcMo1J6Zsy7VAv&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Intelligent Graybox Fuzzing via ATPG-Guided Seed Generation and Submodule Analysis", "first_label": ["Fuzzing"], "second_label": ["Generation"], "data": "R Saravanan, S Paria, A Dasgupta, S Bhunia- arXiv preprint arXiv:2509.20808, 2025\nHardware Fuzzing emerged as one of the crucial techniques for finding security flaws \nin modern hardware designs by testing a wide range of input scenarios. One of the \nmain challenges is creating high-quality input seeds that maximize coverage and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.20808&hl=en&sa=X&d=11635584275403043134&ei=jtrdaJSmPPKOieoP85S7oQk&scisig=AAZF9b-EaDXCg2a3mA1rI2gL4oLU&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Performance and interpretability analysis of code generation large language models", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "VS Pendyala, NB Thakur- Neurocomputing, 2025\nAbstract As Large Language Models (LLMs) are increasingly getting integrated into \nsoftware development workflows, understanding their reliability, error patterns and \ninterpretability in real-world development scenarios is crucial for establishing their\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0925231225021332&hl=en&sa=X&d=12519052331836719178&ei=jtrdaJSmPPKOieoP85S7oQk&scisig=AAZF9b_3S5NkeiHUCnc01CtGOqCD&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Moving Towards Robust and Reliable AI: Vulnerability Detection Framework Through Red Teaming", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "V Raman, A Desarkar, A Sen- Data Science and Communication Engineering, 2025\nEnsuring the reliability of AI-based systems is a crucial challenge in today's AI-driven \nenvironment. However, robustness is a key component of reli-able AI, as the failure \nof these systems could have severe consequences in the critical domains such as in \nhealthcare, transportation and finance. Eventually, the systems in these domains are \nlargely dependent on various language models. Hence, measuring the robustness of \nthose language models ultimately determines the end success though no such\nCites: Large language model for vulnerability detection and repair\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3Dli-KEQAAQBAJ%26oi%3Dfnd%26pg%3DPA209%26ots%3DWIkWfTeWxS%26sig%3DBsjJf3VFapSd3RlrgCNs85_xYMU&hl=en&sa=X&d=6448497152658089733&ei=jtrdaIOUC46IieoP7dK5sA0&scisig=AAZF9b8sv3RIed1EIJJXX70RAtS0&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["1 new citation to articles by Xin ZHOU"]}
{"title": "Fuzzing as editor feedback", "first_label": ["Fuzzing"], "second_label": [], "data": "M Garus, J Lincke, R Hirschfeld- Companion Proceedings of the 9th International, 2025\nLive programming requires concrete examples, but coming up with examples takes \neffort. However, there are ways to execute code without specifying examples, such \nas fuzzing. Fuzzing is a technique that synthesizes program inputs to find bugs in", "link": "https://scholar.google.com/scholar_url?url=https://drops.dagstuhl.de/storage/01oasics/oasics-vol134-programming2025/OASIcs.Programming.2025.8/OASIcs.Programming.2025.8.pdf&hl=en&sa=X&d=4846729257551256103&ei=jdrdaP25D46IieoP7dK5sA0&scisig=AAZF9b_a936tJ2euestamYofC9hC&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "PromeFuzz: A Knowledge-Driven Approach to Fuzzing Harness Generation with Large Language Models", "first_label": ["LLM", "Fuzzing"], "second_label": ["Generation"], "data": "Y Liu, J Deng, X Jia, Y Wang, M Wang, L Huang, T Wei\nFuzzing has long been recognized as an effective technique for uncovering security \nvulnerabilities by automatically generating and executing a diverse set of inputs [2, 3, \n6, 8, 14, 15, 18, 20, 24, 26, 30, 32, 34, 46, 52, 53, 55, 58]. Traditional fuzzing tools", "link": "https://scholar.google.com/scholar_url?url=https://pvz122.github.io/pdf/25-promefuzz.pdf&hl=en&sa=X&d=12396611312661296556&ei=jdrdaP25D46IieoP7dK5sA0&scisig=AAZF9b-wSitwHBsEc3RIko2Rlc5c&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Fuzzing JavaScript Engines by Fusing JavaScript and WebAssembly", "first_label": ["Fuzzing"], "second_label": [], "data": "J Lin, C Luo, M Zhang, L Lin, P Li, C Qian - 2026\nJavaScript engines are a fundamental part of modern browsers, and many efforts \nhave been invested in testing them to enhance their security. However, the \nincorporation of WebAssembly into JavaScript engines introduces new attack\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://peng-hui.github.io/data/paper/icse26:mad-eye.pdf&hl=en&sa=X&d=7025301240690243176&ei=jdrdaP25D46IieoP7dK5sA0&scisig=AAZF9b87H2l6opoFTjGi99T54n3u&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Misactivation-Aware Stealthy Backdoor Attacks on Neural Code Understanding Models", "first_label": ["Code"], "second_label": [], "data": "X Sun, Y Xiao, L Bo, W Sun, X Liu, B Li, J Zhang- IEEE Transactions on Software, 2025\nNeural code models (NCMs) play a crucial role in helping developers solve code \nunderstanding tasks. Recent studies have exposed that NCMs are vulnerable to \nseveral security threats, among which backdoor attack is one of the toughest. It is", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11181191/&hl=en&sa=X&d=1845847614155086033&ei=GyvcaNClLfiu6rQPxbaqoAY&scisig=AAZF9b9cJUSS-tJDGaC1EhJgMR6O&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Richard Fang - new related research", "Xin ZHOU - new related research"]}
{"title": "CodeDiffuSe: A masked diffusion framework for structure-aware code completion and repair", "first_label": ["Code"], "second_label": ["Repair", "Generation"], "data": "A Onan, HA Alhumyani- Journal of King Saud University. Computer and, 2025\nCode completion and code repair have become fundamental tasks in software \nengineering and machine learning research. However, existing large language \nmodels (LLMs) for code generation, predominantly based on autoregressive", "link": "https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/ecd00afac05b4151020d6eb49bc8d7b5/1%3Fpq-origsite%3Dgscholar%26cbl%3D7424686&hl=en&sa=X&d=7004051865866003393&ei=GyvcaNClLfiu6rQPxbaqoAY&scisig=AAZF9b9dkmQafMpLxEoePHF12TwB&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "Bach Le - new related research"]}
{"title": "An empirical study of large language models for type and call graph analysis in Python and JavaScript", "first_label": ["LLM", "Static Analysis"], "second_label": ["Graph"], "data": "APS Venkatesh, R Sunil, S Sabu, AM Mir, S Reis- Empirical Software, 2025\nAbstract Large Language Models (LLMs) are increasingly being explored for their \npotential in software engineering, particularly in static analysis tasks. In this study, we \ninvestigate the potential of current LLMs to enhance call-graph analysis and type", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10704-3&hl=en&sa=X&d=8485468858979245803&ei=GyvcaNClLfiu6rQPxbaqoAY&scisig=AAZF9b9kA51v2W4prYcCPv0TqWS9&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Highlight Test Code: Visualizing the Co-Evolution of Test and Production Code in Software Repositories", "first_label": ["Code", "Software Testing"], "second_label": [], "data": "C Miranda, G Avelino, PS Neto- Simpsio Brasileiro de Engenharia de Software, 2025\nThe asynchronous evolution of test and production code can compromise software \nquality and maintainability. However, identifying and analyzing such co-evolution \ndynamics remains a complex task, often hindered by the lack of scalable tools and\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/sbes/article/download/37075/36860&hl=en&sa=X&d=17577561774027938597&ei=GyvcaNClLfiu6rQPxbaqoAY&scisig=AAZF9b_hW2BJp09WS8xmuDqO8pYI&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "From Cryptic to Clear-Training on LLM Explanations to Detect Smart Contract Vulnerabilities", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": [], "data": "Y Chen, Z Sun, G Wang, Q Liang, X Yu, D Hao- ACM Transactions on Software, 2025\nSmart contracts have revolutionized the way transactions are executed, offering \ndecentralized and immutable frameworks. The immutability of smart contracts poses \nsignificant risks when vulnerabilities exist in their code, leading to financial losses", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3765753&hl=en&sa=X&d=10696251976758637118&ei=GyvcaMncCMmk6rQP4uyfyA4&scisig=AAZF9b9ZBf4NQYTpgMU9yATSPdqf&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "GTVD: a multi-level aggregation vulnerability detection method based on full-dependency program graph", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "H He, S Li, Y Li, Y Li- Cluster Computing, 2025\nIn modern software development life cycles, proactive vulnerability discovery and \nremediation play crucial roles in ensuring application security. However, current \ndeep learning-based vulnerability detection methods frequently face limitations due", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10586-025-05506-7&hl=en&sa=X&d=9365356712912853263&ei=GyvcaMncCMmk6rQP4uyfyA4&scisig=AAZF9b_DdZ4fyL1mLj90wo4wpBRq&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "ISGraphVD: Precise Vulnerability Detection for IoT Supply Chains Based on Identifier Sensitive Graph", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "Y Zhang, X Liu, Z Liu, S Li, N Li, W Niu, R Zhou, Q Zhou\nOpen-source software (OSS) is widely reused in Internet of Things (IoT) devices, \nleading to widespread N-Day vulnerabilities when outdated components remain \nunpatched. Existing methods typically encode features of different Common\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://songli.io/papers/ISGraphVD.pdf&hl=en&sa=X&d=1350040853715836251&ei=GyvcaMncCMmk6rQP4uyfyA4&scisig=AAZF9b9CY8xvjfunqJuaAskMto44&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Parallel Fuzzing based on Sub-tasks Scheduling", "first_label": ["Fuzzing"], "second_label": [], "data": "T Gu, T Wang, X Li, S Lu, Y Nie, Z Zhang, X Kuang- ACM Transactions on Software\nParallel fuzzing introduces two key steps: task division and task merging to improve \nefficiency and effectiveness. However, existing works lack effective analysis of task \nresults during task merging; they employ simple differential seed distribution", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3766542&hl=en&sa=X&d=2693574529684625139&ei=HCvcaIaHEs_O6rQPmPybkQ0&scisig=AAZF9b9aadL5OeSioZ8HLhUivWic&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Conversational Automated Program Repair for ARM Assembly Code using LLMs", "first_label": ["APR", "LLM", "Code"], "second_label": ["Repair"], "data": "J Gomes, D Silveira, T Jorge\nThis paper explores the development of the Automated Program Repair (APR) field, \nwith a specific emphasis on the use of Large Language Models (LLMs) to tackle the \nchallenges of ARM assembly code in the AIR project, a joint initiative between GMV", "link": "https://scholar.google.com/scholar_url?url=https://www.horizon-schumann.eu/wp-content/uploads/2025/07/Conversational_Automated_Program_Repair_for_ARM_Assembly_Code_using_LLMs_final.pdf&hl=en&sa=X&d=4367788842176228212&ei=HCvcaIaHEs_O6rQPmPybkQ0&scisig=AAZF9b_8xrU3osMG0qpQXxLpnrK7&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FuzzRDUCC: Fuzzing with Reconstructed Def-Use Chain Coverage", "first_label": ["Fuzzing"], "second_label": [], "data": "K Feng, J Singer, AK Marnerides- arXiv preprint arXiv:2509.04967, 2025\nBinary-only fuzzing often struggles with achieving thorough code coverage and \nuncovering hidden vulnerabilities due to limited insight into a program's internal \ndataflows. Traditional grey-box fuzzers guide test case generation primarily using", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.04967&hl=en&sa=X&d=12793668697793724612&ei=HCvcaIaHEs_O6rQPmPybkQ0&scisig=AAZF9b9DbASTknJLZ9Qw2muyThkA&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Fuzzing JavaScript JIT compilers with a high-quality differential test oracle", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "J Li, H Xu, Y Wang, Z Jiang, H Chun, P Xie, Y Chen- Computers & Security, 2025\nAbstract Modern JavaScript engines use Just-In-Time (JIT) compilers to convert \nfrequently executed code into machine instructions, boosting performance for web \napplications and cross-platform systems. However, the optimizations in JIT compilers", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825003499&hl=en&sa=X&d=7438620869129233397&ei=HCvcaIaHEs_O6rQPmPybkQ0&scisig=AAZF9b8tN2mMloCI7htWicorKtpq&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FuzzBox: Blending Fuzzing into Emulation for Binary-Only Embedded Targets", "first_label": ["Fuzzing"], "second_label": [], "data": "C Cesarano, R Natella- arXiv preprint arXiv:2509.05643, 2025\nCoverage-guided fuzzing has been widely applied to address zero-day \nvulnerabilities in general-purpose software and operating systems. This approach \nrelies on instrumenting the target code at compile time. However, applying it to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.05643&hl=en&sa=X&d=4585422960426806286&ei=HCvcaIaHEs_O6rQPmPybkQ0&scisig=AAZF9b-p7mmDlvT3yh-ZhB_TgxIV&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Evaluating the Effectiveness of Coverage-Guided Fuzzing for Testing Deep Learning Library APIs", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "F Qin, MM Naziri, H Ai, S Dutta, M d'Amorim- arXiv preprint arXiv:2509.14626, 2025\nDeep Learning (DL) libraries such as PyTorch provide the core components to build \nmajor AI-enabled applications. Finding bugs in these libraries is important and \nchallenging. Prior approaches have tackled this by performing either API-level", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.14626&hl=en&sa=X&d=11350896954294303435&ei=HCvcaIaHEs_O6rQPmPybkQ0&scisig=AAZF9b_GT4mzQ2w1NTOQ8RIfpK9G&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "SWE-QA: Can Language Models Answer Repository-level Code Questions?", "first_label": ["LLM", "Code", "Repository-Level"], "second_label": [], "data": "W Peng, Y Shi, Y Wang, X Zhang, B Shen, X Gu- arXiv preprint arXiv:2509.14635, 2025\nUnderstanding and reasoning about entire software repositories is an essential \ncapability for intelligent software engineering tools. While existing benchmarks such \nas CoSQA and CodeQA have advanced the field, they predominantly focus on small", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.14635&hl=en&sa=X&d=15006803551698078506&ei=HCvcaIaHEs_O6rQPmPybkQ0&scisig=AAZF9b-gcqnrJWuOC2cDSJR6nYNt&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=6&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Leveraging SystemC-TLM-based Virtual Prototypes for Embedded Software Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "C Ghinami, J Winzer, N Bosbach, LM Reimann- arXiv preprint arXiv, 2025\nSystemC-based virtual prototypes have emerged as widely adopted tools to test \nsoftware ahead of hardware availability, reducing the time-to-market and improving \nsoftware reliability. Recently, fuzzing has become a popular method for automated", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01318&hl=en&sa=X&d=1341175212014518141&ei=HCvcaIaHEs_O6rQPmPybkQ0&scisig=AAZF9b9xqbJnzFJ8oCl2uemQ46wF&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=7&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Syntactic multilingual probing of pre-trained language models of code", "first_label": ["LLM", "Code"], "second_label": [], "data": "JAH Lpez, M Weyssow, JS Cuadrado, H Sahraoui- Journal of Systems and, 2026\nPre-trained language models (PLMs) have demonstrated remarkable abilities in \ncoding tasks, establishing themselves as a state-of-the-art technique in machine \nlearning for code. However, due to their deep neural network-based structure, PLMs\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225002730&hl=en&sa=X&d=912414639058686127&ei=HCvcaIaHEs_O6rQPmPybkQ0&scisig=AAZF9b_JpbZnEYTzTsY6dFTnCppp&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=8&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks", "first_label": ["LLM"], "second_label": ["Agent"], "data": "SM Hossain, RK Shayoni, MR Ameen, A Islam- arXiv preprint arXiv, 2025\nPrompt injection attacks represent a major vulnerability in Large Language Model \n(LLM) deployments, where malicious instructions embedded in user inputs can \noverride system prompts and induce unintended behaviors. This paper presents a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.14285&hl=en&sa=X&d=913307193832282926&ei=HCvcaK7VMaSgieoPsa-a2As&scisig=AAZF9b-cOLAwuLy9zQlk8KZ2kPLK&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Unraveling LLM Jailbreaks Through Safety Knowledge Neurons", "first_label": ["LLM"], "second_label": [], "data": "C Zhao, K Huang- arXiv preprint arXiv:2509.01631, 2025\nLarge Language Models (LLMs) are increasingly attracting attention in various \napplications. Nonetheless, there is a growing concern as some users attempt to \nexploit these models for malicious purposes, including the synthesis of controlled", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01631&hl=en&sa=X&d=1514740733256060014&ei=HCvcaK7VMaSgieoPsa-a2As&scisig=AAZF9b9hCs1ysD6JyG0WYWiQsfvZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "When Your Reviewer is an LLM: Biases, Divergence, and Prompt Injection Risks in Peer Review", "first_label": ["LLM"], "second_label": [], "data": "C Zhu, J Xiong, R Ma, Z Lu, Y Liu, L Li- arXiv preprint arXiv:2509.09912, 2025\nPeer review is the cornerstone of academic publishing, yet the process is \nincreasingly strained by rising submission volumes, reviewer overload, and expertise \nmismatches. Large language models (LLMs) are now being used as\" reviewer aids,\"", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.09912&hl=en&sa=X&d=559709989728729115&ei=HCvcaK7VMaSgieoPsa-a2As&scisig=AAZF9b_J-eLdccTA9UluyGqY5GIL&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Beyond PII: How Users Attempt to Estimate and Mitigate Implicit LLM Inference", "first_label": ["LLM"], "second_label": [], "data": "S Wang, ST Peddinti, N Taft, N Feamster- arXiv preprint arXiv:2509.12152, 2025\nLarge Language Models (LLMs) such as ChatGPT can infer personal attributes from \nseemingly innocuous text, raising privacy risks beyond memorized data leakage. \nWhile prior work has demonstrated these risks, little is known about how users", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.12152&hl=en&sa=X&d=12168943809296116787&ei=HCvcaK7VMaSgieoPsa-a2As&scisig=AAZF9b9G6AxGUOxThRc0V2DeV1wz&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Harmful Prompt Laundering: Jailbreaking LLMs with Abductive Styles and Symbolic Encoding", "first_label": ["LLM"], "second_label": [], "data": "S Joo, H Koh, K Jung- arXiv preprint arXiv:2509.10931, 2025\nLarge Language Models (LLMs) have demonstrated remarkable capabilities across \ndiverse tasks, but their potential misuse for harmful purposes remains a significant \nconcern. To strengthen defenses against such vulnerabilities, it is essential to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.10931&hl=en&sa=X&d=7785240652024916599&ei=HCvcaK7VMaSgieoPsa-a2As&scisig=AAZF9b-lQwRskC9IEbTA9AG879iC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SPIDER 2.0: EVALUATING LANGUAGE MODELS ON REAL-WORLD ENTERPRISE TEXT-TO-SQL WORK", "first_label": ["LLM"], "second_label": [], "data": "F Lei, J Chen, Y Ye, R Cao, D Shin, H Su, Z Suo, H Gao\nReal-world enterprise text-to-SQL workflows often involve complex cloud or local \ndata across various database systems, multiple SQL queries in various dialects, and \ndiverse operations from data transformation to analytics. We introduce Spider 2.0, an", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DXmProj9cPs%26utm_source%3Dmail.bycloud.ai%26utm_medium%3Dreferral%26utm_campaign%3Dtop-3-rated-iclr-2025-papers-lora-done-rite-ic-light-hycoclip&hl=en&sa=X&d=4871394914707286311&ei=HCvcaK7VMaSgieoPsa-a2As&scisig=AAZF9b8Cho9Fi7_obzCkOU1Rascf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research", "2 new citations to articles by Abhik Roychoudhury"]}
{"title": "Counterfactual Sensitivity for Faithful Reasoning in Language Models", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "IF Shihab, S Akter, A Sharma- arXiv preprint arXiv:2509.01544, 2025\nLarge language models (LLMs) often produce correct answers while relying on \nflawed or irrelevant reasoning traces, undermining their trustworthiness in high-\nstakes domains. We propose Counterfactual Sensitivity Regularization (CSR), a\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01544&hl=en&sa=X&d=16973430102837298098&ei=HCvcaK7VMaSgieoPsa-a2As&scisig=AAZF9b-nLRKB4WgajHq7UxZ_NYzW&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Detecting code paraphrased by large language models using coding style features", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "S Park, H Jin, J Cha, YS Han- Engineering Applications of Artificial Intelligence, 2025\nRecent progress in large language models (LLMs) for code generation has raised \nserious concerns about intellectual property protection. Malicious users can exploit \nLLMs to produce paraphrased versions of proprietary code that closely resemble the", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0952197625024856&hl=en&sa=X&d=5148275569496423324&ei=HSvcaLPHA5XP6rQP0aSCgAw&scisig=AAZF9b_ntG39PI9nkGiO4Gwy8bEN&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Reinforcement Learning-Guided Chain-of-Draft for Token-Efficient Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "X Tang, IE Olatunji, T Sun, J Klein, TF Bissyand\nLLMs demonstrate surface-level fluency in code generation but struggle with \nstructured reasoning tasks requiring correctness and semantic alignment. While \nChain-of-Thought (CoT) prompting enhances reasoning through intermediate steps\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Xunzhu-Tang-3/publication/395878648_Reinforcement_Learning-Guided_Chain-of-Draft_for_Token-Efficient_Code_Generation/links/68d68e21ffdca73694b32ae7/Reinforcement-Learning-Guided-Chain-of-Draft-for-Token-Efficient-Code-Generation.pdf&hl=en&sa=X&d=9010252028597092600&ei=HSvcaLPHA5XP6rQP0aSCgAw&scisig=AAZF9b_ofxKgksklbsnKAtWCSz8l&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Code like an economist: Analyzing LLMs' code generation capabilities in economics and finance", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Z Song, S Wu, Y Zhou- Finance Research Letters, 2025\nThis study investigates the code generation capabilities of large language models \n(LLMs) in the context of economics and finance research. Using a curated dataset of \n1,088 academic papers from top-tier journals across 19 subfields, we design prompts \nthat task a current LLM with generating code to replicate the analytical procedures \ndescribed in each study. We evaluate the generated outputs for accuracy and track \nregeneration behaviors under both autonomous (self-regeneration) and human\nCites: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1544612325017945&hl=en&sa=X&d=2742372921177426508&ei=GivcaNTtHfiu6rQPxbaqoAY&scisig=AAZF9b-Z9COW29zoALB_mqY18X8z&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["3 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Bach Le"]}
{"title": "Generative Trigger-Action Programming with Ply", "first_label": [], "second_label": [], "data": "TJ Aveni, H Mor, A Fox, B Hartmann- Proceedings of the 38th Annual ACM, 2025\nTrigger-action programming has been a success in end-user programming. \nTraditionally, the simplicity of links between triggers and actions limits the \nexpressivity of such systems. LLM-based code generation promises to enable users \nto specify more complex behavior in natural language. However, users need \nappropriate ways to understand and control this added expressive power. We \nintroduce Ply, a system that tackles this challenge through the following\nCites: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3746059.3747638&hl=en&sa=X&d=12754808862431473512&ei=GivcaNTtHfiu6rQPxbaqoAY&scisig=AAZF9b-eZnf2QeUPLuxa1FIjFQ6h&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["3 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Bach Le"]}
{"title": "Toward Non-Expert Customized Congestion Control", "first_label": [], "second_label": [], "data": "M Zhang, H Bagheri, L Xu- ICC 2025-IEEE International Conference on, 2025\nGeneral-purpose congestion control algorithms (CCAs) are designed to achieve \ngeneral congestion control goals, but they may not meet the specific requirements of \ncertain users. Customized CCAs can meet certain users' specific requirements; \nhowever, non-expert users often lack the expertise to implement them. In this paper, \nwe present an exploratory non-expert customized CCA framework, named NECC, \nwhich enables non-expert users to easily model, implement, and deploy their\nCites: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11160790/&hl=en&sa=X&d=6045942221319862581&ei=GivcaNTtHfiu6rQPxbaqoAY&scisig=AAZF9b-0bvhh6uyMDw7pdANRFWnk&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=2&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["3 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Bach Le"]}
{"title": "A Comparative Study of Solidity and Sui Move: Advancing Smart Contract Development", "first_label": ["Smart Contracts"], "second_label": [], "data": "A Giatzis, S Papangelou, CK Georgiadis- IEEE Access, 2025\nThe emergence of blockchain technology has resulted in the creation of various \nblockchain networks and their accompanying programming languages for creating \nsmart contracts. Each smart contract language, with its unique characteristics, \nadvantages, and drawbacks, leverages blockchain technology to create a secure, \ntransparent, and efficient way to execute agreements without the need for \nintermediaries. In this study, we compared the Solidity language used in the\nCites: Smart contract development: Challenges and opportunities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11180905.pdf&hl=en&sa=X&d=13973492286783786330&ei=GyvcaPuxG8mk6rQP4uyfyA4&scisig=AAZF9b-SqACy8AWmIcj7o9CC6ST8&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=3&folt=cit", "author": ["Bach Le"], "ref": ["4 new citations to articles by Bach Le"]}
{"title": "The Sampling Threat when Mining Generalizable Inter-Library Usage Patterns", "first_label": [], "second_label": [], "data": "YP Correa, C De Roover, J Hrtel- Science of Computer Programming, 2025\nTool support in software engineering often relies on relationships, regularities, \npatterns, or rules mined from other users' code. Examples include approaches to bug \nprediction, code recommendation, and code autocompletion. Mining is typically", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167642325001327&hl=en&sa=X&d=5455663094396867109&ei=HSvcaOaaEoC5ieoPoMr7oAg&scisig=AAZF9b-7Ac2ESJq6PkNfSAsikWSe&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Empirical Study of Code Large Language Models for Binary Security Patch Detection", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "Q Li, B Li, C Gao, S Gao, Z Li- arXiv preprint arXiv:2509.06052, 2025\nSecurity patch detection (SPD) is crucial for maintaining software security, as \nunpatched vulnerabilities can lead to severe security risks. In recent years, numerous \nlearning-based SPD approaches have demonstrated promising results on source", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.06052&hl=en&sa=X&d=13188995808337954619&ei=HSvcaOaaEoC5ieoPoMr7oAg&scisig=AAZF9b-uojbuOzp9rZgBIMmU6x4h&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "From Evaluation to Enhancement: Large Language Models for Zero-Knowledge Proof Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Z Xue, P Ma, Z Wang, S Wang- arXiv preprint arXiv:2509.11708, 2025\nZero-knowledge proofs (ZKPs) are increasingly deployed in domains such as privacy-\npreserving authentication, blockchain scalability, and secure finance. However, \nauthoring ZK programs remains challenging: unlike mainstream programming, ZK", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.11708&hl=en&sa=X&d=10349220616421543327&ei=HSvcaOaaEoC5ieoPoMr7oAg&scisig=AAZF9b9VxdZ6a1w1kBGuJtv-cEtA&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Flowco: Mixed-Initiative Authoring of Reliable End-to-End Data Analyses via Dataflow Graphs and LLMs", "first_label": ["LLM"], "second_label": ["Graph"], "data": "SN Freund, B Simon, ED Berger, E Jun- Proceedings of the 38th Annual ACM, 2025\nConducting data analysis typically involves authoring code to transform, visualize, \nanalyze, and interpret data. Large Language Models (LLMs) are now capable of \ngenerating such code for simple, routine analyses, and they have the potential to \ndemocratize data science by enabling those with limited programming expertise to \nconduct data analyses, including in scientific research, business, and policymaking. \nHowever, analysts in many real-world settings must often exercise fine-grained\nCites: Automated Program Repair\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3746059.3747636&hl=en&sa=X&d=3003520968003789710&ei=HCvcaOS0AY2j6rQPkJiQyQM&scisig=AAZF9b8BA89Z3eUzohsfIwX0RxCE&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["2 new citations to articles by Abhik Roychoudhury"]}
