{"title": "Enhancing LLM-Based Code Generation with Complexity Metrics: A Feedback-Driven Approach", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "M Sepidband, H Taherkhani, S Wang, H Hemmati\\xc2\\xa0- arXiv preprint arXiv:2505.23953, 2025\nAutomatic code generation has gained significant momentum with the advent of \nLarge Language Models (LLMs) such as GPT-4. Although many studies focus on \nimproving the effectiveness of LLMs for code generation, very limited work tries to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23953&hl=en&sa=X&d=13582085771309006894&ei=J_tBaLXmL4qIieoPj_7kqQE&scisig=AAZF9b_CMfsY4xEKkIm7N9DVXs0b&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "HardTests: Synthesizing High-Quality Test Cases for LLM Coding", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "Z He, YM Choi, K Zhang, J Ji, J Zhou, D Xu, I Bercovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nVerifiers play a crucial role in large language model (LLM) reasoning, needed by \npost-training techniques such as reinforcement learning. However, reliable verifiers \nare hard to get for difficult coding problems, because a well-disguised wrong solution\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24098&hl=en&sa=X&d=3676350848881047114&ei=J_tBaLXmL4qIieoPj_7kqQE&scisig=AAZF9b-nTHkCLE3pbXjQ3HdGnwxz&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "Unlocking Code Simplicity: The Role of Prompt Patterns in Managing LLM Code Complexity", "first_label": ["LLM", "Code"], "second_label": [], "data": "A Della Porta, G Recupito, S Lambiase, D Di Nucci\\xe2\\x80\\xa6\nThe rapid growth of generative artificial intelligence, especially Large Language \nModels (LLMs), has greatly influenced software engineering by automating code \ngeneration tasks. Despite the potential, challenges in code maintainability and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://atdepo.github.io/assets/papers/patterns_complexity.pdf&hl=en&sa=X&d=12326388923183369801&ei=J_tBaLXmL4qIieoPj_7kqQE&scisig=AAZF9b8NNBgnrmk0FkEiYAYKSDVx&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "Spectre: Automated Aliasing Specifications Generation for Library APIs with Fuzzing", "first_label": ["Fuzzing"], "second_label": ["Generation"], "data": "S Kan, Y Li, W He, Z Xing, L Zhu, Y Sui\\xc2\\xa0- ACM Transactions on Software Engineering\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nStatic program analysis of real-world software that integrates numerous library \nApplication Programming Interfaces (APIs) faces significant challenges due to \ninaccessible or highly complex source code. A common workaround is to use\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3725811&hl=en&sa=X&d=2352067302594285580&ei=J_tBaJ-KMYOuieoP-ZTn2Aw&scisig=AAZF9b8vKjatyW94SPNBNu4L2TwN&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "8 new citations to articles by Abhik Roychoudhury", "Abhik Roychoudhury - new related research", "David Lo - new related research"]}
{"title": "LLM Agents Should Employ Security Principles", "first_label": ["LLM"], "second_label": ["Agent"], "data": "K Zhang, Z Su, PY Chen, E Bertino, X Zhang, N Li\\xc2\\xa0- arXiv preprint arXiv:2505.24019, 2025\nLarge Language Model (LLM) agents show considerable promise for automating \ncomplex tasks using contextual reasoning; however, interactions involving multiple \nagents and the system's susceptibility to prompt injection and other forms of context \nmanipulation introduce new vulnerabilities related to privacy leakage and system \nexploitation. This position paper argues that the well-established design principles in \ninformation security, which are commonly referred to as security principles, should be\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously hack websites\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24019&hl=en&sa=X&d=10754342589978314789&ei=J_tBaPqfIb2W6rQPmdrokQU&scisig=AAZF9b9WXSbqMs3YY-6YiS90274z&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "R Ko, J Jeong, S Zheng, C Xiao, T Kim, M Onizuka\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are rapidly evolving into autonomous agents that \ncooperate across organizational boundaries, enabling joint disaster response, \nsupply-chain optimization, and other tasks that demand decentralized expertise \nwithout surrendering data ownership. Yet, cross-domain collaboration shatters the \nunified trust assumptions behind current alignment and containment techniques. An \nagent benign in isolation may, when receiving messages from an untrusted peer\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTeams of llm agents can exploit zero-day vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23847&hl=en&sa=X&d=12877987841461213152&ei=J_tBaPqfIb2W6rQPmdrokQU&scisig=AAZF9b-0Dc_aqKLzG9BeK_25VV9I&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "ALDExA: Automated LLM-Assisted Detection of CVE Exploitation Attempts in Host-Captured Data", "first_label": ["LLM"], "second_label": ["Detection", "Exploit"], "data": "N Ilg, M Pfitzenmaier, D Germek, P Duplys, M Menth\\xc2\\xa0- IEEE Access, 2025\nCurrently, the detection of CommonVulnerabilities and Exposures (CVE) exploitation \nattempts heavily depends on rule sets manually written for the detection unit. As the \nnumber of published CVEs increases each year, there is a need to advance \nautomation efforts for CVE detection. For this purpose, we introduce ALDExA, a \nframework that fetches CVE information and corresponding exploit codes to identify \nan exploit string supported by a Large Language Model (LLM). An exploit string is a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11018393.pdf&hl=en&sa=X&d=11004532408836097929&ei=J_tBaPqfIb2W6rQPmdrokQU&scisig=AAZF9b_rygDfabG_5qarxS4QqmGP&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=2&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "Modified Visual Language Model for Robust Use-After-Free Vulnerability Detection", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "L Jie, L Zhang, S Yan, Y Chen, F Yan, Y Feng\nUse-After-Free (UAF) vulnerabilities pose significant risks to software security as \nsystems grow increasingly complex. Traditional Large Language Models (LLMs) like \nBERT, CodeBERT, and GPT excel in pattern recognition but often treat code as flat \ntoken sequences, neglecting essential structural and semantic insights from static \nanalysis. This limitation hampers their robustness against code perturbations and \ntheir ability to generalize to real-world and complex UAFs such as inter-procedural\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTeams of llm agents can exploit zero-day vulnerabilities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Lidi-Jie/publication/392239819_Modified_Visual_Language_Model_for_Robust_Use-After-Free_Vulnerability_Detection/links/683a78cf8a76251f22eaa6e4/Modified-Visual-Language-Model-for-Robust-Use-After-Free-Vulnerability-Detection.pdf&hl=en&sa=X&d=11591715598152814295&ei=J_tBaPqfIb2W6rQPmdrokQU&scisig=AAZF9b9U9Q7tMxMlMnBlQBCJdYGz&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=3&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang", "2 new citations to articles by Xin ZHOU"]}
{"title": "LPASS: Linear Probes as Stepping Stones for vulnerability detection using compressed LLMs", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "L Ibanez-Lissen, L Gonzalez-Manzano, JM de Fuentes\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are being extensively used for cybersecurity \npurposes. One of them is the detection of vulnerable codes. For the sake of efficiency \nand effectiveness, compression and fine-tuning techniques are being developed, \nrespectively. However, they involve spending substantial computational efforts. In \nthis vein, we analyse how Linear Probes (LPs) can be used to provide an estimation \non the performance of a compressed LLM at an early phase--before fine-tuning. We\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection: Emerging results\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24451&hl=en&sa=X&d=2394315711310610645&ei=J_tBaMLwLLXCieoPt6N7&scisig=AAZF9b9IinR24RIrpm2DTM7Bxnev&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU", "David Lo - new related research", "1 new citation to articles by Hong Jin Kang"]}
{"title": "The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models", "first_label": ["APR"], "second_label": ["Repair"], "data": "F Vallecillos Ruiz, M Hort, L Moonen\\xc2\\xa0- arXiv e-prints, 2025\nAutomatic program repair (APR) aims to reduce the manual efforts required to \nidentify and fix errors in source code. Before the rise of LLM-based agents, a \ncommon strategy was to increase the number of generated patches, sometimes to\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ui.adsabs.harvard.edu/abs/2025arXiv250502931V/abstract&hl=en&sa=X&d=17470407147567288266&ei=J_tBaIn1H4OuieoP-ZTn2Aw&scisig=AAZF9b_mTBrB9ej9K91Gs8V1w5Fn&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Quang-Cuong Bui - new related research", "Abhik Roychoudhury - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Adversarial Preference Learning for Robust LLM Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Wang, P Wang, C Xi, B Tang, J Zhu, W Wei, C Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern language models often rely on Reinforcement Learning from Human \nFeedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to \nadversarial attacks due to three key limitations:(1) the inefficiency and high cost of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24369&hl=en&sa=X&d=11526575995055803369&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b-W-NvoVHgcod4hvfb1oD11&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "System Prompt Extraction Attacks and Defenses in Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "BC Das, MH Amini, Y Wu\\xc2\\xa0- arXiv preprint arXiv:2505.23817, 2025\nThe system prompt in Large Language Models (LLMs) plays a pivotal role in guiding \nmodel behavior and response generation. Often containing private configuration \ndetails, user roles, and operational instructions, the system prompt has become an\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23817&hl=en&sa=X&d=8359490024520200495&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b9kewGVoQUmVLeek21BFko2&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Evaluatiing the efficacy of LLM Safety Solutions: The Palit Benchmark Dataset", "first_label": ["LLM"], "second_label": [], "data": "S Palit, D Woods\\xc2\\xa0- arXiv preprint arXiv:2505.13028, 2025\nLarge Language Models (LLMs) are increasingly integrated into critical systems in \nindustries like healthcare and finance. Users can often submit queries to LLM-\nenabled chatbots, some of which can enrich responses with information retrieved\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13028%3F&hl=en&sa=X&d=1273460049730580919&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b9ByON4eaZyjRTpM1-cA_zU&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Benchmarking Large Language Models for Cryptanalysis and Mismatched-Generalization", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, C Zhu, U Naseem\\xc2\\xa0- arXiv preprint arXiv:2505.24621, 2025\nRecent advancements in Large Language Models (LLMs) have transformed natural \nlanguage understanding and generation, leading to extensive benchmarking across \ndiverse tasks. However, cryptanalysis a critical area for data security and encryption\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24621&hl=en&sa=X&d=653713479646221893&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b9TVZeOS4hNS7uC_nMr7uyt&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Wang, W Wang, S Wang, Z Li, Z Ji, Z Lyu, D Wu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Large Language Models (LLMs) has led to the \nemergence of Multi-Agent Systems (MAS) to perform complex tasks through \ncollaboration. However, the intricate nature of MAS, including their architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12442&hl=en&sa=X&d=8825331941370095164&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b_j6hKF2Zy8dNMOx-tobM6E&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AgentXploit: End-to-End Redteaming of Black-Box AI Agents", "first_label": [], "second_label": ["Agent"], "data": "Z Wang, V Siu, Z Ye, T Shi, Y Nie, X Zhao, C Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe strong planning and reasoning capabilities of Large Language Models (LLMs) \nhave fostered the development of agent-based systems capable of leveraging \nexternal tools and interacting with increasingly complex environments. However\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.05849&hl=en&sa=X&d=13145039506086791936&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b_5aWzkLQOK0HBWClMmbpt1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Ripple Effect: On Unforeseen Complications of Backdoor Attacks", "first_label": [], "second_label": [], "data": "R Zhang, Y Shen, H Li, W Jiang, H Chen, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent research highlights concerns about the trustworthiness of third-party Pre-\nTrained Language Models (PTLMs) due to potential backdoor attacks. These \nbackdoored PTLMs, however, are effective only for specific pre-defined downstream\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11586&hl=en&sa=X&d=15157304470732077928&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b997v4XRj8-KVQslhBMZvqE&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadDepth: Backdoor Attacks Against Monocular Depth Estimation in the Physical World", "first_label": [], "second_label": [], "data": "J Guo, L Zhou, Z Wang, J He, Q Song, A Chen, W Jiang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, deep learning-based Monocular Depth Estimation (MDE) models \nhave been widely applied in fields such as autonomous driving and robotics. \nHowever, their vulnerability to backdoor attacks remains unexplored. To fill the gap in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16154%3F&hl=en&sa=X&d=5415910119131408953&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b_P0jMEgHvYQo3O-kEno08o&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "first_label": ["LLM"], "second_label": [], "data": "G Chen, F Song, Z Zhao, X Jia, Y Liu, Y Qiao, W Zhang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreak attacks to Large audio-language models (LALMs) are studied recently, but \nthey achieve suboptimal effectiveness, applicability, and practicability, particularly, \nassuming that the adversary can fully manipulate user prompts. In this work, we first\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14103&hl=en&sa=X&d=12355582258955555442&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b84twuHlVXU1hPFciKO3AfT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "TRIDENT: Enhancing Large Language Model Safety with Tri-Dimensional Diversified Red-Teaming Data Synthesis", "first_label": ["LLM"], "second_label": [], "data": "X Wu, X Mao, F Li, X Zhang, X Li, C Teng, D Ji, Z Li\\xc2\\xa0- arXiv preprint arXiv:2505.24672, 2025\nLarge Language Models (LLMs) excel in various natural language processing tasks \nbut remain vulnerable to generating harmful content or being exploited for malicious \npurposes. Although safety alignment datasets have been introduced to mitigate such\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24672&hl=en&sa=X&d=8807618287327385097&ei=J_tBaJmyLo-UywTXk47YAw&scisig=AAZF9b_IdBuNmJzpASLhMF6kt1gz&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A survey of coverage-guided greybox fuzzing with deep neural models", "first_label": ["Fuzzing"], "second_label": [], "data": "J Qiu, Y Jiang, Y Miao, W Luo, L Pan, X Zheng\\xc2\\xa0- Information and Software Technology, 2025\nCoverage-guided greybox fuzzing (CGF) has emerged as a powerful technique for \nsoftware vulnerability detection, yet traditional techniques often struggle with the \nincreasing complexity of modern software systems and the vastness of input spaces. \nDeep neural networks (DNNs) have begun to fundamentally transform CGF by \naddressing these limitations through automated feature extraction, adaptive input \ngeneration, and intelligent path prioritization. However, despite these advancements\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925001363&hl=en&sa=X&d=13643876251527966728&ei=J_tBaKWyJ5LXieoPwNDK0Qk&scisig=AAZF9b8H31RZwVpkSZO2E_952tv6&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "Multidimensional Approaches in Bug Detection for Parallel Programming and Text-to-Code Semantic Parsing", "first_label": ["Code", "Bug"], "second_label": ["Detection"], "data": "M Alsofyani - 2025\nThis dissertation applies deep learning and large language models to two domains: \nparallel programming fault detection and text-to-code translation, aiming to enhance \nsoftware reliability and natural language-driven code generation. Due to their \nunpredictable nature, concurrency bugs-particularly data race bugs\\xe2\\x80\\x94present \nsignificant challenges in fault detection for parallel programming. We investigate \ndeep learning and LLM-based approaches for detecting data race bugs in OpenMP\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaImproving automatically generated code from Codex via\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://stars.library.ucf.edu/cgi/viewcontent.cgi%3Farticle%3D1130%26context%3Detd2024&hl=en&sa=X&d=8723753203795174331&ei=J_tBaKWyJ5LXieoPwNDK0Qk&scisig=AAZF9b8Dl393s8oGCWHEZDg7I85P&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Flat Minima Perspective on Understanding Augmentations and Model Robustness", "first_label": [], "second_label": [], "data": "W Yoo, SW Yoon\\xc2\\xa0- arXiv preprint arXiv:2505.24592, 2025\nModel robustness indicates a model's capability to generalize well on unforeseen \ndistributional shifts, including data corruption, adversarial attacks, and domain shifts. \nData augmentation is one of the prevalent and effective ways to enhance robustness. \nDespite the great success of augmentations in different fields, a general theoretical \nunderstanding of their efficacy in improving model robustness is lacking. We offer a \nunified theoretical framework to clarify how augmentations can enhance model\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFuzz Testing based Data Augmentation to Improve Robustness of\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24592&hl=en&sa=X&d=1198345596814614490&ei=J_tBaKWyJ5LXieoPwNDK0Qk&scisig=AAZF9b-isYEqXolh_9-VVf16H9Hq&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "RIMFuzz: real-time impact-aware mutation for library API fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "X Wang, L Zhao\\xc2\\xa0- Journal of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs libraries merely expose APIs to developers rather than directly handling user \ninput, applying fuzzing to libraries requires fuzz drivers to help process fuzzer-\nprovided input and invoke APIs. To reduce manual effort and avoid reliance on \nadditional samples, some techniques generate fuzz drivers during fuzzing by \nmodeling the test cases to describe API calls and permitting the mutation on the \nexecution sequence as well as argument values of API calls. However, such\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCoverage-based greybox fuzzing as markov chain\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00050-1&hl=en&sa=X&d=11566396351270247841&ei=J_tBaKWyJ5LXieoPwNDK0Qk&scisig=AAZF9b9NzGapAGT-Gt26V3wejXNn&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury", "Abhik Roychoudhury - new related research"]}
{"title": "Principal Context-aware Diffusion Guided Data Augmentation for Fault Localization", "first_label": ["Fault Localization"], "second_label": ["Localization"], "data": "S Fu, Y Lei\\xc2\\xa0- arXiv preprint arXiv:2505.24079, 2025\nTest cases are indispensable for conducting effective fault localization (FL). \nHowever, test cases in practice are severely class imbalanced, ie the number of \nfailing test cases (ie minority class) is much less than that of passing ones (ie majority \nclass). The severe class imbalance between failing and passing test cases have \nhindered the FL effectiveness. To address this issue, we propose PCD-DAug: a \nPrincipal Context-aware Diffusion guided Data Augmentation approach that\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCodeflaws: a programming competition benchmark for evaluating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24079&hl=en&sa=X&d=2752401929477553722&ei=J_tBaKWyJ5LXieoPwNDK0Qk&scisig=AAZF9b-Sw6EN56n5as-y9e2X3E0V&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury", "David Lo - new related research", "Thanh Le-Cong - new related research"]}
{"title": "\\xe3\\x82\\xb3\\xe3\\x83\\xbc\\xe3\\x83\\x89\\xe3\\x82\\xaf\\xe3\\x83\\xad\\xe3\\x83\\xbc\\xe3\\x83\\xb3\\xe9\\x9b\\x86\\xe7\\xb4\\x84\\xe3\\x81\\xab\\xe3\\x82\\x88\\xe3\\x82\\x8b\\xe3\\x83\\x95\\xe3\\x82\\xa1\\xe3\\x82\\xb8\\xe3\\x83\\xb3\\xe3\\x82\\xb0\\xe3\\x81\\xae\\xe5\\xae\\x9f\\xe8\\xa1\\x8c\\xe5\\x8a\\xb9\\xe7\\x8e\\x87\\xe8\\xaa\\xbf\\xe6\\x9f\\xbb", "first_label": [], "second_label": [], "data": "\\xe5\\xbe\\xb3\\xe4\\xba\\x95\\xe7\\xbf\\x94\\xe6\\xa2\\xa7\\xef\\xbc\\x8c \\xe5\\x90\\x89\\xe7\\x94\\xb0\\xe5\\x89\\x87\\xe8\\xa3\\x95\\xef\\xbc\\x8c \\xe5\\xb4\\x94\\xe6\\x81\\xa9\\xef\\xbc\\x8c \\xe4\\xba\\x95\\xe4\\xb8\\x8a\\xe5\\x85\\x8b\\xe9\\x83\\x8e\\xef\\xbc\\x8c \\xe8\\x82\\xa5\\xe5\\xbe\\x8c\\xe8\\x8a\\xb3\\xe6\\xa8\\xb9\\xc2\\xa0- \\xe3\\x82\\xb3\\xe3\\x83\\xb3\\xe3\\x83\\x94\\xe3\\x83\\xa5\\xe3\\x83\\xbc\\xe3\\x82\\xbf \\xe3\\x82\\xbd\\xe3\\x83\\x95\\xe3\\x83\\x88\\xe3\\x82\\xa6\\xe3\\x82\\xa7\\xe3\\x82\\xa2, 2025\n\\xe6\\x8a\\x84\\xe9\\x8c\\xb2 \\xe3\\x83\\x95\\xe3\\x82\\xa1\\xe3\\x82\\xb8\\xe3\\x83\\xb3\\xe3\\x82\\xb0\\xe3\\x81\\xaf\\xe9\\xab\\x98\\xe9\\x80\\x9f\\xe3\\x81\\xaa\\xe3\\x83\\x86\\xe3\\x82\\xb9\\xe3\\x83\\x88\\xe3\\x82\\xb1\\xe3\\x83\\xbc\\xe3\\x82\\xb9\\xe7\\x94\\x9f\\xe6\\x88\\x90\\xe3\\x81\\xa8\\xe5\\xae\\x9f\\xe8\\xa1\\x8c\\xe3\\x81\\xab\\xe3\\x82\\x88\\xe3\\x81\\xa3\\xe3\\x81\\xa6\\xe8\\x84\\x86\\xe5\\xbc\\xb1\\xe6\\x80\\xa7\\xe3\\x82\\x92\\xe6\\xa4\\x9c\\xe5\\x87\\xba\\xe3\\x81\\x99\\xe3\\x82\\x8b\\xe6\\x89\\x8b\\xe6\\xb3\\x95\\xe3\\x81\\xa7\\xe3\\x81\\x82\\xe3\\x82\\x8b. \nAFL \\xe3\\x81\\xaf\\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe3\\x83\\x96\\xe3\\x83\\xad\\xe3\\x83\\x83\\xe3\\x82\\xaf\\xe3\\x83\\xac\\xe3\\x83\\x99\\xe3\\x83\\xab\\xe3\\x81\\xae\\xe5\\xae\\x9f\\xe8\\xa1\\x8c\\xe3\\x83\\x91\\xe3\\x82\\xb9\\xe3\\x82\\x92\\xe8\\xa6\\xb3\\xe6\\xb8\\xac\\xe3\\x81\\x97, \\xe6\\x9c\\xaa\\xe7\\x99\\xba\\xe8\\xa6\\x8b\\xe3\\x81\\xae\\xe3\\x83\\x91\\xe3\\x82\\xb9\\xe3\\x82\\x92\\xe9\\x80\\x9a\\xe9\\x81\\x8e\\xe3\\x81\\x99\\xe3\\x82\\x8b\\xe3\\x83\\x86\\xe3\\x82\\xb9\\xe3\\x83\\x88\\xe3\\x82\\xb1\\xe3\\x83\\xbc\\xe3\\x82\\xb9\\xe3\\x82\\x92\n\\xe5\\x8a\\xb9\\xe7\\x8e\\x87\\xe7\\x9a\\x84\\xe3\\x81\\xab\\xe6\\x8e\\xa2\\xe7\\xb4\\xa2\\xe3\\x81\\x99\\xe3\\x82\\x8b\\xe3\\x83\\x95\\xe3\\x82\\xa1\\xe3\\x82\\xb8\\xe3\\x83\\xb3\\xe3\\x82\\xb0\\xe3\\x83\\x84\\xe3\\x83\\xbc\\xe3\\x83\\xab\\xe3\\x81\\xa7\\xe3\\x81\\x82\\xe3\\x82\\x8b. \\xe6\\x9c\\xac\\xe7\\xa0\\x94\\xe7\\xa9\\xb6\\xe3\\x81\\xa7\\xe3\\x81\\xaf, \\xe5\\xaf\\xbe\\xe8\\xb1\\xa1\\xe3\\x81\\xae\\xe3\\x82\\xbd\\xe3\\x83\\xbc\\xe3\\x82\\xb9\\xe3\\x82\\xb3\\xe3\\x83\\xbc\\xe3\\x83\\x89\\xe5\\x86\\x85\\xe3\\x81\\xae\\xe3\\x82\\xb3\\xe3\\x83\\xbc\\xe3\\x83\\x89\n\\xe3\\x82\\xaf\\xe3\\x83\\xad\\xe3\\x83\\xbc\\xe3\\x83\\xb3\\xe9\\x9b\\x86\\xe7\\xb4\\x84\\xe3\\x81\\xab\\xe3\\x82\\x88\\xe3\\x82\\x8b, AFL \\xe3\\x81\\xae\\xe3\\x83\\x91\\xe3\\x82\\xb9\\xe6\\x8e\\xa2\\xe7\\xb4\\xa2\\xe5\\x8a\\xb9\\xe7\\x8e\\x87\\xe3\\x81\\xae\\xe5\\xa4\\x89\\xe5\\x8c\\x96\\xe3\\x82\\x92\\xe8\\xaa\\xbf\\xe6\\x9f\\xbb\\xe3\\x81\\x97\\xe3\\x81\\x9f. \\xe5\\x9f\\xba\\xe6\\x9c\\xac\\xe3\\x83\\x96\\xe3\\x83\\xad\\xe3\\x83\\x83\\xe3\\x82\\xaf\\xe3\\x82\\x92\\xe5\\x90\\xab\\xe3\\x82\\x80\\xe3\\x82\\xb3\\xe3\\x83\\xbc\\xe3\\x83\\x89\n\\xe3\\x82\\xaf\\xe3\\x83\\xad\\xe3\\x83\\xbc\\xe3\\x83\\xb3\\xe3\\x82\\x92\\xe9\\x9b\\x86\\xe7\\xb4\\x84\\xe3\\x81\\x99\\xe3\\x82\\x8b\\xe3\\x81\\x93\\xe3\\x81\\xa8\\xe3\\x81\\xa7, \\xe3\\x83\\x91\\xe3\\x82\\xb9\\xe3\\x81\\x8c\\xe5\\x8d\\x98\\xe7\\xb4\\x94\\xe5\\x8c\\x96\\xe3\\x81\\x95\\xe3\\x82\\x8c, AFL \\xe3\\x81\\x8c\\xe8\\xa6\\xb3\\xe6\\xb8\\xac\\xe3\\x81\\x99\\xe3\\x82\\x8b\\xe3\\x83\\x91\\xe3\\x82\\xb9\\xe3\\x81\\xae\\xe6\\x95\\xb0\\xe3\\x81\\x8c\\xe6\\xb8\\x9b\\xe5\\xb0\\x91\\xe3\\x81\\x97, \n\\xe6\\x9c\\xaa\\xe7\\x99\\xba\\xe8\\xa6\\x8b\\xe3\\x81\\xae\\xe3\\x83\\x91\\xe3\\x82\\xb9\\xe3\\x81\\xab\\xe5\\x88\\xb0\\xe9\\x81\\x94\\xe3\\x81\\x97\\xe3\\x82\\x84\\xe3\\x81\\x99\\xe3\\x81\\x8f\\xe3\\x81\\xaa\\xe3\\x82\\x8b\\xe3\\x81\\xa8\\xe8\\x80\\x83\\xe3\\x81\\x88\\xe3\\x81\\x9f. \\xe5\\xae\\x9f\\xe9\\xa8\\x93\\xe3\\x81\\xae\\xe7\\xb5\\x90\\xe6\\x9e\\x9c\\xe3\\x81\\xa8\\xe3\\x81\\x97\\xe3\\x81\\xa6, AFL \\xe3\\x81\\x8c\\xe7\\x99\\xba\\xe8\\xa6\\x8b\\xe3\\x81\\x97\\xe3\\x81\\x9f\\xe3\\x83\\x91\\xe3\\x82\\xb9\\xe6\\x95\\xb0\\xe3\\x81\\xab\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCoverage-based greybox fuzzing as markov chain\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.jstage.jst.go.jp/article/jssst/42/2/42_2_135/_pdf&hl=en&sa=X&d=16179085468725345769&ei=J_tBaKWyJ5LXieoPwNDK0Qk&scisig=AAZF9b8VdqKlzN8hjg9tffa-9fxI&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "Operating system service extensions for microkernels", "first_label": [], "second_label": [], "data": "RW Skowyra, S Jero, J Furgala, BC Ward, R Khazan\\xc2\\xa0- US Patent 12,314,734, 2025\nAccording to embodiments of the present disclosure, a system includes: a \nmicrokernel having a low-level application programming interface (API) and \nproviding memory protection domains to user-level processes; and an abstraction \nlayer running on top of the microkernel and comprising a plurality of service \nextensions to the microkernel and configured to provide a high-level operating \nsystem (OS) API for use by one or more application processes running in user space\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTiming analysis of a protected operating system kernel\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://patents.google.com/patent/US12314734B1/en&hl=en&sa=X&d=5383696432805697768&ei=J_tBaKWyJ5LXieoPwNDK0Qk&scisig=AAZF9b-H-4SoyvjzdAwXCSkPMLBt&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "Fault localization of AI-enabled cyber-physical systems by exploiting temporal neuron activation", "first_label": ["Fault Localization"], "second_label": ["Exploit", "Localization"], "data": "D Lyu, Y Li, Z Zhang, P Arcaini, XY Zhang, F Ishikawa\\xe2\\x80\\xa6\\xc2\\xa0- Journal of Systems and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern cyber\\xe2\\x80\\x93physical systems (CPS) are evolving to integrate deep neural \nnetworks (DNNs) as controllers, leading to the emergence of AI-enabled CPSs. An \ninadequately trained DNN controller may produce incorrect control actions, exposing\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225001438&hl=en&sa=X&d=3286846770327067741&ei=J_tBaPWrKqKr6rQPiJHk4QU&scisig=AAZF9b-jUE3fT364wIMjAbdvLNMM&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Variational Prefix Tuning for diverse and accurate code summarization using pre-trained language models", "first_label": ["LLM", "Code"], "second_label": [], "data": "J Zhao, Y Song, E Cohen\\xc2\\xa0- Journal of Systems and Software, 2025\nRecent advancements in source code summarization have leveraged transformer-\nbased pre-trained models, including Large Language Models of Code (LLMCs), to \nautomate and improve the generation of code summaries. However, existing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.09062&hl=en&sa=X&d=10492238756586633693&ei=J_tBaLbjJc6r6rQPj9ui4AE&scisig=AAZF9b-kVaz6dOvEUYfWxHidq5aY&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Graph neural network for fault localization in sequence-based models", "first_label": ["Fault Localization"], "second_label": ["Localization", "Graph"], "data": "MA Raza, M Wardat\\xc2\\xa0- Empirical Software Engineering, 2025\nDeep learning models, particularly sequence-based models (SBMs) like Recurrent \nNeural Networks (RNNs), Long Short-Term Memory Networks (LSTMs), Gated \nRecurrent Units (GRUs), Transformers, and patch-based architectures, are crucial for\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10666-6&hl=en&sa=X&d=5230572584348431032&ei=J_tBaLbjJc6r6rQPj9ui4AE&scisig=AAZF9b-7MzoJsp70OzaEX6QItv9k&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "LLM-enhanced service Semantic Representation and Category co-occurrence feature Augmentation for Web API recommendation", "first_label": ["LLM"], "second_label": [], "data": "G Zou, P Li, S Yang, S Hu, S Pang, Y Gan\\xc2\\xa0- Information Processing & Management, 2025\nWeb API recommendation for mashup development has become increasingly \nchallenging due to the rapid growth of available APIs. Current approaches face two \ncritical limitations: semantic inconsistency in service descriptions and insufficient\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0306457325001608&hl=en&sa=X&d=9859834031812963668&ei=J_tBaLbjJc6r6rQPj9ui4AE&scisig=AAZF9b-Q8Xoyt2GZwk-3fcDMDIac&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "An Empirical Study of Multi-Language Security Patches in Open Source Software", "first_label": [], "second_label": [], "data": "S Sun, Y Xing, G Zou, X Wang, K Sun\nVulnerabilities in software repositories written in multiple programming languages \npresent a major challenge to modern software quality assurance, especially those \nresulting from interactions between different languages. Existing static and dynamic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://yunlongxing.github.io/publications/dimva25_Empirical.pdf&hl=en&sa=X&d=10326866748066170289&ei=XAtAaJeYMsiE6rQP59uGiAk&scisig=AAZF9b-FrAQMzcNeCYBMoioph8Ze&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Rethinking Code Review Workflows with LLM Assistance: An Empirical Study", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "FS A\\xc3\\xb0alsteinsson, BB Magn\\xc3\\xbasson, M Milicevic\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode reviews are a critical yet time-consuming aspect of modern software \ndevelopment, increasingly challenged by growing system complexity and the \ndemand for faster delivery. This paper presents a study conducted at WirelessCar\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16339&hl=en&sa=X&d=775906120526056084&ei=XAtAaJeYMsiE6rQP59uGiAk&scisig=AAZF9b8cBmXiUvIKNiOXGDa3tGdK&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Evaluating Small-Scale Code Models for Code Clone Detection", "first_label": ["Code"], "second_label": ["Detection"], "data": "J Martinez-Gil - 2025\nDetecting code clones is relevant to software maintenance and code refactoring. This \nchallenge still presents unresolved cases, mainly when structural similarity does not \nreflect functional equivalence, though recent code models show promise. Therefore\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://hal.science/hal-05055646v1/file/small-code-models.pdf&hl=en&sa=X&d=2446613816357308363&ei=XAtAaJeYMsiE6rQP59uGiAk&scisig=AAZF9b8FyaOH5NsvjO7gTQbFjlr6&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Targeted Fuzzing for Unsafe Rust Code: Leveraging Selective Instrumentation", "first_label": ["Fuzzing", "Code"], "second_label": [], "data": "D Paa\\xc3\\x9fen, JR Giesen, L Davi\\xc2\\xa0- arXiv preprint arXiv:2505.02464, 2025\nRust is a promising programming language that focuses on concurrency, usability, \nand security. It is used in production code by major industry players and got \nrecommended by government bodies. Rust provides strong security guarantees\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.02464&hl=en&sa=X&d=17464682910892089266&ei=XAtAaK_wLLWv6rQPgJOzyAw&scisig=AAZF9b-bvKBMc2Po_9BYZAm8NsXQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "OmniGIRL: A Multilingual and Multimodal Benchmark for GitHub Issue Resolution", "first_label": ["GitHub Issue"], "second_label": [], "data": "L Guo, W Tao, R Jiang, Y Wang, J Chen, X Liu, Y Ma\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe GitHub issue resolution task aims to resolve issues reported in repositories \nautomatically. With advances in large language models (LLMs), this task has gained \nincreasing attention, and several benchmarks are proposed to evaluate the issue\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.04606&hl=en&sa=X&d=17721785651242552030&ei=XAtAaMzrKKKr6rQPiJHk4QU&scisig=AAZF9b9vdcHDALBkXHSBcEUw295J&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Adding Context to LLM-Guided Verilog Repair", "first_label": ["LLM"], "second_label": ["Repair"], "data": "A Elnaggar, B Tan\\xc2\\xa0- 2025 26th International Symposium on Quality\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRegister transfer level (RTL) bugs are critical issues that affect the functional \ncorrectness, security, and performance of systems-on-chip (SoC). Traditionally, \nrepairing these bugs is a time-consuming process that requires the expertise of \nexperienced engineers, leading to prolonged SoC development cycles and reduced \nvendor competitiveness. In this paper, we propose an automated framework that \nutilizes a Large Language Model (LLM) to repair RTL bugs. We investigate four\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11014472/&hl=en&sa=X&d=2409201528343540759&ei=XAtAaJbLK-SN6rQPzIKygQU&scisig=AAZF9b-R6QTYYOubdd15pBuoJogx&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["1 new citation to articles by Abhik Roychoudhury"]}
{"title": "Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack", "first_label": ["LLM"], "second_label": [], "data": "S Cappelletti, T Poppi, S Poppi, ZX Yong\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly evaluated on multiple-choice \nquestion answering (MCQA) tasks using* first-token probability*(FTP), which selects \nthe answer option whose initial token has the highest likelihood. While efficient, FTP\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15323%3F&hl=en&sa=X&d=5513891085179250670&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b8ts6vJnVnPKgZRZk2J59vT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Stealthy LLM-Driven Data Poisoning Attacks Against Embedding-Based Retrieval-Augmented Recommender Systems", "first_label": ["LLM"], "second_label": [], "data": "F Nazary, Y Deldjoo, T Di Noia, E Di Sciascio\\xc2\\xa0- arXiv preprint arXiv:2505.05196, 2025\nWe present a systematic study of provider-side data poisoning in retrieval-\naugmented recommender systems (RAG-based). By modifying only a small fraction \nof tokens within item descriptions--for instance, adding emotional keywords or\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.05196&hl=en&sa=X&d=7153996738322631678&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b9XYvMXz8xtJ6dU7EDwB2B7&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "PS Pandey, S Simko, K Pelrine, Z Jin\\xc2\\xa0- arXiv preprint arXiv:2505.16789, 2025\nAs large language models gain popularity, their vulnerability to adversarial attacks \nremains a primary concern. While fine-tuning models on domain-specific datasets is \noften employed to improve model performance, it can introduce vulnerabilities within\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16789%3F&hl=en&sa=X&d=9827187220639785834&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b-hRa3CIybDfceUhaRlecWD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution", "first_label": [], "second_label": [], "data": "J Guo, X Wen, W Jiang, C Huang, J Li, H Li\\xc2\\xa0- arXiv preprint arXiv:2505.15308, 2025\nWith the widespread application of super-resolution (SR) in various fields, \nresearchers have begun to investigate its security. Previous studies have \ndemonstrated that SR models can also be subjected to backdoor attacks through\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15308&hl=en&sa=X&d=13335437674086498390&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b8WmdvUXiuzvPutlRNCBmNP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "An Embarrassingly Simple Defense Against LLM Abliteration Attacks", "first_label": ["LLM"], "second_label": [], "data": "HA Shairah, HAAK Hammoud, B Ghanem, G Turkiyyah\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are typically aligned to comply with safety guidelines \nby refusing harmful instructions. A recent attack, termed abliteration, isolates and \nsuppresses the single latent direction most responsible for refusal behavior, enabling\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19056&hl=en&sa=X&d=3737202939224050048&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b8QKV5yRTnfm0WbZVG9RAGO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Poison in the Well: Feature Embedding Disruption in Backdoor Attacks", "first_label": [], "second_label": [], "data": "Z Feng, J Chen, C Zhou, Y Pu, Q Li, S Ji\\xc2\\xa0- arXiv preprint arXiv:2505.19821, 2025\nBackdoor attacks embed malicious triggers into training data, enabling attackers to \nmanipulate neural network behavior during inference while maintaining high \naccuracy on benign inputs. However, existing backdoor attacks face limitations\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19821&hl=en&sa=X&d=8217579378668490954&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b89XZjYdu_nSk8rXx0clM5e&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Advancing LLM Safe Alignment with Safety Representation Ranking", "first_label": ["LLM"], "second_label": [], "data": "T Du, Z Wei, Q Chen, C Zhang, Y Wang\\xc2\\xa0- arXiv preprint arXiv:2505.15710, 2025\nThe rapid advancement of large language models (LLMs) has demonstrated \nmilestone success in a variety of tasks, yet their potential for generating harmful \ncontent has raised significant safety concerns. Existing safety evaluation approaches\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15710%3F&hl=en&sa=X&d=9147050430051665415&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b_UrCXjo9qqEV1FKXREeILg&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses", "first_label": ["LLM"], "second_label": [], "data": "X Yang, B Stevanoski, M Meeus, YA de Montjoye\\xc2\\xa0- arXiv preprint arXiv:2505.15738, 2025\nLarge language models (LLMs) are rapidly deployed in real-world applications \nranging from chatbots to agentic systems. Alignment is one of the main approaches \nused to defend against attacks such as prompt injection and jailbreaks. Recent\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15738&hl=en&sa=X&d=15949587169759547530&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b9jW2tzEb1jjKg1wddBnl-L&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Llamafirewall: An open source guardrail system for building secure ai agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "S Chennabasappa, C Nikolaidis, D Song, D Molnar\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have evolved from simple chatbots into autonomous \nagents capable of performing complex tasks such as editing production code, \norchestrating workflows, and taking higher-stakes actions based on untrusted inputs\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.03574&hl=en&sa=X&d=4439105352924524607&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b9vbSaup9_At8OcInY6jBmA&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Unleashing the potential of prompt engineering for large language models", "first_label": ["LLM"], "second_label": [], "data": "B Chen, Z Zhang, N Langren\\xc3\\xa9, S Zhu\\xc2\\xa0- Patterns, 2025\nThis review explores the role of prompt engineering in unleashing the capabilities of \nlarge language models (LLMs). Prompt engineering is the process of structuring \ninputs, and it has emerged as a crucial technique for maximizing the utility and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.cell.com/patterns/fulltext/S2666-3899(25)00108-4&hl=en&sa=X&d=6676094083615587801&ei=XAtAaILPMIiI6rQPoOaUkAY&scisig=AAZF9b8tnw1APcMPz1M8W7CTpXY4&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Generative AI for Source Code Creation: Revolutionizing Cloud-Native Software Engineering", "first_label": ["Code"], "second_label": [], "data": "CVS Babu, KH Kishore\\xc2\\xa0- Artificial Intelligence for Cloud-Native Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis study explores the integration of Generative AI in cloud-native software \nengineering, aiming to enhance the efficiency and effectiveness of source code \ncreation. Targeting software developers, engineers, and organizations leveraging\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.igi-global.com/chapter/generative-ai-for-source-code-creation/378773&hl=en&sa=X&d=3868822976676006039&ei=XAtAaO-eKo-UywTXk47YAw&scisig=AAZF9b8Fu8sMrUJel-3NyAV4pq8w&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Implementation of Multi-Level RAG Model for Enhanced Synergistic Vulnerability Analysis", "first_label": ["Vulnerabilities"], "second_label": [], "data": "MJ Yoon, SM Yoo, JH Park, KW Park\\xc2\\xa0- 2025 1st International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nTraditional vulnerability analysis models often rely on a single data source, which \nlimits their ability to comprehensively detect and analyze vulnerabilities. In this study, \nwe propose a multi-level Retrieval-Augmented Generation (RAG) model that \nprogressively integrates multiple vulnerability databases to overcome these \nlimitations. By incorporating core and peripheral data sources at different levels, our \napproach aims to enhance the quality of vulnerability analysis. We integrate four\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model for vulnerability detection and repair\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11012876/&hl=en&sa=X&d=4531646570342184666&ei=XAtAaNefL_iJ6rQP4Lq-sAo&scisig=AAZF9b-YBT4_GKhWHSqOX9g18i9y&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["1 new citation to articles by Xin ZHOU"]}
