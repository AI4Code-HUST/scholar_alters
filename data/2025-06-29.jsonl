{"title": "ChatGPT-Based Test Generation for Refactoring Engines Enhanced by Feature Analysis on Examples", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "C Dong, Y Jiang, Y Zhang, Y Zhang, L Hui\\xc2\\xa0- 2025 IEEE/ACM 47th International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware refactoring is widely employed to improve software quality. However, \nconducting refactorings manually is tedious, time-consuming, and error-prone. \nConsequently, automated and semi-automated tool support is highly desirable for \nsoftware refactoring in the industry, and most of the main-stream IDEs provide \npowerful tool support for refactoring. However, complex refactoring engines are \nprone to errors, which in turn may result in imperfect and incorrect refactorings. To\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaGeneration-based Code Review Automation: How Far Are We?\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a746/251mHnEjeJq&hl=en&sa=X&d=11959797704902320970&ei=pwRgaLCjNvuvieoPupH_2Ak&scisig=AAZF9b-T2BIjwqhZ8YRKplI8rgRn&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["1 new citation to articles by Xin ZHOU"]}
{"title": "VulBinLLM: LLM-powered Vulnerability Detection for Stripped Binaries", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "N Hussain, H Chen, C Tran, P Huang, Z Li, P Chugh\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecognizing vulnerabilities in stripped binary files presents a significant challenge in \nsoftware security. Although some progress has been made in generating human-\nreadable information from decompiled binary files with Large Language Models\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22010&hl=en&sa=X&d=10332909566617513173&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b_uFh0VfBD1MzUN8jZA2T1m&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "FuzzCode: Code Large Language Model-Based Fuzz Testing for Industrial IoT Programs", "first_label": ["LLM", "Fuzzing", "Code", "Software Testing"], "second_label": [], "data": "L Yang, C Wei, J Yang, W Xia, Y Yang, Y Luo, D Niyato\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Internet of Things\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFuzz testing is an dynamic program analysis technique designed for discovering \nvulnerabilities in IoT systems. The core goal is to deliberately feed maliciously crafted \ninputs into an IoT device or service, triggering vulnerabilities such as system crashes\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11028927/&hl=en&sa=X&d=8104462651931100859&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b8NEppCb0nwiT9UFTmtv4yr&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Detecting Functionality-Specific Vulnerabilities via Retrieving Individual Functionality-Equivalent APIs in Open-Source Repositories", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "T Chen, Z Wang, L Li, D Li, Z Li, X Chang, P Bian\\xe2\\x80\\xa6\\xc2\\xa0- 39th European Conference\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFunctionality-specific vulnerabilities, which mainly occur in Application Programming \nInterfaces (APIs) with specific functionalities, are crucial for software developers to \ndetect and avoid. When detecting individual functionality-specific vulnerabilities, the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://drops.dagstuhl.de/storage/00lipics/lipics-vol333-ecoop2025/LIPIcs.ECOOP.2025.6/LIPIcs.ECOOP.2025.6.pdf&hl=en&sa=X&d=14024938291331003331&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b8Zi6s9sahNn8L67Q9ApejJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "2 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Bach Le"]}
{"title": "Walls Have Ears: Demystifying Notification Listener Usage in Android Apps", "first_label": [], "second_label": [], "data": "J Deng, T Liu, Y Zhao, C Wang, L Zhang, H Wang\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe Notification Listener Service (NLS) in Android allows third-party apps to monitor \nand process device notifications, enabling powerful features but also introducing \nsecurity and privacy risks. Despite the special permission required to access NLS, it\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728898&hl=en&sa=X&d=5254092448648347629&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b_haGdL95DBvdLyCsrMhBg1&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Generating vulnerability security fixes with Code Language Models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": [], "data": "G Bhandari, N Gavric, A Shalaginov\\xc2\\xa0- Information and Software Technology, 2025\nAbstract Existing Code Language Models (CLM) have demonstrated significant \npotential in several coding tasks, including automated code generation in software \nengineering. Similarly, Automated Program Repair (APR) has shown considerable\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925001259&hl=en&sa=X&d=3259454824039873950&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b8dA_uKKprpaO6yp2cen0ap&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Direct Repair Optimization: Training Small Language Models For Educational Program Repair Improves Feedback", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "C Koutcheme, N Dainese, A Hellas\nAbstract Locally deployed Small Language Models (SLMs) offer a promising solution \nfor providing timely and effective programming feedback to students learning to code. \nHowever, SLMs often produce misleading or hallucinated feedback, limiting their\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://koutche.me/files/bea25_camera_ready.pdf&hl=en&sa=X&d=1113261810955792766&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b8kcXLxw1lmpsbI_ee25VBh&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research", "Quang-Cuong Bui - new related research", "Thanh Le-Cong - new related research", "Bach Le - new related research"]}
{"title": "Structure-EnhancedPrompt Learning for Graph-Based Code Vulnerability Detection", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection", "Graph"], "data": "W Chang, C Ye, H Zhou\\xc2\\xa0- Applied Sciences, 2025\nRecent advances in prompt learning have opened new avenues for enhancing \nnatural language understanding in domain-specific tasks, including code \nvulnerability detection. Motivated by the limitations of conventional binary\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2076-3417/15/11/6128&hl=en&sa=X&d=14787634818984465351&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b8AbdZB3i79KkRKBO0madiQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Reasoning"], "data": "XC Wen, Y Yang, C Gao, Y Xiao, D Ye\\xc2\\xa0- arXiv preprint arXiv:2506.07390, 2025\nLarge language models (LLMs) demonstrate considerable proficiency in numerous \ncoding-related tasks; however, their capabilities in detecting software vulnerabilities \nremain limited. This limitation primarily stems from two factors:(1) the absence of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07390%3F&hl=en&sa=X&d=10299031030894150274&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b_gI2XqGy6iUeaE4tdr-c1h&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Recurring Vulnerability Detection: How Far Are We?", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "Y Cao, S Wu, R Wang, B Chen, Y Huang, C Lu, Z Zhou\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the rapid development of open-source software, code reuse has become a \ncommon practice to accelerate development. However, it leads to inheritance from \nthe original vulnerability, which recurs at the reusing projects, known as recurring\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728901&hl=en&sa=X&d=18169342812720045655&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b-tZjWk7-linGwbNJwyD3xN&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Li, J Ding, C Peng, B Zhao, X Gao, H Gao, X Gu\\xc2\\xa0- arXiv preprint arXiv:2506.05692, 2025\nThe code generation capabilities of large language models (LLMs) have emerged as \na critical dimension in evaluating their overall performance. However, prior research \nhas largely overlooked the security risks inherent in the generated code. In this work\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05692%3F&hl=en&sa=X&d=5492650506064335063&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b_uwkPsOhWMHWjfdGwYFezG&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research", "Bach Le - new related research"]}
{"title": "Empirical Evaluation of Generalizable Automated Program Repair with Large Language Models", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "V Campos, R Shariffdeen, A Ulges, Y Noller\\xc2\\xa0- arXiv preprint arXiv:2506.03283, 2025\nAutomated Program Repair (APR) proposes bug fixes to aid developers in \nmaintaining software. The state of the art in this domain focuses on using LLMs, \nleveraging their strong capabilities to comprehend specifications in natural language\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03283&hl=en&sa=X&d=200998896991037433&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b_9W2A-NQAXxkYzgRHwtFh8&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Large Language Model Unlearning for Source Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "X Jiang, Y Dong, Z Fang, Y Ma, T Wang, R Cao, B Li\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM4SE has demonstrated significant success, but LLMs' potential memorization of \nsensitive or outdated training data introduces critical risks to legal compliance, \nsoftware security, and code quality. LLM unlearning techniques, which can eliminate\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17125&hl=en&sa=X&d=13604073051426366288&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b8TMw153vfhHtV32PZ_YtWF&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Black-Box Test Code Fault Localization Driven by Large Language Models and Execution Estimation", "first_label": ["LLM", "Fault Localization", "Code", "Software Testing"], "second_label": ["Localization"], "data": "AS Yaraghi, G Gharachorlu, S Fatima, LC Briand\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFault localization (FL) is a critical step in debugging which typically relies on \nrepeated executions to pinpoint faulty code regions. However, repeated executions \ncan be impractical in the presence of non-deterministic failures or high execution\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.19045&hl=en&sa=X&d=4386817275632257489&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b_xCC_qw4vQ-buJEOPT4O7A&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Chain of Grounded Objectives: Concise Goal-Oriented Prompting for Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "S Yeo, SW Hwang, YS Ma\\xc2\\xa0- 39th European Conference on Object-Oriented\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAbstract The use of Large Language Models (LLMs) for code generation has gained \nsignificant attention in recent years. Existing methods often aim to improve the quality \nof generated code by incorporating additional contextual information or guidance\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ECOOP.2025.35&hl=en&sa=X&d=15148634590804607094&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b9NXHU25qRP_AF13iMcvxnS&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "HardTests: Synthesizing High-Quality Test Cases for LLM Coding", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "Z He, YM Choi, K Zhang, J Ji, J Zhou, D Xu, I Bercovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nVerifiers play a crucial role in large language model (LLM) reasoning, needed by \npost-training techniques such as reinforcement learning. However, reliable verifiers \nare hard to get for difficult coding problems, because a well-disguised wrong solution\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24098%3F&hl=en&sa=X&d=3676350848881047114&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b_5MHFtMeBb8cv65N0a4daz&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Principal Context-aware Diffusion Guided Data Augmentation for Fault Localization", "first_label": ["Fault Localization"], "second_label": ["Localization"], "data": "S Fu, Y Lei\\xc2\\xa0- arXiv preprint arXiv:2505.24079, 2025\nTest cases are indispensable for conducting effective fault localization (FL). \nHowever, test cases in practice are severely class imbalanced, ie the number of \nfailing test cases (ie minority class) is much less than that of passing ones (ie majority\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24079&hl=en&sa=X&d=2752401929477553722&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b-Sw6EN56n5as-y9e2X3E0V&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A Preference-Driven Methodology for High-Quality Solidity Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "Z Peng, X Yin, C Ying, C Ni, Y Luo\\xc2\\xa0- arXiv preprint arXiv:2506.03006, 2025\nWhile Large Language Models (LLMs) have demonstrated remarkable progress in \ngenerating functionally correct Solidity code, they continue to face critical challenges \nin producing gas-efficient and secure code, which are critical requirements for real\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03006&hl=en&sa=X&d=17726484644696653033&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b-kQj0MkmtCeWsZksOvGyp1&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Decompiling Smart Contracts with a Large Language Model", "first_label": ["Smart Contracts", "LLM"], "second_label": [], "data": "I David, L Zhou, D Song, A Gervais, K Qin\\xc2\\xa0- arXiv preprint arXiv:2506.19624, 2025\nThe widespread lack of broad source code verification on blockchain explorers such \nas Etherscan, where despite 78,047,845 smart contracts deployed on Ethereum (as \nof May 26, 2025), a mere 767,520 (< 1%) are open source, presents a severe\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.19624&hl=en&sa=X&d=7553370957696156448&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b8lKC81lT2_gZIkgEXE8Ecy&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Simplifying Root Cause Analysis in Kubernetes with StateGraph and LLM", "first_label": ["LLM"], "second_label": ["Graph"], "data": "Y Xiang, CP Chen, L Zeng, W Yin, X Liu, H Li, W Xu\\xc2\\xa0- arXiv preprint arXiv:2506.02490, 2025\nKubernetes, a notably complex and distributed system, utilizes an array of controllers \nto uphold cluster management logic through state reconciliation. Nevertheless, \nmaintaining state consistency presents significant challenges due to unexpected\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02490&hl=en&sa=X&d=5123869491118168077&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b941F9ak4iWL2XhEVmYDE88&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Are LLMs Correctly Integrated into Software Systems?", "first_label": ["LLM"], "second_label": [], "data": "Y Shao, Y Huang, J Shen, L Ma, T Su, C Wan\\xc2\\xa0- 2025 IEEE/ACM 47th International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) provide effective solutions in various application \nscenarios, with the support of retrieval-augmented generation (RAG). However, \ndevelopers face challenges in integrating LLM and RAG into software systems, due \nto lacking interface specifications, various requirements from software context, and \ncomplicated system management. In this paper, we have conducted a \ncomprehensive study of 100 open-source applications that incorporate LLMs with\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaInvalidator: Automated patch correctness assessment via semantic\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a741/251mHkourfy&hl=en&sa=X&d=2548587237289624168&ei=pwRgaN6pJbWP6rQP0NbM6AY&scisig=AAZF9b8W6FWCN365YqKMlSw0_8UH&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Bach Le"]}
{"title": "KRAKEN: Program-Adaptive Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A Zhou, H Huang, C Zhang\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nParallel fuzzing, which utilizes multicore computers to accelerate the fuzzing process, \nhas been widely used in industrial-scale software defect detection. However, \nspecifying efficient parallel fuzzing strategies for programs with different\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728882&hl=en&sa=X&d=6944396394299119143&ei=pwRgaK66M-2rieoPqNCcqA8&scisig=AAZF9b_hlkDFVYGzlySdtgzp9iKJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "deepSURF: Detecting Memory Safety Vulnerabilities in Rust Through Fuzzing LLM-Augmented Harnesses", "first_label": ["Vulnerabilities", "LLM", "Fuzzing"], "second_label": ["Detection"], "data": "G Androutsopoulos, A Bianchi\\xc2\\xa0- arXiv preprint arXiv:2506.15648, 2025\nAlthough Rust ensures memory safety by default, it also permits the use of unsafe \ncode, which can introduce memory safety vulnerabilities if misused. Unfortunately, \nexisting tools for detecting memory bugs in Rust typically exhibit limited detection\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15648&hl=en&sa=X&d=5470473754710042022&ei=pwRgaK66M-2rieoPqNCcqA8&scisig=AAZF9b-QLCAPbmOGA94zxamaJ1DB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Structure-Aware, Diagnosis-Guided ECU Firmware Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "Q Chen, K Hu, S Gong, B Chen, Z Kong, H Jiang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nElectronic Control Units (ECUs), providing a wide range of functions from basic \ncontrol functions to safety-critical functions, play a critical role in modern vehicles. \nFuzzing has emerged as an effective approach to ensure the functional safety and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728914&hl=en&sa=X&d=4127342065268392365&ei=pwRgaK66M-2rieoPqNCcqA8&scisig=AAZF9b_7xTEoMAcPIaTyo-vzOHcB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Directed Testing in MLIR: Unleashing Its Potential by Overcoming the Limitations of Random Fuzzing", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "W Tong, Z Wang, Z Tang, J Fang, Y Zhang, G Ye\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMLIR is a new way of creating compiler infrastructures that can be easily reused and \nextended. Current MLIR fuzzing methods focus primarily on test case generation or \nmutation using randomly selected passes. However, they often overlook the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729372&hl=en&sa=X&d=10225165863736020095&ei=pwRgaK66M-2rieoPqNCcqA8&scisig=AAZF9b9XDaU-7-dG1ms-uNWhw7no&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Malo in the Code Jungle: Explainable Fault Localization for Decentralized Applications", "first_label": ["Fault Localization", "Code"], "second_label": ["Localization"], "data": "H Zhang, J Wu, Z Wu, Z Chen, D Lin, J Chen, Y Zhou\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDecentralized applications (DApps) have long been sitting ducks for hackers due to \ntheir valuable cryptocurrency assets, exposing them to various security risks. When a \nDApp is attacked, promptly identifying faults is crucial to minimizing financial losses\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11034691/&hl=en&sa=X&d=7651709202352945146&ei=pwRgaK66M-2rieoPqNCcqA8&scisig=AAZF9b8cw1Hmz_K4wN9ajW1PUmQk&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FuncVul: An Effective Function Level Vulnerability Detection Model using LLM and Code Chunk", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "S Halder, ME Ahmed, S Camtepe\\xc2\\xa0- arXiv preprint arXiv:2506.19453, 2025\nSoftware supply chain vulnerabilities arise when attackers exploit weaknesses by \ninjecting vulnerable code into widely used packages or libraries within software \nrepositories. While most existing approaches focus on identifying vulnerable\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.19453&hl=en&sa=X&d=2355126994281101941&ei=pwRgaOzIMde5ieoPw--gyAU&scisig=AAZF9b8nV7dMzuUWlB0QlvHRGoC6&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=1&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "Richard Fang - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "EnIGMA: Interactive Tools Substantially Assist LM Agents in Finding Security Vulnerabilities", "first_label": ["Vulnerabilities"], "second_label": ["Agent"], "data": "T Abramovich, M Udeshi, M Shao, K Lieret, H Xi\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nAlthough language model (LM) agents have demonstrated increased performance in \nmultiple domains, including coding and web-browsing, their success in cybersecurity \nhas been limited. We present* EnIGMA*, an LM agent for autonomously solving\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DOf3wZhVv1R&hl=en&sa=X&d=16128230014264438319&ei=pwRgaOzIMde5ieoPw--gyAU&scisig=AAZF9b9wGDtXeg4c4cNhuLqJjBH7&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "SAGE: Specification-Aware Grammar Extraction for Automated Test Case Generation with LLMs", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "H Park, S Sung, YS Han, SK Ko\\xc2\\xa0- arXiv preprint arXiv:2506.11081, 2025\nGrammar-based test case generation has proven effective for competitive \nprogramming problems, but generating valid and general grammars from natural \nlanguage specifications remains a key challenge, especially under limited\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11081&hl=en&sa=X&d=18390577984309828085&ei=pwRgaOzIMde5ieoPw--gyAU&scisig=AAZF9b8jlpuM1YVtAGvpVlGnyxvE&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=4&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "On the Harmfulness of Test Smells in Manual System Testing: A Controlled Experiment", "first_label": ["Software Testing"], "second_label": [], "data": "G Soares, V Santos, M Ribeiro, L Martins, V Pontillo\\xe2\\x80\\xa6\\xc2\\xa0- International Symposium on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nTest smells can pose difficulties during testing activities, such as poor maintainability, \nnon-deterministic behavior, and incomplete verification. Existing research has \nextensively addressed test smells in automated software tests, but little attention has\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://valeriapontillo.github.io/documents/conference/C6.pdf&hl=en&sa=X&d=957642153844525181&ei=pwRgaOzIMde5ieoPw--gyAU&scisig=AAZF9b_VsIiiDShW92x2rjNFTqKL&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=5&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "of Vulnerability-Fixing Code Lines in OSS Security Patches Using Lexical Code", "first_label": ["Vulnerabilities", "Code"], "second_label": [], "data": "RN Arakawa, Y Kanemoto, M Akiyama\\xc2\\xa0- Data and Applications Security and Privacy\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nReusing open-source software (OSS) code has become stan-dard in software \ndevelopment. When vulnerabilities are discovered in reused code, maintainers \ntypically apply security patches. However, these patches often include non\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3D3-pnEQAAQBAJ%26oi%3Dfnd%26pg%3DPA73%26ots%3D_DEgz6XSVT%26sig%3DoohdAgummyP958XHpH0NwJVRkgo&hl=en&sa=X&d=14117885644487496792&ei=pwRgaOzIMde5ieoPw--gyAU&scisig=AAZF9b8L6m1txqRLXI-jc1V-Hufw&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=6&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Your Agent Can Defend Itself against Backdoor Attacks", "first_label": [], "second_label": ["Agent"], "data": "L Changjiang, L Jiacheng, C Bochuan, C Jinghui\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite their growing adoption across domains, large language model (LLM)-\npowered agents face significant security risks from backdoor attacks during training \nand fine-tuning. These compromised agents can subsequently be manipulated to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08336&hl=en&sa=X&d=9281612337423238890&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b8EnIakTDvZQGsyv1duPVA5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Adversarial Preference Learning for Robust LLM Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Wang, P Wang, C Xi, B Tang, J Zhu, W Wei, C Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern language models often rely on Reinforcement Learning from Human \nFeedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to \nadversarial attacks due to three key limitations:(1) the inefficiency and high cost of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24369%3F&hl=en&sa=X&d=11526575995055803369&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b_ilBi9AMSJoKPXxHc_hWg5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SecurityLingua: Efficient Defense of LLM Jailbreak Attacks via Security-Aware Prompt Compression", "first_label": ["LLM"], "second_label": [], "data": "Y Li, S Ahn, H Jiang, AH Abdi, Y Yang, L Qiu\\xc2\\xa0- arXiv preprint arXiv:2506.12707, 2025\nLarge language models (LLMs) have achieved widespread adoption across \nnumerous applications. However, many LLMs are vulnerable to malicious attacks \neven after safety alignment. These attacks typically bypass LLMs' safety guardrails by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12707&hl=en&sa=X&d=8418273368991399970&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b8AOJ5PQ2S2DYr5nVOYpqTl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge", "first_label": ["LLM"], "second_label": [], "data": "S Li, C Xu, J Wang, X Gong, C Chen, J Zhang, J Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable intelligence across \nvarious tasks, which has inspired the development and widespread adoption of LLM-\nas-a-Judge systems for automated model testing, such as red teaming and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09443&hl=en&sa=X&d=2052322274134661445&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b9u9cyhYi06xXXt37CLZpdh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Syntactic paraphrase-based synthetic data generation for backdoor attacks against Chinese language models", "first_label": ["LLM"], "second_label": ["Generation"], "data": "M Hu, Y Yang, D Pan, Z Guo, L Xiao, D Lin, S Zhao\\xc2\\xa0- Information Fusion, 2025\nAbstract Language Models (LMs) have shown significant advancements in various \nNatural Language Processing (NLP) tasks. However, recent studies indicate that \nLMs are particularly susceptible to malicious backdoor attacks, where attackers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S156625352500449X&hl=en&sa=X&d=11939540759867308872&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b_omHEFDqgnSwVne_pfKwnY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Through the Stealth Lens: Rethinking Attacks and Defenses in RAG", "first_label": [], "second_label": [], "data": "S Choudhary, N Palumbo, A Hooda, KD Dvijotham\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRetrieval-augmented generation (RAG) systems are vulnerable to attacks that inject \npoisoned passages into the retrieved set, even at low corruption rates. We show that \nexisting attacks are not designed to be stealthy, allowing reliable detection and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04390&hl=en&sa=X&d=15468735482968103516&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b8u2OUJdUy7skXRySPRbZz3&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AsFT: Anchoring Safety During LLM Fine-Tuning Within Narrow Safety Basin", "first_label": ["LLM"], "second_label": [], "data": "S Yang, Q Zhang, Y Liu, Y Huang, X Jia, K Ning, J Yao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are vulnerable to safety risks during fine-tuning, \nwhere small amounts of malicious or harmless data can compromise safeguards. In \nthis paper, building on the concept of alignment direction--defined by the weight\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08473%3F&hl=en&sa=X&d=15059004078714992755&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b-cmQJQ2nP1jAOJlM9iLuaf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Securing AI Agents with Information-Flow Control", "first_label": [], "second_label": ["Agent"], "data": "M Costa, B K\\xc3\\xb6pf, A Kolluri, A Paverd, M Russinovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI agents become increasingly autonomous and capable, ensuring their security \nagainst vulnerabilities such as prompt injection becomes critical. This paper explores \nthe use of information-flow control (IFC) to provide security guarantees for AI agents\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23643%3F&hl=en&sa=X&d=4534448032257376326&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b-ruPZ7fbYUs0K6HirRZr2z&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Arms Race in Deep Learning: A Survey of Backdoor Defenses and Adaptive Attacks", "first_label": [], "second_label": [], "data": "X Mo, N Sun, LY Zhang, W Luo, S Gao, Y Xiang\\xc2\\xa0- Pacific-Asia Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeep neural networks (DNNs) face a growing threat from backdoor attacks, which \nembed hidden malicious functionalities triggered by specific inputs. This survey \nexamines the escalating arms race between backdoor defenses and increasingly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-96-8183-9_24&hl=en&sa=X&d=4258756518287065675&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b80XRQuOtBuq86IspbsVv3h&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AdaptiveLLM: A Framework for Selecting Optimal Cost-Efficient LLM for Code-Generation Based on CoT Length", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Cheng, F Liu, C Wu, L Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.10525, 2025\nWhile Large Language Models (LLMs) have significantly advanced code generation \nefficiency, they face inherent challenges in balancing performance and inference \ncosts across diverse programming tasks. Dynamically selecting the optimal LLM\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10525&hl=en&sa=X&d=12946040656504681529&ei=pwRgaJXrKdSWieoP7PPKiQQ&scisig=AAZF9b8m2TloB0C3Hd11YMxRGFIR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "The Foundation Cracks: A Comprehensive Study on Bugs and Testing Practices in LLM Libraries", "first_label": ["LLM", "Bug", "Software Testing"], "second_label": [], "data": "W Jiang, X Zhang, X Xie, J Yu, Y Zhi, S Ma, C Shen\\xc2\\xa0- arXiv preprint arXiv:2506.12320, 2025\nLarge Language Model (LLM) libraries have emerged as the foundational \ninfrastructure powering today's AI revolution, serving as the backbone for LLM \ndeployment, inference optimization, fine-tuning, and production serving across\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12320&hl=en&sa=X&d=16202500750200898582&ei=pwRgaJXrKdSWieoP7PPKiQQ&scisig=AAZF9b--UIAtYzwloYca2LhAL11r&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "A First Look at Bugs in LLM Inference Engines", "first_label": ["LLM", "Bug"], "second_label": [], "data": "M Liu, S Zhong, W Bi, Y Zhang, Z Chen, Z Chen, X Liu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language model-specific inference engines (in short as\\\\emph {LLM inference \nengines}) have become a fundamental component of modern AI infrastructure, \nenabling the deployment of LLM-powered applications (LLM apps) across cloud and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09713&hl=en&sa=X&d=1829118811417287869&ei=pwRgaJXrKdSWieoP7PPKiQQ&scisig=AAZF9b9PFvonW4DF-GngDik42RDE&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "HornBro: Homotopy-Like Method for Automated Quantum Program Repair", "first_label": ["APR"], "second_label": ["Repair"], "data": "S Tan, L Lu, D Xiang, T Chu, C Lang, J Chen, X Hu\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nQuantum programs provide exponential speedups compared to classical programs \nin certain areas, but they also inevitably encounter logical faults. Automatically \nrepairing quantum programs is much more challenging than repairing classical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715751&hl=en&sa=X&d=13228585835236654799&ei=pwRgaNLeJqKr6rQPxKWDUA&scisig=AAZF9b-8_CqaMqv576h_a4v0IZHT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "An Adaptive Language-Agnostic Pruning Method for Greener Language Models for Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "M Saad, JAH L\\xc3\\xb3pez, B Chen, D Varr\\xc3\\xb3, T Sharma\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models of code have demonstrated remarkable performance across \nvarious software engineering and source code analysis tasks. However, their \ndemanding computational resource requirements and consequential environmental\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715773&hl=en&sa=X&d=7944316343425442468&ei=pwRgaNLeJqKr6rQPxKWDUA&scisig=AAZF9b_df9m6q87B5fG6FvHqqLve&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Synthesizing Software Engineering Data in a Test-Driven Manner", "first_label": ["Software Testing"], "second_label": [], "data": "L Zhang, J Yang, M Yang, J Yang, M Chen, J Zhang\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nWe introduce** SWE-Flow**, a novel data synthesis framework grounded in Test-\nDriven Development (TDD). Unlike existing software engineering data that rely on \nhuman-submitted issues,** SWE-Flow** automatically infers incremental\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DP9DQ2IExgS&hl=en&sa=X&d=8547569170249215358&ei=pwRgaNLeJqKr6rQPxKWDUA&scisig=AAZF9b8gNj1zFs_dhY5DtQxXJmJ1&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=4&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Generating and Understanding Tests via Path-Aware Symbolic Execution with LLMs", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "Y Wu, X Zhou, A Humayun, MA Gulzar, M Kim\\xc2\\xa0- arXiv preprint arXiv:2506.19287, 2025\nSymbolic execution is a widely used technique for test generation, offering \nsystematic exploration of program paths through constraint solving. However, it is \nfundamentally constrained by the capability to model the target code including library \nfunctions in terms of symbolic constraint and the capability of underlying constraint \nsolvers. As a result, many paths involving complex features remain unanalyzed or \ninsufficiently modeled. Recent advances in large language models (LLMs) have\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge Language Model assisted Hybrid Fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.19287&hl=en&sa=X&d=18293512278044322670&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b-FcozMyrW_hmX3U3LlKbbz&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs", "first_label": ["LLM"], "second_label": [], "data": "L Zeng, Y Li, Y Xiao, C Li, CY Liu, R Yan, T Wei, J He\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware engineering (SWE) has recently emerged as a crucial testbed for next-\ngeneration LLM agents, demanding inherent capabilities in two critical dimensions: \nsustained iterative problem-solving (eg,> 50 interaction rounds) and long-context \ndependency resolution (eg,> 32k tokens). However, the data curation process in \nSWE remains notoriously time-consuming, as it heavily relies on manual annotation \nfor code file filtering and the setup of dedicated runtime environments to execute and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.19290&hl=en&sa=X&d=1346166662242430586&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b8w6YpKd7fGtz_WRHLWgg6M&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "LLMs Meet Library Evolution: Evaluating Deprecated API Usage in LLM-based Code Completion", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "C Wang, K Huang, J Zhang, Y Feng, L Zhang, Y Liu\\xe2\\x80\\xa6\\xc2\\xa0- 2025 IEEE/ACM 47th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs), pre-trained or fine-tuned on large code corpora, \nhave shown effectiveness in generating code completions. However, in LLM-based \ncode completion, LLMs may struggle to use correct and up-to-date Application \nProgramming Interfaces (APIs) due to the rapid and continuous evolution of libraries. \nWhile existing studies have highlighted issues with predicting incorrect APIs, the \nspecific problem of deprecated API usage in LLM-based code completion has not\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a781/251mHK5tjdC&hl=en&sa=X&d=4291983748355056793&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b86kWv8AjbHvLT9O9jQohIT&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "REDII: Test Infrastructure to Enable Deterministic Reproduction of Failures for Distributed Systems", "first_label": ["Software Testing"], "second_label": [], "data": "Y Feng, Z Lin, D Zhao, M Zhou, J Liu, JA Jones\\xc2\\xa0- 2025 IEEE/ACM 47th International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite the fact that distributed systems have become a crucial aspect of modern \ntechnology and support many of the software systems that enable modern life, \ndevelopers experience challenges in performing regression testing of these systems. \nExisting solutions for testing distributed systems are often either:(1) specialized \ntesting environments that are created specifically for each system by its development \nteam, which requires substantial effort for each team, with little-to-no sharing of this\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaGreybox fuzzing of distributed systems\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a780/251mHJqjtmg&hl=en&sa=X&d=3889911031160098752&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b-46KDEXfW7r2y28S4kqKTt&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Protocol Fuzzing-A Comparison between LLM-Assisted and Mutation-Based Fuzzers", "first_label": ["LLM", "Fuzzing"], "second_label": [], "data": "M Eberhardt, L Karlsson - 2025\nAs the demand for secure software and hardware solutions increase in our modern \ndigitalized society, the importance of reliable and cost-effective product testing is \napparent. One such testing technique is fuzzing, which involves generating large \namounts of malformed and randomized data to stress test system interfaces. This \nstudy aimed to compare traditional fuzzing methods to modern approaches assisted \nwith Large Language Models (LLMs) for the data generation, focusing on efficiency\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://lup.lub.lu.se/student-papers/search/publication/9202449&hl=en&sa=X&d=15120985327681873593&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b95ayzzg3DEpNCXHJ-1SN63&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "IsaBIL: A Framework for Verifying (In) correctness of Binaries in Isabelle/HOL", "first_label": [], "second_label": [], "data": "M Griffin, B Dongol, A Raad\\xc2\\xa0- 39th European Conference on Object-Oriented\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis paper presents IsaBIL, a binary analysis framework in Isabelle/HOL that is \nbased on the widely used Binary Analysis Platform (BAP). Specifically, in IsaBIL, we \nformalise BAP's intermediate language, called BIL and integrate it with Hoare logic \n(to enable proofs of correctness) as well as incorrectness logic (to enable proofs of \nincorrectness). IsaBIL inherits the full flexibility of BAP, allowing us to verify binaries \nfor a wide range of languages (C, C++, Rust), toolchains (LLVM, Ghidra) and target\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaoo7: Low-overhead defense against spectre attacks via program\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://drops.dagstuhl.de/storage/00lipics/lipics-vol333-ecoop2025/LIPIcs.ECOOP.2025.14/LIPIcs.ECOOP.2025.14.pdf&hl=en&sa=X&d=16887165659886729219&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b-p5YqV3pRu7W1gfTqORCY4&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Differential Testing Framework to Identify Critical AV Failures Leveraging Arbitrary Inputs", "first_label": ["Software Testing"], "second_label": [], "data": "T Woodlief, C Hildebrandt, S Elbaum\\xc2\\xa0- 2025 IEEE/ACM 47th International Conference\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe proliferation of autonomous vehicles (AVs) has made their failures increasingly \nevident. Testing efforts aimed at identifying the inputs leading to those failures are \nchallenged by the input's long-tail distribution, whose area under the curve is \ndominated by rare scenarios. We hypothesize that leveraging emerging open-access \ndatasets can accelerate the exploration of long-tail inputs. Having access to diverse \ninputs, however, is not sufficient to expose failures; an effective test also requires an\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFuzz Testing based Data Augmentation to Improve Robustness of\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a700/251mGSQPCJq&hl=en&sa=X&d=5529931052041046025&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b_nQnntE-4q1idXL4yr0hma&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Critical Variable State-Aware Directed Greybox Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "X Chen, N Cui, Z Pan, L Chen, G Shi, D Meng\\xc2\\xa0- 2025 IEEE/ACM 47th International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDirected fuzzing is an effective software testing method that guides the fuzzing \ncampaign towards user-defined target sites of interest, enabling the discovery of \nvulnerabilities relevant to those sites. However, even though the generated test \ncases cover the code near the target sites, complex vulnerabilities remain \nuntriggered. By focusing only on test cases that cover new edges, the program states \nrelated to the targets are overlooked, resulting in insufficient testing of the targets and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a755/251mHtx3MSk&hl=en&sa=X&d=8776928002534468621&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b-aKwp3S87nO5x62I8l5MRB&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Reinforcement Learning for Programming Feedback: Aligning Small Language Models Without Human Preferences", "first_label": ["LLM"], "second_label": [], "data": "C Koutcheme, N Dainese, A Hellas - 2025\nProviding students with timely and effective feedback remains a critical challenge in \nprogramming education. Locally deployed Small Language Models (SLMs) offer a \ncost-effective solution that enables educators to generate feedback while avoiding \nthird-party reliance and privacy concerns associated with Large Language Models \n(LLMs). However, SLMs often produce misleading or inaccurate feedback, limiting \ntheir practical use. This paper presents a fully automated reinforcement learning\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRe-factoring based Program Repair applied to Programming\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://koutche.me/files/csedm25_camera_ready.pdf&hl=en&sa=X&d=11009768349760801091&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b8tg0BTboVFoZTl8wDU59dF&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Efficient Fault Injection for Exposing and Reproducing Failures in Cloud Systems", "first_label": [], "second_label": [], "data": "H Wu - 2025\nIn today's digital era, the reliability of cloud systems is paramount as the world \nincreasingly depends on them for services. However, the complexity of modern cloud \ninfrastructures, designed for high availability, fault tolerance, and scalability, makes \nthe reliability of distributed systems a formidable challenge. Failures in these systems \ncan lead to significant financial losses and other consequences, yet they remain \ndifficult to detect, monitor, reproduce, diagnose, and recover from.\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCoverage-based greybox fuzzing as markov chain\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://jscholarship.library.jhu.edu/server/api/core/bitstreams/7a776d34-3709-4c91-b9e9-6b2213958206/content&hl=en&sa=X&d=3925328904427580497&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b_1EK08O1Q6Ugiv__PZGfnC&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=9&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Code Cloning in Solidity Smart Contracts: Prevalence, Evolution, and Impact on Development", "first_label": ["Smart Contracts", "Code"], "second_label": [], "data": "R Mo, H Song, W Ding, C Wu\\xc2\\xa0- 2025 IEEE/ACM 47th International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, the development of Solidity smart contracts has been increasing \nrapidly in popularity. Code cloning is a common coding practice, and many prior \nstudies have revealed that code clones could negatively impact software \nmaintenance and quality. However, there is little work systematically analyzing the \nnature and impacts of code clones in solidity smart contracts. To bridge this gap, we \ninvestigate the prevalence, evolution, and bug-proneness of code clones in solidity\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a660/251mGs7pOeI&hl=en&sa=X&d=10112437422740923033&ei=pwRgaMC5K8mQ6rQPpLDpqQo&scisig=AAZF9b8OCLm3NFuzScMKQAxM0x0d&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["4 new citations to articles by Bach Le"]}
{"title": "Identifying and Ranking Risks in Blockchain-Based Applications: A Systematic and Stakeholder-Informed Approach", "first_label": ["Blockchain"], "second_label": ["Detection"], "data": "R Amadi, ASM Kayes, E Pardede, J Chowdhury\\xe2\\x80\\xa6 - 2025\nAs blockchain-based applications gain widespread adoption, they are increasingly \nsusceptible to a diverse range of risks arising from their technical intricacies and \nrapidly evolving operational contexts. These risks pose significant challenges to user \ntrust and the long-term viability of blockchain solutions. This study aims to \nsystematically identify, categorize, and prioritize the key risks associated with \nblockchain-based applications. To establish a foundational understanding, we first\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.techrxiv.org/doi/pdf/10.36227/techrxiv.175036738.89696526&hl=en&sa=X&d=6544158618557328087&ei=pwRgaMC5K8mQ6rQPpLDpqQo&scisig=AAZF9b_oRk6UpwwSAOgETAmLYKr_&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=3&folt=cit", "author": ["Bach Le"], "ref": ["4 new citations to articles by Bach Le"]}
{"title": "Dockerfile Flakiness: Characterization and Repair", "first_label": [], "second_label": ["Repair"], "data": "T Shabani, N Nashid, P Alian, A Mesbah\\xc2\\xa0- 2025 IEEE/ACM 47th International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDockerfile flakiness-unpredictable temporal build failures caused by external \ndependencies and evolving environments-undermines deployment reliability and \nincreases debugging overhead. Unlike traditional Dockerfile issues, flakiness occurs \nwithout modifications to the Dockerfile itself, complicating its resolution. In this work, \nwe present the first comprehensive study of Dockerfile flakiness, featuring a nine-\nmonth analysis of 8,132 Dockerized projects, revealing that around 10% exhibit flaky\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDockercleaner: Automatic repair of security smells in dockerfiles\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a774/251mHFJwMwg&hl=en&sa=X&d=13795988126487162298&ei=pwRgaLj_LKalieoP0qP0qQs&scisig=AAZF9b_nzpBFwqb5CwQQKGMLb42F&oi=scholaralrt&hist=ylyK0_8AAAAJ:5615766320347152220:AAZF9b9Qy0LEut_atU8F20t2CTM_&html=&pos=0&folt=cit", "author": ["Quang-Cuong Bui"], "ref": ["1 new citation to articles by Quang-Cuong Bui"]}
{"title": "GVI: Guided Vulnerability Imagination for Boosting Deep Vulnerability Detectors", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "H Yong, Z Li, M Pan, T Zhang, J Zhao, X Li\\xc2\\xa0- 2025 IEEE/ACM 47th International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe use of deep learning to achieve automated software vulnerability detection has \nbeen a longstanding interest within the software security community. These deep \nvulnerability detectors are mostly trained in a supervised manner, which heavily \nrelies on large-scale, high-quality vulnerability datasets. However, the vulnerability \ndatasets used to train deep vulnerability detectors frequently exhibit class imbalance \ndue to the inherent nature of vulnerability data, where vulnerable cases are\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaVgx: Large-scale sample generation for boosting learning-based\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a750/251mHqiWAaQ&hl=en&sa=X&d=8914353394877604534&ei=pwRgaPaSKMy8ieoPz8ikiQM&scisig=AAZF9b9M64JhZppOEngQv1XsGMXg&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Machine Learning in Security Vulnerability Research [v\\xc3\\xa9d\\xc3\\xa9s el\\xc5\\x91tt]", "first_label": ["Vulnerabilities"], "second_label": ["Search"], "data": "G Selj\\xc3\\xa1n - 2025\nThis dissertation explores the application of ML in cybersecurity, with a specific focus \non offensive security. To examine existing work on the roles of AI and ML in \nvulnerability discovery, I conducted a targeted review of the literature, which \nindicated that fuzz testing, a method in which an automated tool evaluates software \nfor security flaws using random input data, is a promising area for further exploration. \nTo improve the effectiveness of fuzzers, I propose an ML-based seed selection\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://phd.lib.uni-corvinus.hu/1441/1/Seljan_Gabor_den.pdf&hl=en&sa=X&d=4876622339095215119&ei=pwRgaPaSKMy8ieoPz8ikiQM&scisig=AAZF9b-HCD-QYv9CEQE2ae--ELnx&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Learning the fine-grained code representation for log-level prediction", "first_label": ["Code"], "second_label": [], "data": "Z Zhao, G Fan, J Li, M Zhu, H Zhang, H Su\\xc2\\xa0- \\xe2\\x80\\xa6\\xc2\\xa0of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLog levels are crucial to distinguish the severity of logs and directly reflecting the \nurgency of transactions in software systems. Automatically and efficiently determining \nlog levels is a crucial and challenging task in log management. Current log-level\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00064-9&hl=en&sa=X&d=2987968475870767202&ei=pwRgaLWtOa6l6rQPgvqD4Ao&scisig=AAZF9b-oMqC_G5jyOLyAbJstOPno&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "FuseApplyBench: Multilingual Benchmark for Trustworthy Code Edit Applying Task", "first_label": ["Code"], "second_label": [], "data": "M Liang, Q Zhang, Z Zuo, S Zheng, D Chen, W Jiang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 34th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the rise of Language Models (LMs) and Large Language Models (LLMs), their \npotential for code editing (CE) has gained attention. An approach is to have LLMs \ngenerate draft code modifications, which are then refined by smaller LMs in further\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3732929&hl=en&sa=X&d=7791836070318800823&ei=pwRgaLWtOa6l6rQPgvqD4Ao&scisig=AAZF9b_-xxPAC4O-ILuaMHDNHkH0&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Rethinking the effects of data contamination in Code Intelligence", "first_label": ["Code"], "second_label": [], "data": "Z Yang, H Lin, Y He, J Xu, Z Sun, S Liu, P Wang, Z Yu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, code intelligence has gained increasing importance in the field of \nautomated software engineering. Meanwhile, the widespread adoption of Pretrained \nLanguage Models (PLMs) and Large Language Models (LLMs) has raised concerns\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02791&hl=en&sa=X&d=13914802631128746138&ei=pwRgaLWtOa6l6rQPgvqD4Ao&scisig=AAZF9b9FbJDsSBQv15gRiA2JZNoe&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Mono: Is Your\" Clean\" Vulnerability Dataset Really Solvable? Exposing and Trapping Undecidable Patches and Beyond", "first_label": ["Vulnerabilities"], "second_label": [], "data": "Z Gao, J Zhou, B Zhang, Y He, C Zhang, Y Cui, H Wang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe quantity and quality of vulnerability datasets are essential for developing deep \nlearning solutions to vulnerability-related tasks. Due to the limited availability of \nvulnerabilities, a common approach to building such datasets is analyzing security\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03651&hl=en&sa=X&d=5611261347115113824&ei=pwRgaLWtOa6l6rQPgvqD4Ao&scisig=AAZF9b8ZqDz-8m4J-1VYjUzHamnv&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Which Factors Make Code LLMs More Vulnerable to Backdoor Attacks? A Systematic Study", "first_label": ["LLM", "Code"], "second_label": [], "data": "C Wang, Z Yang, Y Harel, D Lo\\xc2\\xa0- arXiv preprint arXiv:2506.01825, 2025\nCode LLMs are increasingly employed in software development. However, studies \nhave shown that they are vulnerable to backdoor attacks: when a trigger (a specific \ninput pattern) appears in the input, the backdoor will be activated and cause the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.01825&hl=en&sa=X&d=16166340572421918430&ei=pwRgaLWtOa6l6rQPgvqD4Ao&scisig=AAZF9b-phsc8qq-f3lOMccCIs3x-&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Multi-Dataset Evaluation of Models for Automated Vulnerability Repair", "first_label": ["Vulnerabilities"], "second_label": ["Repair"], "data": "ZA Khan, A Garg, Q Tang\\xc2\\xa0- arXiv preprint arXiv:2506.04987, 2025\nSoftware vulnerabilities pose significant security threats, requiring effective \nmitigation. While Automated Program Repair (APR) has advanced in fixing general \nbugs, vulnerability patching, a security-critical aspect of APR remains underexplored\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04987&hl=en&sa=X&d=8355847986163965479&ei=pwRgaLWtOa6l6rQPgvqD4Ao&scisig=AAZF9b9iPSTGWnyCaOCv5RKilXRE&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=9&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "May the Feedback Be with You! Unlocking the Power of Feedback-Driven Deep Learning Framework Fuzzing via LLMs", "first_label": ["LLM", "Fuzzing"], "second_label": [], "data": "S Yang, C Fang, H Lin, X Chen, Z Chen\\xc2\\xa0- arXiv preprint arXiv:2506.17642, 2025\nArtificial Intelligence (AI) Infrastructures, represented by Deep Learning (DL) \nframeworks, have served as fundamental DL systems over the last decade. However, \nthe bugs in DL frameworks could lead to catastrophic consequences in some critical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17642&hl=en&sa=X&d=11889850467341289951&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b91P2KqHxsqfRiaXkVsoi1_&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Enhancing Vulnerability Detection via Inter-procedural Semantic Completion", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Generation"], "data": "B Wu, C Liu, Z Li, Y Cao, J Sun, SW Lin\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInspired by advances in deep learning, numerous learning-based approaches for \nvulnerability detection have emerged, primarily operating at the function level for \nscalability. However, this design choice has a critical limitation: many vulnerabilities\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728912&hl=en&sa=X&d=8986759430451534011&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b9A33CcRPXunqP9s6dXKLU0&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research", "Xin ZHOU - new related research"]}
{"title": "CrossProbe: LLM-Empowered Cross-Project Bug Detection for Deep Learning Frameworks", "first_label": ["LLM", "Bug"], "second_label": ["Detection"], "data": "H Guan, G Bai, Y Liu\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nDeep Learning (DL) models may introduce reliability challenges in the underlying DL \nframeworks. These frameworks may be prone to bugs that can lead to crash or wrong \nresults, particularly when involving complex model architectures and substantial\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728984&hl=en&sa=X&d=1853826777394590417&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b94yhva0cu1ErAoxyUCC4C1&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Reassessing Code Authorship Attribution in the Era of Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "AK Dipongkor, Z Yao, K Moran\\xc2\\xa0- arXiv preprint arXiv:2506.17120, 2025\nThe study of Code Stylometry, and in particular Code Authorship Attribution (CAA), \naims to analyze coding styles to identify the authors of code samples. CAA is crucial \nin cybersecurity and software forensics for addressing, detecting plagiarism, and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17120&hl=en&sa=X&d=12069506939304281396&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b9OxubQtYi2lTNPr1YQmcjb&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research", "David Lo - new related research", "Bach Le - new related research", "Xin ZHOU - new related research"]}
{"title": "Dataflow-Guided Neuro-Symbolic Language Models for Type Inference", "first_label": ["LLM"], "second_label": [], "data": "G Li, Y Wan, H Zhang, Z Zhao, W Jiang, X Shi, H Jin\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nLanguage Models (LMs) are increasingly used for type inference, aiding in error \ndetection and software development. Some real-world deployments of LMs require \nthe model to run on local machines to safeguard the intellectual property of the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Do5D8i2zZ1l&hl=en&sa=X&d=18404508326142477871&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b9xjdjSj7gUqtAzIpU2LhAX&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Bach Le - new related research"]}
{"title": "Nemotron-CORTEXA: Enhancing LLM Agents for Software Engineering Tasks via Improved Localization and Solution Diversity", "first_label": ["LLM"], "second_label": ["Agent", "Localization"], "data": "A Sohrabizadeh, J Song, M Liu, R Roy, C Lee\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nLarge Language Models (LLMs) have demonstrated significant potential in code \ngeneration by following natural language instructions. Unfortunately, crucial real-\nworld software engineering tasks, such as debugging or repository-level feature\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dk6p8UKRdH7&hl=en&sa=X&d=951048739864022913&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b-H11fzuFCoL6Gk97_KnR7i&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "10 new citations to articles by Abhik Roychoudhury", "David Lo - new related research", "Bach Le - new related research", "Xin ZHOU - new related research"]}
{"title": "Call Me Maybe: Enhancing JavaScript Call Graph Construction using Graph Neural Networks", "first_label": ["Static Analysis"], "second_label": ["Graph"], "data": "MHM Bhuiyan, G De Stefano, G Pellegrino, CA Staicu\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nStatic analysis plays a key role in finding bugs, including security issues. A critical \nstep in static analysis is building accurate call graphs that model function calls in a \nprogram. However, due to hard-to-analyze language features, existing call graph\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18191&hl=en&sa=X&d=16428373106821087898&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b8B6-fht3Wn513mIkR_opua&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "7 new citations to articles by Thanh Le-Cong", "10 new citations to articles by Bach Le", "10 new citations to articles by Hong Jin Kang"]}
{"title": "Smart-LLaMA-DPO: Reinforced Large Language Model for Explainable Smart Contract Vulnerability Detection", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection"], "data": "L Yu, Z Huang, H Yuan, S Cheng, L Yang, F Zhang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSmart contract vulnerability detection is a critical challenge in the rapidly evolving \nblockchain landscape. Existing vulnerability detection methods face two main \nissues:(1) Existing datasets lack comprehensiveness and sufficient quality, with\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728878&hl=en&sa=X&d=2135693646383280550&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b-FHJ6rZDCUMR9iJ-6yMeNb&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "10 new citations to articles by Bach Le"]}
{"title": "FANDANGO: Evolving Language-Based Testing", "first_label": ["Software Testing"], "second_label": [], "data": "JA Zamudio Amaya, M Smytzek, A Zeller\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage-based fuzzers leverage formal input specifications (languages) to \ngenerate arbitrarily large and diverse sets of valid inputs for a program under test. \nModern language-based test generators combine grammars and constraints to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728915&hl=en&sa=X&d=13526184046567235231&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b9Ngi_JZAP5Qi9nTPmPtFJJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "TypyBench: Evaluating LLM Type Inference for Untyped Python Repositories", "first_label": ["LLM"], "second_label": [], "data": "H Dong, J Yang, X Deng, Y Jiang, G Pekhimenko\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nType inference for dynamic languages like Python is a persistent challenge in \nsoftware engineering. While large language models (LLMs) have shown promise in \ncode understanding, their type inference capabilities remain underexplored. We\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dxl9sv9vEDy&hl=en&sa=X&d=5590401666570182726&ei=W3JeaK-FHs2l6rQP5MuimAI&scisig=AAZF9b_1v2ZiYt35IkKDr0FkrnZ_&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Y Mao, T Cui, P Liu, D You, H Zhu\\xc2\\xa0- arXiv preprint arXiv:2506.15170, 2025\nLarge language models (LLMs) are rapidly evolving from single-modal systems to \nmultimodal LLMs and intelligent agents, significantly expanding their capabilities \nwhile introducing increasingly severe security risks. This paper presents a systematic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15170&hl=en&sa=X&d=16427093263132639213&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b-zqUEdPZ8IyWJxfUDycl5Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AdvAgent: Controllable Blackbox Red-teaming on Web Agents", "first_label": [], "second_label": ["Agent"], "data": "C Xu, M Kang, J Zhang, Z Liao, L Mo, M Yuan, H Sun\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nFoundation model-based agents are increasingly used to automate complex tasks, \nenhancing efficiency and productivity. However, their access to sensitive resources \nand autonomous decision-making also introduce significant security risks, where\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DbwidSkOyWF&hl=en&sa=X&d=9387054046201912213&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b_vl6xXIhUKB0x_dwYNdPRR&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Emoji attack: Enhancing jailbreak attacks against judge llm detection", "first_label": ["LLM"], "second_label": ["Detection"], "data": "Z Wei, Y Liu, NB Erichson\\xc2\\xa0- Forty-second International Conference on Machine\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreaking techniques trick Large Language Models (LLMs) into producing \nrestricted output, posing a potential threat. One line of defense is to use another LLM \nas a Judge to evaluate the harmfulness of generated text. However, we reveal that\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DQ0rKYiVEZq&hl=en&sa=X&d=17491126507172914063&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b_yTB1R20z-t6ApkecZnFST&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift", "first_label": ["LLM"], "second_label": [], "data": "S Liang, J Liang, T Pang, C Du, A Liu, M Zhu, X Cao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInstruction tuning enhances large vision-language models (LVLMs) but increases \ntheir vulnerability to backdoor attacks due to their open design. Unlike prior studies in \nstatic settings, this paper explores backdoor attacks in LVLM instruction tuning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=http://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.pdf&hl=en&sa=X&d=5142527777954789704&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b9_2Tz_lMykq3n8fQAVehJc&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, M Dras, U Naseem\\xc2\\xa0- arXiv preprint arXiv:2506.02442, 2025\nThis paper presents a systematic evaluation of Large Language Models'(LLMs) \nbehavior on long-tail distributed (encrypted) texts and their safety implications. We \nintroduce a two-dimensional framework for assessing LLM safety:(1) instruction\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02442&hl=en&sa=X&d=15102350404536711280&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b_4gGVOvmiHUrKGvn2E4Vhh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems", "first_label": ["LLM"], "second_label": ["Agent", "Search"], "data": "X Li, J Chen, X Fang, S Ding, H Duan, Q Liu, K Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown remarkable capabilities in solving \ndiverse tasks. However, their proficiency in iteratively optimizing complex solutions \nthrough learning from previous feedback remains insufficiently explored. To bridge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10764&hl=en&sa=X&d=1134890120116902745&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b8s_mGNSGwzfKFs6o2hgsbd&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "L Jiang, Z Zhang, Z Wang, X Sun, Z Li, L Zhen, X Xu\\xc2\\xa0- arXiv preprint arXiv:2506.16760, 2025\nLarge Vision-Language Models (LVLMs) demonstrate exceptional performance \nacross multimodal tasks, yet remain vulnerable to jailbreak attacks that bypass built-\nin safety mechanisms to elicit restricted content generation. Existing black-box\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16760&hl=en&sa=X&d=12136733750645262486&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b8NosIP6RI9jYFVbBgmH01C&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents", "first_label": ["LLM", "Code"], "second_label": ["Agent", "Reasoning"], "data": "K Hariharan, U Girit, A Wang, J Andreas\\xc2\\xa0- arXiv preprint arXiv:2506.00172, 2025\nBenchmarks for large language models (LLMs) have predominantly assessed short-\nhorizon, localized reasoning. Existing long-horizon suites (eg SWE-bench) rely on \nmanually curated issues, so expanding or tuning difficulty demands expensive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00172&hl=en&sa=X&d=7723120566071680437&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b-MEatAoZUO5Dw1f9NQmtaH&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "S-Eval: Towards Automated and Comprehensive Safety Evaluation for Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "X Yuan, J Li, D Wang, Y Chen, X Mao, L Huang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGenerative large language models (LLMs) have revolutionized natural language \nprocessing with their transformative and emergent capabilities. However, recent \nevidence indicates that LLMs can produce harmful content that violates social norms\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728971&hl=en&sa=X&d=8645951356678636667&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b8jZqhUmHLIf6ASSQvQ_7ot&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Yuan, Y Xu, J Shi, P Zhou, L Sun\\xc2\\xa0- arXiv preprint arXiv:2505.23561, 2025\nModel merging for Large Language Models (LLMs) directly fuses the parameters of \ndifferent models finetuned on various tasks, creating a unified model for multi-domain \ntasks. However, due to potential vulnerabilities in models available on open-source\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23561&hl=en&sa=X&d=6617189016454156514&ei=W3JeaKW1FvuvieoP5Im64Qk&scisig=AAZF9b-hKaNf3ql6GqPXtJeaxsCC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Fixing", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "K Huang, J Zhang, X Xie, C Chen\\xc2\\xa0- arXiv preprint arXiv:2506.16136, 2025\nLarge language model-(LLM) based automated program repair (APR) techniques \nhave shown promising results in resolving real-world GitHub issue tasks. Existing \nAPR systems are primarily evaluated in unimodal settings (eg, SWE-bench). \nHowever, these autonomous systems struggle to resolve multimodal problem \nscenarios (eg, SWE-bench M) due to limitations in interpreting and leveraging visual \ninformation. In multimodal scenarios, LLMs need to rely on visual information in the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Programming and Program Repair (Dagstuhl Seminar\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16136&hl=en&sa=X&d=11220685545668409026&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b9kYTbwxGsxJt9tRJbr87sr&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Thanh Le-Cong - new related research", "Bach Le - new related research"]}
{"title": "Quantum Optimization for Software Engineering: A Survey", "first_label": [], "second_label": [], "data": "M Zhang, Y Li, T Yue, KY Cai\\xc2\\xa0- arXiv preprint arXiv:2506.16878, 2025\nQuantum computing, particularly in the area of quantum optimization, is steadily \nprogressing toward practical applications, supported by an expanding range of \nhardware platforms and simulators. While Software Engineering (SE) optimization \nhas a strong foundation, which is exemplified by the active Search-Based Software \nEngineering (SBSE) community and numerous classical optimization methods, the \ngrowing complexity of modern software systems and their engineering processes\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaA 2030 Roadmap for Software Engineering\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16878&hl=en&sa=X&d=13495203515859157363&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b_ejlJTEJUIB_KsddWWyuBU&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "7 new citations to articles by Xin ZHOU"]}
{"title": "AdverIntent-Agent: Adversarial Reasoning for Repair Based on Inferred Program Intent", "first_label": [], "second_label": ["Repair", "Agent", "Reasoning"], "data": "H Ye, AZH Yang, C Hu, Y Wang, T Zhang, C Le Goues\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomated program repair (APR) has shown promising results, particularly with the \nuse of neural networks. Currently, most APR tools focus on code transformations \nspecified by test suites, rather than reasoning about the program's intent and the high-\nlevel bug specification. Without a proper understanding of program intent, these tools \ntend to generate patches that overfit incomplete test suites and fail to reflect the \ndeveloper's intentions. However, reasoning about program intent is challenging. In\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSpecRover: Code Intent Extraction via LLMs\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728939&hl=en&sa=X&d=338931335499312158&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b8rDbimJ50pvziYL6CPyglt&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research", "10 new citations to articles by Bach Le", "Xin ZHOU - new related research"]}
{"title": "Position: Future Research and Challenges Remain Towards AI for Software Engineering", "first_label": [], "second_label": ["Search"], "data": "A Gu, N Jain, WD Li, M Shetty, K Ellis, K Sen\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nAI for software engineering has made remarkable progress, becoming a notable \nsuccess within generative AI. Despite this, achieving fully automated software \nengineering is still a significant challenge, requiring research efforts across both \nacademia and industry. In this position paper, our goal is threefold. First, we provide \na taxonomy of measures and tasks to categorize work towards AI software \nengineering. Second, we outline the key bottlenecks permeating today's approaches\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAI software engineer: Programming with trust\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DRuLsq4LSZK&hl=en&sa=X&d=16570752453588002278&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b-3STm2owtN4TCxlRCJShpl&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "The Sustainability Face of Automated Program Repair Tools", "first_label": ["APR"], "second_label": ["Repair"], "data": "M Martinez, S Mart\\xc3\\xadnez-Fern\\xc3\\xa1ndez, X Franch\\xc2\\xa0- ACM Transactions on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomated program repair (APR) aims to automatize the process of repairing \nsoftware bugs in order to reduce the cost of maintaining software programs. While \nAPR accuracy has significantly improved in recent years, its energy impact remains \nunstudied. The field of green software research aims to measure the energy \nconsumption required to develop, maintain, and use software products. Our main \ngoal is to define the foundation for measuring the energy consumption of the APR\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3744900&hl=en&sa=X&d=4755253952998052333&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b_b2KUTH1ZpL1eFHeVxeyti&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Thanh Le-Cong - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research", "10 new citations to articles by Bach Le", "Xin ZHOU - new related research", "10 new citations to articles by Hong Jin Kang"]}
{"title": "Reinforcement Learning-Based Fuzz Testing for the Gazebo Robotic Simulator", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "Z Ren, Y Li, X Li, G Qi, J Xuan, H Jiang\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGazebo, being the most widely utilized simulator in robotics, plays a pivotal role in \ndeveloping and testing robotic systems. Given its impact on the safety and reliability \nof robotic operations, early bug detection is critical. However, due to the challenges \nof strict input structures and vast state space, it is not effective to directly use existing \nfuzz testing approach to Gazebo. In this paper, we present GzFuzz, the first fuzz \ntesting framework designed for Gazebo. GzFuzz addresses these challenges\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728942&hl=en&sa=X&d=3075738240390385607&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b8VXL9cL4H_XDpqotfpo8TD&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Program Feature-Based Benchmarking for Fuzz Testing", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "M Miao, S Kummita, E Bodden, S Wei\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFuzzing is a powerful software testing technique renowned for its effectiveness in \nidentifying software vulnerabilities. Traditional fuzzing evaluations typically focus on \noverall fuzzer performance across a set of target programs, yet few benchmarks \nconsider how fine-grained program features influence fuzzing effectiveness. To \nbridge this gap, we introduce FeatureBench, a novel benchmark designed to \ngenerate programs with configurable, fine-grained program features to enhance\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaExplainable fuzzer evaluation\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728899&hl=en&sa=X&d=17804857660489567580&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b-ycPYTcoj8tV5Ren2Yr_m3&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "PatchScope: LLM-Enhanced Fine-Grained Stable Patch Classification for Linux Kernel", "first_label": ["LLM"], "second_label": [], "data": "R Liu, H Shi, S Liu, C Hu, S Li, Y Shen, R Wang, X Shi\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nStable patch classification plays a crucial role in vulnerability management for the \nLinux kernel, significantly contributing to the stability and security of Long-term \nsupport (LTS) versions. Although existing tools have effectively assisted in assessing \nwhether patches should be merged into stable versions, they cannot determine \nwhich stable patches should be merged into which LTS versions. This process still \nrequires the maintainers of the distribution community to manually screen based on\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Patch Backporting in Linux (Experience Paper)\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728944&hl=en&sa=X&d=13842233969248958151&ei=W3JeaMnpDZPN6rQP4_q-4Ag&scisig=AAZF9b_UJL3j4gGFSExwdfzqcx38&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "PAGENT: Learning to Patch Software Engineering Agents", "first_label": [], "second_label": ["Agent"], "data": "H Xue, G Uddin, S Wang\\xc2\\xa0- arXiv preprint arXiv:2506.17772, 2025\nLLM Agents produce patches automatically to resolve an issue. However, they can \ngenerate inaccurate patches. Little is known about the root causes behind those \nfailed patches or how those could be fixed. This paper reports an empirical study of \nthe failed patches generated by seven top LLM code agents. We collected 114 \nissues from the SWE-bench Lite dataset that remained unresolved across the agents. \nThe seven agents produced a total of 769 failed patches for those issues, which we\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSemantic-guided Search for Efficient Program Repair with Large\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17772&hl=en&sa=X&d=9634659774701361862&ei=WnJeaJTyO7WP6rQP2a7yoQM&scisig=AAZF9b8M9wHuQ8oUIxiTKFTRdimk&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["7 new citations to articles by Thanh Le-Cong", "7 new citations to articles by Xin ZHOU", "10 new citations to articles by Bach Le"]}
{"title": "Towards Effective Complementary Security Analysis using Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "J Wagner, S M\\xc3\\xbcller, C N\\xc3\\xa4ther, JP Stegh\\xc3\\xb6fer, A Both\\xc2\\xa0- arXiv preprint arXiv:2506.16899, 2025\nA key challenge in security analysis is the manual evaluation of potential security \nweaknesses generated by static application security testing (SAST) tools. Numerous \nfalse positives (FPs) in these reports reduce the effectiveness of security analysis. \nWe propose using Large Language Models (LLMs) to improve the assessment of \nSAST findings. We investigate the ability of LLMs to reduce FPs while trying to \nmaintain a perfect true positive rate, using datasets extracted from the OWASP\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaComparison of static application security testing tools and large\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16899&hl=en&sa=X&d=338234354495058247&ei=WnJeaJTyO7WP6rQP2a7yoQM&scisig=AAZF9b9k578WYv6qBXDIR2_tDFZD&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["7 new citations to articles by Thanh Le-Cong", "7 new citations to articles by Xin ZHOU", "10 new citations to articles by Bach Le"]}
{"title": "Predictive Analytics for Collaborators Answers, Code Quality, and Dropout on Stack Overflow", "first_label": ["Code"], "second_label": [], "data": "E Zolduoarrati, SA Licorish, N Stanger\\xc2\\xa0- arXiv preprint arXiv:2506.18329, 2025\nPrevious studies that used data from Stack Overflow to develop predictive models \noften employed limited benchmarks of 3-5 models or adopted arbitrary selection \nmethods. Despite being insightful, their limited scope suggests the need to \nbenchmark more models to avoid overlooking untested algorithms. Our study \nevaluates 21 algorithms across three tasks: predicting the number of question a user \nis likely to answer, their code quality violations, and their dropout status. We\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaMulti-Granularity Detector for Vulnerability Fixes\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18329&hl=en&sa=X&d=7611469386357600639&ei=WnJeaJTyO7WP6rQP2a7yoQM&scisig=AAZF9b_9aCKiiObZde4sDQdrkYCS&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=3&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["7 new citations to articles by Thanh Le-Cong", "7 new citations to articles by Xin ZHOU", "10 new citations to articles by Bach Le", "10 new citations to articles by Hong Jin Kang"]}
{"title": "Recipe for Discovery: A Framework for Systematic Open Source Project Identification", "first_label": [], "second_label": [], "data": "J Gomez, E Lovell, S Lieggi, AA Cardenas, J Davis\\xc2\\xa0- arXiv preprint arXiv:2506.18359, 2025\nOpen source software development, particularly within institutions such as \nuniversities and research laboratories, is often decentralized and difficult to track. \nDespite producing highly impactful tools in science, these efforts often go \nunrecognized due to a lack of visibility and institutional awareness. This paper \naddresses the challenge of discovering, classifying, and analyzing open source \nsoftware projects developed across distributed institutional systems. We present a\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTopic Recommendation for GitHub Repositories: How Far Can\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18359&hl=en&sa=X&d=4909976324713439627&ei=WnJeaJTyO7WP6rQP2a7yoQM&scisig=AAZF9b8joIL6Dmqc7i3wYZG9nx7K&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=4&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["7 new citations to articles by Thanh Le-Cong", "10 new citations to articles by Hong Jin Kang"]}
{"title": "When LLM-Generated Code Perpetuates User Interface Accessibility Barriers, How Can We Break the Cycle?", "first_label": ["LLM", "Code"], "second_label": [], "data": "AE Guri\\xc5\\xa3\\xc4\\x83, RD Vatavu - 2025\nAbstract The integration of Large Language Models (LLMs) into web development \nworkflows has the potential to revolutionize user interface design, yet their ability to \nproduce accessible interfaces still remains underexplored. In this paper, we present \nan evaluation of LLM-generated user interfaces against the accessibility criteria from \nthe Web Content Accessibility Guidelines (WCAG 2.1), comparing the output of \nChatGPT and Claude with two distinct prompt types\\xe2\\x80\\x94accessibility-agnostic and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaThanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://mintviz.usv.ro/publications/2025.W4A.3.pdf&hl=en&sa=X&d=9523739575333778085&ei=WnJeaJTyO7WP6rQP2a7yoQM&scisig=AAZF9b-YyI5rn7Fn1YbweubpkeNr&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=5&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["7 new citations to articles by Thanh Le-Cong", "10 new citations to articles by Bach Le"]}
{"title": "Adoption of AI tools in software development in Germany: curse or blessing for the SME sector?", "first_label": [], "second_label": [], "data": "R Blischke - 2025\nThis study investigated the adoption of Artificial Intelligence (AI) tools in Germany's \nsoftware development sector, focusing on small and medium-sized enterprises \n(SMEs). AI technologies are reshaping the industry, presenting opportunities and \nchallenges. Using a mixed-methods approach, including 14 expert interviews and a \nsurvey of 262 participants, the research identified key factors affected by AI adoption, \nsuch as efficiency gains, code quality, competitive pressure, security risks\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://repositorio.ucp.pt/bitstreams/798bec1a-ce1c-4920-94d9-48a2af77fcec/download&hl=en&sa=X&d=10961350433696587265&ei=WnJeaJTyO7WP6rQP2a7yoQM&scisig=AAZF9b_E19Obai84E6t8bDDqvOtz&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=6&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["7 new citations to articles by Thanh Le-Cong", "10 new citations to articles by Bach Le"]}
{"title": "Dissecting the SWE-Bench Leaderboards: Profiling Submitters and Architectures of LLM-and Agent-Based Repair Systems", "first_label": ["LLM"], "second_label": ["Repair", "Agent"], "data": "M Martinez, X Franch\\xc2\\xa0- arXiv preprint arXiv:2506.17208, 2025\nThe rapid progress in Automated Program Repair (APR) has been driven by \nadvances in AI, particularly large language models (LLMs) and agent-based \nsystems. SWE-Bench is a recent benchmark designed to evaluate LLM-based repair\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17208&hl=en&sa=X&d=4083813933118197972&ei=W3JeaL2XBczM6rQP1Iv48As&scisig=AAZF9b-dGmeF_-oVFNRpd5V_sd7Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research", "Bach Le - new related research"]}
{"title": "Tracing Errors, Constructing Fixes: Repository-Level Memory Error Repair via Typestate-Guided Context Retrieval", "first_label": ["Repository-Level"], "second_label": ["Repair"], "data": "X Cheng, Z Guo, H Huo, Y Sui\\xc2\\xa0- arXiv preprint arXiv:2506.18394, 2025\nMemory-related errors in C programming continue to pose significant challenges in \nsoftware development, primarily due to the complexities of manual memory \nmanagement inherent in the language. These errors frequently serve as vectors for\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18394&hl=en&sa=X&d=9210024111509700653&ei=W3JeaL2XBczM6rQP1Iv48As&scisig=AAZF9b-KQhWIdRXq44jekrEdQoui&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "ConTested: Consistency-Aided Tested Code Generation with LLM", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation"], "data": "J Dong, J Sun, W Zhang, JS Dong, D Hao\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent advancements in large language models (LLMs) have significantly improved \ncode generation, which generates code snippets automatically based on natural \nlanguage requirements. Despite achieving state-of-the-art performance, LLMs often\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728902&hl=en&sa=X&d=551936643568606765&ei=W3JeaL2XBczM6rQP1Iv48As&scisig=AAZF9b_BffNT3Tq28AAfyZzriimH&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "SemAgent: A Semantics Aware Program Repair Agent", "first_label": ["APR"], "second_label": ["Repair", "Agent"], "data": "A Pabba, A Mathai, A Chakraborty, B Ray\\xc2\\xa0- arXiv preprint arXiv:2506.16650, 2025\nLarge Language Models (LLMs) have shown impressive capabilities in downstream \nsoftware engineering tasks such as Automated Program Repair (APR). In particular, \nthere has been a lot of research on repository-level issue-resolution benchmarks\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16650&hl=en&sa=X&d=9444763424952485232&ei=W3JeaL2XBczM6rQP1Iv48As&scisig=AAZF9b8bAFz9tFwM1PpRte-a75b9&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research", "Abhik Roychoudhury - new related research", "Bach Le - new related research"]}
{"title": "Porting Software Libraries to OpenHarmony: Transitioning from TypeScript or JavaScript to ArkTS", "first_label": [], "second_label": [], "data": "B Zhou, J Shi, Y Wang, L Li, TO Li, H Yu, Z Zhu\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nOpenHarmony emerges as a potent force in the mobile app domain, poised to stand \nalongside established industry giants. ArkTS is its main language, enhancing \nTypeScript (TS) and JavaScript (JS) with strict typing for improved performance\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728941&hl=en&sa=X&d=13970335596822641006&ei=W3JeaL2XBczM6rQP1Iv48As&scisig=AAZF9b_QwQ4c8-BvXsYG1C-dI7ZY&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Bach Le - new related research"]}
{"title": "OJBench: A Competition Level Code Benchmark For Large Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "Z Wang, Y Liu, Y Wang, W He, B Gao, M Diao, Y Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent advancements in large language models (LLMs) have demonstrated \nsignificant progress in math and code reasoning capabilities. However, existing code \nbenchmark are limited in their ability to evaluate the full spectrum of these\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16395&hl=en&sa=X&d=3951203216320964809&ei=W3JeaOKQCqalieoPmtymiQ8&scisig=AAZF9b_bPDAjVh7ixiPmecwBliEw&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Improving Compiler Bug Isolation by Leveraging Large Language Models", "first_label": ["LLM", "Bug"], "second_label": [], "data": "Y Qi, J Jiang, F Li, B Chen, H Zhang, J Chen\\xc2\\xa0- arXiv preprint arXiv:2506.17647, 2025\nCompilers play a foundational role in building reliable software systems, and bugs \nwithin them can lead to catastrophic consequences. The compilation process \ntypically involves hundreds of files, making traditional automated bug isolation\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17647&hl=en&sa=X&d=15966502884654963985&ei=W3JeaOKQCqalieoPmtymiQ8&scisig=AAZF9b8HVK2FSOPtCH0zqcVktTCo&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Enhanced Prompting Framework for Code Summarization with Large Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "M Fang, X Yuan, Y Li, H Li, C Fang, J Du\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode summarization is essential for enhancing the efficiency of software \ndevelopment, enabling developers to swiftly comprehend and maintain software \nprojects. Recent efforts utilizing large language models for generating precise code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728949&hl=en&sa=X&d=14117780386321288734&ei=W3JeaOKQCqalieoPmtymiQ8&scisig=AAZF9b9gNpNnL3RU7XfwGlRRs4g_&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "A Conceptual Framework for AI Capability Evaluations", "first_label": [], "second_label": [], "data": "MV Carro, DA Mester, FG Selasco, LNF Gangi\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI systems advance and integrate into society, well-designed and transparent \nevaluations are becoming essential tools in AI governance, informing decisions by \nproviding evidence about system capabilities and risks. Yet there remains a lack of \nclarity on how to perform these assessments both comprehensively and reliably. To \naddress this gap, we propose a conceptual framework for analyzing AI capability \nevaluations, offering a structured, descriptive approach that systematizes the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLessLeak-Bench: A First Investigation of Data Leakage in LLMs\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18213&hl=en&sa=X&d=2185668946400310733&ei=W3JeaILHFMmQ6rQP85HVmAQ&scisig=AAZF9b8QpvCUs6-Ifqpwk6IvT11k&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["7 new citations to articles by Xin ZHOU"]}
{"title": "Is Your Automated Software Engineer Trustworthy?", "first_label": [], "second_label": [], "data": "NS Mathews, M Nagappan\\xc2\\xa0- arXiv preprint arXiv:2506.17812, 2025\nLarge Language Models (LLMs) are being increasingly used in software engineering \ntasks, with an increased focus on bug report resolution over the past year. However, \nmost proposed systems fail to properly handle uncertain or incorrect inputs and \noutputs. Existing LLM-based tools and coding agents respond to every issue and \ngenerate a patch for every case, even when the input is vague or their own output is \nincorrect. There are no mechanisms in place to abstain when confidence is low. This\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLessLeak-Bench: A First Investigation of Data Leakage in LLMs\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17812&hl=en&sa=X&d=6533195646356826131&ei=W3JeaILHFMmQ6rQP85HVmAQ&scisig=AAZF9b-ix22z26q2tseOa75uG-wk&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["7 new citations to articles by Xin ZHOU"]}
{"title": "Advanced time series modelling to address seasonal variability and extreme rainfall in Ghana", "first_label": [], "second_label": [], "data": "S Bosson-Amedenu, EM Baah, F Ayiah-Mensah\\xe2\\x80\\xa6\\xc2\\xa0- BMC Environmental\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRainfall forecasting is essential for environmental planning, disaster preparedness, \nand resource management. Accurate predictions enable better water resource \nmanagement, agricultural planning, and climate risk mitigation. However, forecasting \nextreme rainfall events remains a challenge due to their inherent unpredictability, \nnonlinearity, and sensitivity to seasonal and climatic variations. This study evaluates \nthe performance of various forecasting models\\xe2\\x80\\x94Facebook Prophet, Seasonal\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaPrioritizing speech test cases\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1186/s44329-025-00024-8&hl=en&sa=X&d=7308643962239435316&ei=W3JeaILHFMmQ6rQP85HVmAQ&scisig=AAZF9b_3U8FHvs12WGOrEHkWFk_n&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=6&folt=cit", "author": ["Xin ZHOU"], "ref": ["7 new citations to articles by Xin ZHOU"]}
{"title": "How Do Community Smells Influence Self-Admitted Technical Debt in Machine Learning Projects?", "first_label": [], "second_label": [], "data": "ST Cynthia, N Almarimi, B Roy\\xc2\\xa0- arXiv preprint arXiv:2506.15884, 2025\nCommunity smells reflect poor organizational practices that often lead to socio-\ntechnical issues and the accumulation of Self-Admitted Technical Debt (SATD). \nWhile prior studies have explored these problems in general software systems, their\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15884&hl=en&sa=X&d=4930810523598524491&ei=W3JeaM3kD66l6rQPjMWH6A8&scisig=AAZF9b9p78UQts06tLkLz3GRfYP7&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=4&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "SAVANT: Vulnerability Detection in Application Dependencies through Semantic-Guided Reachability Analysis", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "W Lingxiang, Q Fu, W Song, G Deng, Y Liu, D Williams\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe integration of open-source third-party library dependencies in Java development \nintroduces significant security risks when these libraries contain known \nvulnerabilities. Existing Software Composition Analysis (SCA) tools struggle to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17798&hl=en&sa=X&d=7380677225520193147&ei=W3JeaM3kD66l6rQPjMWH6A8&scisig=AAZF9b-ohwtk5qyThFSTpAAaGMIR&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=8&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "10 new citations to articles by Hong Jin Kang"]}
{"title": "Towards the Identification of Vulnerability-Fixing Code Lines in OSS Security Patches Using Lexical Code Segmentation and LLMs", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": [], "data": "RN Arakawa, Y Kanemoto, M Akiyama\\xc2\\xa0- IFIP Annual Conference on Data and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nReusing open-source software (OSS) code has become standard in software \ndevelopment. When vulnerabilities are discovered in reused code, maintainers \ntypically apply security patches. However, these patches often include non\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-96590-6_5&hl=en&sa=X&d=17465519127697819777&ei=W3JeaM3kD66l6rQPjMWH6A8&scisig=AAZF9b9GA1CSQxk-KAdJ_aEJwDYH&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=9&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Visualization Task Taxonomy to Understand the Fuzzing Internals", "first_label": ["Fuzzing"], "second_label": [], "data": "S Kummita, M Miao, E Bodden, S Wei\\xc2\\xa0- ACM Transactions on Software Engineering\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGreybox fuzzing is used extensively in research and practice. There are umpteen \npublications that improve greybox fuzzing. However, to what extent do these \nimprovements affect the internal components or internals of a given fuzzer is not yet\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3718346&hl=en&sa=X&d=6310038100822609560&ei=W3JeaNe2EbWP6rQP2a7yoQM&scisig=AAZF9b_Ue_jmzHRI425oDGHolQub&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Unlocking Low Frequency Syscalls in Kernel Fuzzing with Dependency-Based RAG", "first_label": ["Fuzzing"], "second_label": [], "data": "Z Zhang, L Li, R Liang, K Chen\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nMost coverage-guided kernel fuzzers test operating system kernels based on syscall \nsequence synthesis. However, there are still syscalls rarely or not covered (called \nlow frequency syscalls, LFS) in a period of fuzzing, meaning the relevant code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728913&hl=en&sa=X&d=16673182064331655227&ei=W3JeaNe2EbWP6rQP2a7yoQM&scisig=AAZF9b8RLECTw3pbQ9TEm3o8p8To&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "RIMFuzz: real-time impact-aware mutation for library API fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "X Wang, L Zhao\\xc2\\xa0- Journal of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs libraries merely expose APIs to developers rather than directly handling user \ninput, applying fuzzing to libraries requires fuzz drivers to help process fuzzer-\nprovided input and invoke APIs. To reduce manual effort and avoid reliance on\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00050-1&hl=en&sa=X&d=11566396351270247841&ei=W3JeaNe2EbWP6rQP2a7yoQM&scisig=AAZF9b9NzGapAGT-Gt26V3wejXNn&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Trailblazer: Practical End-to-end Web API Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "L Pan, S Cohney, T Murray, VT Pham\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThere are two key challenges in automatically testing web APIs:(a) determine where \nto send API requests and (b) identify how to make a valid payload for a given \nrequest. Both challenges are sometimes addressed by the presence of a machine\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3731717&hl=en&sa=X&d=13250706246401116236&ei=W3JeaNe2EbWP6rQP2a7yoQM&scisig=AAZF9b-ohQDK3DHvGNmHJasK8R14&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "MQueez: Specification-Driven Fuzzing for MQTT Broker (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "X Liu, Q Wang, P Liu, W Wang, S Ji\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecently, the MQTT protocol, favored for its lightweight nature, has emerged as a \npreferred choice for IoT communications. However, MQTT brokers\\xe2\\x80\\x94the critical \ncomponents responsible for message routing\\xe2\\x80\\x94are vulnerable to memory corruption\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3713081.3731724&hl=en&sa=X&d=13307417480603544934&ei=W3JeaNe2EbWP6rQP2a7yoQM&scisig=AAZF9b_xE4_BGfVFrv02wDNdOemT&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=7&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "On the Applicability of Benford's Law to Detect Saturation in Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "J Lee, H Lee, S Park, SK Cha\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nKnowing when a fuzzing campaign has reached saturation is crucial for practitioners \nto avoid unnecessarily lengthy campaigns without missing bugs within given \nresources. Unfortunately, existing solutions for determining the saturation point rely\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3731723&hl=en&sa=X&d=16464785359231774820&ei=W3JeaNe2EbWP6rQP2a7yoQM&scisig=AAZF9b-hP7JkI_Vp2sP6UiYyub7W&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=8&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FreeWavm: Enhanced WebAssembly Runtime Fuzzing Guided by Parse Tree Mutation and Snapshot", "first_label": ["Fuzzing"], "second_label": [], "data": "P Qian, X Ying, J Wang, L Liu, L Zhang, J Chen, Q He\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWebAssembly, recognized as a low-level and portable language, has been widely \nembraced in areas as diverse as browsers and blockchains, emerging as a \nrevolutionary force for Internet evolution. Unfortunately, defects and flaws in\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728877&hl=en&sa=X&d=18038798613601042415&ei=W3JeaNe2EbWP6rQP2a7yoQM&scisig=AAZF9b_-nW9eZphbttu6zMA0Febg&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=9&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories", "first_label": [], "second_label": ["Agent"], "data": "I Bouzenia, M Pradel\\xc2\\xa0- arXiv preprint arXiv:2506.18824, 2025\nLarge Language Model (LLM)-based agents are increasingly employed to automate \ncomplex software engineering tasks such as program repair and issue resolution. \nThese agents operate by autonomously generating natural language thoughts\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18824&hl=en&sa=X&d=1052979868376128117&ei=W3JeaMTnAaKr6rQPu_PX8Ak&scisig=AAZF9b9RCRJ61JSO7LJ69UBWUCsj&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=7&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Use Property-Based Testing to Bridge LLM Code Generation and Validation", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation"], "data": "L He, Z Chen, Z Zhang, J Shao, X Gao, L Sheng\\xc2\\xa0- arXiv preprint arXiv:2506.18315, 2025\nLarge Language Models (LLMs) excel at code generation, but ensuring their outputs \nto be functionally correct, especially in complex programming tasks, is a persistent \nchallenge. While traditional Test-Driven Development (TDD) offers a path for code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18315&hl=en&sa=X&d=3101719763251668573&ei=W3JeaMTnAaKr6rQPu_PX8Ak&scisig=AAZF9b8VwRdS0BYT5dVQlhiDylYe&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=8&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "SWE-GPT: A Process-Centric Language Model for Automated Software Improvement", "first_label": ["LLM"], "second_label": [], "data": "Y Ma, R Cao, Y Cao, Y Zhang, J Chen, Y Liu, Y Liu\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have demonstrated remarkable performance in code \ngeneration, significantly enhancing the coding efficiency of developers. Recent \nadvancements in LLM-based agents have led to significant progress in end-to-end\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728981&hl=en&sa=X&d=16298319323825873072&ei=W3JeaMTnAaKr6rQPu_PX8Ak&scisig=AAZF9b8fbB6Sgf8veT0Tj0g5M6NA&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=9&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "VFArch\\\\= e: A Dual-Mode Framework for Locating Vulnerable Functions in Open-Source Software", "first_label": [], "second_label": [], "data": "L Zhang, J Zhang, K Li, C Wang, C Liu, J Wu, S Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware Composition Analysis (SCA) has become pivotal in addressing \nvulnerabilities inherent in software project dependencies. In particular, reachability \nanalysis is increasingly used in Open-Source Software (OSS) projects to identify \nreachable vulnerabilities (eg, CVEs) through call graphs, enabling a focus on \nexploitable risks. Performing reachability analysis typically requires the vulnerable \nfunction (VF) to track the call chains from downstream applications. However, such\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTest mimicry to assess the exploitability of library vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18050&hl=en&sa=X&d=12706225658298449789&ei=W3JeaIHBCM2l6rQP5MuimAI&scisig=AAZF9b-bn3YUCl4hnVomcS4ab3ua&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=4&folt=cit", "author": ["Bach Le"], "ref": ["10 new citations to articles by Bach Le", "10 new citations to articles by Hong Jin Kang"]}
{"title": "Probing the Robustness of Large Language Models Safety to Latent Perturbations", "first_label": ["LLM"], "second_label": [], "data": "T Gu, K Huang, Z Wang, Y Wang, J Li, Y Yao, Y Yao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSafety alignment is a key requirement for building reliable Artificial General \nIntelligence. Despite significant advances in safety alignment, we observe that minor \nlatent shifts can still trigger unsafe responses in aligned models. We argue that this \nstems from the shallow nature of existing alignment methods, which focus on surface-\nlevel refusal behaviors without sufficiently altering internal representations. \nConsequently, small shifts in hidden activations can re-trigger harmful behaviors\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16078&hl=en&sa=X&d=3967826748183267165&ei=W3JeaJbVA9zM6rQPjezbgAU&scisig=AAZF9b9UxxjGDnYxH7xpW52Wlueu&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["3 new citations to articles by Richard Fang"]}
{"title": "Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "Z Ji, D Wu, W Jiang, P Ma, Z Li, S Wang\\xc2\\xa0- arXiv preprint arXiv:2506.17644, 2025\nCapture-the-Flag (CTF) competitions are crucial for cybersecurity education and \ntraining. As large language models (LLMs) evolve, there is increasing interest in their \nability to automate CTF challenge solving. For example, DARPA has organized the \nAIxCC competition since 2023 to advance AI-powered automated offense and \ndefense. However, this demands a combination of multiple abilities, from knowledge \nto reasoning and further to actions. In this paper, we highlight the importance of\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaTeams of llm agents can exploit zero-day vulnerabilities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17644&hl=en&sa=X&d=18039007939580853816&ei=W3JeaJbVA9zM6rQPjezbgAU&scisig=AAZF9b-ki8gDF4phocydM5b5FXR5&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["3 new citations to articles by Richard Fang"]}
{"title": "Fine-Tuning Lowers Safety and Disrupts Evaluation Consistency", "first_label": [], "second_label": [], "data": "KC Fraser, H Dawkins, I Nejadgholi, S Kiritchenko\\xc2\\xa0- arXiv preprint arXiv:2506.17209, 2025\nFine-tuning a general-purpose large language model (LLM) for a specific domain or \ntask has become a routine procedure for ordinary users. However, fine-tuning is \nknown to remove the safety alignment features of the model, even when the fine-\ntuning data does not contain any harmful content. We consider this to be a critical \nfailure mode of LLMs due to the widespread uptake of fine-tuning, combined with the \nbenign nature of the\" attack\". Most well-intentioned developers are likely unaware\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17209&hl=en&sa=X&d=3946927903142380014&ei=W3JeaJbVA9zM6rQPjezbgAU&scisig=AAZF9b_ZX2kkcXZnkIfmDHeOm3L6&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=2&folt=cit", "author": ["Richard Fang"], "ref": ["3 new citations to articles by Richard Fang"]}
{"title": "Teaching an Old LLM Secure Coding: Localized Preference Optimization on Distilled Preferences", "first_label": ["LLM"], "second_label": ["Localization"], "data": "M Saqib, S Chakraborty, S Karmaker\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM generated code often contains security issues. We address two key challenges \nin improving secure code generation. First, obtaining high quality training data \ncovering a broad set of security issues is critical. To address this, we introduce a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00419&hl=en&sa=X&d=3471320712326210844&ei=W3JeaM64HNzM6rQPjezbgAU&scisig=AAZF9b-zP6iuspafIpJ9gFQhBsZE&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Fuzzy-Assisted Contrastive Decoding Improving Code Generation of Large Language Models", "first_label": ["LLM", "Fuzzing", "Code"], "second_label": ["Generation"], "data": "S Wang, L Ding, Y Zhan, Y Luo, S Liu, W Ding\\xc2\\xa0- IEEE Transactions on Fuzzy Systems, 2025\nLarge Language Models (LLMs) play a crucial role in intelligent code generation \ntasks. Most existing work focuses on pre-training or fine-tuning specialized code \nLLMs, eg, CodeLlama. However, pre-training or fine-tuning a code LLM requires a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11018203/&hl=en&sa=X&d=14224229548332545185&ei=W3JeaM64HNzM6rQPjezbgAU&scisig=AAZF9b84Z_y_EtuSzqsfEfycTvKd&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Using Large Language Models for Aerospace Code Generation: Methods, Benchmarks, and Potential Values", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "R He, L Zhang, M Lyu, L Lyu, C Xue\\xc2\\xa0- Aerospace, 2025\nIn recent years, Large Language Models (LLMs) have witnessed rapid \nadvancements, revolutionizing various domains. Within the realm of software \ndevelopment, code generation technology powered by LLMs has emerged as a\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2226-4310/12/6/498&hl=en&sa=X&d=10774117724622108555&ei=W3JeaM64HNzM6rQPjezbgAU&scisig=AAZF9b_rdKO7Y_152Nx4dsGU87hA&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=9&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Hybrid Neuro-Symbolic Pipeline for Coreference Resolution and AMR-Based Semantic Parsing", "first_label": [], "second_label": [], "data": "C Papakostas, C Troussas, A Krouska\\xe2\\x80\\xa6\\xc2\\xa0- Information, 2025\nLarge Language Models (LLMs) have transformed Natural Language Processing \n(NLP), yet they continue to struggle with deep semantic understanding, particularly in \ntasks like coreference resolution and structured semantic inference. This study \npresents a hybrid neuro-symbolic pipeline that combines transformer-based \ncontextual encoding with symbolic coreference resolution and Abstract Meaning \nRepresentation (AMR) parsing to improve natural language understanding. The\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSurveying neuro-symbolic approaches for reliable artificial\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2078-2489/16/7/529&hl=en&sa=X&d=17750247940711752393&ei=W3JeaPH1BtSWieoP25n1uQQ&scisig=AAZF9b9LVDVTufrzdRQLqrDSlViu&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["10 new citations to articles by Hong Jin Kang"]}
{"title": "Regression Testing Optimization for ROS-based Autonomous Systems: A Comprehensive Review of Techniques", "first_label": ["Software Testing"], "second_label": [], "data": "Y Jiang, S Sun, X Zheng\\xc2\\xa0- arXiv preprint arXiv:2506.16101, 2025\nRegression testing plays a critical role in maintaining software reliability, particularly \nfor ROS-based autonomous systems (ROSAS), which frequently undergo continuous \nintegration and iterative development. However, conventional regression testing \ntechniques face significant challenges when applied to autonomous systems due to \ntheir dynamic and non-deterministic behaviors, complex multi-modal sensor data, \nasynchronous distributed architectures, and stringent safety and real-time\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSurveying neuro-symbolic approaches for reliable artificial\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16101&hl=en&sa=X&d=6869479742326984994&ei=W3JeaPH1BtSWieoP25n1uQQ&scisig=AAZF9b8PFz47rtLzzR2zc2iWry3S&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["10 new citations to articles by Hong Jin Kang"]}
{"title": "NADA: Neural Acceptance-Driven Approximate Specification Mining", "first_label": [], "second_label": [], "data": "W Luo, T Han, J Qiu, H Wan, J Du, B Peng, G Xiao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIt is hard to mine high-quality finite-state automata (FSAs) only from desired software \nbehaviors, ie, positive examples, because of a search space explosion and an \novergeneralization problem induced by a lack of undesired software behaviors, ie, \nnegative examples. To tackle the overgeneralization problem, we suggest modeling \nthe problem as searching for approximate FSAs from positive and negative examples \nwith noise, where the noise originates from synthetic negative examples used to\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAdversarial specification mining\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728956&hl=en&sa=X&d=13513417715284606276&ei=W3JeaPH1BtSWieoP25n1uQQ&scisig=AAZF9b_A5v9t1j8zI8Zqkh3kzBo_&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=8&folt=cit", "author": ["Hong Jin Kang"], "ref": ["10 new citations to articles by Hong Jin Kang"]}
{"title": "Identifying Multi-parameter Constraint Errors in Python Data Science Library API Documentation", "first_label": [], "second_label": ["Detection"], "data": "X Xu, F Xie, C Zhu, G Bai, S Khurshid, Y Li\\xc2\\xa0- Proceedings of the ACM on Software\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern AI-and Data-intensive software systems rely heavily on data science and \nmachine learning libraries that provide essential algorithmic implementations and \ncomputational frameworks. These libraries expose complex APIs whose correct \nusage has to follow constraints among multiple interdependent parameters. \nDevelopers using these APIs are expected to learn about the constraints through the \nprovided documentation and any discrepancy may lead to unexpected behaviors\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaActive learning of discriminative subgraph patterns for api misuse\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728945&hl=en&sa=X&d=1953829909907632975&ei=W3JeaPH1BtSWieoP25n1uQQ&scisig=AAZF9b9JTpkxHy0iFC3UWZsJGOrN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=9&folt=cit", "author": ["Hong Jin Kang"], "ref": ["10 new citations to articles by Hong Jin Kang"]}
