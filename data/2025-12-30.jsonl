{"title": ":", "first_label": [], "second_label": [], "data": "- 2025\n     . \n        \n  .    \n      . \n        \n  .  \nCites: On testing embedded software\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://elar.urfu.ru/bitstream/10995/147534/1/m_th_a.r.shaikhullin_2025.pdf&hl=en&sa=X&d=2331942445289060019&ei=_pJRabrgHbux6rQPi5qW2AE&scisig=ALhkC2SzLGybV1KUFX4A2BsAmufz&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ALhkC2SLNtxsIYV7y8T6Ni2J4ruF&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["1 new citation to articles by Abhik Roychoudhury"]}
{"title": "Assessing the Software Security Comprehension of Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "ML Siddiq, N Sekerak, A Karam, M Leal- arXiv preprint arXiv, 2025\nLarge language models (LLMs) are increasingly used in software development, but \ntheir level of software security expertise remains unclear. This work systematically \nevaluates the security comprehension of five leading LLMs: GPT-4o-Mini, GPT-5\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.21238&hl=en&sa=X&d=3008638681246238265&ei=_5JRaZSPHr6Z6rQPr-v5iAc&scisig=ALhkC2TclUqSPaolcLkUxqJj4FaU&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ALhkC2Q9j5kdmlV_e8u2kLe_NWfw&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Engine Failure Prediction on Large-Scale CMAPSS Data Using Hybrid Feature Selection and Imbalance-Aware Learning", "first_label": [], "second_label": [], "data": "A Junaid, A Iqbal, A Khan, G Husnain, AR Ahmad - 2025\nMost predictive maintenance studies have emphasized accuracy but provide very \nlittle focus on Interpretability or deployment readiness. This study improves on prior \nmethods by developing a small yet robust system that can predict when turbofan \nengines will fail. It uses the NASA CMAPSS dataset, which has over 200,000 engine \ncycles from 260 engines. The process begins with systematic preprocessing, which \nincludes imputation, outlier removal, scaling, and labelling of the remaining useful\nCites: Surveying neuro-symbolic approaches for reliable artificial\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Ghassan-Husnain/publication/399027571_Engine_Failure_Prediction_on_Large-Scale_CMAPSS_Data_Using_Hybrid_Feature_Selection_and_Imbalance-Aware_Learning/links/694b6ee27e61d05b53121a72/Engine-Failure-Prediction-on-Large-Scale-CMAPSS-Data-Using-Hybrid-Feature-Selection-and-Imbalance-Aware-Learning.pdf&hl=en&sa=X&d=7575073542104611010&ei=_ZJRaaTnOZaM6rQP0-TCwQU&scisig=ALhkC2TCqYmxSSu8tUd-7gO-Dr9h&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:ALhkC2Tv0L1GNq4Kk4Fq05ZvgtDM&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["1 new citation to articles by Hong Jin Kang"]}
{"title": "Artificial or Just Artful? Do LLMs Bend the Rules in Programming?", "first_label": ["LLM"], "second_label": [], "data": "OB Sghaier, K Delcourt, H Sahraoui- arXiv preprint arXiv:2512.21028, 2025\nLarge Language Models (LLMs) are widely used for automated code generation, yet \ntheir apparent successes often mask a tension between pretraining objectives and \nalignment choices. While pretraining encourages models to exploit all available", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.21028&hl=en&sa=X&d=5351799457747135438&ei=_pJRaf6WDdKV6rQP84i9kQc&scisig=ALhkC2TW_eRyQmbbnC593J6wW6ag&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ALhkC2THo_3s8tBI3qmyNrpmj0cv&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "1 new citation to articles by Xin ZHOU"]}
{"title": "Beyond Code Pairs: Dialogue-Based Data Generation for LLM Code Translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "L Chen, N Xu, W Chen, B Lei, PH Lin, D Zhou- arXiv preprint arXiv, 2025\nLarge language models (LLMs) have shown remarkable capabilities in code \ntranslation, yet their performance deteriorates in low-resource programming domains \nsuch as Fortran and emerging frameworks like CUDA, where high-quality parallel", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.03086&hl=en&sa=X&d=15724167796935183524&ei=_pJRaf6WDdKV6rQP84i9kQc&scisig=ALhkC2RGUOYClntRywDgzqfB8TOC&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ALhkC2THo_3s8tBI3qmyNrpmj0cv&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Automating Unit Test Generation with Large Language Models: An Integrated Empirical and Theoretical Investigation", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "JK Morales- Research Index Library of Eijmr, 2025\nBackground: The emergence of large language models (LLMs) has introduced novel \ncapabilities for program understanding and automated artifact generation, including \nunit tests. Recent empirical work suggests both promise and limitations of LLMs\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=http://eijmr.net/index.php/rileijmr/article/view/52&hl=en&sa=X&d=7912543035378311447&ei=_pJRaf6WDdKV6rQP84i9kQc&scisig=ALhkC2SUdj4xVWKzayBNSFNL5J3X&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ALhkC2THo_3s8tBI3qmyNrpmj0cv&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "VulnLLM-R: Specialized Reasoning LLM with Agent Scaffold for Vulnerability Detection", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Agent", "Reasoning"], "data": "Y Nie, H Li, C Guo, R Jiang, Z Wang, B Li, D Song- arXiv preprint arXiv, 2025\nWe propose VulnLLM-R, the~\\emph {first specialized reasoning LLM} for \nvulnerability detection. Our key insight is that LLMs can reason about program states \nand analyze the potential vulnerabilities, rather than simple pattern matching. This\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.07533&hl=en&sa=X&d=14822866035105946059&ei=_ZJRaayfFLK16rQPn86DwQ8&scisig=ALhkC2SrItwEGbUy2HNxI0DJG3ud&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:ALhkC2QkVwCdvNzUylYiTyCmheSL&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Dependable Code Repair with LLMs: AI-Driven Vulnerability Detection and Automated Patching", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection", "Repair"], "data": "S Han, H Kim, H Lee, H Moon, Y Jeon, H Bae, D Yeo\nThe rapid proliferation of software vulnerabilities has created an urgent need for \nintelligent, automated methods to detect and mitigate security flaws at scale. \nTraditional vulnerability analysis depends heavily on manual inspection and domain\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://seclab.skku.edu/wp-content/uploads/2025/12/PRDC_AID_136_2025.pdf&hl=en&sa=X&d=5403717416336863891&ei=_pJRaYbkLoaw6rQPkNu46Ao&scisig=ALhkC2RDYmIkwPPsK8HJE3Ozta0n&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:ALhkC2SS1P3l44RDJXsNEdNzDLiT&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Bootstrapping Fuzzers for Compilers of Low-Resource Language Dialects Using Language Models", "first_label": ["LLM", "Fuzzing"], "second_label": [], "data": "S Vaidya, M Bhme, L D'Antoni- arXiv preprint arXiv:2512.05887, 2025\nModern extensible compiler frameworks-such as MLIR-enable rapid creation of \ndomain-specific language dialects. This flexibility, however, makes correctness \nharder to ensure as the same extensibility that accelerates development also\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.05887&hl=en&sa=X&d=4462874127133540648&ei=_ZJRafeAJ9rJieoPiYyysAk&scisig=ALhkC2QrUX2QWbZaardTdZviikC5&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ALhkC2RZmRqgZGCFQXCJyP9vthGu&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Engagement in Code Review: Emotional, Behavioral, and Cognitive Dimensions in Peer vs. LLM Interactions", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "A Alami, N Cassee, TR Silva, E Paja, NA Ernst- arXiv preprint arXiv:2512.05309, 2025\nCode review is a socio-technical practice, yet how software engineers engage in \nLarge Language Model (LLM)-assisted code reviews compared to human peer-led \nreviews is less understood. We report a two-phase qualitative study with 20 software", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.05309&hl=en&sa=X&d=473369942188785420&ei=_5JRaYqVLYaw6rQPkNu46Ao&scisig=ALhkC2SmS13J2E5MGGhr11_c3Wpo&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ALhkC2T269WwPtyd5qvti3WNZV40&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration", "first_label": ["LLM", "Code"], "second_label": [], "data": "R Wang, X Wang, C Gao, CY Chong, X Xia, Q Liao- arXiv preprint arXiv:2512.20159, 2025\nLarge language models (LLMs) have been increasingly deployed in real-world \nsoftware engineering, fostering the development of code evaluation metrics to study \nthe quality of LLM-generated code. Conventional rule-based metrics merely score", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.20159&hl=en&sa=X&d=6711898537773507630&ei=_5JRaYqVLYaw6rQPkNu46Ao&scisig=ALhkC2S1jDXMNAnGCS6haPrkOHJI&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ALhkC2T269WwPtyd5qvti3WNZV40&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "K Wang, B Mao, S Jia, Y Ding, D Han, T Ma, B Cao- arXiv preprint arXiv:2512.17540, 2025\nAutomating code review with Large Language Models (LLMs) shows immense \npromise, yet practical adoption is hampered by their lack of reliability, context-\nawareness, and control. To address this, we propose Specification-Grounded Code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.17540&hl=en&sa=X&d=16382589271726736633&ei=_5JRaYqVLYaw6rQPkNu46Ao&scisig=ALhkC2Rx_2I5F67w4_nJO52_b37Z&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ALhkC2T269WwPtyd5qvti3WNZV40&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
