{"title": "How Do Semantically Equivalent Code Transformations Impact Membership Inference on LLMs for Code?", "first_label": ["LLM", "Code"], "second_label": [], "data": "H Yang, A Velasco, T Le-Cong, MN Haque, B Xu- arXiv preprint arXiv, 2025\nThe success of large language models for code relies on vast amounts of code data, \nincluding public open-source repositories, such as GitHub, and private, confidential \ncode from companies. This raises concerns about intellectual property compliance\n\u00a0\nThis message was sent by Google Scholar because you're following new articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15468&hl=en&sa=X&d=12276196188775065348&ei=FZJIaZ2NJ-bYieoP3dLOmAk&scisig=ALhkC2QrrmYw5cyZ8K7zanxHwpWl&oi=scholaralrt&hist=ylyK0_8AAAAJ:11229180796984360445:ALhkC2T99xKtLspn8uN0tqKjJxRP&html=&pos=0&folt=art", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new articles", "4 new citations to articles by Thanh Le-Cong", "6 new citations to articles by Bach Le", "4 new citations to articles by Hong Jin Kang"]}
{"title": "Imitation Learning for Multi-turn LM Agents via On-policy Expert Corrections", "first_label": [], "second_label": ["Agent"], "data": "N Lauffer, X Deng, S Kundurthy, B Kenstler, J Da- arXiv preprint arXiv:2512.14895, 2025\nA popular paradigm for training LM agents relies on imitation learning, fine-tuning on \nexpert trajectories. However, we show that the off-policy nature of imitation learning \nfor multi-turn LM agents suffers from the fundamental limitation known as covariate", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.14895&hl=en&sa=X&d=7388685968213749228&ei=FZJIadCjNN_OieoPg6WE2QY&scisig=ALhkC2QKM-APqqv4xWiNQ18-TFgg&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ALhkC2Tff526TIEbfh2mbT-kfB65&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Evaluating Code Reasoning Abilities of Large Language Models Under Real-World Settings", "first_label": ["LLM", "Code"], "second_label": ["Reasoning"], "data": "C Liu, A Ghazanfari, Y Chen, R Jabbarvand- arXiv preprint arXiv:2512.14917, 2025\nCode reasoning tasks are becoming prevalent in large language model (LLM) \nassessments. Existing benchmarks involve simple programs, failing to represent real-\nworld complexities such as inter-or intra-procedural dependencies, core or third", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.14917&hl=en&sa=X&d=1782999458797643498&ei=FZJIadCjNN_OieoPg6WE2QY&scisig=ALhkC2SA5r7XzYyhJZJ59rJ4ThXS&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ALhkC2Tff526TIEbfh2mbT-kfB65&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "4 new citations to articles by Thanh Le-Cong", "David Lo - new related research", "Hong Jin Kang - new related research", "6 new citations to articles by Bach Le", "Xin ZHOU - new related research"]}
{"title": "WuppieFuzz: Coverage-Guided, Stateful REST API Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "T Rooijakkers, A Nijsten, C Daniele, E Weitenberg- arXiv preprint arXiv, 2025\nMany business processes currently depend on web services, often using REST APIs \nfor communication. REST APIs expose web service functionality through endpoints, \nallowing easy client interaction over the Internet. To reduce the security risk resulting", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15554&hl=en&sa=X&d=7131526381974548327&ei=FZJIadCjNN_OieoPg6WE2QY&scisig=ALhkC2SFTaa1p0_kYHi7yDU6-OD6&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ALhkC2Tff526TIEbfh2mbT-kfB65&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "9 new citations to articles by Abhik Roychoudhury"]}
{"title": "FirmAgent: Leveraging Fuzzing to Assist LLM Agents with IoT Firmware Vulnerability Discovery", "first_label": ["Vulnerabilities", "LLM", "Fuzzing"], "second_label": ["Agent"], "data": "J Ji, C Zhang, S Gan, L Jian, H Liu, T Liu, L Zheng\nThe rapid proliferation of IoT devices has introduced substantial security \nvulnerabilities. Existing vulnerability detection techniques exhibit various \nweaknesses: static analysis solutions (including large language models, LLMs)", "link": "https://scholar.google.com/scholar_url?url=http://netsec.ccert.edu.cn/files/papers/ndss26-firmagent.pdf&hl=en&sa=X&d=4468527840357825810&ei=FZJIadCjNN_OieoPg6WE2QY&scisig=ALhkC2SfqkQJwRP2Z1BpkgQEKqTC&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ALhkC2Tff526TIEbfh2mbT-kfB65&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Hong Jin Kang - new related research", "9 new citations to articles by Abhik Roychoudhury"]}
{"title": "XBIDetective: Leveraging Vision Language Models for Identifying Cross-Browser Visual Inconsistencies", "first_label": ["LLM"], "second_label": ["Detection"], "data": "B Grewal, J Graham, J Muizelaar, JH Odvarko- arXiv preprint arXiv, 2025\nBrowser rendering bugs can be challenging to detect for browser developers, as they \nmay be triggered by very specific conditions that are exhibited on only a very small \nsubset of websites. Cross-browser inconsistencies (XBIs), variations in how a\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15804&hl=en&sa=X&d=14687870301945225116&ei=FZJIadCjNN_OieoPg6WE2QY&scisig=ALhkC2RCmlNaGFhlPyohNFHIC0rx&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:ALhkC2Tff526TIEbfh2mbT-kfB65&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "David Lo - new related research", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "Bach Le - new related research"]}
{"title": "A Systematic Study of Code Obfuscation Against LLM-based Vulnerability Detection", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Li, Y Li, H Wu, Y Zhang, Y Zhang, F Xu, S Zhong- arXiv preprint arXiv:2512.16538, 2025\nAs large language models (LLMs) are increasingly adopted for code vulnerability \ndetection, their reliability and robustness across diverse vulnerability types have \nbecome a pressing concern. In traditional adversarial settings, code obfuscation has \nlong been used as a general strategy to bypass auditing tools, preserving \nexploitability without tampering with the tools themselves. Numerous efforts have \nexplored obfuscation methods and tools, yet their capabilities differ in terms of\nCites: Thanh Le-Cong, Ting Zhang, Ivana Clairine Irsan, Joshua", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16538&hl=en&sa=X&d=13631870832429413086&ei=EpJIaYvfMsSN6rQPx4HkwQU&scisig=ALhkC2T93LTAifAMeSWHtPXSwr84&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:ALhkC2SLna-N2qwXFiQXiEQOdUM_&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 new citations to articles by Thanh Le-Cong", "David Lo - new related research", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "6 new citations to articles by Bach Le", "Quang-Cuong Bui - new related research", "5 new citations to articles by Xin ZHOU"]}
{"title": "No More Hidden Pitfalls? Exposing Smart Contract Bad Practices with LLM-Powered Hybrid Analysis", "first_label": ["Smart Contracts", "LLM"], "second_label": [], "data": "X Li, Z Li, W Li, Y Zhang, X Wang- arXiv preprint arXiv:2512.15179, 2025\nAs the Ethereum platform continues to mature and gain widespread usage, it is \ncrucial to maintain high standards of smart contract writing practices. While bad \npractices in smart contracts may not directly lead to security issues, they elevate the \nrisk of encountering problems. Therefore, to understand and avoid these bad \npractices, this paper introduces the first systematic study of bad practices in smart \ncontracts, delving into over 47 specific issues. Specifically, we propose SCALM, an\nCites: Thanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15179&hl=en&sa=X&d=10857076878193794032&ei=EpJIaYvfMsSN6rQPx4HkwQU&scisig=ALhkC2RhURqriPDE0QP0zrYGxUQd&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:ALhkC2SLna-N2qwXFiQXiEQOdUM_&html=&pos=2&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["4 new citations to articles by Thanh Le-Cong", "6 new citations to articles by Bach Le", "5 new citations to articles by Xin ZHOU"]}
{"title": "An Exploratory Study of Bayesian Prompt Optimization for Test-Driven Code Generation with Large Language Models", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation"], "data": "S Tomar, A Deshwal, E Villalovoz, M Fazzini, H Cai- arXiv preprint arXiv, 2025\nWe consider the task of generating functionally correct code using large language \nmodels (LLMs). The correctness of generated code is influenced by the prompt used \nto query the given base LLM. We formulate the problem of finding the appropriate", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15076&hl=en&sa=X&d=8570747161176575765&ei=FJJIae_KLIKUieoP5cGFWQ&scisig=ALhkC2TMZAWmnqFa7jD8tv0PYXq9&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ALhkC2THo_3s8tBI3qmyNrpmj0cv&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Toxicity Ahead: Forecasting Conversational Derailment on GitHub", "first_label": [], "second_label": [], "data": "MM Imran, R Zita, RR Rahman, P Chatterjee- arXiv preprint arXiv, 2025\nToxic interactions in Open Source Software (OSS) communities reduce contributor \nengagement and threaten project sustainability. Preventing such toxicity before it \nemerges requires a clear understanding of how harmful conversations unfold", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15031&hl=en&sa=X&d=10819991011472612274&ei=FJJIae_KLIKUieoP5cGFWQ&scisig=ALhkC2RdEpg2LSZZvVzluxAS8kWc&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ALhkC2THo_3s8tBI3qmyNrpmj0cv&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "2 new citations to articles by Shengyi Pan"]}
{"title": "SPVR: syntax-to-prompt vulnerability repair based on large language models", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Repair"], "data": "R Wang, Z Li, C Gao, C Wang, Y Xiao, X Wang- Automated Software Engineering, 2026\nPurpose: In the field of vulnerability repair, previous research has leveraged pre-\ntrained models and LLM-based prompt engineering, among which LLM-based \napproaches show better generalizability and achieve the best performance", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10515-025-00579-5&hl=en&sa=X&d=15103634288925366238&ei=FJJIae_KLIKUieoP5cGFWQ&scisig=ALhkC2TGkvphddAGi0iQyeMZZe5f&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ALhkC2THo_3s8tBI3qmyNrpmj0cv&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "9 new citations to articles by Abhik Roychoudhury", "Xin ZHOU - new related research"]}
{"title": "XRFix: Exploring Performance Bug Repair of Extended Reality Applications with Large Language Models", "first_label": ["LLM", "Bug"], "second_label": ["Repair"], "data": "J Wu, H Guo, HN Dai, X Luo - 2026\nAs an emerging technology, Extended Reality (XR) provides endusers with an \nimmersive experience of interacting with virtual and physical environments. Unlike \ntraditional software, the execution of XR applications involves more computationally", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Wu-Jingwen-6/publication/398772694_XRFix_Exploring_Performance_Bug_Repair_of_Extended_Reality_Applications_with_Large_Language_Models/links/69428b9f06a9ab54f847bdcf/XRFix-Exploring-Performance-Bug-Repair-of-Extended-Reality-Applications-with-Large-Language-Models.pdf&hl=en&sa=X&d=765321088982324966&ei=FJJIae_KLIKUieoP5cGFWQ&scisig=ALhkC2R49a2CLADNxooN1tj1WyS-&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ALhkC2THo_3s8tBI3qmyNrpmj0cv&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "6 new citations to articles by Bach Le", "9 new citations to articles by Abhik Roychoudhury", "Xin ZHOU - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Toward Systematic Counterfactual Fairness Evaluation of Large Language Models: The CAFFE Framework", "first_label": ["LLM"], "second_label": [], "data": "A Parziale, G Voria, V Pontillo, G Catolino, A De Lucia- arXiv preprint arXiv, 2025\nNowadays, Large Language Models (LLMs) are foundational components of modern \nsoftware systems. As their influence grows, concerns about fairness have become \nincreasingly pressing. Prior work has proposed metamorphic testing to detect", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16816&hl=en&sa=X&d=13945611357990131720&ei=FJJIae_KLIKUieoP5cGFWQ&scisig=ALhkC2SJ3_WKXbKgYOI4O253XC6G&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ALhkC2THo_3s8tBI3qmyNrpmj0cv&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "4 new citations to articles by Hong Jin Kang"]}
{"title": "WebViewJSdetect: JavaScript Vulnerability Detection in Android WebView via Coverage-Guided Thread-Adaptive Concurrent Abstract Interpretation", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "Z Yuan, Z Yang, J Tan, H Zhang- Computer Networks, 2025\nAndroid WebView enables applications to embed web content within native User \nInterface (UI), wherein embedded JavaScript codes often require elevated privileges \nto perform operations such as cross-origin requests and access to sensitive data\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1389128625008746&hl=en&sa=X&d=7081116760364312196&ei=FJJIae_KLIKUieoP5cGFWQ&scisig=ALhkC2SWP5ff-nBGALO7PXRW5xWf&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:ALhkC2THo_3s8tBI3qmyNrpmj0cv&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Aligning Academia with Industry: An Empirical Study of Industrial Needs and Academic Capabilities in AI-Driven Software Engineering", "first_label": [], "second_label": [], "data": "H Yu, Y Lai, L Zhang, X Lian, F Liu, Y Dong, T Zhang- arXiv preprint arXiv, 2025\nThe rapid advancement of large language models (LLMs) is fundamentally \nreshaping software engineering (SE), driving a paradigm shift in both academic \nresearch and industrial practice. While top-tier SE venues continue to show", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15148&hl=en&sa=X&d=17620178415310020134&ei=E5JIabOCK56u6rQPotyMwAQ&scisig=ALhkC2Qqp97U9HGzQAZnrzcgEw03&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ALhkC2RZmRqgZGCFQXCJyP9vthGu&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "4 new citations to articles by Hong Jin Kang", "1 new citation to articles by Quang-Cuong Bui", "5 new citations to articles by Xin ZHOU"]}
{"title": "LLM Assisted Coding with Metamorphic Specification Mutation Agent", "first_label": ["LLM"], "second_label": ["Agent"], "data": "MR Akhond, G Uddin- arXiv preprint arXiv:2511.18249, 2025\nMetamorphic Relations (MRs) serve as a foundational mechanism for generating \nsemantically equivalent mutations. Software engineering has advanced significantly \nin recent years with the advent of Large Language Models (LLMs). However, the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.18249&hl=en&sa=X&d=10413103399697962147&ei=E5JIabOCK56u6rQPotyMwAQ&scisig=ALhkC2TLO2INEEpsMtcyeSceXBK6&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ALhkC2RZmRqgZGCFQXCJyP9vthGu&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "LLMPORT: Cross-file Patch Porting via Task Decomposition and Self-correction", "first_label": ["LLM"], "second_label": [], "data": "B Chen, L Zhang, P Deng, N Wang, H Xu, M Guo\nSecurity patch porting aims to adapt patches developed for one software version so \nthey can be used in another version. This approach is crucial for maintaining the \nsecurity of software systems over time. However, existing works often rely on", "link": "https://scholar.google.com/scholar_url?url=https://yuanxzhang.github.io/paper/LLMPort-ase25.pdf&hl=en&sa=X&d=15123620356696275366&ei=E5JIabOCK56u6rQPotyMwAQ&scisig=ALhkC2SgQSgjqNBKFRiyCHAem3Fz&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ALhkC2RZmRqgZGCFQXCJyP9vthGu&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "2 new citations to articles by Shengyi Pan", "9 new citations to articles by Abhik Roychoudhury", "Quang-Cuong Bui - new related research"]}
{"title": "Adapting Language Models for Low-Resource Programming Languages", "first_label": ["LLM"], "second_label": [], "data": "A Singha, M Singh, H Hasanbeig, A Radhakrishna- NeurIPS 2025 Fourth Workshop on\nLarge Language Models (LLMs) have achieved remarkable success in code \ngeneration, yet their capabilities remain predominantly concentrated in well-\nresourced programming languages such as Python and Java. In contrast, low\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3D2ctRK8h3AZ&hl=en&sa=X&d=10639384588679978541&ei=E5JIabOCK56u6rQPotyMwAQ&scisig=ALhkC2TU1E8-xJojBcX0Q0YHF0cb&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:ALhkC2RZmRqgZGCFQXCJyP9vthGu&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Bug Priority Change Prediction: An Exploratory Study on Apache Software", "first_label": ["Bug"], "second_label": [], "data": "G Cai, Z Li, P Liang, R Mo, H Liu, Y Ma- ACM Transactions on Software Engineering, 2025\nBug fixing is a critical activity in the software development process. In issue tracking \nsystems such as JIRA, each bug report is assigned a priority level to indicate the \nurgency and importance level of the bug. The priority may change during the bug", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3785148&hl=en&sa=X&d=12156943870783235092&ei=FpJIad-WKLPFieoPper8uAM&scisig=ALhkC2QUwM-dOQT6O2CgTBoydVDb&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:ALhkC2T269WwPtyd5qvti3WNZV40&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Ethereum smart contract security: Vulnerabilities, analysis techniques, challenges and research directions", "first_label": ["Vulnerabilities", "Smart Contracts", "Ethereum"], "second_label": ["Search"], "data": "VK Jain, M Tripathi- Computers and Electrical Engineering, 2026\nSmart contracts, a key component of blockchain technology, automate and enforce \ncontractual agreements, facilitating trustless transactions across decentralized \nnetworks. However, their immutable and decentralized nature introduces unique \nsecurity challenges, making vulnerability analysis crucial as vulnerabilities can lead \nto financial losses, exploitation, and manipulation. This research presents a \ncomprehensive survey of smart contract vulnerability analysis techniques\nCites: Smart contract development: Challenges and opportunities", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0045790625008389&hl=en&sa=X&d=4179197611366917280&ei=FJJIabSqDqC16rQPm4fPgQQ&scisig=ALhkC2Q4nvPKERuP5qQswY2l694o&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:ALhkC2SEiW6V5LLNyO9vTSEOmBLL&html=&pos=4&folt=cit", "author": ["Bach Le"], "ref": ["6 new citations to articles by Bach Le"]}
{"title": "CONCORD: A DSL for Generating Simplified and Scalable Graph-Based Code Representations", "first_label": ["Code"], "second_label": ["Graph"], "data": "M Saad, T Sharma\nGraph-based representations have gained attention for their ability to model \nstructural and semantic information capturing relevant characteristics and features of \nsource code for training deep learning models. However, existing methods face \nlimitations: they lack flexibility in constructing cross-language graphs, produce non-\ninteroperable outputs, and generate excessively large graphs, hindering their \nadoption and raising scalability and efficiency issues in graph-based neural network\nCites: Compressing pre-trained models of code into 3 mb", "link": "https://scholar.google.com/scholar_url?url=https://tusharma.in/preprints/SANER2026_CONCORD.pdf&hl=en&sa=X&d=15733217673387559054&ei=E5JIaZrHO7LrieoPwNLAkQw&scisig=ALhkC2RuLGjEyCbRFpA0B3awU4YN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:ALhkC2Tv0L1GNq4Kk4Fq05ZvgtDM&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["4 new citations to articles by Hong Jin Kang"]}
{"title": "The Test Pyramid 2.0: AI-assisted testing across the pyramid", "first_label": ["Software Testing"], "second_label": [], "data": "P Desai, S Singh, S Amilkanthwar- Frontiers in Artificial Intelligence, 2025\nEnsuring robust test coverage, high code quality, and a strong security posture are \npersistent challenges in modern industrial software development, especially as \nsystems grow in complexity and release cycles accelerate with recent Artificial \nIntelligence (AI) related productivity gains. This paper introduces a conceptual \nframework,\" The Test Pyramid 2.0\", which offers a clear and actionable path to \nintegrate the latest advances in AI and DevSecOps principles into engineering\nCites: Large language model guided protocol fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://pmc.ncbi.nlm.nih.gov/articles/PMC12713685/&hl=en&sa=X&d=3983903479059889309&ei=FZJIaeGfDMSN6rQPx4HkwQU&scisig=ALhkC2THkKSOM02m5O848v-uFpjD&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ALhkC2SLNtxsIYV7y8T6Ni2J4ruF&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Exploring Static Taint Analysis in LLMs: A Dynamic Benchmarking Framework for Measurement and Enhancement", "first_label": ["LLM"], "second_label": [], "data": "H Zhao, L Zhang, K Lian, F Sun, B Chen, Y Liu, Z Wu\nLLMs offer a promising avenue to overcome the limitations of traditional taint analysis \ntechniques, with a growing number of studies leveraging LLMs for taint analysis and \nits downstream applications. However, these studies lack a systematic \nunderstanding of LLMs' taint analysis capabilities, limiting their transferability and \nreliability. To bridge this gap and better apply LLMs to static taint analysis, we aim to \ncomprehensively measure and understand LLMs' taint analysis capabilities. Using\nCites: Large language model guided protocol fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://yuanxzhang.github.io/paper/LLMTaint-ase25.pdf&hl=en&sa=X&d=5279790769370848503&ei=FZJIaeGfDMSN6rQPx4HkwQU&scisig=ALhkC2Qj2yaXtxvsIHyQJemBV_i5&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ALhkC2SLNtxsIYV7y8T6Ni2J4ruF&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "DEEPEXPLOITOR: LLM-Enhanced Automated Exploitation of DeepLink Attack in Hybrid Apps", "first_label": ["LLM"], "second_label": ["Exploit"], "data": "Z Zhang, L Zhang, Z Zhang, Y Liu, Z Yang, Y Zhang\nModern mobile apps widely embed WebView to enable rich and dynamic content, \nmaking it an increasingly attractive target for attackers. It is well known that \ninsufficient or improper input validation on WebView-loaded URLs can compromise \nthe entire app or even the underlying system. Among these threats, one of the most \ncritical attack vectors is the DeepLink Attack, which often requires only a single user \nclick to exploit WebView vulnerabilities. Despite the deployment of defense such as\nCites: Large language model guided protocol fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://yuanxzhang.github.io/paper/DeepExploitor-ase25.pdf&hl=en&sa=X&d=8977200315811750113&ei=FZJIaeGfDMSN6rQPx4HkwQU&scisig=ALhkC2ScqOea1qsL6HO4-_1bXwnT&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ALhkC2SLNtxsIYV7y8T6Ni2J4ruF&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "ALGERNON: A Flag-Guided Hybrid Fuzzer for Unlocking Hidden Program Paths", "first_label": ["Fuzzing"], "second_label": [], "data": "P Deng, L Zhang, J Long, W Hong, Z Yang, Y Zhang\nFuzz testing is a widely used method for finding security issues in software. However, \ncertain code paths can only be explored under specific program states. Flag \nvariables, which represent internal states, are crucial in influencing program \nbehavior through flag-guarded branches. Unfortunately, existing fuzzing tools \nstruggle to efficiently explore them due to the implicit data dependency between flag \nvariables and the input. As a result, they commonly lack awareness of the\nCites: Stateful Greybox Fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://yuanxzhang.github.io/paper/Algernon-ase25.pdf&hl=en&sa=X&d=4003102365115329887&ei=FZJIaeGfDMSN6rQPx4HkwQU&scisig=ALhkC2TqUnKU6k2ZXFSDxx2HUxV-&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:ALhkC2SLNtxsIYV7y8T6Ni2J4ruF&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["9 new citations to articles by Abhik Roychoudhury"]}
{"title": "Measuring and mitigating debugging effectiveness decay in code language models", "first_label": ["LLM", "Code", "Bug"], "second_label": [], "data": "M Adnan, CCN Kuhn- Scientific Reports, 2025\nThe effectiveness of AI debugging follows a predictable exponential decay pattern; \nmost models lose 60-80% of their debugging capability within just 2-3 attempts, \ndespite iterative debugging being a critical capability for practical code generation", "link": "https://scholar.google.com/scholar_url?url=https://www.nature.com/articles/s41598-025-27846-5&hl=en&sa=X&d=6731753644843912533&ei=FpJIaZGtHMW4ieoP4szBiAE&scisig=ALhkC2R9-g7tasGI9yZLQ9BrUhQ0&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:ALhkC2Q9j5kdmlV_e8u2kLe_NWfw&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Fine-tuning a vulnerability-specific large language model for a hybrid software vulnerability detection method", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "S Wang, Y Jiang, S Xu, Y Liu, M Yin, G He- Engineering Applications of Artificial, 2026\nDetecting vulnerabilities in large-scale, multi-file software systems remains a critical \nchallenge, as traditional techniques and current large language models (LLMs) \nstruggle with long code dependencies and complex control flows. This challenge is", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0952197625034414&hl=en&sa=X&d=11842574605725066426&ei=FZJIab3kGaGvieoPtIGfoAw&scisig=ALhkC2QjAhyaiHzwc9cFjfl-4_R_&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:ALhkC2SS1P3l44RDJXsNEdNzDLiT&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Retrieval-Augmented Few-Shot Prompting Versus Fine-Tuning for Code Vulnerability Detection", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "F Trad, A Chehab- arXiv preprint arXiv:2512.04106, 2025\nFew-shot prompting has emerged as a practical alternative to fine-tuning for \nleveraging the capabilities of large language models (LLMs) in specialized tasks. \nHowever, its effectiveness depends heavily on the selection and quality of in-context", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.04106&hl=en&sa=X&d=14413181853887891056&ei=FZJIab3kGaGvieoPtIGfoAw&scisig=ALhkC2Rqj9yxVEmg913NYOxXQfSD&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:ALhkC2SS1P3l44RDJXsNEdNzDLiT&html=&pos=1&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "A Systematic Literature Review on Vulnerability Detection Approaches for IoT Mobile Applications", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "Z Meyo, R Morales, I Pete, YG Guhneuc- IEEE Internet of Things Journal, 2025\nInternet of Things (IoT) systems are pervasive and increasingly managed through \nmobile applications. However, poorly designed mobile applications can expose \nsensitive information to external adversaries. Mitigating such vulnerabilities requires", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11282438/&hl=en&sa=X&d=3814595063893863926&ei=FZJIab3kGaGvieoPtIGfoAw&scisig=ALhkC2RIUsww3A0EYUTxJIOFSbnn&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:ALhkC2SS1P3l44RDJXsNEdNzDLiT&html=&pos=4&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Cold-Start Anti-Patterns and Refactorings in Serverless Systems: An Empirical Study", "first_label": [], "second_label": [], "data": "SSM Tariq, F Hassan, A Bosu, P Roy- arXiv preprint arXiv:2512.16066, 2025\nServerless computing simplifies deployment and scaling, yet cold-start latency \nremains a major performance bottleneck. Unlike prior work that treats mitigation as a \nblack-box optimization, we study cold starts as a developer-visible design problem", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16066&hl=en&sa=X&d=5843153834108716306&ei=FZJIab3kGaGvieoPtIGfoAw&scisig=ALhkC2Sy9bZ2htxo1rXiQne_gR0W&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:ALhkC2SS1P3l44RDJXsNEdNzDLiT&html=&pos=6&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "FLIMs: Fault Localization Interference Mutants, Definition, Recognition and Mitigation", "first_label": ["Fault Localization"], "second_label": ["Localization"], "data": "H Liu, Z Li, D Wang, Y Wu, X Chen, Y Liu- arXiv preprint arXiv:2511.23302, 2025\nMutation-based Fault Localization (MBFL) has been widely explored for automated \nsoftware debugging, leveraging artificial mutants to identify faulty code entities. \nHowever, MBFL faces significant challenges due to interference mutants generated", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2511.23302&hl=en&sa=X&d=15330727092267869548&ei=FZJIab3kGaGvieoPtIGfoAw&scisig=ALhkC2TtsXnr-yKdW7qZ1KSpUiPG&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:ALhkC2SS1P3l44RDJXsNEdNzDLiT&html=&pos=7&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Impact of identifier normalization on vulnerability detection techniques", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "T Hinrichs, T Diercks, R Scandariato- IEEE International Conference on Software, 2025\nThis study examines the impact of identifier normalization on software vulnerability \ndetection using three approaches: static application security testing (SAST), \nspecialized machine learning (ML) models, and Large Language Models (LLM)\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://tore.tuhh.de/entities/publication/190027eb-ee13-4d39-927f-192d3854a968&hl=en&sa=X&d=14035095563255972296&ei=FZJIab3kGaGvieoPtIGfoAw&scisig=ALhkC2TKfa58ia9Bwl6BDUYodQee&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:ALhkC2SS1P3l44RDJXsNEdNzDLiT&html=&pos=8&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Inside Out: Uncovering How Comment Internalization Steers LLMs for Better or Worse", "first_label": ["LLM"], "second_label": [], "data": "A Imani, M Moshirpour, I Ahmed- arXiv preprint arXiv:2512.16790, 2025\nWhile comments are non-functional elements of source code, Large Language \nModels (LLM) frequently rely on them to perform Software Engineering (SE) tasks. \nYet, where in the model this reliance resides, and how it affects performance, \nremains poorly understood. We present the first concept-level interpretability study of \nLLMs in SE, analyzing three tasks-code completion, translation, and refinement-\nthrough the lens of internal comment representation. Using Concept Activation\nCites: Assessing and Advancing Benchmarks for Evaluating Large", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.16790&hl=en&sa=X&d=11829934250558278448&ei=FpJIaeuSEJaM6rQP0-TCwQU&scisig=ALhkC2SmUSAXVPKEoxPvb0YRmB7R&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ALhkC2S1ZxbvKZLR2YX67Bvdxjyf&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["5 new citations to articles by Xin ZHOU"]}
{"title": "On Assessing the Relevance of Code Reviews Authored by Generative Models", "first_label": ["Code Review", "Code"], "second_label": [], "data": "R Heumller, F Ortmeier- arXiv preprint arXiv:2512.15466, 2025\nThe use of large language models like ChatGPT in code review offers promising \nefficiency gains but also raises concerns about correctness and safety. Existing \nevaluation methods for code review generation either rely on automatic comparisons \nto a single ground truth, which fails to capture the variability of human perspectives, \nor on subjective assessments of\" usefulness\", a highly ambiguous concept. We \npropose a novel evaluation approach based on what we call multi-subjective\nCites: Generation-based Code Review Automation: How Far Are We?\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2512.15466&hl=en&sa=X&d=12426198866498320241&ei=FpJIaeuSEJaM6rQP0-TCwQU&scisig=ALhkC2S6Gzfbr0Pxat7Yzhevr3E-&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:ALhkC2S1ZxbvKZLR2YX67Bvdxjyf&html=&pos=4&folt=cit", "author": ["Xin ZHOU"], "ref": ["5 new citations to articles by Xin ZHOU"]}
