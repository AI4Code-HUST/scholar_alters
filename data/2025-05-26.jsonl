{"title": "DuoReduce: Bug Isolation for Multi-Layer Extensible Compilation", "first_label": ["Bug"], "second_label": [], "data": "J Wang, Y Qiu, B Limpanukorn, HJ Kang, Q Zhang\\xe2\\x80\\xa6 - 2025\nIn recent years, the MLIR framework has had explosive growth due to the need for \nextensible deep learning compilers for hardware accelerators. Such examples \ninclude Triton [39], CIRCT [14], and ONNX-MLIR [22]. MLIR compilers introduce\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://par.nsf.gov/biblio/10592191&hl=en&sa=X&d=16704826441152364364&ei=mHAyaKqYLOG86rQP8bDQeA&scisig=AAZF9b8cZzXp6d7FxXcCX8_GEGxu&oi=scholaralrt&hist=ylyK0_8AAAAJ:2125936049491152889:AAZF9b-lPWWMN6t2xDAeKM1BPPMk&html=&pos=0&folt=art", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new articles"]}
{"title": "The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models", "first_label": ["APR"], "second_label": ["Repair"], "data": "FV Ruiz, M Hort, L Moonen\\xc2\\xa0- arXiv preprint arXiv:2505.02931, 2025\nAutomatic program repair (APR) aims to reduce the manual efforts required to \nidentify and fix errors in source code. Before the rise of LLM-based agents, a \ncommon strategy was to increase the number of generated patches, sometimes to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.02931&hl=en&sa=X&d=16837479357373517474&ei=mHAyaKXENPCuieoP583H-QE&scisig=AAZF9b_oekcjeS14XjGNQo9mtAE5&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "CORECRISIS: Threat-Guided and Context-Aware Iterative Learning and Fuzzing of 5G Core Networks", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Dong, T Yang, A Al Ishtiaq, SMM Rashid, A Ranjbar\\xe2\\x80\\xa6\nWe develop CORECRISIS, a stateful black-box fuzz-testing framework for 5G core \nnetwork (5GC) implementations. Unlike previous stateful security analysis efforts of \ncellular networks which rely on manually-crafted, static test inputs and are limited to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.usenix.org/system/files/conference/usenixsecurity25/sec25cycle1-prepub-1292-dong-yilu.pdf&hl=en&sa=X&d=4291979592406815479&ei=mHAyaKXENPCuieoP583H-QE&scisig=AAZF9b8xMpoFy9xYsoZdVl1unvGx&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "JNFuzz-Droid: a lightweight fuzzing and taint analysis framework for native code of Android applications", "first_label": ["Fuzzing", "Code"], "second_label": [], "data": "J Cao, F Guo, Y Qu\\xc2\\xa0- Empirical Software Engineering, 2025\nThe need to account for native code in Android apps is becoming urgent as the \nusage of native code is growing in both benign and malicious apps. However, most \ncurrent state-of-the-art analysis tools cannot effectively analyze the data-flow\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10664-025-10671-9&hl=en&sa=X&d=11975277543600467260&ei=mHAyaKXENPCuieoP583H-QE&scisig=AAZF9b-V-QJRIFsAWjireox8y_xR&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Fuzzing Space Communication Protocols", "first_label": ["Fuzzing"], "second_label": [], "data": "S Havermans, L Baumg\\xc3\\xa4rtner, J Roberts, M Wallum\\xe2\\x80\\xa6\nSpace systems are critical assets and protecting them against cyberattacks is a \nparamount challenge that has received limited attention. In particular, it is \nfundamental to secure spacecraft communications by identifying and removing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://software.imdea.org/~juanca/papers/spacefuzz_spacesec25.pdf&hl=en&sa=X&d=964000194933772866&ei=mHAyaKXENPCuieoP583H-QE&scisig=AAZF9b9To-YtFkNH0V2NeHA65cZP&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "WildSync: Automated Fuzzing Harness Synthesis via Wild API Usage Recovery", "first_label": ["Fuzzing"], "second_label": [], "data": "WEIC WU, S NAGY, C HAUSER - 2025\nAuthors' Contact Information: Wei-Cheng Wu, Dartmouth College, Hanover, USA, wei-\ncheng. wu. gr@ dartmouth. edu; Stefan Nagy, University of Utah, Salt Lake City, USA, \nstefan. nagy@ utah. edu; Christophe Hauser, Dartmouth College, Hanover, USA\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://users.cs.utah.edu/~snagy/papers/25ISSTA.pdf&hl=en&sa=X&d=3125007074729669279&ei=mHAyaKXENPCuieoP583H-QE&scisig=AAZF9b8Pijs9BnZif9GfvBHcFCPy&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "LEANCODE: Understanding Models Better for Code Simplification of Pre-trained Large Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "Y Wang, L Ding, TN Nguyen, S Wang, Y Zheng\\xc2\\xa0- arXiv preprint arXiv:2505.14759, 2025\nLarge Language Models for code often entail significant computational complexity, \nwhich grows significantly with the length of the input code sequence. We propose \nLeanCode for code simplification to reduce training and prediction time, leveraging\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14759&hl=en&sa=X&d=3248557237439334794&ei=mHAyaPvsOPel6rQP6dvK4Ao&scisig=AAZF9b_zaxyG8JpihPx8XNA4sIet&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "RAG or Fine-tuning? A Comparative Study on LCMs-based Code Completion in Industry", "first_label": ["Code"], "second_label": ["Generation"], "data": "C Wang, Z Yang, S Gao, C Gao, T Peng, H Huang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCode completion, a crucial practice in industrial settings, helps developers improve \nprogramming efficiency by automatically suggesting code snippets during \ndevelopment. With the emergence of Large Code Models (LCMs), this field has\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15179&hl=en&sa=X&d=6796322448260186262&ei=mHAyaPvsOPel6rQP6dvK4Ao&scisig=AAZF9b-0hTJNlMgjhng-YBv3LBF1&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research"]}
{"title": "DS-Bench: A Realistic Benchmark for Data Science Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "S Ouyang, D Huang, J Guo, Z Sun, Q Zhu, JM Zhang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWe introduce DS-bench, a new benchmark designed to evaluate large language \nmodels (LLMs) on complicated and realistic data science code generation tasks. DS-\nbench consists of 1,000 carefully constructed problems sourced from realistic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15621&hl=en&sa=X&d=7689829491268805054&ei=mHAyaPvsOPel6rQP6dvK4Ao&scisig=AAZF9b8p3V31WIhnI4wv-RzXSsiv&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research", "Hong Jin Kang - new related research", "Bach Le - new related research"]}
{"title": "HybridProver: Augmenting Theorem Proving with LLM-Driven Proof Synthesis and Refinement", "first_label": ["LLM"], "second_label": [], "data": "J Hu, J Zhang, Y Zhao, T Ringer\\xc2\\xa0- arXiv preprint arXiv:2505.15740, 2025\nFormal methods is pivotal for verifying the reliability of critical systems through \nrigorous mathematical proofs. However, its adoption is hindered by labor-intensive \nmanual proofs and the expertise required to use theorem provers. Recent\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15740&hl=en&sa=X&d=11638096528726351561&ei=mHAyaPvsOPel6rQP6dvK4Ao&scisig=AAZF9b88iKMA_2buuMpNX2t8P1Kx&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "7 new citations to articles by Abhik Roychoudhury"]}
{"title": "Are requirements really all you need? A case study of LLM-driven configuration code generation for automotive simulations", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "K Lebioda, N Petrovic, F Pan, V Zolfaghari\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are taking many industries by storm. They possess \nimpressive reasoning capabilities and are capable of handling complex problems, as \nshown by their steadily improving scores on coding and mathematical benchmarks\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13263&hl=en&sa=X&d=8142159630564180976&ei=mHAyaPvsOPel6rQP6dvK4Ao&scisig=AAZF9b8JjDXL2WTWCxGT05T_vG1H&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Secret Breach Detection in Source Code with Large Language Models", "first_label": ["LLM", "Code"], "second_label": ["Detection"], "data": "MN Rahman, S Ahmed, Z Wahab, SM Sohan\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBackground: Leaking sensitive information, such as API keys, tokens, and \ncredentials, in source code remains a persistent security threat. Traditional regex and \nentropy-based tools often generate high false positives due to limited contextual\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.18784&hl=en&sa=X&d=12009667987401074433&ei=mHAyaPvsOPel6rQP6dvK4Ao&scisig=AAZF9b8WC1VKgTvjxoIAkc7ukuBh&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "An Empirical Analysis of Vulnerability Detection Tools for Solidity Smart Contracts Using Line Level Manually Annotated Vulnerabilities", "first_label": ["Vulnerabilities", "Smart Contracts"], "second_label": ["Detection"], "data": "F Salzano, CK Antenucci, S Scalabrino, G Rosa\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid adoption of blockchain technology highlighted the importance of ensuring \nthe security of smart contracts due to their critical role in automated business logic \nexecution on blockchain platforms. This paper provides an empirical evaluation of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15756&hl=en&sa=X&d=8442828954099712047&ei=mHAyaPiaMKalieoP5f2nkAE&scisig=AAZF9b-EAcvYZ_J4_9XdhW2rqHOc&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "3 new citations to articles by Bach Le", "Quang-Cuong Bui - new related research"]}
{"title": "NL-Debugging: Exploiting Natural Language as an Intermediate Representation for Code Debugging", "first_label": ["Code", "Bug"], "second_label": ["Exploit"], "data": "W Zhang, Q Li, X Dai, J Chen, K Du, W Zhang, W Liu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDebugging is a critical aspect of LLM's coding ability. Early debugging efforts \nprimarily focused on code-level analysis, which often falls short when addressing \ncomplex programming errors that require a deeper understanding of algorithmic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15356&hl=en&sa=X&d=4143706178160146132&ei=mHAyaPiaMKalieoP5f2nkAE&scisig=AAZF9b-0DStOAacdkUcGc9ionRoT&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Bach Le - new related research"]}
{"title": "MARCO: A Multi-Agent System for Optimizing HPC Code Generation Using Large Language Models", "first_label": ["LLM", "Code"], "second_label": ["Generation", "Agent"], "data": "A Rahman, V Cvetkovic, K Reece, A Walters, Y Hassan\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have transformed software development through \ncode generation capabilities, yet their effectiveness for high-performance computing \n(HPC) remains limited. HPC code requires specialized optimizations for parallelism\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.03906&hl=en&sa=X&d=17867515124636780677&ei=mHAyaPiaMKalieoP5f2nkAE&scisig=AAZF9b9SpUJHcH-TletqVNtFUBN6&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Towards a Science of Causal Interpretability in Deep Learning for Software Engineering", "first_label": [], "second_label": [], "data": "DN Palacio\\xc2\\xa0- arXiv preprint arXiv:2505.15023, 2025\nThis dissertation addresses achieving causal interpretability in Deep Learning for \nSoftware Engineering (DL4SE). While Neural Code Models (NCMs) show strong \nperformance in automating software tasks, their lack of transparency in causal\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15023&hl=en&sa=X&d=539836201692368647&ei=mHAyaPiaMKalieoP5f2nkAE&scisig=AAZF9b8R8Qo6Le76nXXW1THn9HE-&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Cross-Level Requirements Tracing Based on Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "C Ge, TT Wang, XT Yang, C Treude\\xc2\\xa0- IEEE Transactions on Software Engineering, 2025\nCross-level requirements traceability, linking high-level requirements (HLRs) and \nlow-level requirements (LLRs), is essential for maintaining relationships and \nconsistency in software development. However, the manual creation of requirements\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/journal/ts/5555/01/11008781/26TEcLRNtvy&hl=en&sa=X&d=13934667537654443335&ei=mHAyaPiaMKalieoP5f2nkAE&scisig=AAZF9b864Be_md4Iip2bVKxL4wMh&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Leveraging Ethical Narratives to Enhance LLM\\xe2\\x80\\x90AutoML Generated Machine Learning Models", "first_label": ["LLM"], "second_label": [], "data": "J Nelson, M Pavlidis, A Fish, N Polatidis\\xe2\\x80\\xa6\\xc2\\xa0- Expert Systems, 2025\nThe growing popularity of generative AI and large language models (LLMs) has \nsparked innovation alongside debate, particularly around issues of plagiarism and \nintellectual property law. However, a less\\xe2\\x80\\x90discussed concern is the quality of code \ngenerated by these models, which often contains errors and encourages poor \nprogramming practices. This paper proposes a novel solution by integrating LLMs \nwith automated machine learning (AutoML). By leveraging AutoML's strengths in\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/pdf/10.1111/exsy.70072&hl=en&sa=X&d=17665266423314408285&ei=mHAyaNTtKtHSieoP4tatoQU&scisig=AAZF9b8F1FH2vCrQZfK3GxxA6GL2&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 new citation to articles by Thanh Le-Cong", "3 new citations to articles by Bach Le"]}
{"title": "LELANTE: LEveraging LLM for Automated ANdroid TEsting", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "S Fatin, MH Al-Quvi, HS Shahgir, S Barua, A Iqbal\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGiven natural language test case description for an Android application, existing \ntesting approaches require developers to manually write scripts using tools such as \nAppium and Espresso to execute the corresponding test case. This process is labor\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.20896&hl=en&sa=X&d=17615025726171243016&ei=mHAyaP6POp-mieoPoOrjuQU&scisig=AAZF9b8-TWsDerYtYXgkjb3Dz2BH&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "PRIMG: Efficient LLM-driven Test Generation Using Mutant Prioritization", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "MS Bouafif, M Hamdaqa, E Zulkoski\\xc2\\xa0- arXiv preprint arXiv:2505.05584, 2025\nMutation testing is a widely recognized technique for assessing and enhancing the \neffectiveness of software test suites by introducing deliberate code mutations. \nHowever, its application often results in overly large test suites, as developers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.05584%3F&hl=en&sa=X&d=11403797073407320761&ei=mHAyaP6POp-mieoPoOrjuQU&scisig=AAZF9b_8rRCKKaF4lP39iEYsaKlR&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "FuzzFlesh: Randomised Testing of Decompilers Via Control Flow Graph-based Program Generation", "first_label": ["Fuzzing", "Software Testing", "Static Analysis"], "second_label": ["Generation", "Graph"], "data": "A Gorzynski, AF Donaldson\nDecompilation is the process of translating compiled code into high-level code. \nControl flow recovery is a challenging part of the process.'Misdecompilations' can \noccur, whereby the decompiled code does not accurately represent the semantics of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.doc.ic.ac.uk/~afd/papers/2025/ECOOP-FuzzFlesh.pdf&hl=en&sa=X&d=904693152685957307&ei=mHAyaP6POp-mieoPoOrjuQU&scisig=AAZF9b8Lv9KaxB9WgdBF01r9IOYL&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Poster: Towards Understanding Bug Bounties for AI/ML Open-Source Vulnerabilities in GitHub Repositories", "first_label": ["Vulnerabilities", "Bug"], "second_label": [], "data": "J Ayala, J Garcia\nRecently, specialized bug bounty platforms, such as huntr, have emerged to \nincentivize the discovery of vulnerabilities in open-source software (OSS) that power \nAI (Artificial Intelligence) and ML (Machine Learning) systems. In this extended\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://sp2025.ieee-security.org/downloads/posters/sp25posters-final9.pdf&hl=en&sa=X&d=4514136328140428675&ei=mHAyaP6POp-mieoPoOrjuQU&scisig=AAZF9b-P5QwQGR52cbjrqe0OzmpI&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Can test generation and program repair inform automated assessment of programming projects?", "first_label": ["APR", "Software Testing"], "second_label": ["Repair", "Generation"], "data": "R Gu, JM Rojas, D Shin\\xc2\\xa0- 2025 IEEE Conference on Software Testing\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nComputer Science educators assessing student programming assignments are \ntypically responsible for two challenging tasks: grading and providing feedback. \nProducing grades that are fair and feedback that is useful to students is a goal \ncommon to most educators. In this context, automated test generation and program \nrepair offer promising solutions for detecting bugs and suggesting corrections in \nstudents' code which could be leveraged to inform grading and feedback generation\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaHistory driven program repair\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icst/2025/10988955/26S4ITvftoA&hl=en&sa=X&d=15304299180329145691&ei=mHAyaMbxLubGieoP1sTUqQ8&scisig=AAZF9b_1qN3yoEG9pKZt3_SvMG2c&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le", "7 new citations to articles by Abhik Roychoudhury"]}
{"title": "Fully Randomized Pointers", "first_label": [], "second_label": [], "data": "SD Phaye, GJ Duck, RHC Yap, TE Carlson - 2025\nMemory errors continue to be a critical concern for programs written in low-level \nprogramming languages such as C and C++. Many different memory error defenses \nhave been proposed, each with varying trade-offs in terms of overhead, compatibility, \nand attack resistance. Some defenses are highly compatible but only provide \nminimal protection, and can be easily bypassed by knowledgeable attackers. On the \nother end of the spectrum, capability systems offer very strong (unforgeable)\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaEfficient Greybox Fuzzing to Detect Memory Errors\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.comp.nus.edu.sg/~tcarlson/pdfs/phaye2025frp.pdf&hl=en&sa=X&d=2878539714208456769&ei=mHAyaPTPMeW16rQPsqVy&scisig=AAZF9b_ZpxPIQ2Ha2sPPXdUow8f7&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "Increasing The Practicality Of Verification Using Incomplete Solutions", "first_label": ["Verification"], "second_label": [], "data": "E Goldweber - 2025\nBuilding correct software systems is challenging. To ensure correctness, developers \nhave increasingly turned to formal verification to help achieve this goal. Verification \nprovides strong assurances of correctness by construction. Developers write proof \nannotations to show that their implementation adheres to desired properties captured \nin a formal specification. Checking if the implementation meets the specification is \nautomated by encoding the proof, specification, and implementation as a satisfiability\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFuzzing: Challenges and Reflections\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://deepblue.lib.umich.edu/bitstream/handle/2027.42/197340/edgoldwe_1.pdf%3Fsequence%3D1&hl=en&sa=X&d=7975383174051443547&ei=mHAyaPTPMeW16rQPsqVy&scisig=AAZF9b_BuKyDXXqxq4vyqUc4UWbm&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "ASIRDetector: Scheduling-driven, asynchronous execution to discover asynchronous improper releases bug in linux kernel", "first_label": ["Bug"], "second_label": ["Detection"], "data": "J Zhao, Q Wei, X Li, Y Wang, X Li\\xc2\\xa0- Computers & Security, 2025\nAsynchronous operations are the cornerstone of modern operating systems, \nenabling high-performance task scheduling and efficient resource management. \nHowever, if the asynchronous mechanism releases resources at incorrect times, it \nwill pose significant security risks to the Linux kernel, such as high-risk vulnerabilities \nlike use-after-free and null pointer dereferencing. Due to the indirect triggerability of \nasynchronous operations by users, existing methods for detecting kernel\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825002196&hl=en&sa=X&d=4899331987769959650&ei=mHAyaPTPMeW16rQPsqVy&scisig=AAZF9b836z7fK9Nih3g6eqTjufOC&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "ComplementaryRepair: Enhancing Small Open-Source Large Language Models for Repairing Introductory Student Code with Prompt Diversity", "first_label": ["LLM", "Code"], "second_label": ["Repair"], "data": "J Yang - 2025\nAbstract Automated Program Repair (APR) could enhance introductory programming \neducation by repairing errors in student code efficiently. Beyond simply providing \nsolutions, APR can offer partial repairs as hints, aid instructors in identifying errors, \nand serve as a basis for generating automated feedback. Moreover, repaired student \ncode can offer a more personalized and effective reference for post-submission \nlearning. Recent advancements in Large Language Models (LLMs) have\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRe-factoring based Program Repair applied to Programming\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://aaltodoc.aalto.fi/bitstreams/0bc5e811-58e1-41fe-aefc-cd1120c1c89c/download&hl=en&sa=X&d=3337997423257487216&ei=mHAyaPTPMeW16rQPsqVy&scisig=AAZF9b-K8mr28ijF0lmRZJ0eXLeT&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "Probabilistic Analysis of Time to Discover Paths in Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "R Shevade - 2025\nFuzzing is a popular program testing technique in the software security community. It \noperates by creating unexpected inputs for the program that may cause bugs and \nmonitors the program for crashes or abnormal behavior. The inputs created by the \nfuzzer is the product of random mutations on an initial input (seed) or a set of seeds \n(corpus). Greybox fuzzer, a specific type of fuzzer, strategically pick seeds which, it \nbelieves is more likely to lead to a discovery of a bug. This selection is guided by\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://etda.libraries.psu.edu/files/final_submissions/32659&hl=en&sa=X&d=1441640927391494910&ei=mHAyaPTPMeW16rQPsqVy&scisig=AAZF9b8TO34pbUZDtpnPsdhEOyZ_&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["7 new citations to articles by Abhik Roychoudhury"]}
{"title": "Leveraging Open-Source LLMs for Zero-Shot Vulnerability Detection: A Comparative Analysis", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "N Capuano, V Carletti, P Foggia, G Parrella, M Vento\\xc2\\xa0- International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid expansion of the Internet of Things (IoT) has brought significant security \nchallenges, primarily due to vulnerabilities in the firmware of IoT and network \ndevices, which is predominantly written in low-level programming languages such as\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-87775-9_2&hl=en&sa=X&d=8724089268434184607&ei=mHAyaIiTM4Ct6rQP9sPUwAg&scisig=AAZF9b-ahkowI222f9SeGE9jq2lb&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Tighter Clusters, Safer Code? Improving Vulnerability Detection with Enhanced Contrastive Loss", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "P Kapparad, BR Mohan\\xc2\\xa0- Proceedings of the 2025 Conference of the Nations of\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDistinguishing vulnerable code from non-vulnerable code is challenging due to high \ninter-class similarity. Supervised contrastive learning (SCL) improves embedding \nseparation but struggles with intra-class clustering, especially when variations within\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.naacl-srw.24.pdf&hl=en&sa=X&d=568853348667603882&ei=mHAyaIiTM4Ct6rQP9sPUwAg&scisig=AAZF9b81gkouWADoP2Iw2ABqDW_S&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack", "first_label": ["LLM"], "second_label": [], "data": "S Cappelletti, T Poppi, S Poppi, ZX Yong\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly evaluated on multiple-choice \nquestion answering (MCQA) tasks using* first-token probability*(FTP), which selects \nthe answer option whose initial token has the highest likelihood. While efficient, FTP\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15323&hl=en&sa=X&d=5513891085179250670&ei=mHAyaOCvN7eC6rQP9sj2mQ8&scisig=AAZF9b9edBmGRix6lx3Ht8Bnn61V&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SafeQuant: LLM Safety Analysis via Quantized Gradient Inspection", "first_label": ["LLM"], "second_label": [], "data": "S Padakandla, S Babar, M Kaul\\xc2\\xa0- Proceedings of the 2025 Conference of the\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nContemporary jailbreak attacks on Large Language Models (LLMs) employ \nsophisticated techniques with obfuscated content to bypass safety guardrails. \nExisting defenses either use computationally intensive LLM verification or require\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://aclanthology.org/2025.naacl-long.127.pdf&hl=en&sa=X&d=15183737478241495930&ei=mHAyaOCvN7eC6rQP9sj2mQ8&scisig=AAZF9b-IAmGkHDwpPHasWJdSh6QL&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "FIGhost: Fluorescent Ink-based Stealthy and Flexible Backdoor Attacks on Physical Traffic Sign Recognition", "first_label": [], "second_label": [], "data": "S Yuan, G Xu, H Li, R Zhang, X Qian, W Jiang, H Cao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nTraffic sign recognition (TSR) systems are crucial for autonomous driving but are \nvulnerable to backdoor attacks. Existing physical backdoor attacks either lack stealth, \nprovide inflexible attack control, or ignore emerging Vision-Large-Language-Models\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12045&hl=en&sa=X&d=486471126133404257&ei=mHAyaOCvN7eC6rQP9sj2mQ8&scisig=AAZF9b9uZDwtYCinn-s4WZ6ahuHJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Advancing LLM Safe Alignment with Safety Representation Ranking", "first_label": ["LLM"], "second_label": [], "data": "T Du, Z Wei, Q Chen, C Zhang, Y Wang\\xc2\\xa0- arXiv preprint arXiv:2505.15710, 2025\nThe rapid advancement of large language models (LLMs) has demonstrated \nmilestone success in a variety of tasks, yet their potential for generating harmful \ncontent has raised significant safety concerns. Existing safety evaluation approaches\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15710&hl=en&sa=X&d=9147050430051665415&ei=mHAyaOCvN7eC6rQP9sj2mQ8&scisig=AAZF9b_EiI4FmCbxurZY4HFEhWA5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses", "first_label": ["LLM"], "second_label": [], "data": "X Yang, B Stevanoski, M Meeus, YA de Montjoye\\xc2\\xa0- arXiv preprint arXiv:2505.15738, 2025\nLarge language models (LLMs) are rapidly deployed in real-world applications \nranging from chatbots to agentic systems. Alignment is one of the main approaches \nused to defend against attacks such as prompt injection and jailbreaks. Recent\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15738&hl=en&sa=X&d=15949587169759547530&ei=mHAyaOCvN7eC6rQP9sj2mQ8&scisig=AAZF9b9jW2tzEb1jjKg1wddBnl-L&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Layer Frozen Multi-Net & latent space feature-concealed backdoor samples detection", "first_label": [], "second_label": ["Detection"], "data": "J Li, S Luo, L Pan, C Zhang, Z Zhang, C Lu\\xc2\\xa0- Neural Networks, 2025\nIdentifying feature-concealed backdoor samples that entangle with benign semantics \nof target-class or possess dynamic triggers challenges backdoor attack detection. \nExisting methods focus on sample distribution differences in latent space of victim\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0893608025003764&hl=en&sa=X&d=9440568821815382276&ei=mHAyaOCvN7eC6rQP9sj2mQ8&scisig=AAZF9b9KQWzgsrGxwNibQ2QDGZPT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Invisible trigger image: A dynamic neural backdoor attack based on hidden feature", "first_label": [], "second_label": [], "data": "X Chen, M Li, Y Sun, Z Tian\\xc2\\xa0- Neurocomputing, 2025\nNeural backdoor is one of the most significant supply chain threat faced by deep \nneural networks (DNNs). A common attack method for implanting backdoors in DNNs \ninvolves injecting poisoned training data that contains triggers. Triggers are\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0925231225009683&hl=en&sa=X&d=17933955967710027848&ei=mHAyaOCvN7eC6rQP9sj2mQ8&scisig=AAZF9b8vcZJvcttnhTa_udTLOVjg&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Exploring Jailbreak Attacks on LLMs through Intent Concealment and Diversion", "first_label": ["LLM"], "second_label": [], "data": "T Cui, Y Mao, P Liu, C Liu, D You\\xc2\\xa0- arXiv preprint arXiv:2505.14316, 2025\nAlthough large language models (LLMs) have achieved remarkable advancements, \ntheir security remains a pressing concern. One major threat is jailbreak attacks, \nwhere adversarial prompts bypass model safeguards to generate harmful or\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14316&hl=en&sa=X&d=4317580650000119700&ei=mHAyaOCvN7eC6rQP9sj2mQ8&scisig=AAZF9b9krK_d1hcPwfwGDIEjENim&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "NoEsis: Differentially Private Knowledge Transfer in Modular LLM Adaptation", "first_label": ["LLM"], "second_label": [], "data": "R Romijnders, S Laskaridis, AS Shamsabadi\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLM) are typically trained on vast amounts of data from \nvarious sources. Even when designed modularly (eg, Mixture-of-Experts), LLMs can \nleak privacy on their sources. Conversely, training such models in isolation arguably\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.18147%3F&hl=en&sa=X&d=5115743027930617572&ei=mHAyaOCvN7eC6rQP9sj2mQ8&scisig=AAZF9b-zZHmB78f-Ya4d-6GmF3AY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Revisiting Data Auditing in Large Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "H Zhu, S Liang, W Wang, B Li, T Yuan, F Li, SL Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the surge of large language models (LLMs), Large Vision-Language Models \n(VLMs)--which integrate vision encoders with LLMs for accurate visual grounding--\nhave shown great potential in tasks like generalist agents and robotic control\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2504.18349&hl=en&sa=X&d=928423691795550423&ei=mHAyaOCvN7eC6rQP9sj2mQ8&scisig=AAZF9b99grWlNGgtJWvNrjQ6l87h&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
