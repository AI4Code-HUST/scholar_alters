{"title": "Mono: Is Your\" Clean\" Vulnerability Dataset Really Solvable? Exposing and Trapping Undecidable Patches and Beyond", "first_label": ["Vulnerabilities"], "second_label": [], "data": "Z Gao, J Zhou, B Zhang, Y He, C Zhang, Y Cui, H Wang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe quantity and quality of vulnerability datasets are essential for developing deep \nlearning solutions to vulnerability-related tasks. Due to the limited availability of \nvulnerabilities, a common approach to building such datasets is analyzing security\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03651&hl=en&sa=X&d=5611261347115113824&ei=n9ZEaMbjKL2W6rQPjI6v-QY&scisig=AAZF9b8ZqDz-8m4J-1VYjUzHamnv&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Xin ZHOU - new related research", "David Lo - new related research", "2 new citations to articles by Hong Jin Kang", "Quang-Cuong Bui - new related research"]}
{"title": "Boosting Open-Source LLMs for Program Repair via Reasoning Transfer and LLM-Guided Reinforcement Learning", "first_label": ["APR", "LLM"], "second_label": ["Repair", "Reasoning"], "data": "X Tang, J Klein, TF Bissyand\\xc3\\xa9\\xc2\\xa0- arXiv preprint arXiv:2506.03921, 2025\nSeveral closed-source LLMs have consistently outperformed open-source \nalternatives in program repair tasks, primarily due to their superior reasoning \ncapabilities and extensive pre-training. This paper introduces Repairity, a novel three\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03921&hl=en&sa=X&d=5236192915434052745&ei=n9ZEaPeQLqalieoP4J3H2A8&scisig=AAZF9b_Pyh0Or56hIIZbIHm5nDC2&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research", "6 new citations to articles by Abhik Roychoudhury", "Thanh Le-Cong - new related research", "David Lo - new related research", "Bach Le - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Empirical Evaluation of Generalizable Automated Program Repair with Large Language Models", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "V Campos, R Shariffdeen, A Ulges, Y Noller\\xc2\\xa0- arXiv preprint arXiv:2506.03283, 2025\nAutomated Program Repair (APR) proposes bug fixes to aid developers in \nmaintaining software. The state of the art in this domain focuses on using LLMs, \nleveraging their strong capabilities to comprehend specifications in natural language\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03283&hl=en&sa=X&d=200998896991037433&ei=n9ZEaPeQLqalieoP4J3H2A8&scisig=AAZF9b_9W2A-NQAXxkYzgRHwtFh8&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research", "6 new citations to articles by Abhik Roychoudhury", "2 new citations to articles by Xin ZHOU", "Thanh Le-Cong - new related research", "David Lo - new related research", "Bach Le - new related research", "2 new citations to articles by Hong Jin Kang", "Quang-Cuong Bui - new related research"]}
{"title": "EduFuncSum: a function-wise progressive transformer for code summarization in undergraduate programming education", "first_label": ["Code"], "second_label": [], "data": "Y Rong, M Xu, R Li, L Xin, W Bao\\xc2\\xa0- Journal of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomatic code summarization holds significant promise for enhancing program \ncomprehension in undergraduate programming education. Traditional end-to-end \nsummarization models generate isolated descriptions for individual functions, but\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00075-6&hl=en&sa=X&d=4849396417901382170&ei=n9ZEaPeQLqalieoP4J3H2A8&scisig=AAZF9b-ti903CWiOCqr3nE930Xeg&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Across Programming Language Silos: A Study on Cross-Lingual Retrieval-augmented Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "Q Zhu, J Cao, X Chen, Y Lu, H Lin, X Han, L Sun\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCurrent research on large language models (LLMs) with retrieval-augmented code \ngeneration (RACG) mainly focuses on single-language settings, leaving cross-\nlingual effectiveness and security unexplored. Multi-lingual RACG systems are\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03535&hl=en&sa=X&d=14758371788704078162&ei=n9ZEaPeQLqalieoP4J3H2A8&scisig=AAZF9b-dcuDDIx5KNKIkulVIbOZM&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Selective Code Generation for Functional Guarantees", "first_label": ["Code"], "second_label": ["Generation"], "data": "J Jeong, T Kim, S Park\\xc2\\xa0- arXiv preprint arXiv:2505.13553, 2025\nLarge language models (LLMs) show human-level performance and their \nspecialized descendants, code generation models, play core roles in solving \ncomplex tasks, including mathematical reasoning and software development. On the\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13553%3F&hl=en&sa=X&d=10618887701165566141&ei=n9ZEaPeQLqalieoP4J3H2A8&scisig=AAZF9b_uNrZGuMhLrQI8_eSOoX4J&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Understanding API Usage and Testing: An Empirical Study of C Libraries", "first_label": ["Software Testing"], "second_label": [], "data": "A Zaki, C Cadar - 2025\nFor library developers, understanding how their Application Programming Interfaces \n(APIs) are used in the! eld can be invaluable. Knowing how clients are using their \nAPIs allows for data-driven decisions on prioritising bug reports, feature requests\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://srg.doc.ic.ac.uk/files/papers/libprobe-ease-25.pdf&hl=en&sa=X&d=9565695415974607721&ei=n9ZEaLHQL5LXieoP7MLq8Ak&scisig=AAZF9b_PG-CbhRwjkRcs04GlpNl9&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "How Far Are We from Predicting Missing Modalities with Foundation Models?", "first_label": [], "second_label": [], "data": "G Ke, Y Xie, X Wang, G Chao, B Wang, S He\\xc2\\xa0- arXiv preprint arXiv:2506.03530, 2025\nMultimodal foundation models have demonstrated impressive capabilities across \ndiverse tasks. However, their potential as plug-and-play solutions for missing \nmodality prediction remains underexplored. To investigate this, we categorize \nexisting approaches into three representative paradigms, encompassing a total of 42 \nmodel variants, and conduct a comprehensive evaluation in terms of prediction \naccuracy and adaptability to downstream tasks. Our analysis reveals that current\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAgentic AI Software Engineers: Programming with Trust\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03530&hl=en&sa=X&d=9230336641897558877&ei=n9ZEaIeDJrXCieoP_vz9iAU&scisig=AAZF9b9sU3X9gSWk098qVoWg622h&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "Evaluating Large Language Models: A Systematic Review of Efficiency, Applications, and Future Directions", "first_label": ["LLM"], "second_label": [], "data": "Y Saleh, M Abu Talib, Q Nasir, F Dakalbab\\xc2\\xa0- Frontiers in Computer Science\nLarge language models, the innovative breakthrough taking the world by storm, have \nbeen applied in several fields, such as medicine, education, finance, and law. \nMoreover, large language models can integrate into those fields through their \nabilities in natural language processing, text generation, question answering, and \nseveral other use cases that benefit human interactions and decision-making. \nFurthermore, it is imperative to acknowledge the differences involved with large\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2025.1523699/pdf&hl=en&sa=X&d=4093044423653206135&ei=n9ZEaIeDJrXCieoP_vz9iAU&scisig=AAZF9b984VNAB2RS62Pr80qOBNRH&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "BOOSTING SYMBOLIC EXECUTION FOR VULNERABILITY DETECTION", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "H TU - 2025\nSoftware systems written by humans tend to be unreliable and insecure, hence bugs \nor vulnerabilities in them are inevitable. Symbolic execution has shown considerable \npotential in detecting diverse types of software bugs and also vulnerabilities that \nhave severe security implications. However, existing symbolic execution engines still \nsuffer from at least three fundamental limitations in memory modeling, path \nexploration, and structured input generation, which significantly impede existing\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://haoxintu.github.io/files/smu_thesis.pdf&hl=en&sa=X&d=3920640297285392836&ei=n9ZEaIeDJrXCieoP_vz9iAU&scisig=AAZF9b8T7RfLhP6QYSt_dUsdr9rq&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury"]}
{"title": "CETBench: A Novel Dataset constructed via Transformations over Programs for Benchmarking LLMs for Code-Equivalence Checking", "first_label": ["LLM", "Code"], "second_label": [], "data": "N Oza, I Govil, P Gupta, D Khandelwal, D Garg\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLMs have been extensively used for the task of automated code generation. In this \nwork, we examine the applicability of LLMs for the related but relatively unexplored \ntask of code-equivalence checking, ie, given two programs, whether they are \nfunctionally equivalent or not. This is an important problem since benchmarking code \nequivalence can play a critical role in evaluating LLM capabilities for tasks such as \ncode re-writing and code translation. Towards this end, we present CETBench-Code\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Program Repair\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04019&hl=en&sa=X&d=6260632840952853971&ei=n9ZEaIeDJrXCieoP_vz9iAU&scisig=AAZF9b8WRAQxAGhy7eO0km5XHnT0&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["6 new citations to articles by Abhik Roychoudhury", "David Lo - new related research"]}
{"title": "Real-time tracking railway intruders using multiple-agent cooperated large language models with edge stream processing engine", "first_label": ["LLM"], "second_label": ["Agent"], "data": "W Huang, X Deng\\xc2\\xa0- Journal of Network and Computer Applications, 2025\nTracking intruders is crucial for ensuring safe railway operations globally, particularly \nin high-speed railway systems. Traditional methods either rely on post-processing on \ncloud platforms or suffer from limited analytical capabilities on edge devices. \nAlthough large language models (LLMs) have shown great potential to support \ngeneral intelligence, challenges remain for edge devices in accurately and timely \ntracking of intruders along railway lines. This study proposes a novel method that\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaExploring Parameter-Efficient Fine-Tuning Techniques for Code\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1084804525001286&hl=en&sa=X&d=6722182859117754225&ei=n9ZEaI6wK8y8ieoP89mfwQY&scisig=AAZF9b9KFn1ShKpuwlH3TF6FIP3m&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["2 new citations to articles by Xin ZHOU"]}
{"title": "Vulnerability-Aware Alignment: Mitigating Uneven Forgetting in Harmful Fine-Tuning", "first_label": ["Vulnerabilities"], "second_label": [], "data": "L Chen, X Han, L Shen, J Bai, KF Wong\\xc2\\xa0- arXiv preprint arXiv:2506.03850, 2025\nHarmful fine-tuning (HFT), performed directly on open-source LLMs or through Fine-\ntuning-as-a-Service, breaks safety alignment and poses significant threats. Existing \nmethods aim to mitigate HFT risks by learning robust representation on alignment \ndata or making harmful data unlearnable, but they treat each data sample equally, \nleaving data vulnerability patterns understudied. In this work, we reveal that certain \nsubsets of alignment data are consistently more prone to forgetting during HFT\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRemoving rlhf protections in gpt-4 via fine-tuning\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03850&hl=en&sa=X&d=1311313001180143322&ei=n9ZEaJTiH_iJ6rQPkqSymQY&scisig=AAZF9b8lDPXobanPi9JuXZr1M1uy&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang"]}
{"title": "Improving LLM-Based Fault Localization with External Memory and Project Context", "first_label": ["LLM", "Fault Localization"], "second_label": ["Localization"], "data": "I Yeo, D Ryu, J Baik\\xc2\\xa0- arXiv preprint arXiv:2506.03585, 2025\nFault localization, the process of identifying the software components responsible for \nfailures, is essential but often time-consuming. Recent advances in Large Language \nModels (LLMs) have enabled fault localization without extensive defect datasets or\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03585&hl=en&sa=X&d=6976682449842682697&ei=n9ZEaL2mIZLXieoP7MLq8Ak&scisig=AAZF9b9yWjShUCNBl2qtWzrOq6a8&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "\\xe2\\x80\\x9cWe've Met Some Problems\\xe2\\x80\\x9d: Developers' Issues with Privacy-Preserving Computation Techniques on Stack Overflow", "first_label": [], "second_label": [], "data": "P K\\xc3\\xbchtreiber, S Heimermann, S Schillinger\\xe2\\x80\\xa6\\xc2\\xa0- \\xe2\\x80\\xa6\\xc2\\xa0International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware developers must adhere to privacy regulations and apply privacy principles. \nHowever, developers may not be privacy experts and hence are likely to encounter \nissues when choosing, applying, and implementing the corresponding Privacy\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-92882-6_4&hl=en&sa=X&d=12170750192969461747&ei=n9ZEaKzGJOWs6rQPpf7X-Aw&scisig=AAZF9b-2VAlnCZ3VFsZgIT-IQ1ir&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "AI Powered Code Generation: The Next Era of Automated Software Development", "first_label": ["Code"], "second_label": ["Generation"], "data": "H Verma, S Choudhary, K Pandey\\xc2\\xa0- International Journal of Sciences and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn the ever-changing software engineering paradigm, artificial intelligence has \nbecome the revolutionary driver, changing the method by which code is generated, \noptimized, & deployed. The paper delves into the emergence of AI-enabled code\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.ijsci.com/index.php/home/article/download/167/143&hl=en&sa=X&d=5827903349629826673&ei=n9ZEaKzGJOWs6rQPpf7X-Aw&scisig=AAZF9b-P4SV97piIohZWqUsrg_jj&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Fault Localisation and Repair for DL Systems: An Empirical Study with LLMs", "first_label": ["LLM"], "second_label": ["Repair"], "data": "J Kim, N Humbatova, G Jahangirova, S Yoo, P Tonella\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nNumerous Fault Localisation (FL) and repair techniques have been proposed to \naddress faults in Deep Learning (DL) models. However, their effectiveness in \npractical applications remains uncertain due to the reliance on pre-defined rules\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03396&hl=en&sa=X&d=2993196625760325493&ei=n9ZEaJ--HqalieoP4J3H2A8&scisig=AAZF9b8BjoHxJ7ENnG0lxho0lpNU&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Evaluatiing the efficacy of LLM Safety Solutions: The Palit Benchmark Dataset", "first_label": ["LLM"], "second_label": [], "data": "S Palit, D Woods\\xc2\\xa0- arXiv preprint arXiv:2505.13028, 2025\nLarge Language Models (LLMs) are increasingly integrated into critical systems in \nindustries like healthcare and finance. Users can often submit queries to LLM-\nenabled chatbots, some of which can enrich responses with information retrieved\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13028%3F&hl=en&sa=X&d=1273460049730580919&ei=n9ZEaPXOLM6r6rQP3rzY-QM&scisig=AAZF9b9ByON4eaZyjRTpM1-cA_zU&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Wang, W Wang, S Wang, Z Li, Z Ji, Z Lyu, D Wu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Large Language Models (LLMs) has led to the \nemergence of Multi-Agent Systems (MAS) to perform complex tasks through \ncollaboration. However, the intricate nature of MAS, including their architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12442&hl=en&sa=X&d=8825331941370095164&ei=n9ZEaPXOLM6r6rQP3rzY-QM&scisig=AAZF9b_j6hKF2Zy8dNMOx-tobM6E&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Agentxploit: End-to-end redteaming of black-box ai agents", "first_label": [], "second_label": ["Agent"], "data": "Z Wang, V Siu, Z Ye, T Shi, Y Nie, X Zhao, C Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe strong planning and reasoning capabilities of Large Language Models (LLMs) \nhave fostered the development of agent-based systems capable of leveraging \nexternal tools and interacting with increasingly complex environments. However\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.05849&hl=en&sa=X&d=13145039506086791936&ei=n9ZEaPXOLM6r6rQP3rzY-QM&scisig=AAZF9b_5aWzkLQOK0HBWClMmbpt1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Ripple Effect: On Unforeseen Complications of Backdoor Attacks", "first_label": [], "second_label": [], "data": "R Zhang, Y Shen, H Li, W Jiang, H Chen, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent research highlights concerns about the trustworthiness of third-party Pre-\nTrained Language Models (PTLMs) due to potential backdoor attacks. These \nbackdoored PTLMs, however, are effective only for specific pre-defined downstream\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11586&hl=en&sa=X&d=15157304470732077928&ei=n9ZEaPXOLM6r6rQP3rzY-QM&scisig=AAZF9b997v4XRj8-KVQslhBMZvqE&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "first_label": ["LLM"], "second_label": [], "data": "G Chen, F Song, Z Zhao, X Jia, Y Liu, Y Qiao, W Zhang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreak attacks to Large audio-language models (LALMs) are studied recently, but \nthey achieve suboptimal effectiveness, applicability, and practicability, particularly, \nassuming that the adversary can fully manipulate user prompts. In this work, we first\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14103&hl=en&sa=X&d=12355582258955555442&ei=n9ZEaPXOLM6r6rQP3rzY-QM&scisig=AAZF9b84twuHlVXU1hPFciKO3AfT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Securing AI Agents with Information-Flow Control", "first_label": [], "second_label": ["Agent"], "data": "M Costa, B K\\xc3\\xb6pf, A Kolluri, A Paverd, M Russinovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI agents become increasingly autonomous and capable, ensuring their security \nagainst vulnerabilities such as prompt injection becomes critical. This paper explores \nthe use of information-flow control (IFC) to provide security guarantees for AI agents\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23643%3F&hl=en&sa=X&d=4534448032257376326&ei=n9ZEaPXOLM6r6rQP3rzY-QM&scisig=AAZF9b-ruPZ7fbYUs0K6HirRZr2z&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadDepth: Backdoor Attacks Against Monocular Depth Estimation in the Physical World", "first_label": [], "second_label": [], "data": "J Guo, L Zhou, Z Wang, J He, Q Song, A Chen, W Jiang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, deep learning-based Monocular Depth Estimation (MDE) models \nhave been widely applied in fields such as autonomous driving and robotics. \nHowever, their vulnerability to backdoor attacks remains unexplored. To fill the gap in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16154%3F&hl=en&sa=X&d=5415910119131408953&ei=n9ZEaPXOLM6r6rQP3rzY-QM&scisig=AAZF9b_P0jMEgHvYQo3O-kEno08o&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A4FL: Federated Adversarial Defense via Adversarial Training and Pruning Against Backdoor Attack", "first_label": [], "second_label": [], "data": "B Li, M Hamid, M Saleem, M Aman\\xc2\\xa0- IEEE Access, 2025\nBackdoor attacks threaten federated learning (FL) models, where malicious \nparticipants embed hidden triggers into local models during training. These triggers \ncan compromise crucial applications, such as autonomous systems, when they\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/10992684.pdf&hl=en&sa=X&d=4691259454218143835&ei=n9ZEaPXOLM6r6rQP3rzY-QM&scisig=AAZF9b-NVXh_0LVfWkgmGPYIRTtu&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "EntropyMark: Towards More Harmless Backdoor Watermark via Entropy-based Constraint for Open-source Dataset Copyright Protection", "first_label": [], "second_label": [], "data": "M Sun, R Wang, Z Zhu, L Jing, Y Guo\\xc2\\xa0- Proceedings of the Computer Vision and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nHigh-quality open-source datasets are essential for advancing deep neural \nnetworks. However, the unauthorized commercial use of these datasets has raised \nsignificant concerns about copyright protection. One promising approach is backdoor\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_EntropyMark_Towards_More_Harmless_Backdoor_Watermark_via_Entropy-based_Constraint_for_CVPR_2025_paper.pdf&hl=en&sa=X&d=3999981307599099721&ei=n9ZEaPXOLM6r6rQP3rzY-QM&scisig=AAZF9b-KVOWLvLNl_9VwbGvBpqDH&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Bullying the Machine: How Personas Increase LLM Vulnerability", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "Z Xu, U Sanghi, M Kankanhalli\\xc2\\xa0- arXiv preprint arXiv:2505.12692, 2025\nLarge Language Models (LLMs) are increasingly deployed in interactions where \nthey are prompted to adopt personas. This paper investigates whether such persona \nconditioning affects model safety under bullying, an adversarial manipulation that\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12692%3F&hl=en&sa=X&d=3130006781540917286&ei=n9ZEaPXOLM6r6rQP3rzY-QM&scisig=AAZF9b-r43I7NUbwAxgd2MM-t4Q_&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "VADER: A Human-Evaluated Benchmark for Vulnerability Assessment, Detection, Explanation, and Remediation", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "ETS Liu, A Wang, S Mateega, C Georgescu, D Tang\\xc2\\xa0- arXiv preprint arXiv:2505.19395, 2025\nEnsuring that large language models (LLMs) can effectively assess, detect, explain, \nand remediate software vulnerabilities is critical for building robust and secure \nsoftware systems. We introduce VADER, a human-evaluated benchmark designed\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19395%3F&hl=en&sa=X&d=9714217024162720024&ei=n9ZEaKPIJ4qIieoPrumR8AU&scisig=AAZF9b_-FsHIQqysH23COzO04ZAM&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Accelerating Automated Program Verifiers by Automatic Proof Localization", "first_label": [], "second_label": ["Localization"], "data": "K Gopinathan, D Spiliopoulos, V Goyal, P M\\xc3\\xbcller\\xe2\\x80\\xa6\nAutomated program verifiers such as Dafny, F*, Verus, and Viper are now routinely \nused to verify real-world software. Unfortunately, the performance of the SMT solvers \nemployed by these tools is not always able to keep up with the increasing size and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ilyasergey.net/assets/pdf/papers/axolocl-cav25.pdf&hl=en&sa=X&d=12540905409007805483&ei=n9ZEaKPIJ4qIieoPrumR8AU&scisig=AAZF9b--TR062xcgaOy_C_2kqr9N&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=4&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
