{"title": "Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift", "first_label": ["LLM"], "second_label": [], "data": "S Liang, J Liang, T Pang, C Du, A Liu, M Zhu, X Cao\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInstruction tuning enhances large vision-language models (LVLMs) but increases \ntheir vulnerability to backdoor attacks due to their open design. Unlike prior studies in \nstatic settings, this paper explores backdoor attacks in LVLM instruction tuning\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.pdf&hl=en&sa=X&d=5142527777954789704&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b_Zz7b9xsyiBVRqo7nDX3YO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, M Dras, U Naseem\\xc2\\xa0- arXiv preprint arXiv:2506.02442, 2025\nThis paper presents a systematic evaluation of Large Language Models'(LLMs) \nbehavior on long-tail distributed (encrypted) texts and their safety implications. We \nintroduce a two-dimensional framework for assessing LLM safety:(1) instruction\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02442&hl=en&sa=X&d=15102350404536711280&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b_4gGVOvmiHUrKGvn2E4Vhh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Evaluatiing the efficacy of LLM Safety Solutions: The Palit Benchmark Dataset", "first_label": ["LLM"], "second_label": [], "data": "S Palit, D Woods\\xc2\\xa0- arXiv preprint arXiv:2505.13028, 2025\nLarge Language Models (LLMs) are increasingly integrated into critical systems in \nindustries like healthcare and finance. Users can often submit queries to LLM-\nenabled chatbots, some of which can enrich responses with information retrieved\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13028%3F&hl=en&sa=X&d=1273460049730580919&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b9ByON4eaZyjRTpM1-cA_zU&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Ip leakage attacks targeting llm-based multi-agent systems", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Wang, W Wang, S Wang, Z Li, Z Ji, Z Lyu, D Wu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe rapid advancement of Large Language Models (LLMs) has led to the \nemergence of Multi-Agent Systems (MAS) to perform complex tasks through \ncollaboration. However, the intricate nature of MAS, including their architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.12442&hl=en&sa=X&d=8825331941370095164&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b_j6hKF2Zy8dNMOx-tobM6E&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning", "first_label": ["LLM"], "second_label": [], "data": "P Yang, Q Wang, Z Huang, T Liu, C Zhang, B Han\\xc2\\xa0- arXiv preprint arXiv:2505.11953, 2025\nLoss reweighting has shown significant benefits for machine unlearning with large \nlanguage models (LLMs). However, their exact functionalities are left unclear and the \noptimal strategy remains an open question, thus impeding the understanding and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11953%3F&hl=en&sa=X&d=10115741309441283535&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b_qGRbxQa3QaxEAOlNnGTTW&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Ripple Effect: On Unforeseen Complications of Backdoor Attacks", "first_label": [], "second_label": [], "data": "R Zhang, Y Shen, H Li, W Jiang, H Chen, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent research highlights concerns about the trustworthiness of third-party Pre-\nTrained Language Models (PTLMs) due to potential backdoor attacks. These \nbackdoored PTLMs, however, are effective only for specific pre-defined downstream\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.11586&hl=en&sa=X&d=15157304470732077928&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b997v4XRj8-KVQslhBMZvqE&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "first_label": ["LLM"], "second_label": [], "data": "G Chen, F Song, Z Zhao, X Jia, Y Liu, Y Qiao, W Zhang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreak attacks to Large audio-language models (LALMs) are studied recently, but \nthey achieve suboptimal effectiveness, applicability, and practicability, particularly, \nassuming that the adversary can fully manipulate user prompts. In this work, we first\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.14103&hl=en&sa=X&d=12355582258955555442&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b84twuHlVXU1hPFciKO3AfT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Securing AI Agents with Information-Flow Control", "first_label": [], "second_label": ["Agent"], "data": "M Costa, B K\\xc3\\xb6pf, A Kolluri, A Paverd, M Russinovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI agents become increasingly autonomous and capable, ensuring their security \nagainst vulnerabilities such as prompt injection becomes critical. This paper explores \nthe use of information-flow control (IFC) to provide security guarantees for AI agents\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23643%3F&hl=en&sa=X&d=4534448032257376326&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b-ruPZ7fbYUs0K6HirRZr2z&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SVA-ICL: Improving LLM-based software vulnerability assessment via in-context learning and information fusion", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "C Gao, X Chen, G Zhang\\xc2\\xa0- Information and Software Technology, 2025\nContext: Software vulnerability assessment (SVA) is critical for identifying, evaluating, \nand prioritizing security weaknesses in software applications. Objective: Despite the \nincreasing application of large language models (LLMs) in various software\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.10008&hl=en&sa=X&d=1264413811272727540&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b8ALX06m_riBYkcPk3CfsTb&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents", "first_label": [], "second_label": ["Agent", "Reasoning"], "data": "X Yu, B Peng, R Xu, M Galley, H Cheng, S Nath, J Gao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecent progress in reasoning with large language models (LLMs), such as \nDeepSeek-R1, demonstrates impressive capabilities in domains like mathematics \nand coding, by exhibiting complex cognitive behaviors such as verification, goal\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00320&hl=en&sa=X&d=5278749394870424961&ei=HPVNaMnpFe2rieoPnJq6oQ8&scisig=AAZF9b9b-0jt4alWRaYfXuIUsA9R&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Understanding Software Engineering Agents Through the Lens of Traceability: An Empirical Study", "first_label": [], "second_label": ["Agent"], "data": "I Ceka, S Pujar, S Ramji, L Buratti, G Kaiser, B Ray\\xc2\\xa0- arXiv preprint arXiv:2506.08311, 2025\nWith the advent of large language models (LLMs), software engineering agents \n(SWE agents) have emerged as a powerful paradigm for automating a range of \nsoftware tasks--from code generation and repair to test case synthesis. These agents\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08311&hl=en&sa=X&d=15551141672916262062&ei=HPVNaN3dCsOr6rQPmID_oA8&scisig=AAZF9b_bf5rYaWtKTaAySzqwEBNs&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Bach Le - new related research", "David Lo - new related research", "3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Multi-source cross-domain vulnerability detection based on code pre-trained model", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "Y Cao, Y Dong\\xc2\\xa0- Information and Software Technology, 2025\nContext: In recent years, deep learning-based vulnerability detection methods have \nachieved significant success. These methods predict vulnerabilities by automatically \nlearning patterns from code annotated with vulnerability information. However\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S095058492500103X&hl=en&sa=X&d=15955544814733929240&ei=HPVNaN3dCsOr6rQPmID_oA8&scisig=AAZF9b81Qmv0jwO9frlyKQ4ruxkr&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming", "first_label": ["LLM"], "second_label": [], "data": "X Yang, Z Liu, C Huang, J Zhang, T Zhang, Y Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWhile recent research increasingly emphasizes the value of human-LLM \ncollaboration in competitive programming and proposes numerous empirical \nmethods, a comprehensive understanding remains elusive due to the fragmented\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16667%3F&hl=en&sa=X&d=12301434090185084314&ei=HPVNaN3dCsOr6rQPmID_oA8&scisig=AAZF9b9tTvxcX5KbZYQ_r65OszA_&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "LLM Contribution Summarization in Software Projects", "first_label": ["LLM"], "second_label": [], "data": "R Corsi Ferrao, FR de Miranda, D Pavan Soler\\xc2\\xa0- arXiv e-prints, 2025\nThis full paper in innovative practice provides an automated tool to summarize \nindividual code contributions in project-based courses with external clients. Real \nindustry projects offer valuable learning opportunities by immersing students in\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ui.adsabs.harvard.edu/abs/2025arXiv250517710C/abstract&hl=en&sa=X&d=2924767007286761413&ei=HPVNaKCnF_uvieoPlKmY8Ag&scisig=AAZF9b_Y1Z5q_NBLq3-QXm64AzIV&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Selective Code Generation for Functional Guarantees", "first_label": ["Code"], "second_label": ["Generation"], "data": "J Jeong, T Kim, S Park\\xc2\\xa0- arXiv preprint arXiv:2505.13553, 2025\nLarge language models (LLMs) show human-level performance and their \nspecialized descendants, code generation models, play core roles in solving \ncomplex tasks, including mathematical reasoning and software development. On the\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13553%3F&hl=en&sa=X&d=10618887701165566141&ei=HPVNaKCnF_uvieoPlKmY8Ag&scisig=AAZF9b_uNrZGuMhLrQI8_eSOoX4J&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "FuzzCode: Code Large Language Model-Based Fuzz Testing for Industrial IoT Programs", "first_label": ["LLM", "Fuzzing", "Code", "Software Testing"], "second_label": [], "data": "L Yang, C Wei, J Yang, W Xia, Y Yang, Y Luo, D Niyato\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Internet of Things\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFuzz testing is an dynamic program analysis technique designed for discovering \nvulnerabilities in IoT systems. The core goal is to deliberately feed maliciously crafted \ninputs into an IoT device or service, triggering vulnerabilities such as system crashes\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11028927/&hl=en&sa=X&d=8104462651931100859&ei=HPVNaLXfGL2W6rQP-8qayAk&scisig=AAZF9b8NEppCb0nwiT9UFTmtv4yr&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Go Source Code Vulnerability Detection Method Based on Graph Neural Network", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection", "Graph"], "data": "L Yuan, Y Fang, Q Zhang, Z Liu, Y Xu\\xc2\\xa0- Applied Sciences, 2025\nWith the widespread application of the Go language, the demand for vulnerability \ndetection in Go programs is increasing. Existing detection models and methods have \ndeficiencies in extracting source code features of Go programs and mainly focus on\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2076-3417/15/12/6524&hl=en&sa=X&d=1520445956479606427&ei=HPVNaLXfGL2W6rQP-8qayAk&scisig=AAZF9b-uiS-nVflS0tUcia7Ts2wb&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Boosting Rust Unit Test Coverage through Hybrid Program Analysis and Large Language Models", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "B Chu, Y Feng, K Liu, H Shi, Z Nan, Z Guo, B Xu\\xc2\\xa0- arXiv preprint arXiv:2506.09002, 2025\nUnit testing is essential for ensuring software reliability and correctness. Classic \nSearch-Based Software Testing (SBST) methods and concolic execution-based \napproaches for generating unit tests often fail to achieve high coverage due to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09002&hl=en&sa=X&d=14169512283310140838&ei=HPVNaLXfGL2W6rQP-8qayAk&scisig=AAZF9b_gp7PsvepNWNWQE1trZg2v&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Boosting symbolic execution for vulnerability detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "H TU - 2025\nSoftware systems written by humans tend to be unreliable and insecure, hence bugs \nor vulnerabilities in them are inevitable. Symbolic execution has shown considerable \npotential in detecting diverse types of software bugs and also vulnerabilities that\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ink.library.smu.edu.sg/cgi/viewcontent.cgi%3Farticle%3D1702%26context%3Detd_coll&hl=en&sa=X&d=3920640297285392836&ei=HPVNaLXfGL2W6rQP-8qayAk&scisig=AAZF9b_cpEXSZl5wcaWni5FjQSLY&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Zheng, X Qian, H Zhou, S Yang, Y He, S Jana\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models (LMs) show promise for vulnerability detection but struggle with \nlong, real-world code due to sparse and uncertain vulnerability locations. These \nissues, exacerbated by token limits, often cause models to miss vulnerability-related\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17460&hl=en&sa=X&d=9334848497739178959&ei=HPVNaPGdCffWieoPkIfZ2Q8&scisig=AAZF9b_EDz61GJXVBfE-c2mGro5g&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Using Large Language Models for Aerospace Code Generation: Methods, Benchmarks, and Potential Values", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "R He, L Zhang, M Lyu, L Lyu, C Xue\\xc2\\xa0- Aerospace, 2025\nIn recent years, Large Language Models (LLMs) have witnessed rapid \nadvancements, revolutionizing various domains. Within the realm of software \ndevelopment, code generation technology powered by LLMs has emerged as a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2226-4310/12/6/498&hl=en&sa=X&d=10774117724622108555&ei=HPVNaPCRD8y8ieoP6KaDYQ&scisig=AAZF9b_rdKO7Y_152Nx4dsGU87hA&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A File-Statement Approach for Bug Localization: Optimizing IRBL and Combination Strategy", "first_label": ["Bug"], "second_label": ["Localization"], "data": "Z Guo, X Xu, X Chen, C Geng\\xc2\\xa0- IEEE Access, 2025\nOne of the main objectives of software testing is to locate the position of bugs. Bug \nlocalization is generally categorized into statement-level and file-level localization. \nFile-level bug localization is typically performed using information retrieval-based\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11028032.pdf&hl=en&sa=X&d=3135869785806186788&ei=HPVNaPCRD8y8ieoP6KaDYQ&scisig=AAZF9b-RHaCL_MTzyWKVQP6ob0pX&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Differences between Neurodivergent and Neurotypical Software Engineers: Analyzing the 2022 Stack Overflow Survey", "first_label": [], "second_label": [], "data": "P Verma, MV Cruz, G Liebel\\xc2\\xa0- arXiv preprint arXiv:2506.03840, 2025\nNeurodiversity describes variation in brain function among people, including \ncommon conditions such as Autism spectrum disorder (ASD), Attention deficit \nhyperactivity disorder (ADHD), and dyslexia. While Software Engineering (SE)\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03840&hl=en&sa=X&d=17371332141025912649&ei=HPVNaPCRD8y8ieoP6KaDYQ&scisig=AAZF9b_KDLc1Jt-BJLnmOipanZpT&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Chaos Engineering in the Wild: Findings from GitHub", "first_label": [], "second_label": [], "data": "J Owotogbe, I Kumara, D Di Nucci, DA Tamburri\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nChaos engineering aims to improve the resilience of software systems by \nintentionally injecting faults to identify and address system weaknesses that cause \noutages in production environments. Although many tools for chaos engineering\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13654&hl=en&sa=X&d=4195159524352258371&ei=HPVNaPCRD8y8ieoP6KaDYQ&scisig=AAZF9b_WRW9pwu6TVrg6WbqMqMx8&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Design Patterns for Securing LLM Agents against Prompt Injections", "first_label": ["LLM"], "second_label": ["Agent"], "data": "L Beurer-Kellner, BBAM Cre\\xc5\\xa3u, E Debenedetti\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI agents powered by Large Language Models (LLMs) become increasingly \nversatile and capable of addressing a broad spectrum of tasks, ensuring their \nsecurity has become a critical challenge. Among the most pressing threats are\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/abs/2506.08837&hl=en&sa=X&d=2124308329893910985&ei=HPVNaPCRD8y8ieoP6KaDYQ&scisig=AAZF9b_aF8Go0WFp_k9j_u4oGfds&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Which Prompting Technique Should I Use? An Empirical Investigation of Prompting Techniques for Software Engineering Tasks", "first_label": [], "second_label": [], "data": "EG Santana Jr, G Benjamin, M Araujo, H Santos\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nA growing variety of prompt engineering techniques has been proposed for Large \nLanguage Models (LLMs), yet systematic evaluation of each technique on individual \nsoftware engineering (SE) tasks remains underexplored. In this study, we present a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05614&hl=en&sa=X&d=4559781597299000274&ei=HPVNaPCRD8y8ieoP6KaDYQ&scisig=AAZF9b_AF-dA0y6FLiHUrH36iEtZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Visualization Task Taxonomy to Understand the Fuzzing Internals", "first_label": ["Fuzzing"], "second_label": [], "data": "S Kummita, M Miao, E Bodden, S Wei\\xc2\\xa0- ACM Transactions on Software Engineering\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGreybox fuzzing is used extensively in research and practice. There are umpteen \npublications that improve greybox fuzzing. However, to what extent do these \nimprovements affect the internal components or internals of a given fuzzer is not yet\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3718346&hl=en&sa=X&d=6310038100822609560&ei=HPVNaKGtE6alieoPsZriwAs&scisig=AAZF9b_Ue_jmzHRI425oDGHolQub&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "KRAKEN: Program-Adaptive Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A ZHOU, H HUANG, C ZHANG - 2025\nDespite numerous advances, most existing fuzzers still require more than 24 hours to \nthoroughly test the target programs to achieve satisfactory code coverage or bug \ndetection results [7, 32, 42, 64]. Recently, as cloud-based computing and multicore\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://seviezhou.github.io/files/kraken.pdf&hl=en&sa=X&d=6944396394299119143&ei=HPVNaKGtE6alieoPsZriwAs&scisig=AAZF9b9QILhkfV1b1x87AW8NkoEo&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Systematic exploration of fuzzing in IoT: techniques, vulnerabilities, and open challenges", "first_label": ["Vulnerabilities", "Fuzzing"], "second_label": [], "data": "A Touqir, F Iradat, W Iqbal, A Rakib, N Taskin\\xe2\\x80\\xa6\\xc2\\xa0- The Journal of\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs our dependence on the internet and digital platforms grows, the risk of cyber \nthreats rises, making it essential to implement effective measures to safeguard \nsensitive information through cybersecurity, ensure system integrity, and prevent\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11227-025-07371-y&hl=en&sa=X&d=6083537071761720509&ei=HPVNaKGtE6alieoPsZriwAs&scisig=AAZF9b9_2tGbhprfWVgY0gWilcYB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Bridging the Gap between Hardware Fuzzing and Industrial Verification", "first_label": ["Verification", "Fuzzing"], "second_label": [], "data": "R Ma, T Wei, J Zhang, C Yang, J Yi, G Luo\\xc2\\xa0- arXiv preprint arXiv:2506.00461, 2025\nAs hardware design complexity increases, hardware fuzzing emerges as a promising \ntool for automating the verification process. However, a significant gap still exists \nbefore it can be applied in industry. This paper aims to summarize the current\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.00461&hl=en&sa=X&d=14385885432995434427&ei=HPVNaKGtE6alieoPsZriwAs&scisig=AAZF9b9ExAQfYB5BQiwy0_OZzW8C&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Dynamic Mitigation of RESTful Service Failures Using LLMs", "first_label": ["LLM"], "second_label": [], "data": "S Salva, J Sue\nThis paper presents a novel self-healing approach for RESTful services, leveraging \nthe capabilities of large language models (LLMs) to generate source code that \nimplement fine-grained mitigations. The proposed solution introduces 18 healing \noperators tailored for RESTful services, accommodating both grey-box and black-box \nperspectives. These operators implement a dual-mitigation strategy. The first \nmitigation employs encapsulation techniques, enabling dynamic service adaptation\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://perso.limos.fr/~sesalva/publication/icsoft25/icsoft25.pdf&hl=en&sa=X&d=1091410930778564032&ei=HPVNaPTUENSWieoP89D1uAI&scisig=AAZF9b_2KnIffn6-QuaGJNSdTjFl&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Fuzzing Test Data Generation Technique to Cyber-Physical System by Exploring Token Tree", "first_label": ["Fuzzing", "Software Testing"], "second_label": ["Generation"], "data": "I Shin\\xc2\\xa0- Journal of Internet of Things and Convergence, 2025\nAbstract The Korea Internet of Things Society. In particular, Internet of Things (IoTs) \ndevices, which are composed of Cyber Physical Systems (CPS), which combine \ncyber systems and physical systems, have a greater impact from potential \nvulnerabilities than other Information Technologies (IT) systems due to their \ncharacteristics of operating in public places. Therefore, fuzzing tests are useful as a \ntool for improving security by identifying vulnerabilities in such IoT devices and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAFLNet: a greybox fuzzer for network protocols\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://koreascience.kr/article/JAKO202516236003159.pdf&hl=en&sa=X&d=3240172125295905899&ei=HPVNaPTUENSWieoP89D1uAI&scisig=AAZF9b8xnC6fyDwn1T9PyGo1ixcD&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": "Implementing undetectable backdoor attacks in AI models", "first_label": [], "second_label": [], "data": "TT van Harskamp, SS Picek, LL Batina - 2025\nIn this thesis we describe different ways of planting undetectable backdoors in AI \nmodels. The notion of an undetectable backdoor can differ, so we will look at both so-\ncalled black-box and white-box undetectable backdoors. We focus mostly on the \npractical implementation of these backdoors. We show the implementation of two \nblack-box and two white-box undetectable backdoors. The two black-box \nundetectable backdoors use the RSA and Unbalanced Oil and Vinegar signature\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaStealthy backdoor attack for code models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.cs.ru.nl/masters-theses/2025/T_van_Harskamp___Implementing_undetectable_backdoor_attacks_in_AI_models.pdf&hl=en&sa=X&d=14043002036521238704&ei=HPVNaLKTDIOuieoPg4C8kAY&scisig=AAZF9b8xodwfbCZ1lc4ibSHqDdPw&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang"]}
{"title": "Pattern-Based Graph Classification: Comparison of Quality Measures and Importance of Preprocessing", "first_label": [], "second_label": ["Graph"], "data": "L Potin, R Figueiredo, V Labatut, C Largeron\\xc2\\xa0- ACM Transactions on Knowledge\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nGraph classification aims to categorize graphs based on their structural and attribute \nfeatures, with applications in diverse fields such as social network analysis and \nbioinformatics. Among the methods proposed to solve this task, those relying on \npatterns (ie subgraphs) provide good explainability, as the patterns used for \nclassification can be directly interpreted. To identify meaningful patterns, a standard \napproach is to use a quality measure, ie a function that evaluates the discriminative\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaActive learning of discriminative subgraph patterns for api misuse\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3743143&hl=en&sa=X&d=1589827619687434893&ei=HPVNaLKTDIOuieoPg4C8kAY&scisig=AAZF9b8Ir3rVvWnaQSKIUZoewoqR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang"]}
{"title": "LLMs as Evaluators: A Novel Approach to Commit Message Quality Assessment", "first_label": ["LLM", "Commit Message"], "second_label": [], "data": "A Kumar, S Sankar, S Haiduc, PP Das, PP Chakrabarti\\xc2\\xa0- 2025 IEEE/ACM 47th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nEvaluating the quality of commit messages is a challenging task in software \nengineering. Existing evaluation approaches, such as automatic metrics like BLEU, \nROUGE and METEOR, as well as manual human assessments have notable \nlimitations. Automatic metrics often overlook semantic relevance and context, while \nhuman evaluations are time consuming and costly. To address these challenges, we \nexplore the potential of using Large Language Models (LLMs) as an alternative\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCc2vec: Distributed representations of code changes\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11023957/&hl=en&sa=X&d=9472711919149824888&ei=HPVNaLKTDIOuieoPg4C8kAY&scisig=AAZF9b-Nwmxk5n7wb9Zz0DkMudxO&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang"]}
{"title": "DockInsight: A Knowledge-Augmented Dependency Extraction Approach for Dockerfile", "first_label": [], "second_label": [], "data": "Z Zhu, T Chen, Y Zhong, Q Song\\xc2\\xa0- 2025 IEEE/ACM 22nd International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDevOps enhances software production through IT automation, continuous \nintegration, and deployment, with Docker as a key tool that packages applications \nand their environments into standardized images for consistent and efficient \ndeployment. Dockerfiles, which are text-based configuration files, define the \ncomposition and runtime actions of these images. Mismanagement of dependencies \nbetween Dockerfile instructions can cause build failures, highlighting the need for\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDockercleaner: Automatic repair of security smells in dockerfiles\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11024505/&hl=en&sa=X&d=5013678824898105456&ei=HPVNaMXIDdGM6rQP7_O2WA&scisig=AAZF9b8vSs841lxLIysaljFAk4Pf&oi=scholaralrt&hist=ylyK0_8AAAAJ:5615766320347152220:AAZF9b9Qy0LEut_atU8F20t2CTM_&html=&pos=0&folt=cit", "author": ["Quang-Cuong Bui"], "ref": ["1 new citation to articles by Quang-Cuong Bui"]}
