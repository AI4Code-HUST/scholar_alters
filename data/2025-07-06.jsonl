{"title": "Enhancing vulnerability detection by fusing code semantic features with LLM-generated explanations", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "Z Tian, M Li, J Sun, Y Chen, L Chen\\xc2\\xa0- Information Fusion, 2025\nThe rising prevalence of software vulnerabilities highlights the critical need for more \neffective detection techniques. Although recent deep learning (DL) approaches have \nmade notable progress, they primarily rely on code-centric modalities, such as token \nsequences, abstract syntax trees (ASTs), and graph-based representations, while \nlargely neglecting complementary semantic cues available from natural language \nartifacts like code explanations. This paper proposes FuSEVul, a novel multi-modal\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBenchmarking Large Language Models for Multi-Language\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1566253525005238&hl=en&sa=X&d=10509352427264447846&ei=zIBpaIeDFLXCieoP3oeY-Qc&scisig=AAZF9b8cmTWKCKm_3Vy62JuNDyUu&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang", "Bach Le - new related research", "3 new citations to articles by Xin ZHOU", "David Lo - new related research", "Richard Fang - new related research", "Hong Jin Kang - new related research", "Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact", "first_label": [], "second_label": [], "data": "R Qureshi, R Sapkota, A Shah, A Muneer, A Zafar\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCan machines truly think, reason and act in domains like humans? This enduring \nquestion continues to shape the pursuit of Artificial General Intelligence (AGI). \nDespite the growing capabilities of models such as GPT-4.5, DeepSeek, Claude 3.5 \nSonnet, Phi-4, and Grok 3, which exhibit multimodal fluency and partial reasoning, \nthese systems remain fundamentally limited by their reliance on token-level \nprediction and lack of grounded agency. This paper offers a cross-disciplinary\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSurveying neuro-symbolic approaches for reliable artificial\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2507.00951&hl=en&sa=X&d=6322081208042755978&ei=zIBpaIeDFLXCieoP3oeY-Qc&scisig=AAZF9b_6NXWvod4Ij0KTjSQ8LZkn&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["2 new citations to articles by Hong Jin Kang"]}
{"title": "APRMCTS: Improving LLM-based Automated Program Repair with Iterative Tree Search", "first_label": ["APR", "LLM"], "second_label": ["Repair", "Search"], "data": "H Hu, C He, H Zhang, X Xie, Q Zhang\\xc2\\xa0- arXiv preprint arXiv:2507.01827, 2025\nAutomated Program Repair (APR) attempts to fix software bugs without human \nintervention, which plays a crucial role in software development and maintenance. \nRecently, with the advances in Large Language Models (LLMs), a rapidly increasing\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2507.01827&hl=en&sa=X&d=5563687699639240941&ei=zIBpaLnZD_uvieoPzc2EkQE&scisig=AAZF9b-gEpZE6y1-MZaIcjhofBjZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "8 new citations to articles by Abhik Roychoudhury", "Thanh Le-Cong - new related research"]}
{"title": "A First Look at Bugs in LLM Inference Engines", "first_label": ["LLM", "Bug"], "second_label": [], "data": "M Liu, S Zhong, W Bi, Y Zhang, Z Chen, Z Chen, X Liu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language model-specific inference engines (in short as\\\\emph {LLM inference \nengines}) have become a fundamental component of modern AI infrastructure, \nenabling the deployment of LLM-powered applications (LLM apps) across cloud and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09713&hl=en&sa=X&d=1829118811417287869&ei=zIBpaLnZD_uvieoPzc2EkQE&scisig=AAZF9b9PFvonW4DF-GngDik42RDE&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "David Lo - new related research", "Hong Jin Kang - new related research", "Thanh Le-Cong - new related research"]}
{"title": "MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution", "first_label": ["LLM"], "second_label": [], "data": "Y Wang, Z Peng, Y Wang, Z Wei, H Yu, Z Zhu\\xc2\\xa0- arXiv preprint arXiv:2506.12728, 2025\nLLMs demonstrate strong performance in auto-mated software engineering, \nparticularly for code generation and issue resolution. While proprietary models like \nGPT-4o achieve high benchmarks scores on SWE-bench, their API dependence\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12728&hl=en&sa=X&d=2604248405659445617&ei=zIBpaLnZD_uvieoPzc2EkQE&scisig=AAZF9b81DHSvOhQG3is-OJnqV2OF&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "GSIDroid: A Suspicious Subgraph-Driven and Interpretable Android Malware Detection System", "first_label": [], "second_label": ["Detection", "Graph"], "data": "H Huang, W Huang, F Jiang\\xc2\\xa0- Sensors, 2025\nIn recent years, the growing threat of Android malware has caused significant \neconomic losses and posed serious risks to user security and privacy. Machine \nlearning-based detection approaches have improved the accuracy of malware \nidentification, thereby providing more effective protection for Android users. However, \ngraph-based detection methods rely on whole-graph computations instead of \nsubgraph-level analyses, and they often ignore the semantic information of individual\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDexBERT: Effective, Task-Agnostic and Fine-grained\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/1424-8220/25/13/4116&hl=en&sa=X&d=57399085651042221&ei=zIBpaP23INSWieoP7_C3mAw&scisig=AAZF9b-oMvzxzw9f8hOQEIExq24Z&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["3 new citations to articles by Xin ZHOU"]}
{"title": "HPDA: An enhanced GNN-based software vulnerability detection approach by hybrid-scale perception and data augmentation", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "S Cheng, Q Yu, Y Zhu, Z Huang\\xc2\\xa0- Software Quality Journal, 2025\nAs software systems become increasingly complex, the demand for the research of \nvulnerability detection technologies also grows. Recently, vulnerability detection \nmethods based on graph neural networks (GNN) have demonstrated commendable \ngeneralization performance. However, they encounter challenges when dealing with \nlarge-scale code graphs and complex vulnerability patterns. Moreover, the limited \navailability of training samples further restricts the generalization capabilities of\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAssessing generalizability of codebert\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11219-025-09726-3&hl=en&sa=X&d=5959449875215087745&ei=zIBpaP23INSWieoP7_C3mAw&scisig=AAZF9b-b1l_AkDeKeVunH9zlW4Ch&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["3 new citations to articles by Xin ZHOU", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Algorithmic Learning: Assessing the Potential of Large Language Models (LLMs) for Automated Exercise Generation and Grading in Educational Settings", "first_label": ["LLM"], "second_label": ["Generation"], "data": "W Zou, TT Goh, H Zhu, M Liu, B Yang\\xc2\\xa0- International Journal of Human\\xe2\\x80\\x93Computer\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis study explores ChatGPT's role as a teaching aid in algorithmic education, \nfocusing on its ability to generate and evaluate algorithmic questions and solutions. \nQualitative analysis shows strong performance in Sensibleness, Readiness, and \nTopicality, though Novelty remains an area for improvement. ChatGPT also \ndemonstrated self-improvement in criteria like Efficiency and Robustness, with over \n60% enhancement. A comparison of AI and teacher grading revealed that ChatGPT\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.tandfonline.com/doi/abs/10.1080/10447318.2025.2520931&hl=en&sa=X&d=8942095948229549211&ei=zIBpaKDRFbvM6rQP-5ru-QU&scisig=AAZF9b_F-yTrY5OsYI4pKC04cMbq&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le", "1 new citation to articles by Thanh Le-Cong"]}
{"title": "Towards Mining Robust Coq Proof Patterns", "first_label": [], "second_label": [], "data": "C Kaliszyk, B Le, C Rizkallah\nTo reduce the human effort involved in maintaining Coq formal proof scripts, we \ndiscuss the software engineering program repair approaches and our plan to adapt \nthem and apply them to proof repair. This talk proposes a mining approach on a \nrecently published Coq dataset, that aims to adapt established software maintenance \nmethodologies to benefit the area of proof maintenance. We would appreciate \nfeedback from the Coq community on our planned approach.\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaS3: Syntax- and Semantic-Guided Repair Synthesis via\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://people.eng.unimelb.edu.au/rizkallahc/publications/coqpl25-mining-proof-patterns.pdf&hl=en&sa=X&d=82896413540352194&ei=zIBpaKDRFbvM6rQP-5ru-QU&scisig=AAZF9b_FCA0VBMoGZCus8eFIhtiY&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le", "8 new citations to articles by Abhik Roychoudhury", "Bach Le - new articles", "Thanh Le-Cong - new related research"]}
{"title": "Adversarial Attack Classification and Robustness Testing for Large Language Models for Code", "first_label": ["LLM", "Code", "Software Testing"], "second_label": [], "data": "Y Liu, A Foundjem, F Khomh, H Li\\xc2\\xa0- arXiv preprint arXiv:2506.07942, 2025\nLarge Language Models (LLMs) have become vital tools in software development \ntasks such as code generation, completion, and analysis. As their integration into \nworkflows deepens, ensuring robustness against vulnerabilities especially those\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07942&hl=en&sa=X&d=10411796502631711196&ei=zIBpaIWRF_fWieoPlcTkiAc&scisig=AAZF9b-eMQpfZUdxJwBqS5XD673H&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Retrieval-Augmented Code Review Comment Generation", "first_label": ["Code Review", "Code"], "second_label": ["Generation"], "data": "H Hong, J Baik\\xc2\\xa0- arXiv preprint arXiv:2506.11591, 2025\nAutomated code review comment generation (RCG) aims to assist developers by \nautomatically producing natural language feedback for code changes. Existing \napproaches are primarily either generation-based, using pretrained language\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11591&hl=en&sa=X&d=15885059784306332833&ei=zIBpaIWRF_fWieoPlcTkiAc&scisig=AAZF9b-1WT7RGxAC1bABTNtyDxhD&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "HPCTransCompile: An AI Compiler Generated Dataset for High-Performance CUDA Transpilation and LLM Preliminary Exploration", "first_label": ["LLM"], "second_label": [], "data": "J Lv, X He, Y Liu, X Dai, Y Hu, S Yin\\xc2\\xa0- arXiv preprint arXiv:2506.10401, 2025\nThe rapid growth of deep learning has driven exponential increases in model \nparameters and computational demands. NVIDIA GPUs and their CUDA-based \nsoftware ecosystem provide robust support for parallel computing, significantly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10401&hl=en&sa=X&d=14309937792901999617&ei=zIBpaIWRF_fWieoPlcTkiAc&scisig=AAZF9b_LyVd5W0C0U28-mRiJrH9j&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Stack overflow vulnerability detection based on BiLSTM-attention KAN deep learning model: J. Zhai et al.", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "J Zhai, Z Qi, H Yang\\xc2\\xa0- The Journal of Supercomputing, 2025\nStack overflow vulnerabilities pose serious security threats, potentially leading to \ncrashes, data breaches or system compromise. Accordingly, we propose KBS \n(Kolmogorov\\xe2\\x80\\x93Arnold Network-enhanced bidirectional long short-term memory and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11227-025-07605-z&hl=en&sa=X&d=12073243095894407265&ei=zIBpaIWRF_fWieoPlcTkiAc&scisig=AAZF9b-PSAwaC-uO6KhrNrSAGfEq&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Reductive Analysis with Compiler-Guided Large Language Models for Input-Centric Code Optimizations", "first_label": ["LLM", "Code"], "second_label": [], "data": "X Wang, X Hui, C Liao, X Shen\\xc2\\xa0- Proceedings of the ACM on Programming\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nInput-centric program optimization aims to optimize code by considering the relations \nbetween program inputs and program behaviors. Despite its promise, a long-\nstanding barrier for its adoption is the difficulty of automatically identifying critical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729282&hl=en&sa=X&d=4066048552262082451&ei=zIBpaIWRF_fWieoPlcTkiAc&scisig=AAZF9b_cHHDNeP008iH4qW9Tn7JR&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Estimating Correctness Without Oracles in LLM-Based Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "T Valentin, A Madadi, G Sapia, M B\\xc3\\xb6hme\\xc2\\xa0- arXiv preprint arXiv:2507.00057, 2025\nGenerating code from natural language specifications is one of the most successful \napplications of Large Language Models (LLMs). Yet, they hallucinate: LLMs produce \noutputs that may be grammatically correct but are factually incorrect. Without an\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2507.00057&hl=en&sa=X&d=10424116284340339344&ei=zIBpaIWRF_fWieoPlcTkiAc&scisig=AAZF9b-nvv27ImRkyPZ8uZkpohBV&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "8 new citations to articles by Abhik Roychoudhury", "Xin ZHOU - new related research"]}
{"title": "A Framework for Creating Non-Regressive Test Cases via Branch Consistency Analysis Driven by Descriptions", "first_label": ["Software Testing"], "second_label": [], "data": "Y Zhang, P Xue, Z Yang, X Ren, X Li, L Wu, J Zhao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutomated test-generation research overwhelmingly assumes the correctness of \nfocal methods, yet practitioners routinely face non-regression scenarios where the \nfocal method may be defective. A baseline evaluation of EvoSuite and two leading\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07486&hl=en&sa=X&d=12300473129148860276&ei=zIBpaIWRF_fWieoPlcTkiAc&scisig=AAZF9b8EYaZUm5p8en4HDg1pCFjV&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Y Mao, T Cui, P Liu, D You, H Zhu\\xc2\\xa0- arXiv preprint arXiv:2506.15170, 2025\nLarge language models (LLMs) are rapidly evolving from single-modal systems to \nmultimodal LLMs and intelligent agents, significantly expanding their capabilities \nwhile introducing increasingly severe security risks. This paper presents a systematic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15170&hl=en&sa=X&d=16427093263132639213&ei=zIBpaJ2vIqalieoP6cDi4QI&scisig=AAZF9b-zqUEdPZ8IyWJxfUDycl5Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Emoji attack: Enhancing jailbreak attacks against judge llm detection", "first_label": ["LLM"], "second_label": ["Detection"], "data": "Z Wei, Y Liu, NB Erichson\\xc2\\xa0- Forty-second International Conference on Machine\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nJailbreaking techniques trick Large Language Models (LLMs) into producing \nrestricted output, posing a potential threat. One line of defense is to use another LLM \nas a Judge to evaluate the harmfulness of generated text. However, we reveal that\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DQ0rKYiVEZq&hl=en&sa=X&d=17491126507172914063&ei=zIBpaJ2vIqalieoP6cDi4QI&scisig=AAZF9b_yTB1R20z-t6ApkecZnFST&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Enhancing LLM Agent Safety via Causal Influence Prompting", "first_label": ["LLM"], "second_label": ["Agent"], "data": "D Hahm, W Jin, JS Choi, S Ahn, K Lee\\xc2\\xa0- arXiv preprint arXiv:2507.00979, 2025\nAs autonomous agents powered by large language models (LLMs) continue to \ndemonstrate potential across various assistive tasks, ensuring their safe and reliable \nbehavior is crucial for preventing unintended consequences. In this work, we\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2507.00979&hl=en&sa=X&d=14917789128874928614&ei=zIBpaJ2vIqalieoP6cDi4QI&scisig=AAZF9b-FeAd_5vIe5QR_9td5I4fk&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems", "first_label": ["LLM"], "second_label": ["Agent", "Search"], "data": "X Li, J Chen, X Fang, S Ding, H Duan, Q Liu, K Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have shown remarkable capabilities in solving \ndiverse tasks. However, their proficiency in iteratively optimizing complex solutions \nthrough learning from previous feedback remains insufficiently explored. To bridge\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10764&hl=en&sa=X&d=1134890120116902745&ei=zIBpaJ2vIqalieoP6cDi4QI&scisig=AAZF9b8s_mGNSGwzfKFs6o2hgsbd&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "L Jiang, Z Zhang, Z Wang, X Sun, Z Li, L Zhen, X Xu\\xc2\\xa0- arXiv preprint arXiv:2506.16760, 2025\nLarge Vision-Language Models (LVLMs) demonstrate exceptional performance \nacross multimodal tasks, yet remain vulnerable to jailbreak attacks that bypass built-\nin safety mechanisms to elicit restricted content generation. Existing black-box\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.16760&hl=en&sa=X&d=12136733750645262486&ei=zIBpaJ2vIqalieoP6cDi4QI&scisig=AAZF9b8NosIP6RI9jYFVbBgmH01C&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring", "first_label": ["LLM"], "second_label": [], "data": "Y Li, Q Sheng, Y Yang, X Zhang, J Cao\\xc2\\xa0- arXiv preprint arXiv:2506.09996, 2025\nThough safety alignment has been applied to most large language models (LLMs), \nLLM service providers generally deploy a subsequent moderation as the external \nsafety guardrail in real-world products. Existing moderators mainly practice a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09996&hl=en&sa=X&d=8967671192696781749&ei=zIBpaJ2vIqalieoP6cDi4QI&scisig=AAZF9b-I099JquXawda445fWweEs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLM Jailbreak Oracle", "first_label": ["LLM"], "second_label": [], "data": "S Lin, A Suri, A Oprea, C Tan\\xc2\\xa0- arXiv preprint arXiv:2506.17299, 2025\nAs large language models (LLMs) become increasingly deployed in safety-critical \napplications, the lack of systematic methods to assess their vulnerability to jailbreak \nattacks presents a critical security gap. We introduce the jailbreak oracle problem\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17299&hl=en&sa=X&d=13276394224623482198&ei=zIBpaJ2vIqalieoP6cDi4QI&scisig=AAZF9b9_2v0eFVwHwueuxrSl-vyP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Use Property-Based Testing to Bridge LLM Code Generation and Validation", "first_label": ["LLM", "Code", "Software Testing"], "second_label": ["Generation"], "data": "L He, Z Chen, Z Zhang, J Shao, X Gao, L Sheng\\xc2\\xa0- arXiv preprint arXiv:2506.18315, 2025\nLarge Language Models (LLMs) excel at code generation, but ensuring their outputs \nto be functionally correct, especially in complex programming tasks, is a persistent \nchallenge. While traditional Test-Driven Development (TDD) offers a path for code\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.18315&hl=en&sa=X&d=3101719763251668573&ei=zIBpaJ2vIqalieoP6cDi4QI&scisig=AAZF9b8VwRdS0BYT5dVQlhiDylYe&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning", "first_label": ["LLM"], "second_label": [], "data": "GJ Perin, R Chen, X Chen, NST Hirata, Z Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have become indispensable in real-world \napplications. However, their widespread adoption raises significant safety concerns, \nparticularly in responding to socially harmful questions. Despite substantial efforts to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15606&hl=en&sa=X&d=5494164285246185827&ei=zIBpaJ2vIqalieoP6cDi4QI&scisig=AAZF9b83jkzg6GWJfE0yBor7b9qA&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Optimization for threat classification of various data types-based on ML model and LLM", "first_label": ["LLM"], "second_label": [], "data": "C Hong, T Oh\\xc2\\xa0- Scientific Reports, 2025\nWith the development of AI technology, the number of cyber security threats that \nexploit it is increasing rapidly, and it is urgent to build an effective security threat \ndetection system to respond to these threats. There is active research on AI-based \nsecurity tools to detect and respond to these security threats. This study explores how \nheterogeneous data, such as signs of security attacks from security threat news and \nweaknesses in source code, can be analyzed integrally in an ML model and LLM\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.nature.com/articles/s41598-025-05182-y&hl=en&sa=X&d=13693626839261527240&ei=zIBpaNPGGrWP6rQP2NG60As&scisig=AAZF9b9nxinxm2TfWQN286ZSnZ52&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "Context-Aware Code Wiring Recommendation with LLM-based Agent", "first_label": ["LLM", "Code"], "second_label": ["Agent"], "data": "T Wang, Y Jiang, C Dong, Y Zhang, H Liu\\xc2\\xa0- arXiv preprint arXiv:2507.01315, 2025\nCopy-paste-modify is a widespread and pragmatic practice in software development, \nwhere developers adapt reused code snippets, sourced from platforms such as Stack \nOverflow, GitHub, or LLM outputs, into their local codebase. A critical yet \nunderexplored aspect of this adaptation is code wiring, which involves substituting \nunresolved variables in the pasted code with suitable ones from the surrounding \ncontext. Existing solutions either rely on heuristic rules or historical templates, often\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2507.01315&hl=en&sa=X&d=17409656378723556423&ei=zIBpaNPGGrWP6rQP2NG60As&scisig=AAZF9b-tDrA8-0GDtY77h_Sc0-Qp&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Software Vulnerabilities Detection Framework Based on Graph Neural Network with Graph-Based Feature Representations", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "M Bin Mohd Illzam Elahee - 2025\nWith the rapid growth of software development and increasing system complexity, the \nrisk of undetected software flaws has become a significant concern. This research \nexplores an improved approach to identifying such flaws by representing source \ncode in structured visual forms, allowing patterns of vulnerabilities to be more easily \nrecognized. The study finds that different flaw types are best identified through \nspecific representations, leading to higher detection accuracy. These findings offer\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaGreybox fuzzing of distributed systems\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://figshare.swinburne.edu.au/articles/thesis/A_Software_Vulnerabilities_Detection_Framework_Based_on_Graph_Neural_Network_with_Graph-Based_Feature_Representations/29442392/1/files/55824053.pdf&hl=en&sa=X&d=8768106445895290033&ei=zIBpaNPGGrWP6rQP2NG60As&scisig=AAZF9b8vJloiRLmoI1gmgK0TXb0d&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "Coverage-Guided Testing for Deep Learning Models: A Comprehensive Survey", "first_label": ["Software Testing"], "second_label": [], "data": "H Guo, C Tao, Z Huang, W Zou\\xc2\\xa0- arXiv preprint arXiv:2507.00496, 2025\nAs Deep Learning (DL) models are increasingly applied in safety-critical domains, \nensuring their quality has emerged as a pressing challenge in modern software \nengineering. Among emerging validation paradigms, coverage-guided testing (CGT) \nhas gained prominence as a systematic framework for identifying erroneous or \nunexpected model behaviors. Despite growing research attention, existing CGT \nstudies remain methodologically fragmented, limiting the understanding of current\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFuzz Testing based Data Augmentation to Improve Robustness of\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2507.00496&hl=en&sa=X&d=4799916188725293785&ei=zIBpaNPGGrWP6rQP2NG60As&scisig=AAZF9b97vqNzIQk9KVRCF7cKLMOn&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "Assessing and improving isolation in real-time cloud platforms", "first_label": [], "second_label": [], "data": "G Farina\nReal-time cloud foresees the porting of critical applications to cloud platforms, in \norder to enable cloud benefits for critical scenarios, such as ease of usability and \nreconfiguration, as well as higher scalability and availability. However, this vision has \nbeen limited by several threats that live within cloud platforms, mostly related to the \nsharing of resources.\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaA unified WCET analysis framework for multicore platforms\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://dessert.unina.it/phd_thesis/phd_thesis_farina.pdf&hl=en&sa=X&d=7962436176172161659&ei=zIBpaNPGGrWP6rQP2NG60As&scisig=AAZF9b9PGmmaKAtoOOnegvGTsCP2&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["8 new citations to articles by Abhik Roychoudhury"]}
{"title": "ZTaint-Havoc: From Havoc Mode to Zero-Execution Fuzzing-Driven Taint Inference", "first_label": ["Fuzzing"], "second_label": [], "data": "Y Xie, W Zhang, D She\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nFuzzing is a popular software testing technique for discovering vulnerabilities. A \ncentral problem in fuzzing is identifying hot bytes that can influence program \nbehavior. Taint analysis can track the data flow of hot bytes in a white-box fashion\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728916&hl=en&sa=X&d=11807420278266769302&ei=zIBpaKekJczM6rQP_8mNwQs&scisig=AAZF9b8qJKOy3h08rQgyQ5y4FnqB&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "FuzzCode: Code Large Language Model-Based Fuzz Testing for Industrial IoT Programs", "first_label": ["LLM", "Fuzzing", "Code", "Software Testing"], "second_label": [], "data": "L Yang, C Wei, J Yang, W Xia, Y Yang, Y Luo, D Niyato\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Internet of Things\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFuzz testing is an dynamic program analysis technique designed for discovering \nvulnerabilities in IoT systems. The core goal is to deliberately feed maliciously crafted \ninputs into an IoT device or service, triggering vulnerabilities such as system crashes\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11028927/&hl=en&sa=X&d=8104462651931100859&ei=zIBpaKekJczM6rQP_8mNwQs&scisig=AAZF9b8NEppCb0nwiT9UFTmtv4yr&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Reasoning"], "data": "XC Wen, Y Yang, C Gao, Y Xiao, D Ye\\xc2\\xa0- arXiv preprint arXiv:2506.07390, 2025\nLarge language models (LLMs) demonstrate considerable proficiency in numerous \ncoding-related tasks; however, their capabilities in detecting software vulnerabilities \nremain limited. This limitation primarily stems from two factors:(1) the absence of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07390%3F&hl=en&sa=X&d=10299031030894150274&ei=zIBpaKekJczM6rQP_8mNwQs&scisig=AAZF9b_gI2XqGy6iUeaE4tdr-c1h&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Machine Learning-Based Vulnerability Detection in Rust Code Using LLVM IR and Transformer Model", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "Y Lee, SJ Boshra, J Yang, Z Cao, G Liang - 2025\nRust's growing popularity in high-integrity systems requires automated vulnerability \ndetection in order to maintain its strong safety guarantees. Although Rust's \nownership model and compile-time checks prevent many errors, sometimes\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.preprints.org/frontend/manuscript/ca734f823156d514cc7253ead760b337/download_pub&hl=en&sa=X&d=1302858160719542411&ei=zIBpaKekJczM6rQP_8mNwQs&scisig=AAZF9b_v5NTcZP2pCNCvAOVwkIQn&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Classifying Bug-Inducing Commits with Semi-Supervised Learning", "first_label": ["Bug"], "second_label": [], "data": "B Wilkes, L Mayall, J Kaberry, D Newcombe, V Behl\nDespite providing significant value, bug inducing commits are difficult to identify, and \nas such there exists tremendous value in the ability to classify them. The SZZ \nalgorithm is the current industry standard for mapping bug fixing commits into their\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://bw.codexwilkes.com/_media/CommitML.pdf&hl=en&sa=X&d=17677730522097801867&ei=zIBpaKekJczM6rQP_8mNwQs&scisig=AAZF9b_cjag7-83pKwhG78JiNSHN&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "On the Surprising Efficacy of LLMs for Penetration-Testing", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "A Happe, J Cito\\xc2\\xa0- arXiv preprint arXiv:2507.00829, 2025\nThis paper presents a critical examination of the surprising efficacy of Large \nLanguage Models (LLMs) in penetration testing. The paper thoroughly reviews the \nevolution of LLMs and their rapidly expanding capabilities which render them \nincreasingly suitable for complex penetration testing operations. It systematically \ndetails the historical adoption of LLMs in both academic research and industry, \nshowcasing their application across various offensive security tasks and covering\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLLM agents can autonomously exploit one-day vulnerabilities (2024)\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2507.00829&hl=en&sa=X&d=5029838711805019197&ei=zIBpaLSXEZPN6rQPhMr3yAg&scisig=AAZF9b_Gud3ijlfuQEIPULAWFm3s&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang"]}
{"title": "Reassessing Code Authorship Attribution in the Era of Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "AK Dipongkor, Z Yao, K Moran\\xc2\\xa0- arXiv preprint arXiv:2506.17120, 2025\nThe study of Code Stylometry, and in particular Code Authorship Attribution (CAA), \naims to analyze coding styles to identify the authors of code samples. CAA is crucial \nin cybersecurity and software forensics for addressing, detecting plagiarism, and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17120&hl=en&sa=X&d=12069506939304281396&ei=zIBpaKO_Eq6l6rQP7MCumQ8&scisig=AAZF9b9OxubQtYi2lTNPr1YQmcjb&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "TypyBench: Evaluating LLM Type Inference for Untyped Python Repositories", "first_label": ["LLM"], "second_label": [], "data": "H Dong, J Yang, X Deng, Y Jiang, G Pekhimenko\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nType inference for dynamic languages like Python is a persistent challenge in \nsoftware engineering. While large language models (LLMs) have shown promise in \ncode understanding, their type inference capabilities remain underexplored. We\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dxl9sv9vEDy&hl=en&sa=X&d=5590401666570182726&ei=zIBpaKO_Eq6l6rQP7MCumQ8&scisig=AAZF9b_1v2ZiYt35IkKDr0FkrnZ_&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Li, J Ding, C Peng, B Zhao, X Gao, H Gao, X Gu\\xc2\\xa0- arXiv preprint arXiv:2506.05692, 2025\nThe code generation capabilities of large language models (LLMs) have emerged as \na critical dimension in evaluating their overall performance. However, prior research \nhas largely overlooked the security risks inherent in the generated code. In this work\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05692%3F&hl=en&sa=X&d=5492650506064335063&ei=zIBpaKO_Eq6l6rQP7MCumQ8&scisig=AAZF9b_uwkPsOhWMHWjfdGwYFezG&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Bach Le - new related research", "Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "Nemotron-CORTEXA: Enhancing LLM Agents for Software Engineering Tasks via Improved Localization and Solution Diversity", "first_label": ["LLM"], "second_label": ["Agent", "Localization"], "data": "A Sohrabizadeh, J Song, M Liu, R Roy, C Lee\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nLarge Language Models (LLMs) have demonstrated significant potential in code \ngeneration by following natural language instructions. Unfortunately, crucial real-\nworld software engineering tasks, such as debugging or repository-level feature\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3Dk6p8UKRdH7&hl=en&sa=X&d=951048739864022913&ei=zIBpaKO_Eq6l6rQP7MCumQ8&scisig=AAZF9b-H11fzuFCoL6Gk97_KnR7i&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "UCP: a unified framework for code generation with pseudocode-based multi-task learning and reinforcement alignment", "first_label": ["Code"], "second_label": ["Generation"], "data": "Y Wen, Z Cui, Y Liu, Z Zhang, J Zhou, L Tang\\xc2\\xa0- The Journal of Supercomputing, 2025\nPre-trained large language models (LLMs) have been widely applied to natural \nlanguage-based code generation. However, because code generation tasks are \nhighly sensitive to structured information and exhibit diverse logical forms, directly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11227-025-07487-1&hl=en&sa=X&d=264978427275781755&ei=zIBpaOXcI9zM6rQPvNHN6QQ&scisig=AAZF9b8HnhQLRB1NFzaWU0iyGBfI&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Mapping NVD Records to Their VFCs: How Hard is it?", "first_label": [], "second_label": [], "data": "HH Nguyen, DM Tran, Y Cheng, T Le-Cong, HJ Kang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMapping National Vulnerability Database (NVD) records to vulnerability-fixing \ncommits (VFCs) is crucial for vulnerability analysis but challenging due to sparse \nexplicit links in NVD references. This study explores this mapping's feasibility through\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09702&hl=en&sa=X&d=17350753801902205444&ei=zIBpaOXcI9zM6rQPvNHN6QQ&scisig=AAZF9b9GdE1B-xLLhUOLme72JT4D&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Today's Cat Is Tomorrow's Dog: Accounting for Time-Based Changes in the Labels of ML Vulnerability Detection Approaches", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "R Paramitha, Y Feng, F Massacci\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nVulnerability datasets used for ML testing implicitly contain retrospective information. \nWhen tested on the field, one can only use the labels available at the time of training \nand testing (eg seen and assumed negatives). As vulnerabilities are discovered\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715731&hl=en&sa=X&d=7396654833478791244&ei=zIBpaOXcI9zM6rQPvNHN6QQ&scisig=AAZF9b8Le9KZc3LupQcs5YssN_DQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "VulStamp: Vulnerability Assessment using Large Language Model", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "M Hu, X Xie, J Li, M Chen\\xc2\\xa0- arXiv preprint arXiv:2506.11484, 2025\nAlthough modern vulnerability detection tools enable developers to efficiently identify \nnumerous security flaws, indiscriminate remediation efforts often lead to superfluous \ndevelopment expenses. This is particularly true given that a substantial portion of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11484&hl=en&sa=X&d=10210371631874132603&ei=zIBpaOXcI9zM6rQPvNHN6QQ&scisig=AAZF9b8D5-GPG5LVOP0Ejn5MaoBB&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Identifying Helpful Context for LLM-based Vulnerability Repair: A Preliminary Study", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Repair"], "data": "G Antal, B Bogenf\\xc3\\xbcrst, R Ferenc, P Heged\\xc5\\xb1s\\xc2\\xa0- arXiv preprint arXiv:2506.11561, 2025\nRecent advancements in large language models (LLMs) have shown promise for \nautomated vulnerability detection and repair in software systems. This paper \ninvestigates the performance of GPT-4o in repairing Java vulnerabilities from a\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11561%3F&hl=en&sa=X&d=18395494134633245315&ei=zIBpaOXcI9zM6rQPvNHN6QQ&scisig=AAZF9b98eJCzixgUEEGn-02A8M8D&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "AST2CVCode: A New Benchmark Dataset for Source Code Generation on Computer Vision Applications", "first_label": ["Code"], "second_label": ["Generation"], "data": "WS Alshehri, SK Jarraya, AA Allinjawi\\xc2\\xa0- International Conference on Advanced\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nBenchmark datasets are important in evaluating various methods for source code \ngeneration tasks. In this paper, we present AST2CVCode, a new benchmark dataset \nto enhance deep learning models for source code generation. AST2CVCode is\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-91337-2_46&hl=en&sa=X&d=15545214955806460595&ei=zIBpaOXcI9zM6rQPvNHN6QQ&scisig=AAZF9b-xEY_Bo700rs_NZO5gdshG&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=7&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Evaluating and Improving Large Language Models for Competitive Program Generation", "first_label": ["LLM"], "second_label": ["Generation"], "data": "M Wei, Z Li, X Chen, M Zheng, Z Qu, C Yu, S Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nContext: Due to the demand for strong algorithmic reasoning, complex logic \nimplementation, and strict adherence to input/output formats and resource \nconstraints, competitive programming generation by large language models (LLMs)\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.22954&hl=en&sa=X&d=17951461991195684868&ei=zIBpaOXcI9zM6rQPvNHN6QQ&scisig=AAZF9b8x1Dwf_2_RAutnaamTQC2w&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=8&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Trailblazer: Practical End-to-end Web API Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "L Pan, S Cohney, T Murray, VT Pham\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThere are two key challenges in automatically testing web APIs:(a) determine where \nto send API requests and (b) identify how to make a valid payload for a given \nrequest. Both challenges are sometimes addressed by the presence of a machine\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3731717&hl=en&sa=X&d=13250706246401116236&ei=zIBpaPvxHY_WieoP67Tl8As&scisig=AAZF9b-ohQDK3DHvGNmHJasK8R14&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "On the Applicability of Benford's Law to Detect Saturation in Fuzzing (Registered Report)", "first_label": ["Fuzzing"], "second_label": [], "data": "J Lee, H Lee, S Park, SK Cha\\xc2\\xa0- Proceedings of the 34th ACM SIGSOFT International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nKnowing when a fuzzing campaign has reached saturation is crucial for practitioners \nto avoid unnecessarily lengthy campaigns without missing bugs within given \nresources. Unfortunately, existing solutions for determining the saturation point rely\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3731723&hl=en&sa=X&d=16464785359231774820&ei=zIBpaPvxHY_WieoP67Tl8As&scisig=AAZF9b-hP7JkI_Vp2sP6UiYyub7W&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Leveraging activation and optimisation layers as dynamic strategies in the multi-task fuzzing scheme", "first_label": ["Fuzzing"], "second_label": [], "data": "S Bamohabbat Chafjiri, P Legg, MA Tsompanas\\xe2\\x80\\xa6 - 2025\nFuzzing is a common technique for identifying vulnerabilities in software. Recent \napproaches, like She et al.'s Multi-Task Fuzzing (MTFuzz), use neural networks to \nimprove fuzzing efficiency. However, key elements like network architecture and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1016/j.csi.2025.104011&hl=en&sa=X&d=18210490462320417689&ei=zIBpaPvxHY_WieoP67Tl8As&scisig=AAZF9b-SniAFgKPoPY_eeSgA0SFX&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "NASS: Fuzzing All Native Android System Services with Interface Awareness and Coverage", "first_label": ["Fuzzing"], "second_label": [], "data": "P Mao, M Busch, M Payer, R Model\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.usenix.org/conference/usenixsecurity25/presentation/mao&hl=en&sa=X&d=2315419360336007102&ei=zIBpaPvxHY_WieoP67Tl8As&scisig=AAZF9b9jp5fL-hL9kz_JKzlaeywy&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "A Survey of LLM-based Automated Program Repair: Taxonomies, Design Paradigms, and Applications", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "B Yang, Z Cai, F Liu, B Le, L Zhang, TF Bissyand\\xc3\\xa9\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are reshaping automated program repair (APR). We \ncategorize the recent 63 LLM-based APR systems published from January 2022 to \nJune 2025 into four paradigms, and show how retrieval-or analysis-augmented \ncontexts strengthen any of them. This taxonomy clarifies key trade-offs: fine-tuning \ndelivers strong task alignment at high training cost; prompting enables rapid \ndeployment but is limited by prompt design and context windows; procedural\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCleanVul: Automatic Function-Level Vulnerability Detection in\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.23749&hl=en&sa=X&d=15695479663289892601&ei=sSpoaJe2DbXCieoP3oeY-Qc&scisig=AAZF9b8AAYjG2Tx53yz4KxcJPoNe&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["4 new citations to articles by Hong Jin Kang", "10 new citations to articles by Abhik Roychoudhury", "Bach Le - new articles", "3 new citations to articles by Xin ZHOU", "2 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Bach Le", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research", "David Lo - new related research"]}
{"title": "Bug Fixing with Broader Context: Enhancing LLM-Based Program Repair via Layered Knowledge Injection", "first_label": ["APR", "LLM", "Bug"], "second_label": ["Repair"], "data": "R Ehsani, E Parra, S Haiduc, P Chatterjee\\xc2\\xa0- arXiv preprint arXiv:2506.24015, 2025\nPrompting LLMs with bug-related context (eg, error messages, stack traces) \nimproves automated program repair, but many bugs still remain unresolved. In real-\nworld projects, developers often rely on broader repository and project-level context \nbeyond the local code to resolve such bugs. In this paper, we investigate how \nautomatically extracting and providing such knowledge can improve LLM-based \nprogram repair. We propose a layered knowledge injection framework that\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaBugsinpy: a database of existing bugs in python programs to\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.24015&hl=en&sa=X&d=303844423185874638&ei=sSpoaJe2DbXCieoP3oeY-Qc&scisig=AAZF9b8oOYKqGmdAYIucXHURA82f&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["4 new citations to articles by Hong Jin Kang", "Xin ZHOU - new related research", "10 new citations to articles by Abhik Roychoudhury", "Thanh Le-Cong - new related research", "4 new citations to articles by Bach Le", "Hong Jin Kang - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "A framework for evaluation and requirement extraction for fine-tuning of Large Language Models in multimodal medical diagnosis", "first_label": ["LLM"], "second_label": [], "data": "DP Panagoulias, A Palamidas, M Virvou, GA Tsihrintzis\\xc2\\xa0- Knowledge-Based Systems, 2025\nObjective: Large language models constitute a breakthrough state-of-the-art Artificial \nIntelligence technology which is rapidly evolving and promises to aid in medical \ndiagnosis. In this study, we propose a novel evaluation framework for extraction of \nfine-tuning requirements based on the Objective Structured Clinical Examinations \n(OSCE) that can increase LLM potential and applicability. Methods: We developed \nan OSCE based evaluation meta-framework leveraging IoT-based data retrieval with\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAssessing the generalizability of code2vec token embeddings\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950705125010202&hl=en&sa=X&d=4441237570274955084&ei=sSpoaJe2DbXCieoP3oeY-Qc&scisig=AAZF9b8kfUr1DfrLtzJMExXBIzOl&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["4 new citations to articles by Hong Jin Kang"]}
{"title": "VulnSyncAI: PLN e LLMs para Constru\\xc3\\xa7\\xc3\\xa3o e Atualiza\\xc3\\xa7\\xc3\\xa3o Cont\\xc3\\xadnua de Datasets de Vulnerabilidades", "first_label": ["LLM"], "second_label": [], "data": "DR Fideles, DP Lautert, D Kreutz, SE Quincozes\\xc2\\xa0- Simp\\xc3\\xb3sio Brasileiro de Redes de\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nA constru\\xc3\\xa7\\xc3\\xa3o e manuten\\xc3\\xa7\\xc3\\xa3o de datasets atualizados de vulnerabilidades enfrentam \ndesafios como falta de padroniza\\xc3\\xa7\\xc3\\xa3o e necessidade de automa\\xc3\\xa7\\xc3\\xa3o. Neste trabalho, \napresentamos a VulnSyncAI, uma ferramenta modular que utiliza PLN e LLMs para \ncorrelacionar informa\\xc3\\xa7\\xc3\\xb5es de m\\xc3\\xbaltiplas fontes, garantindo datasets atualizados e \nrelevantes. A VulnSyncAI melhora a efic\\xc3\\xa1cia de modelos de IA na detec\\xc3\\xa7\\xc3\\xa3o de \namea\\xc3\\xa7as, automatizando processos e aumentando a efici\\xc3\\xaancia na cria\\xc3\\xa7\\xc3\\xa3o de\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCc2vec: Distributed representations of code changes\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/sbrc_estendido/article/download/35868/35655&hl=en&sa=X&d=16322785358058468095&ei=sSpoaJe2DbXCieoP3oeY-Qc&scisig=AAZF9b-JZgqmOsWnoRxX_-VD_sna&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=3&folt=cit", "author": ["Hong Jin Kang"], "ref": ["4 new citations to articles by Hong Jin Kang"]}
{"title": "Guiding AI to Fix Its Own Flaws: An Empirical Study on LLM-Driven Secure Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "H Yan, SS Vaidya, X Zhang, Z Yao\\xc2\\xa0- arXiv preprint arXiv:2506.23034, 2025\nLarge Language Models (LLMs) have become powerful tools for automated code \ngeneration. However, these models often overlook critical security practices, which \ncan result in the generation of insecure code that contains vulnerabilities\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.23034&hl=en&sa=X&d=8772683163430113126&ei=sSpoaLTCHsmQ6rQPzMjc4AI&scisig=AAZF9b9Wt9UFAZLC3jOar0vhJyDj&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Thanh Le-Cong - new related research", "Bach Le - new related research", "Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research", "1 new citation to articles by Quang-Cuong Bui", "David Lo - new related research"]}
{"title": "AdaptiveLLM: A Framework for Selecting Optimal Cost-Efficient LLM for Code-Generation Based on CoT Length", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Cheng, F Liu, C Wu, L Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.10525, 2025\nWhile Large Language Models (LLMs) have significantly advanced code generation \nefficiency, they face inherent challenges in balancing performance and inference \ncosts across diverse programming tasks. Dynamically selecting the optimal LLM\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10525&hl=en&sa=X&d=12946040656504681529&ei=sSpoaLTCHsmQ6rQPzMjc4AI&scisig=AAZF9b8m2TloB0C3Hd11YMxRGFIR&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Improving vulnerability type prediction and line-level detection via adversarial training-based data augmentation and multi-task learning", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "S Chen, J Yang, X Chen, M Zheng, M Wei, X Ju\\xc2\\xa0- arXiv preprint arXiv:2506.23534, 2025\nContext: Software vulnerabilities pose a significant threat to modern software \nsystems, as evidenced by the growing number of reported vulnerabilities and \ncyberattacks. These escalating trends underscore the urgent need for effective\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.23534&hl=en&sa=X&d=3956612507863695306&ei=sSpoaLTCHsmQ6rQPzMjc4AI&scisig=AAZF9b-PomZH63fxydQMbGHEJs7p&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "FuseApplyBench: Multilingual Benchmark for Trustworthy Code Edit Applying Task", "first_label": ["Code"], "second_label": [], "data": "M Liang, Q Zhang, Z Zuo, S Zheng, D Chen, W Jiang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 34th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the rise of Language Models (LMs) and Large Language Models (LLMs), their \npotential for code editing (CE) has gained attention. An approach is to have LLMs \ngenerate draft code modifications, which are then refined by smaller LMs in further\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3732929&hl=en&sa=X&d=7791836070318800823&ei=sSpoaLTCHsmQ6rQPzMjc4AI&scisig=AAZF9b_-xxPAC4O-ILuaMHDNHkH0&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Rethinking the effects of data contamination in Code Intelligence", "first_label": ["Code"], "second_label": [], "data": "Z Yang, H Lin, Y He, J Xu, Z Sun, S Liu, P Wang, Z Yu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, code intelligence has gained increasing importance in the field of \nautomated software engineering. Meanwhile, the widespread adoption of Pretrained \nLanguage Models (PLMs) and Large Language Models (LLMs) has raised concerns\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02791&hl=en&sa=X&d=13914802631128746138&ei=sSpoaLTCHsmQ6rQPzMjc4AI&scisig=AAZF9b9FbJDsSBQv15gRiA2JZNoe&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Mono: Is Your\" Clean\" Vulnerability Dataset Really Solvable? Exposing and Trapping Undecidable Patches and Beyond", "first_label": ["Vulnerabilities"], "second_label": [], "data": "Z Gao, J Zhou, B Zhang, Y He, C Zhang, Y Cui, H Wang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe quantity and quality of vulnerability datasets are essential for developing deep \nlearning solutions to vulnerability-related tasks. Due to the limited availability of \nvulnerabilities, a common approach to building such datasets is analyzing security\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03651&hl=en&sa=X&d=5611261347115113824&ei=sSpoaLTCHsmQ6rQPzMjc4AI&scisig=AAZF9b8ZqDz-8m4J-1VYjUzHamnv&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Repair Ingredients Are All You Need: Improving Large Language Model-Based Program Repair via Repair Ingredients Search", "first_label": ["APR", "LLM"], "second_label": ["Repair", "Search"], "data": "J Zhang, K Huang, J Zhang, Y Liu, C Chen\\xc2\\xa0- arXiv preprint arXiv:2506.23100, 2025\nAutomated Program Repair (APR) techniques aim to automatically fix buggy \nprograms. Among these, Large Language Model-based (LLM-based) approaches \nhave shown great promise. Recent advances demonstrate that directly leveraging\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.23100&hl=en&sa=X&d=7202370303573960420&ei=sSpoaLTCHsmQ6rQPzMjc4AI&scisig=AAZF9b-jx8AGe-RfiZLtjqOsnZac&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "10 new citations to articles by Abhik Roychoudhury", "Thanh Le-Cong - new related research", "Bach Le - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Evaluating Large Language Models on Non-Code Software Engineering Tasks", "first_label": ["LLM", "Code"], "second_label": [], "data": "FC Pe\\xc3\\xb1a, S Herbold\\xc2\\xa0- arXiv preprint arXiv:2506.10833, 2025\nLarge Language Models (LLMs) have demonstrated remarkable capabilities in code \nunderstanding and generation; however, their effectiveness on non-code Software \nEngineering (SE) tasks remains underexplored. We present the first comprehensive\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10833&hl=en&sa=X&d=11330207664789335570&ei=sSpoaLTCHsmQ6rQPzMjc4AI&scisig=AAZF9b-o1DrbJ7pUNkr3zs_CtfAF&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=7&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Multi-Dataset Evaluation of Models for Automated Vulnerability Repair", "first_label": ["Vulnerabilities"], "second_label": ["Repair"], "data": "ZA Khan, A Garg, Q Tang\\xc2\\xa0- arXiv preprint arXiv:2506.04987, 2025\nSoftware vulnerabilities pose significant security threats, requiring effective \nmitigation. While Automated Program Repair (APR) has advanced in fixing general \nbugs, vulnerability patching, a security-critical aspect of APR remains underexplored\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04987&hl=en&sa=X&d=8355847986163965479&ei=sSpoaLTCHsmQ6rQPzMjc4AI&scisig=AAZF9b9iPSTGWnyCaOCv5RKilXRE&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=8&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Can Large Language Models Help Students Prove Software Correctness? An Experimental Study with Dafny", "first_label": ["LLM"], "second_label": [], "data": "C Carreira, \\xc3\\x81 Silva, A Abreu, A Mendes\\xc2\\xa0- arXiv preprint arXiv:2506.22370, 2025\nStudents in computing education increasingly use large language models (LLMs) \nsuch as ChatGPT. Yet, the role of LLMs in supporting cognitively demanding tasks, \nlike deductive program verification, remains poorly understood. This paper \ninvestigates how students interact with an LLM when solving formal verification \nexercises in Dafny, a language that supports functional correctness, by allowing \nprogrammers to write formal specifications and automatically verifying that the\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAssured automatic programming via large language models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.22370&hl=en&sa=X&d=14179902742949085744&ei=sSpoaIOFFq6l6rQP7MCumQ8&scisig=AAZF9b9xf_0Qv7VsAo8BFqpNwRU8&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements", "first_label": ["LLM"], "second_label": [], "data": "B Zhao, D Magka, M Jiang, X Li, R Raileanu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRapid advancements in large language models (LLMs) have the potential to assist in \nscientific progress. A critical capability toward this endeavor is the ability to \nreproduce existing work. To evaluate the ability of AI agents to reproduce results in \nan active research area, we introduce the Automated LLM Speedrunning \nBenchmark, leveraging the research community contributions on the NanoGPT \nspeedrun, a competition to train a GPT-2 model in the shortest time. Each of the 19\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.22419&hl=en&sa=X&d=15409745592482103200&ei=sSpoaIOFFq6l6rQP7MCumQ8&scisig=AAZF9b_Oc5aTysaB9TE7w0Uila3b&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "What Makes ChatGPT Effective for Software Issue Resolution? An Empirical Study of Developer-ChatGPT Conversations in GitHub", "first_label": ["LLM"], "second_label": [], "data": "R Ehsani, S Pathak, E Parra, S Haiduc, P Chatterjee\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nConversational large-language models are extensively used for issue resolution \ntasks. However, not all developer-LLM conversations are useful for effective issue \nresolution. In this paper, we analyze 686 developer-ChatGPT conversations shared \nwithin GitHub issue threads to identify characteristics that make these conversations \neffective for issue resolution. First, we analyze the conversations and their \ncorresponding issues to distinguish helpful from unhelpful conversations. We begin\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.22390&hl=en&sa=X&d=6374327683634410848&ei=sSpoaIOFFq6l6rQP7MCumQ8&scisig=AAZF9b8mJKgH8LNRT4DS52jlRGXH&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "David Lo - new related research"]}
{"title": "Function-to-style guidance of llms for code translation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "L Zhang, B Wang, J Wang, X Zhao, M Zhang, H Yang\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have made significant strides in code translation \ntasks. However, ensuring both the correctness and readability of translated code \nremains a challenge, limiting their effective adoption in real-world software \ndevelopment. In this work, we propose F2STrans, a function-to-style guiding \nparadigm designed to progressively improve the performance of LLMs in code \ntranslation. Our approach comprises two key stages:(1) Functional learning, which\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DbLng6Z10Vx&hl=en&sa=X&d=238123021128748602&ei=sSpoaIOFFq6l6rQP7MCumQ8&scisig=AAZF9b9Wq5i-W8yOnPmqwiYmA5Hl&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Coverage-Guided Fuzzing Method for Non-Access Stratum Protocol", "first_label": ["Fuzzing"], "second_label": [], "data": "B Liu, W Wang, Y Zhang, X Huang, X Zhang, Y Xiao\\xe2\\x80\\xa6\\xc2\\xa0- 2025 31st International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe Non-Access Stratum (NAS) protocol, a critical signaling protocol in the radio \naccess networks of LTE and 5 G systems, plays a pivotal role in ensuring the security \nand stability of communication sessions between user equipment (UE) and the core \nnetwork. Exploitation of vulnerabilities in the NAS protocol by attackers can lead to \nsevere consequences. However, the lowlatency requirements of the NAS protocol \npose challenges for fuzzing, as prolonged message mutation and coverage statistics\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaStateful Greybox Fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11046294/&hl=en&sa=X&d=10703973721855194660&ei=sSpoaIOFFq6l6rQP7MCumQ8&scisig=AAZF9b9uqzJxClmVwCwAgmjJWApt&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "HF-DGF: Hybrid Feedback Guided Directed Grey-box Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "G Lyu, Z Cao, X Ren, F Wang\\xc2\\xa0- arXiv preprint arXiv:2506.23063, 2025\nDirected Grey-box Fuzzing (DGF) has emerged as a widely adopted technique for \ncrash reproduction and patch testing, leveraging its capability to precisely navigate \ntoward target locations and exploit vulnerabilities. However, current DGF tools are \nconstrained by insufficient runtime feedback, limiting their efficiency in reaching \ntargets and exploring state spaces. This study presents HF-DGF, a novel directed \ngrey-box fuzzing framework. Its seed scheduling is guided by a hybrid feedback\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.23063&hl=en&sa=X&d=9216945522471038399&ei=sSpoaIOFFq6l6rQP7MCumQ8&scisig=AAZF9b_2OQSF8eF4wBWyUJmO2TrP&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Opening Pandora's Packet: Expose IPv6 Implementations Vulnerabilities Using Differential Fuzzing", "first_label": ["Vulnerabilities", "Fuzzing"], "second_label": [], "data": "E Bassetti, E Di Paolo, F Drago, M Conti, A Spognardi\\xc2\\xa0- International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIPv6 is the next generation of the Internet Protocol that is being deployed around the \nworld to replace IPv4. In the design of IPv6, extension headers allow the protocol to \nbe flexible, enabling optional features, such as fragmentation or encryption. \nHowever, the complexity of this design often leads to vulnerabilities that can affect \nmillions of hosts worldwide. In this paper, we propose a new methodology that \nexploits differential fuzzing to uncover and analyze vulnerabilities in IPv6 network\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAFLNet: a greybox fuzzer for network protocols\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-95761-1_14&hl=en&sa=X&d=10125293885331637886&ei=sSpoaIOFFq6l6rQP7MCumQ8&scisig=AAZF9b-JA2WNPz_KrMTsMBMisMe8&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=9&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Smaller= Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "S Fang, W Ding, A Mastropaolo, B Xu\\xc2\\xa0- arXiv preprint arXiv:2506.22776, 2025\nQuantization has emerged as a mainstream method for compressing Large \nLanguage Models (LLMs), reducing memory requirements and accelerating \ninference without architectural modifications. While existing research primarily \nfocuses on evaluating the effectiveness of quantized LLMs compared to their original \ncounterparts, the impact on robustness remains largely unexplored. In this paper, we \npresent the first systematic investigation of how quantization affects the robustness of\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaExploring Parameter-Efficient Fine-Tuning Techniques for Code\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.22776&hl=en&sa=X&d=13020771071669433972&ei=sSpoaLW6G4vT6rQP_IvssAQ&scisig=AAZF9b-4_FS2ULroJ2BDVyjxvgXK&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["3 new citations to articles by Xin ZHOU"]}
{"title": "Software Engineering for Large Language Models: Research Status, Challenges and the Road Ahead", "first_label": ["LLM"], "second_label": ["Search"], "data": "H Rao, Y Zhao, X Hou, S Wang, H Wang\\xc2\\xa0- arXiv preprint arXiv:2506.23762, 2025\nThe rapid advancement of large language models (LLMs) has redefined artificial \nintelligence (AI), pushing the boundaries of AI research and enabling unbounded \npossibilities for both academia and the industry. However, LLM development faces \nincreasingly complex challenges throughout its lifecycle, yet no existing research \nsystematically explores these challenges and solutions from the perspective of \nsoftware engineering (SE) approaches. To fill the gap, we systematically analyze\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaThe Devil is in the Tails: How Long-Tailed Code Distributions\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.23762&hl=en&sa=X&d=9121519873455430042&ei=sSpoaLW6G4vT6rQP_IvssAQ&scisig=AAZF9b_zvNgJDhSXIyxpuiaDRKTQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["3 new citations to articles by Xin ZHOU"]}
{"title": "The Foundation Cracks: A Comprehensive Study on Bugs and Testing Practices in LLM Libraries", "first_label": ["LLM", "Bug", "Software Testing"], "second_label": [], "data": "W Jiang, X Zhang, X Xie, J Yu, Y Zhi, S Ma, C Shen\\xc2\\xa0- arXiv preprint arXiv:2506.12320, 2025\nLarge Language Model (LLM) libraries have emerged as the foundational \ninfrastructure powering today's AI revolution, serving as the backbone for LLM \ndeployment, inference optimization, fine-tuning, and production serving across\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12320&hl=en&sa=X&d=16202500750200898582&ei=sSpoaKzrC8zM6rQP_8mNwQs&scisig=AAZF9b--UIAtYzwloYca2LhAL11r&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "ChatGPT sebagai Asisten Pemrograman: Studi Deskriptif pada Mahasiswa Pendidikan Matematika dalam Pembelajaran MATLAB", "first_label": ["LLM"], "second_label": [], "data": "NH Salsabila, NP Wulandari, RY Tyaningsih\\xc2\\xa0- Griya Journal of Mathematics\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nPenelitian ini bertujuan untuk mengetahui pengalaman mahasiswa pendidikan \nmatematika dalam menggunakan ChatGPT sebagai alat bantu dalam menyusun \nprogram MATLAB pada pembelajaran Komputer Matematika. Penelitian ini \nmenggunakan pendekatan deskriptif kualitatif dengan melibatkan empat mahasiswa \nyang bekerja dalam dua kelompok kecil. Data dikumpulkan melalui lembar aktivitas \nyang berisi tugas membuat tiga program MATLAB dengan bantuan ChatGPT dan\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRefining chatgpt-generated code: Characterizing and mitigating\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://mathjournal.unram.ac.id/index.php/Griya/article/download/722/549&hl=en&sa=X&d=15644569893172877168&ei=sSpoaKm_B8mQ6rQPzMjc4AI&scisig=AAZF9b9Y9nh8bwSa4EVESFKj-oe3&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Bach Le"]}
{"title": "Security vulnerabilities in C++ programs", "first_label": ["Vulnerabilities"], "second_label": [], "data": "PM Adamczyk, M Mi\\xc5\\x82osz\\xc2\\xa0- Journal of Computer Sciences Institute, 2025\nSoftware security is a challenge posed to modern programming developers it is \nimportant not only to protect data and resources, but also to ensure stability, reliability \nand confidence in the systems used. The C++ language, due to its lack of memory \ncontrol and high flexibility, is particularly prone to security vulnerabilities. The aim of \nthis paper is to review the literature to evaluate the effectiveness of existing methods \nto detect and prevent security vulnerabilities in programmes written in C++. The\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaOverfitting in Semantics-based Automated Program Repair\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://ph.pollub.pl/index.php/jcsi/article/download/7389/5025&hl=en&sa=X&d=8690212459596541858&ei=sSpoaLfyDvfWieoPlcTkiAc&scisig=AAZF9b86L27pYIzcmmr9rWGHf2YU&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["4 new citations to articles by Bach Le"]}
{"title": "HornBro: Homotopy-Like Method for Automated Quantum Program Repair", "first_label": ["APR"], "second_label": ["Repair"], "data": "S Tan, L Lu, D Xiang, T Chu, C Lang, J Chen, X Hu\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nQuantum programs provide exponential speedups compared to classical programs \nin certain areas, but they also inevitably encounter logical faults. Automatically \nrepairing quantum programs is much more challenging than repairing classical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715751&hl=en&sa=X&d=13228585835236654799&ei=sSpoaIbqCNzM6rQPvNHN6QQ&scisig=AAZF9b-8_CqaMqv576h_a4v0IZHT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "An Adaptive Language-Agnostic Pruning Method for Greener Language Models for Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "M Saad, JAH L\\xc3\\xb3pez, B Chen, D Varr\\xc3\\xb3, T Sharma\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models of code have demonstrated remarkable performance across \nvarious software engineering and source code analysis tasks. However, their \ndemanding computational resource requirements and consequential environmental\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715773&hl=en&sa=X&d=7944316343425442468&ei=sSpoaIbqCNzM6rQPvNHN6QQ&scisig=AAZF9b_df9m6q87B5fG6FvHqqLve&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Invocable APIs derived from NL2SQL datasets for LLM Tool-Calling Evaluation", "first_label": ["LLM"], "second_label": [], "data": "B Elder, A Murthi, J Kang, AR Naik, K Kate, K Basu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are routinely deployed as agentic systems, with \naccess to tools that interact with live environments to accomplish tasks. In enterprise \ndeployments these systems need to interact with API collections that can be\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11266&hl=en&sa=X&d=12367842913750027747&ei=sSpoaKWgINe5ieoPgIGkkA0&scisig=AAZF9b92WAoZBXEDjoawXtjdB18D&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Adding Context to Automated Vulnerability Detection for Teaching Software Security", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "A Dorard, B K\\xc3\\xbcppers, AR Sai, T Schnitzler\\xc2\\xa0- Proceedings of the 30th ACM Conference\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nConsidering the recent developments in the fiel of generative AI, large language \nmodels (LLMs) can be leveraged to enhance static application security testing \n(SAST) tools and teaching about this topic. These models provide contextual\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3724389.3730794&hl=en&sa=X&d=12324313130335697247&ei=sSpoaKWgINe5ieoPgIGkkA0&scisig=AAZF9b__hfcJJD6znHO6WGfWqZGn&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "deepSURF: Detecting Memory Safety Vulnerabilities in Rust Through Fuzzing LLM-Augmented Harnesses", "first_label": ["Vulnerabilities", "LLM", "Fuzzing"], "second_label": ["Detection"], "data": "G Androutsopoulos, A Bianchi\\xc2\\xa0- arXiv preprint arXiv:2506.15648, 2025\nAlthough Rust ensures memory safety by default, it also permits the use of unsafe \ncode, which can introduce memory safety vulnerabilities if misused. Unfortunately, \nexisting tools for detecting memory bugs in Rust typically exhibit limited detection\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15648&hl=en&sa=X&d=5470473754710042022&ei=sSpoaP3sGNSWieoP7_C3mAw&scisig=AAZF9b-QLCAPbmOGA94zxamaJ1DB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Directed Testing in MLIR: Unleashing Its Potential by Overcoming the Limitations of Random Fuzzing", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "W Tong, Z Wang, Z Tang, J Fang, Y Zhang, G Ye\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMLIR is a new way of creating compiler infrastructures that can be easily reused and \nextended. Current MLIR fuzzing methods focus primarily on test case generation or \nmutation using randomly selected passes. However, they often overlook the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729372&hl=en&sa=X&d=10225165863736020095&ei=sSpoaP3sGNSWieoP7_C3mAw&scisig=AAZF9b9XDaU-7-dG1ms-uNWhw7no&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Malo in the Code Jungle: Explainable Fault Localization for Decentralized Applications", "first_label": ["Fault Localization", "Code"], "second_label": ["Localization"], "data": "H Zhang, J Wu, Z Wu, Z Chen, D Lin, J Chen, Y Zhou\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDecentralized applications (DApps) have long been sitting ducks for hackers due to \ntheir valuable cryptocurrency assets, exposing them to various security risks. When a \nDApp is attacked, promptly identifying faults is crucial to minimizing financial losses\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11034691/&hl=en&sa=X&d=7651709202352945146&ei=sSpoaP3sGNSWieoP7_C3mAw&scisig=AAZF9b8cw1Hmz_K4wN9ajW1PUmQk&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows", "first_label": ["LLM"], "second_label": ["Agent", "Exploit"], "data": "MA Ferrag, N Tihanyi, D Hamouda, L Maglaras\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAutonomous AI agents powered by large language models (LLMs) with structured \nfunction-calling interfaces have dramatically expanded capabilities for real-time data \nretrieval, complex computation, and multi-step orchestration. Yet, the explosive \nproliferation of plugins, connectors, and inter-agent protocols has outpaced \ndiscovery mechanisms and security practices, resulting in brittle integrations \nvulnerable to diverse threats. In this survey, we introduce the first unified, end-to-end\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAdaptive attacks break defenses against indirect prompt injection\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.23260&hl=en&sa=X&d=13772379081735697914&ei=sSpoaPWoCvuvieoPzc2EkQE&scisig=AAZF9b_28ELVzHZXi4OhL2WV-Kpf&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang", "Richard Fang - new related research"]}
{"title": "Lage Network Model: \\xe5\\xa4\\xa7\\xe8\\xa6\\x8f\\xe6\\xa8\\xa1\\xe8\\xa8\\x80\\xe8\\xaa\\x9e\\xe3\\x83\\xa2\\xe3\\x83\\x87\\xe3\\x83\\xab\\xe3\\x82\\x92\\xe5\\xbf\\x9c\\xe7\\x94\\xa8\\xe3\\x81\\x97\\xe3\\x81\\x9f\\xe9\\x80\\x9a\\xe4\\xbf\\xa1\\xe3\\x83\\x8d\\xe3\\x83\\x83\\xe3\\x83\\x88\\xe3\\x83\\xaf\\xe3\\x83\\xbc\\xe3\\x82\\xaf\\xe3\\x82\\xb7\\xe3\\x83\\x9f\\xe3\\x83\\xa5\\xe3\\x83\\xac\\xe3\\x83\\xbc\\xe3\\x82\\xb7\\xe3\\x83\\xa7\\xe3\\x83\\xb3\\xe3\\x81\\xae\\xe3\\x81\\x9f\\xe3\\x82\\x81\\xe3\\x81\\xae\\xe7\\x94\\x9f\\xe6\\x88\\x90\\xe3\\x83\\xa2\\xe3\\x83\\x87\\xe3\\x83\\xab\\xe3\\x81\\xae\\xe6\\xa4\\x9c\\xe8\\xa8\\x8e", "first_label": [], "second_label": [], "data": "\\xe7\\xa7\\x8b\\xe5\\x85\\x83\\xe8\\xa3\\x95\\xe4\\xbb\\x8b\\xef\\xbc\\x8c \\xe5\\xb1\\xb1\\xe5\\xb5\\x9c\\xe8\\x81\\x96\\xe4\\xb9\\x9f\\xc2\\xa0- \\xe4\\xba\\xba\\xe5\\xb7\\xa5\\xe7\\x9f\\xa5\\xe8\\x83\\xbd\\xe5\\xad\\xa6\\xe4\\xbc\\x9a\\xe5\\x85\\xa8\\xe5\\x9b\\xbd\\xe5\\xa4\\xa7\\xe4\\xbc\\x9a\\xe8\\xab\\x96\\xe6\\x96\\x87\\xe9\\x9b\\x86 \\xe7\\xac\\xac 39 \\xe5\\x9b\\x9e (2025), 2025\n\\xe6\\x8a\\x84\\xe9\\x8c\\xb2 \\xe3\\x82\\xaf\\xe3\\x83\\xa9\\xe3\\x82\\xa6\\xe3\\x83\\x89\\xe3\\x82\\x84 IoT \\xe6\\xa9\\x9f\\xe5\\x99\\xa8\\xe3\\x81\\xae\\xe6\\x99\\xae\\xe5\\x8f\\x8a\\xe3\\x81\\xaa\\xe3\\x81\\xa9, \\xe7\\x8f\\xbe\\xe4\\xbb\\xa3\\xe3\\x81\\xae\\xe3\\x83\\x86\\xe3\\x82\\xaf\\xe3\\x83\\x8e\\xe3\\x83\\xad\\xe3\\x82\\xb8\\xe3\\x83\\xbc\\xe3\\x81\\xaf\\xe9\\x80\\x9a\\xe4\\xbf\\xa1\\xe3\\x83\\x8d\\xe3\\x83\\x83\\xe3\\x83\\x88\\xe3\\x83\\xaf\\xe3\\x83\\xbc\\xe3\\x82\\xaf\\xe3\\x81\\xae\\xe4\\xb8\\x8a\\xe3\\x81\\xab\n\\xe6\\x88\\x90\\xe3\\x82\\x8a\\xe7\\xab\\x8b\\xe3\\x81\\xa3\\xe3\\x81\\xa6\\xe3\\x81\\x84\\xe3\\x82\\x8b. \\xe3\\x82\\xb5\\xe3\\x82\\xa4\\xe3\\x83\\x90\\xe3\\x83\\xbc\\xe6\\x94\\xbb\\xe6\\x92\\x83\\xe3\\x81\\xab\\xe5\\xaf\\xbe\\xe3\\x81\\x99\\xe3\\x82\\x8b\\xe3\\x82\\xbb\\xe3\\x82\\xad\\xe3\\x83\\xa5\\xe3\\x83\\xaa\\xe3\\x83\\x86\\xe3\\x82\\xa3\\xe3\\x81\\xae\\xe5\\xbc\\xb7\\xe5\\x8c\\x96\\xe3\\x82\\x84\\xe9\\x80\\x9a\\xe4\\xbf\\xa1\\xe5\\x93\\x81\\xe8\\xb3\\xaa\\xe3\\x81\\xae\\xe5\\x90\\x91\\xe4\\xb8\\x8a\\xe3\\x81\\xaa\\xe3\\x81\\xa9, \n\\xe9\\x80\\x9a\\xe4\\xbf\\xa1\\xe3\\x83\\x87\\xe3\\x83\\xbc\\xe3\\x82\\xbf\\xe3\\x82\\x92\\xe5\\xaf\\xbe\\xe8\\xb1\\xa1\\xe3\\x81\\xa8\\xe3\\x81\\x97\\xe3\\x81\\x9f\\xe6\\x8a\\x80\\xe8\\xa1\\x93\\xe9\\x96\\x8b\\xe7\\x99\\xba\\xe3\\x81\\xae\\xe9\\x87\\x8d\\xe8\\xa6\\x81\\xe6\\x80\\xa7\\xe3\\x81\\x8c\\xe9\\xab\\x98\\xe3\\x81\\xbe\\xe3\\x81\\xa3\\xe3\\x81\\xa6\\xe3\\x81\\x84\\xe3\\x82\\x8b\\xe3\\x81\\x8c, \\xe9\\x80\\x9a\\xe4\\xbf\\xa1\\xe3\\x83\\x87\\xe3\\x83\\xbc\\xe3\\x82\\xbf\\xe3\\x82\\x92\\xe5\\xaf\\xbe\\xe8\\xb1\\xa1\\xe3\\x81\\xa8\\xe3\\x81\\x97\\xe3\\x81\\x9f\\xe7\\xa0\\x94\\xe7\\xa9\\xb6\n\\xe3\\x81\\xab\\xe3\\x81\\x8a\\xe3\\x81\\x84\\xe3\\x81\\xa6\\xe3\\x81\\xaf, \\xe9\\x81\\xa9\\xe5\\x88\\x87\\xe3\\x81\\xaa\\xe3\\x83\\x8d\\xe3\\x83\\x83\\xe3\\x83\\x88\\xe3\\x83\\xaf\\xe3\\x83\\xbc\\xe3\\x82\\xaf\\xe3\\x81\\xae\\xe6\\xa7\\x8b\\xe7\\xaf\\x89\\xe3\\x82\\x84\\xe9\\x80\\x9a\\xe4\\xbf\\xa1\\xe3\\x83\\x91\\xe3\\x82\\xb1\\xe3\\x83\\x83\\xe3\\x83\\x88\\xe3\\x82\\x92\\xe3\\x82\\xad\\xe3\\x83\\xa3\\xe3\\x83\\x97\\xe3\\x83\\x81\\xe3\\x83\\xa3\\xe3\\x81\\x99\\xe3\\x82\\x8b\\xe4\\xbb\\x95\\xe7\\xb5\\x84\\xe3\\x81\\xbf\\xe3\\x81\\xaa\\xe3\\x81\\xa9\\xe3\\x83\\x87\\xe3\\x83\\xbc\\xe3\\x82\\xbf\n\\xe5\\x8f\\x96\\xe5\\xbe\\x97\\xe3\\x81\\xae\\xe3\\x82\\xb3\\xe3\\x82\\xb9\\xe3\\x83\\x88\\xe3\\x81\\x8c\\xe9\\xab\\x98\\xe3\\x81\\x84\\xe5\\xa0\\xb4\\xe5\\x90\\x88\\xe3\\x81\\x8c\\xe5\\xa4\\x9a\\xe3\\x81\\x84. \\xe4\\xbb\\x96\\xe6\\x96\\xb9, \\xe6\\x9c\\x80\\xe8\\xbf\\x91\\xe3\\x81\\xa7\\xe3\\x81\\xaf\\xe7\\x94\\x9f\\xe6\\x88\\x90 AI \\xe3\\x81\\xae\\xe7\\x99\\xba\\xe5\\xb1\\x95\\xe3\\x81\\xab\\xe3\\x82\\x88\\xe3\\x82\\x8a, \\xe8\\xa8\\x80\\xe8\\xaa\\x9e\\xe3\\x82\\x92\\xe3\\x81\\xaf\\xe3\\x81\\x98\\xe3\\x82\\x81\\xe3\\x81\\xa8\\xe3\\x81\\x99\\xe3\\x82\\x8b\n\\xe6\\xa7\\x98\\xe3\\x80\\x85\\xe3\\x81\\xaa\\xe5\\xbd\\xa2\\xe5\\xbc\\x8f\\xe3\\x81\\xae\\xe3\\x83\\x87\\xe3\\x83\\xbc\\xe3\\x82\\xbf\\xe3\\x81\\x8c\\xe7\\xa2\\xba\\xe7\\x8e\\x87\\xe3\\x83\\xa2\\xe3\\x83\\x87\\xe3\\x83\\xab\\xe3\\x81\\xab\\xe3\\x82\\x88\\xe3\\x81\\xa3\\xe3\\x81\\xa6\\xe7\\x94\\x9f\\xe6\\x88\\x90\\xe3\\x81\\x95\\xe3\\x82\\x8c\\xe3\\x82\\x8b\\xe3\\x82\\x88\\xe3\\x81\\x86\\xe3\\x81\\xab\\xe3\\x81\\xaa\\xe3\\x81\\xa3\\xe3\\x81\\x9f\\xe3\\x81\\x8c, \\xe9\\x80\\x9a\\xe4\\xbf\\xa1\\xe3\\x83\\x8d\\xe3\\x83\\x83\\xe3\\x83\\x88\\xe3\\x83\\xaf\\xe3\\x83\\xbc\\xe3\\x82\\xaf\\xe3\\x82\\x92\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.jstage.jst.go.jp/article/pjsai/JSAI2025/0/JSAI2025_2Win596/_pdf&hl=en&sa=X&d=5060100346587033016&ei=sSpoaPWoCvuvieoPzc2EkQE&scisig=AAZF9b_NjdQ6D91c4WNNba7XrApD&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Can AI Fix Buggy Code? Exploring the Use of Large Language Models in Automated Program Repair", "first_label": ["APR", "LLM", "Code", "Bug"], "second_label": ["Repair"], "data": "L Zhang, A Singhal, Q Zou, X Sun, P Liu, HY Lin\\xc2\\xa0- Computer, 2025\nCan AI Fix Buggy Code? Exploring the Use of Large Language Models in \n\\r\\nAutomated Program Repair | IEEE Journals & Magazine | IEEE Xplore Can AI Fix \n\\r\\nBuggy Code? Exploring the Use of Large Language Models in Automated Program\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11052844/&hl=en&sa=X&d=15652723893456234360&ei=sSpoaM28F4_WieoP67Tl8As&scisig=AAZF9b8B3c0EjM1umu2Lns8FQ5wx&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=3&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Boosting Open-Source LLMs for Program Repair via Reasoning Transfer and LLM-Guided Reinforcement Learning", "first_label": ["APR", "LLM"], "second_label": ["Repair", "Reasoning"], "data": "X Tang, J Klein, TF Bissyand\\xc3\\xa9\\xc2\\xa0- arXiv preprint arXiv:2506.03921, 2025\nSeveral closed-source LLMs have consistently outperformed open-source \nalternatives in program repair tasks, primarily due to their superior reasoning \ncapabilities and extensive pre-training. This paper introduces Repairity, a novel three\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03921&hl=en&sa=X&d=5236192915434052745&ei=sSpoaI_PEpPN6rQPhMr3yAg&scisig=AAZF9b_Pyh0Or56hIIZbIHm5nDC2&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Synthesizing Software Engineering Data in a Test-Driven Manner", "first_label": ["Software Testing"], "second_label": [], "data": "L Zhang, J Yang, M Yang, J Yang, M Chen, J Zhang\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nWe introduce** SWE-Flow**, a novel data synthesis framework grounded in Test-\nDriven Development (TDD). Unlike existing software engineering data that rely on \nhuman-submitted issues,** SWE-Flow** automatically infers incremental\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DP9DQ2IExgS&hl=en&sa=X&d=8547569170249215358&ei=sSpoaI_PEpPN6rQPhMr3yAg&scisig=AAZF9b8gNj1zFs_dhY5DtQxXJmJ1&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "LLM-Guided Scenario-based GUI Testing", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "S Yu, Y Ling, C Fang, Q Zhou, C Chen, S Zhu, Z Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe assurance of mobile app GUI is more and more significant. Automated GUI \ntesting approaches of different strategies have been developed, while there are still \nhuge gaps between the approaches and the app business logic, not taking the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05079&hl=en&sa=X&d=10587655884573272012&ei=sSpoaI_PEpPN6rQPhMr3yAg&scisig=AAZF9b_9oZAteogzTFVCpm4ZVNB0&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Across Programming Language Silos: A Study on Cross-Lingual Retrieval-augmented Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "Q Zhu, J Cao, X Chen, Y Lu, H Lin, X Han, L Sun\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCurrent research on large language models (LLMs) with retrieval-augmented code \ngeneration (RACG) mainly focuses on single-language settings, leaving cross-\nlingual effectiveness and security unexplored. Multi-lingual RACG systems are\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03535&hl=en&sa=X&d=14758371788704078162&ei=sSpoaI_PEpPN6rQPhMr3yAg&scisig=AAZF9b-dcuDDIx5KNKIkulVIbOZM&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Characterizing Multi-Hunk Patches: Divergence, Proximity, and LLM Repair Challenges", "first_label": ["LLM"], "second_label": ["Repair"], "data": "N Nashid, D Ding, K Gallaba, AE Hassan, A Mesbah\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMulti-hunk bugs, where fixes span disjoint regions of code, are common in practice, \nyet remain underrepresented in automated repair. Existing techniques and \nbenchmarks pre-dominantly target single-hunk scenarios, overlooking the added\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04418&hl=en&sa=X&d=15657538929124675032&ei=sSpoaI_PEpPN6rQPhMr3yAg&scisig=AAZF9b_-gIMENh8EU3j9mHDoC8N1&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A Preference-Driven Methodology for High-Quality Solidity Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "Z Peng, X Yin, C Ying, C Ni, Y Luo\\xc2\\xa0- arXiv preprint arXiv:2506.03006, 2025\nWhile Large Language Models (LLMs) have demonstrated remarkable progress in \ngenerating functionally correct Solidity code, they continue to face critical challenges \nin producing gas-efficient and secure code, which are critical requirements for real\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03006&hl=en&sa=X&d=17726484644696653033&ei=sSpoaI_PEpPN6rQPhMr3yAg&scisig=AAZF9b-kQj0MkmtCeWsZksOvGyp1&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Your Agent Can Defend Itself against Backdoor Attacks", "first_label": [], "second_label": ["Agent"], "data": "L Changjiang, L Jiacheng, C Bochuan, C Jinghui\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite their growing adoption across domains, large language model (LLM)-\npowered agents face significant security risks from backdoor attacks during training \nand fine-tuning. These compromised agents can subsequently be manipulated to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08336&hl=en&sa=X&d=9281612337423238890&ei=sSpoaLnzHKalieoP6cDi4QI&scisig=AAZF9b8EnIakTDvZQGsyv1duPVA5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SecurityLingua: Efficient Defense of LLM Jailbreak Attacks via Security-Aware Prompt Compression", "first_label": ["LLM"], "second_label": [], "data": "Y Li, S Ahn, H Jiang, AH Abdi, Y Yang, L Qiu\\xc2\\xa0- arXiv preprint arXiv:2506.12707, 2025\nLarge language models (LLMs) have achieved widespread adoption across \nnumerous applications. However, many LLMs are vulnerable to malicious attacks \neven after safety alignment. These attacks typically bypass LLMs' safety guardrails by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12707&hl=en&sa=X&d=8418273368991399970&ei=sSpoaLnzHKalieoP6cDi4QI&scisig=AAZF9b8AOJ5PQ2S2DYr5nVOYpqTl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge", "first_label": ["LLM"], "second_label": [], "data": "S Li, C Xu, J Wang, X Gong, C Chen, J Zhang, J Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable intelligence across \nvarious tasks, which has inspired the development and widespread adoption of LLM-\nas-a-Judge systems for automated model testing, such as red teaming and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09443&hl=en&sa=X&d=2052322274134661445&ei=sSpoaLnzHKalieoP6cDi4QI&scisig=AAZF9b9u9cyhYi06xXXt37CLZpdh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Syntactic paraphrase-based synthetic data generation for backdoor attacks against Chinese language models", "first_label": ["LLM"], "second_label": ["Generation"], "data": "M Hu, Y Yang, D Pan, Z Guo, L Xiao, D Lin, S Zhao\\xc2\\xa0- Information Fusion, 2025\nAbstract Language Models (LMs) have shown significant advancements in various \nNatural Language Processing (NLP) tasks. However, recent studies indicate that \nLMs are particularly susceptible to malicious backdoor attacks, where attackers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S156625352500449X&hl=en&sa=X&d=11939540759867308872&ei=sSpoaLnzHKalieoP6cDi4QI&scisig=AAZF9b_omHEFDqgnSwVne_pfKwnY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas", "first_label": ["LLM"], "second_label": ["Search"], "data": "C Si, T Hashimoto, D Yang\\xc2\\xa0- arXiv preprint arXiv:2506.20803, 2025\nLarge Language Models (LLMs) have shown promise in accelerating the scientific \nresearch pipeline. A key capability for this process is the ability to generate novel \nresearch ideas, and prior studies have found settings in which LLM-generated\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.20803&hl=en&sa=X&d=12936314858694523072&ei=sSpoaLnzHKalieoP6cDi4QI&scisig=AAZF9b9OO1DSvhRdAUtwVxkfCQ2j&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Advancing Jailbreak Strategies: A Hybrid Approach to Exploiting LLM Vulnerabilities and Bypassing Modern Defenses", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Exploit"], "data": "M Ahmed, M Abdelmouty, M Kim, G Kandula, A Park\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe advancement of Pre-Trained Language Models (PTLMs) and Large Language \nModels (LLMs) has led to their widespread adoption across diverse applications. \nDespite their success, these models remain vulnerable to attacks that exploit their\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.21972&hl=en&sa=X&d=675653787277926698&ei=sSpoaLnzHKalieoP6cDi4QI&scisig=AAZF9b91mMHa8_Zo3bUEFFi7T1Lf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Enhancing Reasoning Capabilities of Small Language Models with Blueprints and Prompt Template Search", "first_label": ["LLM"], "second_label": ["Search", "Reasoning"], "data": "D Han, M Xia, DM Diaz, S Kessler, A Mallick, X Zhang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSmall language models (SLMs) offer promising and efficient alternatives to large \nlanguage models (LLMs). However, SLMs' limited capacity restricts their reasoning \ncapabilities and makes them sensitive to prompt variations. To address these\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08669%3F&hl=en&sa=X&d=15704474230557976749&ei=sSpoaLnzHKalieoP6cDi4QI&scisig=AAZF9b8p3WkTiOwxN4IoT6Yx5Fu_&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Kill Two Birds with One Stone! Trajectory enabled Unified Online Detection of Adversarial Examples and Backdoor Attacks", "first_label": [], "second_label": ["Detection"], "data": "A Fu, F Meng, H Peng, H Ma, Z Zhang, Y Zheng\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe proposed UniGuard is the first unified online detection framework capable of \nsimultaneously addressing adversarial examples and backdoor attacks. UniGuard \nbuilds upon two key insights: first, both AE and backdoor attacks have to compromise\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.22722&hl=en&sa=X&d=13093507617708419502&ei=sSpoaLnzHKalieoP6cDi4QI&scisig=AAZF9b8n_qu391txTcOD2oGBZnJs&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Through the Stealth Lens: Rethinking Attacks and Defenses in RAG", "first_label": [], "second_label": [], "data": "S Choudhary, N Palumbo, A Hooda, KD Dvijotham\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRetrieval-augmented generation (RAG) systems are vulnerable to attacks that inject \npoisoned passages into the retrieved set, even at low corruption rates. We show that \nexisting attacks are not designed to be stealthy, allowing reliable detection and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04390&hl=en&sa=X&d=15468735482968103516&ei=sSpoaLnzHKalieoP6cDi4QI&scisig=AAZF9b8u2OUJdUy7skXRySPRbZz3&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
