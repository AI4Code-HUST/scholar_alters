{"title": "ChatGPT-Based Test Generation for Refactoring Engines Enhanced by Feature Analysis on Examples", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "C Dong, Y Jiang, Y Zhang, Y Zhang, L Hui\\xc2\\xa0- 2025 IEEE/ACM 47th International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware refactoring is widely employed to improve software quality. However, \nconducting refactorings manually is tedious, time-consuming, and error-prone. \nConsequently, automated and semi-automated tool support is highly desirable for \nsoftware refactoring in the industry, and most of the main-stream IDEs provide \npowerful tool support for refactoring. However, complex refactoring engines are \nprone to errors, which in turn may result in imperfect and incorrect refactorings. To\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaGeneration-based Code Review Automation: How Far Are We?\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a746/251mHnEjeJq&hl=en&sa=X&d=11959797704902320970&ei=pwRgaLCjNvuvieoPupH_2Ak&scisig=AAZF9b-T2BIjwqhZ8YRKplI8rgRn&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["1 new citation to articles by Xin ZHOU"]}
{"title": "VulBinLLM: LLM-powered Vulnerability Detection for Stripped Binaries", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection"], "data": "N Hussain, H Chen, C Tran, P Huang, Z Li, P Chugh\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRecognizing vulnerabilities in stripped binary files presents a significant challenge in \nsoftware security. Although some progress has been made in generating human-\nreadable information from decompiled binary files with Large Language Models\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.22010&hl=en&sa=X&d=10332909566617513173&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b_uFh0VfBD1MzUN8jZA2T1m&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "FuzzCode: Code Large Language Model-Based Fuzz Testing for Industrial IoT Programs", "first_label": ["LLM", "Fuzzing", "Code", "Software Testing"], "second_label": [], "data": "L Yang, C Wei, J Yang, W Xia, Y Yang, Y Luo, D Niyato\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Internet of Things\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFuzz testing is an dynamic program analysis technique designed for discovering \nvulnerabilities in IoT systems. The core goal is to deliberately feed maliciously crafted \ninputs into an IoT device or service, triggering vulnerabilities such as system crashes\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11028927/&hl=en&sa=X&d=8104462651931100859&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b8NEppCb0nwiT9UFTmtv4yr&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Detecting Functionality-Specific Vulnerabilities via Retrieving Individual Functionality-Equivalent APIs in Open-Source Repositories", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "T Chen, Z Wang, L Li, D Li, Z Li, X Chang, P Bian\\xe2\\x80\\xa6\\xc2\\xa0- 39th European Conference\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFunctionality-specific vulnerabilities, which mainly occur in Application Programming \nInterfaces (APIs) with specific functionalities, are crucial for software developers to \ndetect and avoid. When detecting individual functionality-specific vulnerabilities, the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://drops.dagstuhl.de/storage/00lipics/lipics-vol333-ecoop2025/LIPIcs.ECOOP.2025.6/LIPIcs.ECOOP.2025.6.pdf&hl=en&sa=X&d=14024938291331003331&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b8Zi6s9sahNn8L67Q9ApejJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "2 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Bach Le"]}
{"title": "Walls Have Ears: Demystifying Notification Listener Usage in Android Apps", "first_label": [], "second_label": [], "data": "J Deng, T Liu, Y Zhao, C Wang, L Zhang, H Wang\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe Notification Listener Service (NLS) in Android allows third-party apps to monitor \nand process device notifications, enabling powerful features but also introducing \nsecurity and privacy risks. Despite the special permission required to access NLS, it\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728898&hl=en&sa=X&d=5254092448648347629&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b_haGdL95DBvdLyCsrMhBg1&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Generating vulnerability security fixes with Code Language Models", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": [], "data": "G Bhandari, N Gavric, A Shalaginov\\xc2\\xa0- Information and Software Technology, 2025\nAbstract Existing Code Language Models (CLM) have demonstrated significant \npotential in several coding tasks, including automated code generation in software \nengineering. Similarly, Automated Program Repair (APR) has shown considerable\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925001259&hl=en&sa=X&d=3259454824039873950&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b8dA_uKKprpaO6yp2cen0ap&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Direct Repair Optimization: Training Small Language Models For Educational Program Repair Improves Feedback", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "C Koutcheme, N Dainese, A Hellas\nAbstract Locally deployed Small Language Models (SLMs) offer a promising solution \nfor providing timely and effective programming feedback to students learning to code. \nHowever, SLMs often produce misleading or hallucinated feedback, limiting their\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://koutche.me/files/bea25_camera_ready.pdf&hl=en&sa=X&d=1113261810955792766&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b8kcXLxw1lmpsbI_ee25VBh&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Abhik Roychoudhury - new related research", "Quang-Cuong Bui - new related research", "Thanh Le-Cong - new related research", "Bach Le - new related research"]}
{"title": "Structure-EnhancedPrompt Learning for Graph-Based Code Vulnerability Detection", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection", "Graph"], "data": "W Chang, C Ye, H Zhou\\xc2\\xa0- Applied Sciences, 2025\nRecent advances in prompt learning have opened new avenues for enhancing \nnatural language understanding in domain-specific tasks, including code \nvulnerability detection. Motivated by the limitations of conventional binary\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2076-3417/15/11/6128&hl=en&sa=X&d=14787634818984465351&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b8AbdZB3i79KkRKBO0madiQ&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data", "first_label": ["Vulnerabilities", "LLM"], "second_label": ["Detection", "Reasoning"], "data": "XC Wen, Y Yang, C Gao, Y Xiao, D Ye\\xc2\\xa0- arXiv preprint arXiv:2506.07390, 2025\nLarge language models (LLMs) demonstrate considerable proficiency in numerous \ncoding-related tasks; however, their capabilities in detecting software vulnerabilities \nremain limited. This limitation primarily stems from two factors:(1) the absence of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.07390%3F&hl=en&sa=X&d=10299031030894150274&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b_gI2XqGy6iUeaE4tdr-c1h&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Recurring Vulnerability Detection: How Far Are We?", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "Y Cao, S Wu, R Wang, B Chen, Y Huang, C Lu, Z Zhou\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the rapid development of open-source software, code reuse has become a \ncommon practice to accelerate development. However, it leads to inheritance from \nthe original vulnerability, which recurs at the reusing projects, known as recurring\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728901&hl=en&sa=X&d=18169342812720045655&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b-tZjWk7-linGwbNJwyD3xN&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "X Li, J Ding, C Peng, B Zhao, X Gao, H Gao, X Gu\\xc2\\xa0- arXiv preprint arXiv:2506.05692, 2025\nThe code generation capabilities of large language models (LLMs) have emerged as \na critical dimension in evaluating their overall performance. However, prior research \nhas largely overlooked the security risks inherent in the generated code. In this work\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05692%3F&hl=en&sa=X&d=5492650506064335063&ei=pwRgaIiRO4OuieoPqtaP6Ag&scisig=AAZF9b_uwkPsOhWMHWjfdGwYFezG&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research", "Bach Le - new related research"]}
{"title": "Empirical Evaluation of Generalizable Automated Program Repair with Large Language Models", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "V Campos, R Shariffdeen, A Ulges, Y Noller\\xc2\\xa0- arXiv preprint arXiv:2506.03283, 2025\nAutomated Program Repair (APR) proposes bug fixes to aid developers in \nmaintaining software. The state of the art in this domain focuses on using LLMs, \nleveraging their strong capabilities to comprehend specifications in natural language\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03283&hl=en&sa=X&d=200998896991037433&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b_9W2A-NQAXxkYzgRHwtFh8&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Large Language Model Unlearning for Source Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "X Jiang, Y Dong, Z Fang, Y Ma, T Wang, R Cao, B Li\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLM4SE has demonstrated significant success, but LLMs' potential memorization of \nsensitive or outdated training data introduces critical risks to legal compliance, \nsoftware security, and code quality. LLM unlearning techniques, which can eliminate\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.17125&hl=en&sa=X&d=13604073051426366288&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b8TMw153vfhHtV32PZ_YtWF&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "Black-Box Test Code Fault Localization Driven by Large Language Models and Execution Estimation", "first_label": ["LLM", "Fault Localization", "Code", "Software Testing"], "second_label": ["Localization"], "data": "AS Yaraghi, G Gharachorlu, S Fatima, LC Briand\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nFault localization (FL) is a critical step in debugging which typically relies on \nrepeated executions to pinpoint faulty code regions. However, repeated executions \ncan be impractical in the presence of non-deterministic failures or high execution\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.19045&hl=en&sa=X&d=4386817275632257489&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b_xCC_qw4vQ-buJEOPT4O7A&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research"]}
{"title": "Chain of Grounded Objectives: Concise Goal-Oriented Prompting for Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "S Yeo, SW Hwang, YS Ma\\xc2\\xa0- 39th European Conference on Object-Oriented\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAbstract The use of Large Language Models (LLMs) for code generation has gained \nsignificant attention in recent years. Existing methods often aim to improve the quality \nof generated code by incorporating additional contextual information or guidance\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ECOOP.2025.35&hl=en&sa=X&d=15148634590804607094&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b9NXHU25qRP_AF13iMcvxnS&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Xin ZHOU - new related research"]}
{"title": "HardTests: Synthesizing High-Quality Test Cases for LLM Coding", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "Z He, YM Choi, K Zhang, J Ji, J Zhou, D Xu, I Bercovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nVerifiers play a crucial role in large language model (LLM) reasoning, needed by \npost-training techniques such as reinforcement learning. However, reliable verifiers \nare hard to get for difficult coding problems, because a well-disguised wrong solution\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24098%3F&hl=en&sa=X&d=3676350848881047114&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b_5MHFtMeBb8cv65N0a4daz&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Principal Context-aware Diffusion Guided Data Augmentation for Fault Localization", "first_label": ["Fault Localization"], "second_label": ["Localization"], "data": "S Fu, Y Lei\\xc2\\xa0- arXiv preprint arXiv:2505.24079, 2025\nTest cases are indispensable for conducting effective fault localization (FL). \nHowever, test cases in practice are severely class imbalanced, ie the number of \nfailing test cases (ie minority class) is much less than that of passing ones (ie majority\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24079&hl=en&sa=X&d=2752401929477553722&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b-Sw6EN56n5as-y9e2X3E0V&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "A Preference-Driven Methodology for High-Quality Solidity Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "Z Peng, X Yin, C Ying, C Ni, Y Luo\\xc2\\xa0- arXiv preprint arXiv:2506.03006, 2025\nWhile Large Language Models (LLMs) have demonstrated remarkable progress in \ngenerating functionally correct Solidity code, they continue to face critical challenges \nin producing gas-efficient and secure code, which are critical requirements for real\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03006&hl=en&sa=X&d=17726484644696653033&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b-kQj0MkmtCeWsZksOvGyp1&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Decompiling Smart Contracts with a Large Language Model", "first_label": ["Smart Contracts", "LLM"], "second_label": [], "data": "I David, L Zhou, D Song, A Gervais, K Qin\\xc2\\xa0- arXiv preprint arXiv:2506.19624, 2025\nThe widespread lack of broad source code verification on blockchain explorers such \nas Etherscan, where despite 78,047,845 smart contracts deployed on Ethereum (as \nof May 26, 2025), a mere 767,520 (< 1%) are open source, presents a severe\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.19624&hl=en&sa=X&d=7553370957696156448&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b8lKC81lT2_gZIkgEXE8Ecy&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Simplifying Root Cause Analysis in Kubernetes with StateGraph and LLM", "first_label": ["LLM"], "second_label": ["Graph"], "data": "Y Xiang, CP Chen, L Zeng, W Yin, X Liu, H Li, W Xu\\xc2\\xa0- arXiv preprint arXiv:2506.02490, 2025\nKubernetes, a notably complex and distributed system, utilizes an array of controllers \nto uphold cluster management logic through state reconciliation. Nevertheless, \nmaintaining state consistency presents significant challenges due to unexpected\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02490&hl=en&sa=X&d=5123869491118168077&ei=pwRgaL20LtzM6rQPvLye6As&scisig=AAZF9b941F9ak4iWL2XhEVmYDE88&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=9&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Are LLMs Correctly Integrated into Software Systems?", "first_label": ["LLM"], "second_label": [], "data": "Y Shao, Y Huang, J Shen, L Ma, T Su, C Wan\\xc2\\xa0- 2025 IEEE/ACM 47th International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) provide effective solutions in various application \nscenarios, with the support of retrieval-augmented generation (RAG). However, \ndevelopers face challenges in integrating LLM and RAG into software systems, due \nto lacking interface specifications, various requirements from software context, and \ncomplicated system management. In this paper, we have conducted a \ncomprehensive study of 100 open-source applications that incorporate LLMs with\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaInvalidator: Automated patch correctness assessment via semantic\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a741/251mHkourfy&hl=en&sa=X&d=2548587237289624168&ei=pwRgaN6pJbWP6rQP0NbM6AY&scisig=AAZF9b8W6FWCN365YqKMlSw0_8UH&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Bach Le"]}
{"title": "KRAKEN: Program-Adaptive Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "A Zhou, H Huang, C Zhang\\xc2\\xa0- Proceedings of the ACM on Software Engineering, 2025\nParallel fuzzing, which utilizes multicore computers to accelerate the fuzzing process, \nhas been widely used in industrial-scale software defect detection. However, \nspecifying efficient parallel fuzzing strategies for programs with different\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728882&hl=en&sa=X&d=6944396394299119143&ei=pwRgaK66M-2rieoPqNCcqA8&scisig=AAZF9b_hlkDFVYGzlySdtgzp9iKJ&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "deepSURF: Detecting Memory Safety Vulnerabilities in Rust Through Fuzzing LLM-Augmented Harnesses", "first_label": ["Vulnerabilities", "LLM", "Fuzzing"], "second_label": ["Detection"], "data": "G Androutsopoulos, A Bianchi\\xc2\\xa0- arXiv preprint arXiv:2506.15648, 2025\nAlthough Rust ensures memory safety by default, it also permits the use of unsafe \ncode, which can introduce memory safety vulnerabilities if misused. Unfortunately, \nexisting tools for detecting memory bugs in Rust typically exhibit limited detection\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.15648&hl=en&sa=X&d=5470473754710042022&ei=pwRgaK66M-2rieoPqNCcqA8&scisig=AAZF9b-QLCAPbmOGA94zxamaJ1DB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Structure-Aware, Diagnosis-Guided ECU Firmware Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "Q Chen, K Hu, S Gong, B Chen, Z Kong, H Jiang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nElectronic Control Units (ECUs), providing a wide range of functions from basic \ncontrol functions to safety-critical functions, play a critical role in modern vehicles. \nFuzzing has emerged as an effective approach to ensure the functional safety and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3728914&hl=en&sa=X&d=4127342065268392365&ei=pwRgaK66M-2rieoPqNCcqA8&scisig=AAZF9b_7xTEoMAcPIaTyo-vzOHcB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Directed Testing in MLIR: Unleashing Its Potential by Overcoming the Limitations of Random Fuzzing", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "W Tong, Z Wang, Z Tang, J Fang, Y Zhang, G Ye\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMLIR is a new way of creating compiler infrastructures that can be easily reused and \nextended. Current MLIR fuzzing methods focus primarily on test case generation or \nmutation using randomly selected passes. However, they often overlook the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3729372&hl=en&sa=X&d=10225165863736020095&ei=pwRgaK66M-2rieoPqNCcqA8&scisig=AAZF9b9XDaU-7-dG1ms-uNWhw7no&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Malo in the Code Jungle: Explainable Fault Localization for Decentralized Applications", "first_label": ["Fault Localization", "Code"], "second_label": ["Localization"], "data": "H Zhang, J Wu, Z Wu, Z Chen, D Lin, J Chen, Y Zhou\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDecentralized applications (DApps) have long been sitting ducks for hackers due to \ntheir valuable cryptocurrency assets, exposing them to various security risks. When a \nDApp is attacked, promptly identifying faults is crucial to minimizing financial losses\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11034691/&hl=en&sa=X&d=7651709202352945146&ei=pwRgaK66M-2rieoPqNCcqA8&scisig=AAZF9b8cw1Hmz_K4wN9ajW1PUmQk&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "FuncVul: An Effective Function Level Vulnerability Detection Model using LLM and Code Chunk", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "S Halder, ME Ahmed, S Camtepe\\xc2\\xa0- arXiv preprint arXiv:2506.19453, 2025\nSoftware supply chain vulnerabilities arise when attackers exploit weaknesses by \ninjecting vulnerable code into widely used packages or libraries within software \nrepositories. While most existing approaches focus on identifying vulnerable\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.19453&hl=en&sa=X&d=2355126994281101941&ei=pwRgaOzIMde5ieoPw--gyAU&scisig=AAZF9b8nV7dMzuUWlB0QlvHRGoC6&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=1&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "Richard Fang - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research"]}
{"title": "EnIGMA: Interactive Tools Substantially Assist LM Agents in Finding Security Vulnerabilities", "first_label": ["Vulnerabilities"], "second_label": ["Agent"], "data": "T Abramovich, M Udeshi, M Shao, K Lieret, H Xi\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nAlthough language model (LM) agents have demonstrated increased performance in \nmultiple domains, including coding and web-browsing, their success in cybersecurity \nhas been limited. We present* EnIGMA*, an LM agent for autonomously solving\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DOf3wZhVv1R&hl=en&sa=X&d=16128230014264438319&ei=pwRgaOzIMde5ieoPw--gyAU&scisig=AAZF9b9wGDtXeg4c4cNhuLqJjBH7&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "SAGE: Specification-Aware Grammar Extraction for Automated Test Case Generation with LLMs", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "H Park, S Sung, YS Han, SK Ko\\xc2\\xa0- arXiv preprint arXiv:2506.11081, 2025\nGrammar-based test case generation has proven effective for competitive \nprogramming problems, but generating valid and general grammars from natural \nlanguage specifications remains a key challenge, especially under limited\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.11081&hl=en&sa=X&d=18390577984309828085&ei=pwRgaOzIMde5ieoPw--gyAU&scisig=AAZF9b8jlpuM1YVtAGvpVlGnyxvE&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=4&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "On the Harmfulness of Test Smells in Manual System Testing: A Controlled Experiment", "first_label": ["Software Testing"], "second_label": [], "data": "G Soares, V Santos, M Ribeiro, L Martins, V Pontillo\\xe2\\x80\\xa6\\xc2\\xa0- International Symposium on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nTest smells can pose difficulties during testing activities, such as poor maintainability, \nnon-deterministic behavior, and incomplete verification. Existing research has \nextensively addressed test smells in automated software tests, but little attention has\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://valeriapontillo.github.io/documents/conference/C6.pdf&hl=en&sa=X&d=957642153844525181&ei=pwRgaOzIMde5ieoPw--gyAU&scisig=AAZF9b_VsIiiDShW92x2rjNFTqKL&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=5&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "of Vulnerability-Fixing Code Lines in OSS Security Patches Using Lexical Code", "first_label": ["Vulnerabilities", "Code"], "second_label": [], "data": "RN Arakawa, Y Kanemoto, M Akiyama\\xc2\\xa0- Data and Applications Security and Privacy\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nReusing open-source software (OSS) code has become stan-dard in software \ndevelopment. When vulnerabilities are discovered in reused code, maintainers \ntypically apply security patches. However, these patches often include non\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3D3-pnEQAAQBAJ%26oi%3Dfnd%26pg%3DPA73%26ots%3D_DEgz6XSVT%26sig%3DoohdAgummyP958XHpH0NwJVRkgo&hl=en&sa=X&d=14117885644487496792&ei=pwRgaOzIMde5ieoPw--gyAU&scisig=AAZF9b8L6m1txqRLXI-jc1V-Hufw&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=6&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Your Agent Can Defend Itself against Backdoor Attacks", "first_label": [], "second_label": ["Agent"], "data": "L Changjiang, L Jiacheng, C Bochuan, C Jinghui\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite their growing adoption across domains, large language model (LLM)-\npowered agents face significant security risks from backdoor attacks during training \nand fine-tuning. These compromised agents can subsequently be manipulated to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08336&hl=en&sa=X&d=9281612337423238890&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b8EnIakTDvZQGsyv1duPVA5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Adversarial Preference Learning for Robust LLM Alignment", "first_label": ["LLM"], "second_label": [], "data": "Y Wang, P Wang, C Xi, B Tang, J Zhu, W Wei, C Chen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nModern language models often rely on Reinforcement Learning from Human \nFeedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to \nadversarial attacks due to three key limitations:(1) the inefficiency and high cost of\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.24369%3F&hl=en&sa=X&d=11526575995055803369&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b_ilBi9AMSJoKPXxHc_hWg5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SecurityLingua: Efficient Defense of LLM Jailbreak Attacks via Security-Aware Prompt Compression", "first_label": ["LLM"], "second_label": [], "data": "Y Li, S Ahn, H Jiang, AH Abdi, Y Yang, L Qiu\\xc2\\xa0- arXiv preprint arXiv:2506.12707, 2025\nLarge language models (LLMs) have achieved widespread adoption across \nnumerous applications. However, many LLMs are vulnerable to malicious attacks \neven after safety alignment. These attacks typically bypass LLMs' safety guardrails by\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12707&hl=en&sa=X&d=8418273368991399970&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b8AOJ5PQ2S2DYr5nVOYpqTl&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge", "first_label": ["LLM"], "second_label": [], "data": "S Li, C Xu, J Wang, X Gong, C Chen, J Zhang, J Wang\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) have demonstrated remarkable intelligence across \nvarious tasks, which has inspired the development and widespread adoption of LLM-\nas-a-Judge systems for automated model testing, such as red teaming and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09443&hl=en&sa=X&d=2052322274134661445&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b9u9cyhYi06xXXt37CLZpdh&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Syntactic paraphrase-based synthetic data generation for backdoor attacks against Chinese language models", "first_label": ["LLM"], "second_label": ["Generation"], "data": "M Hu, Y Yang, D Pan, Z Guo, L Xiao, D Lin, S Zhao\\xc2\\xa0- Information Fusion, 2025\nAbstract Language Models (LMs) have shown significant advancements in various \nNatural Language Processing (NLP) tasks. However, recent studies indicate that \nLMs are particularly susceptible to malicious backdoor attacks, where attackers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S156625352500449X&hl=en&sa=X&d=11939540759867308872&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b_omHEFDqgnSwVne_pfKwnY&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Through the Stealth Lens: Rethinking Attacks and Defenses in RAG", "first_label": [], "second_label": [], "data": "S Choudhary, N Palumbo, A Hooda, KD Dvijotham\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRetrieval-augmented generation (RAG) systems are vulnerable to attacks that inject \npoisoned passages into the retrieved set, even at low corruption rates. We show that \nexisting attacks are not designed to be stealthy, allowing reliable detection and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04390&hl=en&sa=X&d=15468735482968103516&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b8u2OUJdUy7skXRySPRbZz3&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AsFT: Anchoring Safety During LLM Fine-Tuning Within Narrow Safety Basin", "first_label": ["LLM"], "second_label": [], "data": "S Yang, Q Zhang, Y Liu, Y Huang, X Jia, K Ning, J Yao\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are vulnerable to safety risks during fine-tuning, \nwhere small amounts of malicious or harmless data can compromise safeguards. In \nthis paper, building on the concept of alignment direction--defined by the weight\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.08473%3F&hl=en&sa=X&d=15059004078714992755&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b-cmQJQ2nP1jAOJlM9iLuaf&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Securing AI Agents with Information-Flow Control", "first_label": [], "second_label": ["Agent"], "data": "M Costa, B K\\xc3\\xb6pf, A Kolluri, A Paverd, M Russinovich\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs AI agents become increasingly autonomous and capable, ensuring their security \nagainst vulnerabilities such as prompt injection becomes critical. This paper explores \nthe use of information-flow control (IFC) to provide security guarantees for AI agents\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23643%3F&hl=en&sa=X&d=4534448032257376326&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b-ruPZ7fbYUs0K6HirRZr2z&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Arms Race in Deep Learning: A Survey of Backdoor Defenses and Adaptive Attacks", "first_label": [], "second_label": [], "data": "X Mo, N Sun, LY Zhang, W Luo, S Gao, Y Xiang\\xc2\\xa0- Pacific-Asia Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDeep neural networks (DNNs) face a growing threat from backdoor attacks, which \nembed hidden malicious functionalities triggered by specific inputs. This survey \nexamines the escalating arms race between backdoor defenses and increasingly\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-96-8183-9_24&hl=en&sa=X&d=4258756518287065675&ei=pwRgaNrwN5PN6rQP1ZangAQ&scisig=AAZF9b80XRQuOtBuq86IspbsVv3h&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "AdaptiveLLM: A Framework for Selecting Optimal Cost-Efficient LLM for Code-Generation Based on CoT Length", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "J Cheng, F Liu, C Wu, L Zhang\\xc2\\xa0- arXiv preprint arXiv:2506.10525, 2025\nWhile Large Language Models (LLMs) have significantly advanced code generation \nefficiency, they face inherent challenges in balancing performance and inference \ncosts across diverse programming tasks. Dynamically selecting the optimal LLM\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.10525&hl=en&sa=X&d=12946040656504681529&ei=pwRgaJXrKdSWieoP7PPKiQQ&scisig=AAZF9b8m2TloB0C3Hd11YMxRGFIR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "The Foundation Cracks: A Comprehensive Study on Bugs and Testing Practices in LLM Libraries", "first_label": ["LLM", "Bug", "Software Testing"], "second_label": [], "data": "W Jiang, X Zhang, X Xie, J Yu, Y Zhi, S Ma, C Shen\\xc2\\xa0- arXiv preprint arXiv:2506.12320, 2025\nLarge Language Model (LLM) libraries have emerged as the foundational \ninfrastructure powering today's AI revolution, serving as the backbone for LLM \ndeployment, inference optimization, fine-tuning, and production serving across\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.12320&hl=en&sa=X&d=16202500750200898582&ei=pwRgaJXrKdSWieoP7PPKiQQ&scisig=AAZF9b--UIAtYzwloYca2LhAL11r&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "A First Look at Bugs in LLM Inference Engines", "first_label": ["LLM", "Bug"], "second_label": [], "data": "M Liu, S Zhong, W Bi, Y Zhang, Z Chen, Z Chen, X Liu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language model-specific inference engines (in short as\\\\emph {LLM inference \nengines}) have become a fundamental component of modern AI infrastructure, \nenabling the deployment of LLM-powered applications (LLM apps) across cloud and\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.09713&hl=en&sa=X&d=1829118811417287869&ei=pwRgaJXrKdSWieoP7PPKiQQ&scisig=AAZF9b9PFvonW4DF-GngDik42RDE&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "HornBro: Homotopy-Like Method for Automated Quantum Program Repair", "first_label": ["APR"], "second_label": ["Repair"], "data": "S Tan, L Lu, D Xiang, T Chu, C Lang, J Chen, X Hu\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nQuantum programs provide exponential speedups compared to classical programs \nin certain areas, but they also inevitably encounter logical faults. Automatically \nrepairing quantum programs is much more challenging than repairing classical\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715751&hl=en&sa=X&d=13228585835236654799&ei=pwRgaNLeJqKr6rQPxKWDUA&scisig=AAZF9b-8_CqaMqv576h_a4v0IZHT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "An Adaptive Language-Agnostic Pruning Method for Greener Language Models for Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "M Saad, JAH L\\xc3\\xb3pez, B Chen, D Varr\\xc3\\xb3, T Sharma\\xc2\\xa0- Proceedings of the ACM on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLanguage models of code have demonstrated remarkable performance across \nvarious software engineering and source code analysis tasks. However, their \ndemanding computational resource requirements and consequential environmental\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3715773&hl=en&sa=X&d=7944316343425442468&ei=pwRgaNLeJqKr6rQPxKWDUA&scisig=AAZF9b_df9m6q87B5fG6FvHqqLve&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Synthesizing Software Engineering Data in a Test-Driven Manner", "first_label": ["Software Testing"], "second_label": [], "data": "L Zhang, J Yang, M Yang, J Yang, M Chen, J Zhang\\xe2\\x80\\xa6\\xc2\\xa0- Forty-second International\\xc2\\xa0\\xe2\\x80\\xa6\nWe introduce** SWE-Flow**, a novel data synthesis framework grounded in Test-\nDriven Development (TDD). Unlike existing software engineering data that rely on \nhuman-submitted issues,** SWE-Flow** automatically infers incremental\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DP9DQ2IExgS&hl=en&sa=X&d=8547569170249215358&ei=pwRgaNLeJqKr6rQPxKWDUA&scisig=AAZF9b8gNj1zFs_dhY5DtQxXJmJ1&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=4&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Generating and Understanding Tests via Path-Aware Symbolic Execution with LLMs", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "Y Wu, X Zhou, A Humayun, MA Gulzar, M Kim\\xc2\\xa0- arXiv preprint arXiv:2506.19287, 2025\nSymbolic execution is a widely used technique for test generation, offering \nsystematic exploration of program paths through constraint solving. However, it is \nfundamentally constrained by the capability to model the target code including library \nfunctions in terms of symbolic constraint and the capability of underlying constraint \nsolvers. As a result, many paths involving complex features remain unanalyzed or \ninsufficiently modeled. Recent advances in large language models (LLMs) have\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge Language Model assisted Hybrid Fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.19287&hl=en&sa=X&d=18293512278044322670&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b-FcozMyrW_hmX3U3LlKbbz&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs", "first_label": ["LLM"], "second_label": [], "data": "L Zeng, Y Li, Y Xiao, C Li, CY Liu, R Yan, T Wei, J He\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware engineering (SWE) has recently emerged as a crucial testbed for next-\ngeneration LLM agents, demanding inherent capabilities in two critical dimensions: \nsustained iterative problem-solving (eg,> 50 interaction rounds) and long-context \ndependency resolution (eg,> 32k tokens). However, the data curation process in \nSWE remains notoriously time-consuming, as it heavily relies on manual annotation \nfor code file filtering and the setup of dedicated runtime environments to execute and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutoCodeRover: Autonomous program improvement\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.19290&hl=en&sa=X&d=1346166662242430586&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b8w6YpKd7fGtz_WRHLWgg6M&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "LLMs Meet Library Evolution: Evaluating Deprecated API Usage in LLM-based Code Completion", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "C Wang, K Huang, J Zhang, Y Feng, L Zhang, Y Liu\\xe2\\x80\\xa6\\xc2\\xa0- 2025 IEEE/ACM 47th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs), pre-trained or fine-tuned on large code corpora, \nhave shown effectiveness in generating code completions. However, in LLM-based \ncode completion, LLMs may struggle to use correct and up-to-date Application \nProgramming Interfaces (APIs) due to the rapid and continuous evolution of libraries. \nWhile existing studies have highlighted issues with predicting incorrect APIs, the \nspecific problem of deprecated API usage in LLM-based code completion has not\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaAutomated Repair of Programs from Large Language Models\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a781/251mHK5tjdC&hl=en&sa=X&d=4291983748355056793&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b86kWv8AjbHvLT9O9jQohIT&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "REDII: Test Infrastructure to Enable Deterministic Reproduction of Failures for Distributed Systems", "first_label": ["Software Testing"], "second_label": [], "data": "Y Feng, Z Lin, D Zhao, M Zhou, J Liu, JA Jones\\xc2\\xa0- 2025 IEEE/ACM 47th International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDespite the fact that distributed systems have become a crucial aspect of modern \ntechnology and support many of the software systems that enable modern life, \ndevelopers experience challenges in performing regression testing of these systems. \nExisting solutions for testing distributed systems are often either:(1) specialized \ntesting environments that are created specifically for each system by its development \nteam, which requires substantial effort for each team, with little-to-no sharing of this\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaGreybox fuzzing of distributed systems\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a780/251mHJqjtmg&hl=en&sa=X&d=3889911031160098752&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b-46KDEXfW7r2y28S4kqKTt&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Protocol Fuzzing-A Comparison between LLM-Assisted and Mutation-Based Fuzzers", "first_label": ["LLM", "Fuzzing"], "second_label": [], "data": "M Eberhardt, L Karlsson - 2025\nAs the demand for secure software and hardware solutions increase in our modern \ndigitalized society, the importance of reliable and cost-effective product testing is \napparent. One such testing technique is fuzzing, which involves generating large \namounts of malformed and randomized data to stress test system interfaces. This \nstudy aimed to compare traditional fuzzing methods to modern approaches assisted \nwith Large Language Models (LLMs) for the data generation, focusing on efficiency\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLarge language model guided protocol fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://lup.lub.lu.se/student-papers/search/publication/9202449&hl=en&sa=X&d=15120985327681873593&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b95ayzzg3DEpNCXHJ-1SN63&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "IsaBIL: A Framework for Verifying (In) correctness of Binaries in Isabelle/HOL", "first_label": [], "second_label": [], "data": "M Griffin, B Dongol, A Raad\\xc2\\xa0- 39th European Conference on Object-Oriented\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThis paper presents IsaBIL, a binary analysis framework in Isabelle/HOL that is \nbased on the widely used Binary Analysis Platform (BAP). Specifically, in IsaBIL, we \nformalise BAP's intermediate language, called BIL and integrate it with Hoare logic \n(to enable proofs of correctness) as well as incorrectness logic (to enable proofs of \nincorrectness). IsaBIL inherits the full flexibility of BAP, allowing us to verify binaries \nfor a wide range of languages (C, C++, Rust), toolchains (LLVM, Ghidra) and target\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaoo7: Low-overhead defense against spectre attacks via program\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://drops.dagstuhl.de/storage/00lipics/lipics-vol333-ecoop2025/LIPIcs.ECOOP.2025.14/LIPIcs.ECOOP.2025.14.pdf&hl=en&sa=X&d=16887165659886729219&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b-p5YqV3pRu7W1gfTqORCY4&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Differential Testing Framework to Identify Critical AV Failures Leveraging Arbitrary Inputs", "first_label": ["Software Testing"], "second_label": [], "data": "T Woodlief, C Hildebrandt, S Elbaum\\xc2\\xa0- 2025 IEEE/ACM 47th International Conference\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe proliferation of autonomous vehicles (AVs) has made their failures increasingly \nevident. Testing efforts aimed at identifying the inputs leading to those failures are \nchallenged by the input's long-tail distribution, whose area under the curve is \ndominated by rare scenarios. We hypothesize that leveraging emerging open-access \ndatasets can accelerate the exploration of long-tail inputs. Having access to diverse \ninputs, however, is not sufficient to expose failures; an effective test also requires an\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFuzz Testing based Data Augmentation to Improve Robustness of\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a700/251mGSQPCJq&hl=en&sa=X&d=5529931052041046025&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b_nQnntE-4q1idXL4yr0hma&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Critical Variable State-Aware Directed Greybox Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "X Chen, N Cui, Z Pan, L Chen, G Shi, D Meng\\xc2\\xa0- 2025 IEEE/ACM 47th International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDirected fuzzing is an effective software testing method that guides the fuzzing \ncampaign towards user-defined target sites of interest, enabling the discovery of \nvulnerabilities relevant to those sites. However, even though the generated test \ncases cover the code near the target sites, complex vulnerabilities remain \nuntriggered. By focusing only on test cases that cover new edges, the program states \nrelated to the targets are overlooked, resulting in insufficient testing of the targets and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDirected greybox fuzzing\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a755/251mHtx3MSk&hl=en&sa=X&d=8776928002534468621&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b-aKwp3S87nO5x62I8l5MRB&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=7&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Reinforcement Learning for Programming Feedback: Aligning Small Language Models Without Human Preferences", "first_label": ["LLM"], "second_label": [], "data": "C Koutcheme, N Dainese, A Hellas - 2025\nProviding students with timely and effective feedback remains a critical challenge in \nprogramming education. Locally deployed Small Language Models (SLMs) offer a \ncost-effective solution that enables educators to generate feedback while avoiding \nthird-party reliance and privacy concerns associated with Large Language Models \n(LLMs). However, SLMs often produce misleading or inaccurate feedback, limiting \ntheir practical use. This paper presents a fully automated reinforcement learning\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaRe-factoring based Program Repair applied to Programming\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://koutche.me/files/csedm25_camera_ready.pdf&hl=en&sa=X&d=11009768349760801091&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b8tg0BTboVFoZTl8wDU59dF&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Efficient Fault Injection for Exposing and Reproducing Failures in Cloud Systems", "first_label": [], "second_label": [], "data": "H Wu - 2025\nIn today's digital era, the reliability of cloud systems is paramount as the world \nincreasingly depends on them for services. However, the complexity of modern cloud \ninfrastructures, designed for high availability, fault tolerance, and scalability, makes \nthe reliability of distributed systems a formidable challenge. Failures in these systems \ncan lead to significant financial losses and other consequences, yet they remain \ndifficult to detect, monitor, reproduce, diagnose, and recover from.\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaCoverage-based greybox fuzzing as markov chain\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://jscholarship.library.jhu.edu/server/api/core/bitstreams/7a776d34-3709-4c91-b9e9-6b2213958206/content&hl=en&sa=X&d=3925328904427580497&ei=pwRgaID5L8zM6rQPhtenwAU&scisig=AAZF9b_1EK08O1Q6Ugiv__PZGfnC&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=9&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Code Cloning in Solidity Smart Contracts: Prevalence, Evolution, and Impact on Development", "first_label": ["Smart Contracts", "Code"], "second_label": [], "data": "R Mo, H Song, W Ding, C Wu\\xc2\\xa0- 2025 IEEE/ACM 47th International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, the development of Solidity smart contracts has been increasing \nrapidly in popularity. Code cloning is a common coding practice, and many prior \nstudies have revealed that code clones could negatively impact software \nmaintenance and quality. However, there is little work systematically analyzing the \nnature and impacts of code clones in solidity smart contracts. To bridge this gap, we \ninvestigate the prevalence, evolution, and bug-proneness of code clones in solidity\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a660/251mGs7pOeI&hl=en&sa=X&d=10112437422740923033&ei=pwRgaMC5K8mQ6rQPpLDpqQo&scisig=AAZF9b8OCLm3NFuzScMKQAxM0x0d&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["4 new citations to articles by Bach Le"]}
{"title": "Identifying and Ranking Risks in Blockchain-Based Applications: A Systematic and Stakeholder-Informed Approach", "first_label": ["Blockchain"], "second_label": ["Detection"], "data": "R Amadi, ASM Kayes, E Pardede, J Chowdhury\\xe2\\x80\\xa6 - 2025\nAs blockchain-based applications gain widespread adoption, they are increasingly \nsusceptible to a diverse range of risks arising from their technical intricacies and \nrapidly evolving operational contexts. These risks pose significant challenges to user \ntrust and the long-term viability of blockchain solutions. This study aims to \nsystematically identify, categorize, and prioritize the key risks associated with \nblockchain-based applications. To establish a foundational understanding, we first\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart contract development: Challenges and opportunities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.techrxiv.org/doi/pdf/10.36227/techrxiv.175036738.89696526&hl=en&sa=X&d=6544158618557328087&ei=pwRgaMC5K8mQ6rQPpLDpqQo&scisig=AAZF9b_oRk6UpwwSAOgETAmLYKr_&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=3&folt=cit", "author": ["Bach Le"], "ref": ["4 new citations to articles by Bach Le"]}
{"title": "Dockerfile Flakiness: Characterization and Repair", "first_label": [], "second_label": ["Repair"], "data": "T Shabani, N Nashid, P Alian, A Mesbah\\xc2\\xa0- 2025 IEEE/ACM 47th International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nDockerfile flakiness-unpredictable temporal build failures caused by external \ndependencies and evolving environments-undermines deployment reliability and \nincreases debugging overhead. Unlike traditional Dockerfile issues, flakiness occurs \nwithout modifications to the Dockerfile itself, complicating its resolution. In this work, \nwe present the first comprehensive study of Dockerfile flakiness, featuring a nine-\nmonth analysis of 8,132 Dockerized projects, revealing that around 10% exhibit flaky\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaDockercleaner: Automatic repair of security smells in dockerfiles\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a774/251mHFJwMwg&hl=en&sa=X&d=13795988126487162298&ei=pwRgaLj_LKalieoP0qP0qQs&scisig=AAZF9b_nzpBFwqb5CwQQKGMLb42F&oi=scholaralrt&hist=ylyK0_8AAAAJ:5615766320347152220:AAZF9b9Qy0LEut_atU8F20t2CTM_&html=&pos=0&folt=cit", "author": ["Quang-Cuong Bui"], "ref": ["1 new citation to articles by Quang-Cuong Bui"]}
{"title": "GVI: Guided Vulnerability Imagination for Boosting Deep Vulnerability Detectors", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "H Yong, Z Li, M Pan, T Zhang, J Zhao, X Li\\xc2\\xa0- 2025 IEEE/ACM 47th International\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe use of deep learning to achieve automated software vulnerability detection has \nbeen a longstanding interest within the software security community. These deep \nvulnerability detectors are mostly trained in a supervised manner, which heavily \nrelies on large-scale, high-quality vulnerability datasets. However, the vulnerability \ndatasets used to train deep vulnerability detectors frequently exhibit class imbalance \ndue to the inherent nature of vulnerability data, where vulnerable cases are\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaVgx: Large-scale sample generation for boosting learning-based\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.computer.org/csdl/proceedings-article/icse/2025/056900a750/251mHqiWAaQ&hl=en&sa=X&d=8914353394877604534&ei=pwRgaPaSKMy8ieoPz8ikiQM&scisig=AAZF9b9M64JhZppOEngQv1XsGMXg&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Machine Learning in Security Vulnerability Research [v\\xc3\\xa9d\\xc3\\xa9s el\\xc5\\x91tt]", "first_label": ["Vulnerabilities"], "second_label": ["Search"], "data": "G Selj\\xc3\\xa1n - 2025\nThis dissertation explores the application of ML in cybersecurity, with a specific focus \non offensive security. To examine existing work on the roles of AI and ML in \nvulnerability discovery, I conducted a targeted review of the literature, which \nindicated that fuzz testing, a method in which an automated tool evaluates software \nfor security flaws using random input data, is a promising area for further exploration. \nTo improve the effectiveness of fuzzers, I propose an ML-based seed selection\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaLlm agents can autonomously exploit one-day vulnerabilities\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://phd.lib.uni-corvinus.hu/1441/1/Seljan_Gabor_den.pdf&hl=en&sa=X&d=4876622339095215119&ei=pwRgaPaSKMy8ieoPz8ikiQM&scisig=AAZF9b-HCD-QYv9CEQE2ae--ELnx&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Learning the fine-grained code representation for log-level prediction", "first_label": ["Code"], "second_label": [], "data": "Z Zhao, G Fan, J Li, M Zhu, H Zhang, H Su\\xc2\\xa0- \\xe2\\x80\\xa6\\xc2\\xa0of King Saud University Computer and\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLog levels are crucial to distinguish the severity of logs and directly reflecting the \nurgency of transactions in software systems. Automatically and efficiently determining \nlog levels is a crucial and challenging task in log management. Current log-level\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s44443-025-00064-9&hl=en&sa=X&d=2987968475870767202&ei=pwRgaLWtOa6l6rQPgvqD4Ao&scisig=AAZF9b-oMqC_G5jyOLyAbJstOPno&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "FuseApplyBench: Multilingual Benchmark for Trustworthy Code Edit Applying Task", "first_label": ["Code"], "second_label": [], "data": "M Liang, Q Zhang, Z Zuo, S Zheng, D Chen, W Jiang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 34th\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nWith the rise of Language Models (LMs) and Large Language Models (LLMs), their \npotential for code editing (CE) has gained attention. An approach is to have LLMs \ngenerate draft code modifications, which are then refined by smaller LMs in further\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3713081.3732929&hl=en&sa=X&d=7791836070318800823&ei=pwRgaLWtOa6l6rQPgvqD4Ao&scisig=AAZF9b_-xxPAC4O-ILuaMHDNHkH0&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Rethinking the effects of data contamination in Code Intelligence", "first_label": ["Code"], "second_label": [], "data": "Z Yang, H Lin, Y He, J Xu, Z Sun, S Liu, P Wang, Z Yu\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn recent years, code intelligence has gained increasing importance in the field of \nautomated software engineering. Meanwhile, the widespread adoption of Pretrained \nLanguage Models (PLMs) and Large Language Models (LLMs) has raised concerns\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.02791&hl=en&sa=X&d=13914802631128746138&ei=pwRgaLWtOa6l6rQPgvqD4Ao&scisig=AAZF9b9FbJDsSBQv15gRiA2JZNoe&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Mono: Is Your\" Clean\" Vulnerability Dataset Really Solvable? Exposing and Trapping Undecidable Patches and Beyond", "first_label": ["Vulnerabilities"], "second_label": [], "data": "Z Gao, J Zhou, B Zhang, Y He, C Zhang, Y Cui, H Wang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe quantity and quality of vulnerability datasets are essential for developing deep \nlearning solutions to vulnerability-related tasks. Due to the limited availability of \nvulnerabilities, a common approach to building such datasets is analyzing security\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.03651&hl=en&sa=X&d=5611261347115113824&ei=pwRgaLWtOa6l6rQPgvqD4Ao&scisig=AAZF9b8ZqDz-8m4J-1VYjUzHamnv&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Which Factors Make Code LLMs More Vulnerable to Backdoor Attacks? A Systematic Study", "first_label": ["LLM", "Code"], "second_label": [], "data": "C Wang, Z Yang, Y Harel, D Lo\\xc2\\xa0- arXiv preprint arXiv:2506.01825, 2025\nCode LLMs are increasingly employed in software development. However, studies \nhave shown that they are vulnerable to backdoor attacks: when a trigger (a specific \ninput pattern) appears in the input, the backdoor will be activated and cause the\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.01825&hl=en&sa=X&d=16166340572421918430&ei=pwRgaLWtOa6l6rQPgvqD4Ao&scisig=AAZF9b-phsc8qq-f3lOMccCIs3x-&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Multi-Dataset Evaluation of Models for Automated Vulnerability Repair", "first_label": ["Vulnerabilities"], "second_label": ["Repair"], "data": "ZA Khan, A Garg, Q Tang\\xc2\\xa0- arXiv preprint arXiv:2506.04987, 2025\nSoftware vulnerabilities pose significant security threats, requiring effective \nmitigation. While Automated Program Repair (APR) has advanced in fixing general \nbugs, vulnerability patching, a security-critical aspect of APR remains underexplored\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04987&hl=en&sa=X&d=8355847986163965479&ei=pwRgaLWtOa6l6rQPgvqD4Ao&scisig=AAZF9b9iPSTGWnyCaOCv5RKilXRE&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=9&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
