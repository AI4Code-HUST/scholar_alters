{"title": "Generating High-Quality Datasets for Code Editing via Open-Source Language Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "Z Zhang, M Liu, Z Chen, L Liang, Y Chen, G Ou- arXiv preprint arXiv, 2025\nCode editing plays a vital role in software engineering, requiring developers to adjust \nexisting code according to natural language instructions while keeping functionality \nintact and avoiding unnecessary modifications. However, commit-based datasets", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25203&hl=en&sa=X&d=16003307718581653243&ei=mtvuaIPPMdeHieoP2sa5uAI&scisig=AAZF9b-WX82g5S_NgG548uiHBBUN&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=0&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "PVDetector: Pretrained Vulnerability Detection on Vulnerability-enriched Code Semantic Graph", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection", "Graph"], "data": "J Li, L Cui, J Zhang, L Li, R Xi, H Zhu- ACM Transactions on Software Engineering, 2025\nAutomated vulnerability detection is a critical issue in software security. The advent of \ndeep learning (DL) has led to numerous studies employing DL to detect \nvulnerabilities in software source code. However, existing approaches still perform", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3768582&hl=en&sa=X&d=8582469852291084545&ei=mtvuaIPPMdeHieoP2sa5uAI&scisig=AAZF9b-KDpNTmZzjJ738P4MlJP3u&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research"]}
{"title": "VulAgent: Hypothesis-Validation based Multi-Agent Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Agent"], "data": "Z Wang, G Li, J Li, H Zhu, Z Jin- arXiv preprint arXiv:2509.11523, 2025\nThe application of language models to project-level vulnerability detection remains \nchallenging, owing to the dual requirement of accurately localizing security-sensitive \ncode and correctly correlating and reasoning over complex program context. We", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.11523&hl=en&sa=X&d=15896523810638326847&ei=mtvuaIPPMdeHieoP2sa5uAI&scisig=AAZF9b8oEc6vOjmXYpw9QnTPeH90&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "CWM: An Open-Weights LLM for Research on Code Generation with World Models", "first_label": ["LLM", "Code"], "second_label": ["Generation", "Search"], "data": "Q Carbonneaux, G Cohen, J Gehring, J Kahn- arXiv preprint arXiv, 2025\nWe release Code World Model (CWM), a 32-billion-parameter open-weights LLM, to \nadvance research on code generation with world models. To improve code \nunderstanding beyond what can be learned from training on static code alone, we", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02387&hl=en&sa=X&d=11106853655839860417&ei=mtvuaIPPMdeHieoP2sa5uAI&scisig=AAZF9b-WuhYXpqDjJ8fNegt1jIv9&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "MC-LRNN: A logic-based neural network for multi-class software vulnerability prediction", "first_label": ["Vulnerabilities"], "second_label": [], "data": "Y Shang, S Liu- Journal of Systems and Software, 2025\nSoftware vulnerabilities are a major threat to information systems. Detecting them \nearly and accurately is critical. Software metrics are commonly used in vulnerability \nprediction, but choosing the most relevant features remains a major challenge. In this", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0164121225002961&hl=en&sa=X&d=8570138772226985730&ei=mtvuaIPPMdeHieoP2sa5uAI&scisig=AAZF9b84q-crm5S0aBJ7OE9mFpMl&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing", "first_label": ["LLM", "Fuzzing", "Bug"], "second_label": [], "data": "S Ou, Y Li, L Yu, C Wei, T Wen, Q Chen, Y Chen- IEEE Transactions on, 2025\nDeep learning (DL) frameworks serve as the backbone for a wide range of artificial \nintelligence applications. However, bugs within DL frameworks can cascade into \ncritical issues in higher-level applications, jeopardizing reliability and security. While", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/32/4359463/11201027.pdf&hl=en&sa=X&d=1422528139240657868&ei=mtvuaIPPMdeHieoP2sa5uAI&scisig=AAZF9b899-spy-aa2AQhyA9vfr3w&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Abhik Roychoudhury - new related research", "Bach Le - new related research", "David Lo - new related research", "Quang-Cuong Bui - new related research", "Hong Jin Kang - new related research"]}
{"title": "On the Resilience of Traditional AI Algorithms Toward Poisoning Attacks for Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "L Gonzlez-Manzano, J Garcia-Alfaro- IET Information Security, 2025\nThe complexity of implementations and the interconnection of assorted systems and \ndevices facilitate the emergence of vulnerabilities. Detection systems are developed \nto fight against this security issue, being the use of artificial intelligence (AI) a", "link": "https://scholar.google.com/scholar_url?url=https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/ise2/9997989&hl=en&sa=X&d=5722794315536622997&ei=mtvuaIPPMdeHieoP2sa5uAI&scisig=AAZF9b-Fhz7NN8TpdH7H5q31-CCb&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=6&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "AI-Augmented Software Architecture: Autonomous Refactoring with Design Pattern Awareness", "first_label": [], "second_label": [], "data": "MSK Konakanchi- International Journal of Emerging Trends in Computer, 2025\nThe maintenance of legacy software systems presents a significant and escalating \nchallenge in software engineering, characterized by high costs, technical debt, and \nresistance to modernization. This paper introduces an innovative AI-augmented", "link": "https://scholar.google.com/scholar_url?url=https://www.ijetcsit.org/index.php/ijetcsit/article/download/379/330&hl=en&sa=X&d=2204072520113560680&ei=mtvuaIPPMdeHieoP2sa5uAI&scisig=AAZF9b891InT6uKNAWougza9M-04&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=7&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "On the Use of Imbalanced Datasets for Learning-Based Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "RZL Foulefack, A Marchetto- IFIP International Conference on Testing Software and, 2025\nStatic code analysis conducted by means of learning-based methods is an essential \npart of Security Testing. Effective learning algorithms are crucial for training reliable \nmodels that can accurately detect weaknesses and vulnerabilities. During models'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-05188-2_20&hl=en&sa=X&d=7711185064955775681&ei=mtvuaIPPMdeHieoP2sa5uAI&scisig=AAZF9b89r6zwK8DmhfjAM2OZUwge&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=8&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "Hong Jin Kang - new related research"]}
{"title": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "X Yin, C Ni, X Li, L Chen, G Ma, X Yang\nRecently, Large Language Models (LLMs) have gained attention for their ability to \nhandle a broad range of tasks, including unit test generation. Despite their success, \nLLMs may exhibit hallucinations when generating unit tests for focal methods or\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://vinci-grape.github.io/papers/Enhancing_LLM_s_Ability_to_Generate_More_Repository_Aware_Unit_Tests_Through_Precise_Context_Injection.pdf&hl=en&sa=X&d=3506872574868649515&ei=mtvuaIPPMdeHieoP2sa5uAI&scisig=AAZF9b8t-WfSL2eZjQ-5h6SvSin3&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=9&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "1 new citation to articles by Hong Jin Kang", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "InsightQL: Advancing Human-Assisted Fuzzing with a Unified Code Database and Parameterized Query Interface", "first_label": ["Fuzzing", "Code"], "second_label": [], "data": "W Gao, R Borovica-Gajic, SK Cha, T Qiu, VT Pham- arXiv preprint arXiv:2510.04835, 2025\nFuzzing is a highly effective automated testing method for uncovering software \nvulnerabilities. Despite advances in fuzzing techniques, such as coverage-guided \ngreybox fuzzing, many fuzzers struggle with coverage plateaus caused by fuzz", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04835&hl=en&sa=X&d=7721758508651636625&ei=nNvuaMCnB9eHieoP2sa5uAI&scisig=AAZF9b9S6TLnsxYfSiDSKvyS6fS2&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Balancing Validity and Vulnerability: Knowledge-Driven Seed Generation via LLMs for Deep Learning Library Fuzzing", "first_label": ["Vulnerabilities", "LLM", "Fuzzing"], "second_label": ["Generation"], "data": "R Liao, X Yan, Z Pang, K Zhu- Applied Sciences, 2025\nFuzzing deep learning (DL) libraries is essential for uncovering security \nvulnerabilities in AI systems. Existing approaches enhance large language models \n(LLMs) with external knowledge such as bug reports to improve the quality of", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2076-3417/15/19/10396&hl=en&sa=X&d=9374413942225787882&ei=nNvuaMCnB9eHieoP2sa5uAI&scisig=AAZF9b_coV2M25K3l6JkCX-ZdrMr&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "DynamiQ: Unlocking the Potential of Dynamic Task Allocation in Parallel Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "W Yan, T Murray, B Rubinstein, VT Pham- arXiv preprint arXiv:2510.04469, 2025\nWe present DynamiQ, a full-fledged and optimized successor to AFLTeam that \nsupports dynamic and adaptive parallel fuzzing. Unlike most existing approaches \nthat treat individual seeds as tasks, DynamiQ leverages structural information from", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04469&hl=en&sa=X&d=10962816615102660239&ei=nNvuaMCnB9eHieoP2sa5uAI&scisig=AAZF9b_5VltWA46OsWSnq5GXtqKm&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "SWE-QA: Can Language Models Answer Repository-level Code Questions?", "first_label": ["LLM", "Code", "Repository-Level"], "second_label": [], "data": "W Peng, Y Shi, Y Wang, X Zhang, B Shen, X Gu- arXiv preprint arXiv:2509.14635, 2025\nUnderstanding and reasoning about entire software repositories is an essential \ncapability for intelligent software engineering tools. While existing benchmarks such \nas CoSQA and CodeQA have advanced the field, they predominantly focus on small", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.14635&hl=en&sa=X&d=15006803551698078506&ei=nNvuaMCnB9eHieoP2sa5uAI&scisig=AAZF9b-gcqnrJWuOC2cDSJR6nYNt&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Bach Le - new related research", "Hong Jin Kang - new related research"]}
{"title": "Function Clustering-Based Fuzzing Termination: Toward Smarter Early Stopping", "first_label": ["Fuzzing"], "second_label": [], "data": "L Ding, W Yang, Y Xue\nFuzzing is a testing technique that generates a large number of inputs to cause \nprogram crashes. As software development accelerates and projects scale, the \ndemand for fuzz testing in software assurance has increased. Performing", "link": "https://scholar.google.com/scholar_url?url=https://wzyang.cn/files/FuzzingTermination.pdf&hl=en&sa=X&d=16741608997780760317&ei=nNvuaMCnB9eHieoP2sa5uAI&scisig=AAZF9b8PamUxP4hadUhNaXUhRS_c&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=5&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Multi Language Models for On-the-Fly Syntax Highlighting", "first_label": ["LLM"], "second_label": [], "data": "ME Palma, P Rani, HC Gall- arXiv preprint arXiv:2510.04166, 2025\nSyntax highlighting is a critical feature in modern software development \nenvironments, enhancing code readability and developer productivity. However, \ndelivering accurate highlighting in real time remains challenging for online and web", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.04166&hl=en&sa=X&d=2254729212502568662&ei=nNvuaMCnB9eHieoP2sa5uAI&scisig=AAZF9b-SZy6QCdbolKYgV0xZsjiV&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=6&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "CG-Bench: Can Language Models Assist Call Graph Construction in the Real World?", "first_label": ["LLM", "Static Analysis"], "second_label": ["Graph"], "data": "T Yuan, W Zhang, D Chen, J Wang- Proceedings of the 1st ACM SIGPLAN, 2025\nLanguage models for coding are shifting their focus from function-level to repository-\nlevel, with complex function invocations. We introduce CG-Bench, the first manually \nconstructed benchmark that measures the ability to understand call graphs for", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3759425.3763379&hl=en&sa=X&d=11570618845570061776&ei=nNvuaMCnB9eHieoP2sa5uAI&scisig=AAZF9b8qflr4UNBQdgiN0mJqf1U8&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=7&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "Bach Le - new related research"]}
{"title": "Postdoc Position Dolev-Yao-Model-Guided Fuzzing of Cryptographic Protocols", "first_label": ["Fuzzing"], "second_label": ["Graph"], "data": "L Hirschi, S Kremer\nTL; DR. We are seeking a post-doctoral researcher to join our puffin [1] team and \nadvance the field of Dolev-Yao model-guided fuzzing of cryptographic protocols (DY \nfuzzing)[2]. This position offers the opportunity to work on research questions that\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://members.loria.fr/LHirschi/pdfs/Postdoc-position_DYfuzzing.pdf&hl=en&sa=X&d=829133187957435831&ei=nNvuaMCnB9eHieoP2sa5uAI&scisig=AAZF9b-3FoOn3Uc26cA5Q8wh58tR&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=8&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Backdoor-Powered Prompt Injection Attacks Nullify Defense Methods", "first_label": [], "second_label": [], "data": "Y Chen, H Li, Y Sui, Y Song, B Hooi- arXiv preprint arXiv:2510.03705, 2025\nWith the development of technology, large language models (LLMs) have dominated \nthe downstream natural language processing (NLP) tasks. However, because of the \nLLMs' instruction-following abilities and inability to distinguish the instructions in the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03705&hl=en&sa=X&d=9793005798347645046&ei=nNvuaO_pJZ2k6rQP0P3a8Ao&scisig=AAZF9b_HnZpDS0idSVQ9IazqK7ZK&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Q Wei, T Yang, Y Wang, X Li, L Li, Z Yin, Y Zhan, T Holz- arXiv preprint arXiv, 2025\nLarge Language Model (LLM) agents use memory to learn from past interactions, \nenabling autonomous planning and decision-making in complex environments. \nHowever, this reliance on memory introduces a critical security risk: an adversary can", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.02373%3F&hl=en&sa=X&d=4598414696562770679&ei=nNvuaO_pJZ2k6rQP0P3a8Ao&scisig=AAZF9b81TzOjaUWLDsP44BPpjuXB&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Dual-Space Smoothness for Robust and Balanced LLM Unlearning", "first_label": ["LLM"], "second_label": [], "data": "H Yan, Z Liu, M Jiang- arXiv preprint arXiv:2509.23362, 2025\nWith the rapid advancement of large language models, Machine Unlearning has \nemerged to address growing concerns around user privacy, copyright infringement, \nand overall safety. Yet state-of-the-art (SOTA) unlearning methods often suffer from", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.23362&hl=en&sa=X&d=1871730686130311929&ei=nNvuaO_pJZ2k6rQP0P3a8Ao&scisig=AAZF9b8As51yVW8jz__d_c1PoJ_F&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Misactivation-Aware Stealthy Backdoor Attacks on Neural Code Understanding Models", "first_label": ["Code"], "second_label": [], "data": "X Sun, Y Xiao, L Bo, W Sun, X Liu, B Li, J Zhang- IEEE Transactions on Software, 2025\nNeural code models (NCMs) play a crucial role in helping developers solve code \nunderstanding tasks. Recent studies have exposed that NCMs are vulnerable to \nseveral security threats, among which backdoor attack is one of the toughest. It is", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11181191/&hl=en&sa=X&d=1845847614155086033&ei=nNvuaO_pJZ2k6rQP0P3a8Ao&scisig=AAZF9b9cJUSS-tJDGaC1EhJgMR6O&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks", "first_label": ["LLM"], "second_label": ["Agent"], "data": "SM Hossain, RK Shayoni, MR Ameen, A Islam- arXiv preprint arXiv, 2025\nPrompt injection attacks represent a major vulnerability in Large Language Model \n(LLM) deployments, where malicious instructions embedded in user inputs can \noverride system prompts and induce unintended behaviors. This paper presents a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.14285&hl=en&sa=X&d=913307193832282926&ei=nNvuaO_pJZ2k6rQP0P3a8Ao&scisig=AAZF9b-cOLAwuLy9zQlk8KZ2kPLK&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "C Ziakas, N Loo, N Jain, A Russo- arXiv preprint arXiv:2510.07239, 2025\nAutomated red-teaming has emerged as a scalable approach for auditing Large \nLanguage Models (LLMs) prior to deployment, yet existing approaches lack \nmechanisms to efficiently adapt to model-specific vulnerabilities at inference. We", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.07239&hl=en&sa=X&d=7730973334197366962&ei=nNvuaO_pJZ2k6rQP0P3a8Ao&scisig=AAZF9b8HKzciIVRpXaBPE8Jnt6FU&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Defense against Backdoor Attacks in Federated Learning with Robust Adaptive Learning Rates", "first_label": [], "second_label": [], "data": "H Li, Y Fang, J Wang, X Li, B Wang- Computer Networks, 2025\nFederated Learning (FL) serves as a privacy-preserving paradigm that not only \nprotects user privacy, but also improves model generalization ability and data \nsecurity. However, by launching a backdoor attack, a vicious client can embed the", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1389128625006863&hl=en&sa=X&d=4008962396919419879&ei=nNvuaO_pJZ2k6rQP0P3a8Ao&scisig=AAZF9b9M20taUV0RToZCCLJwRs7a&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Valid Stopping for LLM Generation via Empirical Dynamic Formal Lift", "first_label": ["LLM"], "second_label": ["Generation"], "data": "S Akter, IF Shihab, A Sharma- arXiv preprint arXiv:2510.06478, 2025\nWe introduce Sequential-EDFL (Empirical Dynamic Formal Lift), applying anytime-\nvalid sequential testing to language model generation stopping. Our approach tracks \ninformation lift--the log-likelihood ratio between full models and deliberately", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.06478&hl=en&sa=X&d=14932518012707883160&ei=nNvuaO_pJZ2k6rQP0P3a8Ao&scisig=AAZF9b9Dby7z2N2n_QBkW3Cth3vw&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?", "first_label": [], "second_label": ["Agent"], "data": "X Deng, J Da, E Pan, YY He, C Ide, K Garg, N Lauffer- arXiv preprint arXiv, 2025\nWe introduce SWE-Bench Pro, a substantially more challenging benchmark that \nbuilds upon the best practices of SWE-BENCH [25], but is explicitly designed to \ncapture realistic, complex, enterprise-level problems beyond the scope of SWE", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.16941&hl=en&sa=X&d=16612405126166951427&ei=nNvuaO_pJZ2k6rQP0P3a8Ao&scisig=AAZF9b_Sny1WEMFE1cCFOEYpk5pL&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Certifiable Safe RLHF: Fixed-Penalty Constraint Optimization for Safer Language Models", "first_label": ["LLM"], "second_label": [], "data": "K Pandit, S Ganguly, A Banerjee, S Angizi, A Ghosh- arXiv preprint arXiv:2510.03520, 2025\nEnsuring safety is a foundational requirement for large language models (LLMs). \nAchieving an appropriate balance between enhancing the utility of model outputs \nand mitigating their potential for harm is a complex and persistent challenge\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2510.03520&hl=en&sa=X&d=4542062984345920079&ei=nNvuaO_pJZ2k6rQP0P3a8Ao&scisig=AAZF9b_omsEoXaAlAeSrRZXeE5Ed&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Do LLMs Generate Useful Test Oracles? An Empirical Study with an Unbiased Dataset", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "D Molinelli, L Di Grazia, A Martin-Lopez, MD Ernst\nGeneration of thorough test oracles is an open problem. Popular test case \ngenerators, like EvoSuite and Randoop, rely on implicit, rule-based, and regression \noracles that miss failures that depend on the semantics of the program under test. \nFormal specifications can yield test oracles but are expensive to create. Large \nLanguage Models (LLMs) have the potential to overcome these limitations. The few \nstudies of using LLMs to generate test oracles use modest-sized public benchmarks\nCites: A 2030 Roadmap for Software Engineering", "link": "https://scholar.google.com/scholar_url?url=https://www.lucadigrazia.com/papers/ase2025.pdf&hl=en&sa=X&d=9661637757589239718&ei=m9vuaICBKJOJ6rQP_NP20QE&scisig=AAZF9b_HFtkeraJdkMeG-gV0bU4t&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Concurrency-Testing Approach for Detecting Isolation Level Bugs in Database Systems", "first_label": ["Bug", "Software Testing"], "second_label": ["Detection"], "data": "A Kamili- Companion Proceedings of the 2025 ACM SIGPLAN, 2025\nEnforcing the correctness of isolation levels in modern database management \nsystems (DBMSs) is essential but notoriously challenging. Although formal \nframeworks like Adya's model capture concurrency anomalies precisely, they are \ndifficult to apply in practice when DBMS internals remain opaque. Conventional \nblack-box verification tools, while accessible, often fail to observe nuanced read/write \ndependencies that underlie subtle isolation violations. In this paper, we introduce\nCites: Greybox fuzzing of distributed systems", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3758316.3763248&hl=en&sa=X&d=15354163846845788741&ei=m9vuaICBKJOJ6rQP_NP20QE&scisig=AAZF9b87Kzaggfwa6dYuSJS57m0e&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Challenging Bug Prediction and Repair Models with Synthetic Bugs", "first_label": ["Bug"], "second_label": ["Repair"], "data": "AR Ibrahimzada, Y Chen, R Rong, R Jabbarvand- 2025 IEEE International, 2025\nBugs are essential in software engineering; many research studies in the past \ndecades have been proposed to detect, localize, and repair bugs in software \nsystems. Effectiveness evaluation of such techniques requires complex bugs, ie, \nthose that are hard to detect through testing and hard to repair through debugging. \nFrom the classic software engineering point of view, a hard-to-repair bug differs from \nthe correct code in multiple locations, making it hard to localize and repair. Hard-to\nCites: Corebench: Studying complexity of regression errors", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11190139/&hl=en&sa=X&d=11287818516444435153&ei=m9vuaICBKJOJ6rQP_NP20QE&scisig=AAZF9b9bHC01IlO6mlGl_BXzbrKm&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Leveraging Structural Stability for Efficient Compute-Memory Tradeoffs in Edge Systems", "first_label": [], "second_label": [], "data": "MS Ramanujam - 2025\nEdge systemssuch as mobile devices, IoT nodes, and embedded sensors\nincreasingly operate in dynamic environments while facing severe resource \nconstraints. Among these, compute is often the primary bottleneck, limited not only by \nhardware capacity but also by thermal and energy constraints inherent to untethered \noperation. A common strategy in systems design is to trade memory for compute, eg, \nvia caching or memoization. But on the edge, memory is also scarce, making\nCites: Concurrency-related flaky test detection in android apps\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/25f1984d9c85cd152f4ec27a499b68a1/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=en&sa=X&d=7328437148348768935&ei=m9vuaICBKJOJ6rQP_NP20QE&scisig=AAZF9b9HnlmPz4pQPHa9Zr7nkog6&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "K Shehada, Y Wu, WD Feng, A Iyer, G Kumfert, Y Ding- NeurIPS 2025 Workshop on\nLarge Language Models (LLMs) have revolutionized automated program repair \n(APR) but current benchmarks like SWE-Bench predominantly focus on userspace \napplications and overlook the complexities of kernel-space debugging and repair", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DNY4wv5C39G&hl=en&sa=X&d=13284020585308537468&ei=mtvuaMSpD52k6rQP0P3a8Ao&scisig=AAZF9b8qiQW2WOt5dhxoK0fl5lFh&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation", "first_label": ["LLM", "Fault Localization"], "second_label": ["Localization"], "data": "F Liu, T Wang, L Zhang, Z Yang, J Jiang, Z Sun- arXiv preprint arXiv:2509.25676, 2025\nProviding timely and personalized guidance for students' programming assignments, \noffers significant practical value for helping students complete assignments and \nenhance their learning. In recent years, various automated Fault Localization (FL)", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.25676&hl=en&sa=X&d=16831300563596066577&ei=mtvuaMSpD52k6rQP0P3a8Ao&scisig=AAZF9b8KiRs4870r1KbKTYTF0UyR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language", "first_label": ["LLM", "Software Testing"], "second_label": ["Agent"], "data": "S Salva, R Taguelmimt- arXiv preprint arXiv:2509.19136, 2025\nThe use of natural language (NL) test cases for validating graphical user interface \n(GUI) applications is emerging as a promising direction to manually written \nexecutable test scripts, which are costly to develop and difficult to maintain. Recent", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.19136&hl=en&sa=X&d=14763218273592887225&ei=mtvuaMSpD52k6rQP0P3a8Ao&scisig=AAZF9b-UHW8cguy7BjMGIC6z7CK9&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=3&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Large Language Models for Code Editing", "first_label": ["LLM", "Code"], "second_label": [], "data": "RJ Mooney, A Shi\nPretrained language models have been shown to be effective in many \nsoftwarerelated generation tasks; however, they are not well-suited for editing tasks \nduring maintaining the software as they are not designed to reason about edits. To", "link": "https://scholar.google.com/scholar_url?url=https://users.ece.utexas.edu/~gligoric/papers/Zhang25PhD.pdf&hl=en&sa=X&d=10229569576199033599&ei=mtvuaMSpD52k6rQP0P3a8Ao&scisig=AAZF9b-AAj-nlZ7037FA7A0uSF2z&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=5&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "Xin ZHOU - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "VulTriNet: A software vulnerability detection method based on tri-channel network", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "Y Yang, Y Yao, X Lv, W Chen- Information and Software Technology, 2025\nContext: Software vulnerabilities represent a critical concern in cybersecurity. As \nvulnerability patterns become increasingly complex, advanced detection methods \nare needed to fully analyze them. Recent studies have treated source codes as text", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950584925002320&hl=en&sa=X&d=6846078968872890597&ei=nNvuaOfBM52k6rQP0P3a8Ao&scisig=AAZF9b9A2WNvXsJ4XtBAnM84SodY&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Systematic Evaluation of Parameter-Efficient Fine-Tuning Methods for the Security of Code LLMs", "first_label": ["LLM", "Code"], "second_label": [], "data": "K Lee, J Kim, D Kim, H Kim- arXiv preprint arXiv:2509.12649, 2025\nCode-generating Large Language Models (LLMs) significantly accelerate software \ndevelopment. However, their frequent generation of insecure code presents serious \nrisks. We present a comprehensive evaluation of seven parameter-efficient fine", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.12649&hl=en&sa=X&d=7696794774262272409&ei=nNvuaOfBM52k6rQP0P3a8Ao&scisig=AAZF9b91MaqL-Oau2ztvPU9w1eiz&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=4&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "for Learning-Based Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "RZL Foulefack, A Marchetto- Testing Software and Systems: 37th IFIP WG 6.1\nStatic code analysis conducted by means of learning-based methods is an essential \npart of Security Testing. Effective learning algo-rithms are crucial for training reliable \nmodels that can accurately detect weaknesses and vulnerabilities. During models'\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DHQuHEQAAQBAJ%26oi%3Dfnd%26pg%3DPA307%26ots%3DdVPsbsPsvn%26sig%3DbEhbSlbs5wYAqxUalKxcucyz_gc&hl=en&sa=X&d=879843498815082224&ei=nNvuaOfBM52k6rQP0P3a8Ao&scisig=AAZF9b-p43IqI9-P_8eI-xypDN5M&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=5&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "A Study on Thinking Patterns of Large Reasoning Models in Code Generation", "first_label": ["Code"], "second_label": ["Generation", "Reasoning"], "data": "K Halim, SG Teo, R Feng, Z Chen, Y Gu, C Wang, Y Liu- arXiv preprint arXiv, 2025\nCurrently, many large language models (LLMs) are utilized for software engineering \ntasks such as code generation. The emergence of more advanced models known as \nlarge reasoning models (LRMs), such as OpenAI's o3, DeepSeek R1, and Qwen3", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.13758&hl=en&sa=X&d=2224436918693180739&ei=m9vuaL2LGJm96rQP7_WWqAs&scisig=AAZF9b8PXkuQShZa8PJmAUV09aCI&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Automating Code Generation for Semiconductor Equipment Control from Developer Utterances with LLMs", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Y Kim, S Park, M Kim, G Yoon, E Lee, SS Woo- arXiv preprint arXiv:2509.13055, 2025\nSemiconductors form the backbone of modern electronics, with their manufacturing \nand testing relying on highly specialized equipment and domain-specific \nprogramming languages. Equipment languages such as the Algorithmic Pattern", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.13055&hl=en&sa=X&d=8083439099579672792&ei=m9vuaL2LGJm96rQP7_WWqAs&scisig=AAZF9b_6B1-ggVyk13BUPke_jxTs&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Large Language Models for Online Log Parsing in AIOps", "first_label": ["LLM"], "second_label": [], "data": "S Zhang, D Fan, Y Liu, L He, Z Ding- International Conference on Document Analysis, 2025\nLogs play a crucial role in modern software development by providing essential \nruntime information. Automated log analysis begins with log parsing, which \ntransforms unstructured log data into a structured format. In AIOps (Artificial\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-04624-6_32&hl=en&sa=X&d=6558475950455973420&ei=m9vuaL2LGJm96rQP7_WWqAs&scisig=AAZF9b_-b1415ERTR_L5P2Wg62gt&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Automatisierung offensiver Cybersicherheitsmanahmen: Eine Betrachtung der datenschutzrechtlichen und strafrechtlichen Verantwortung", "first_label": [], "second_label": [], "data": "J Esser, C Pltz- INFORMATIK 2025, 2025\nDie zunehmende Automatisierung und Anonymisierung technischer Systeme stellt \ndas bestehende System der Verantwortungszuschreibung im Datenschutz-und \nStrafrecht vor erhebliche Herausforderungen. Da Maschinen selbst keine \nVerantwortung tragen knnen, bleibt menschliches Handeln und Entscheidenetwa \nvon Anwender: innen und Entwickler: innenfr die Verantwortungszuschreibung \nzentral. Sowohl im Datenschutzrecht als auch im Strafrecht geraten etablierte\nCites: Llm agents can autonomously hack websites\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://dl.gi.de/bitstreams/e9d35c9c-f158-4f28-99df-8d924ff7cca1/download&hl=en&sa=X&d=12023444490227642822&ei=mtvuaPzoIaXB6rQP9f-iwA8&scisig=AAZF9b88sg79J7xRTXIdVwscvhef&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["1 new citation to articles by Richard Fang"]}
{"title": "DeepVulHunter: enhancing the code vulnerability detection capability of LLMs through multi-round analysis", "first_label": ["Vulnerabilities", "LLM", "Code"], "second_label": ["Detection"], "data": "Y Jiao, J Han, C Huang- Journal of Intelligent Information Systems, 2025\nAs the economic losses caused by software vulnerabilities continue to escalate, \nautomated vulnerability detection has emerged as a crucial demand in software \nengineering. While current Large Language Model (LLM)-based approaches", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s10844-025-00982-0&hl=en&sa=X&d=10731011443501691155&ei=m9vuaNiyN52k6rQP0P3a8Ao&scisig=AAZF9b8_D0qJ-czSLs52zGjpgxFk&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "WIP: Tunable Automation in Automated Program Verification", "first_label": ["Verification"], "second_label": [], "data": "A Lattuada\nAutomated verification tools based on SMT solvers have made significant progress in \nverifying complex software systems. However, these tools face a fundamental \ntension between automation and performance when dealing with quantifier", "link": "https://scholar.google.com/scholar_url?url=https://systemf.epfl.ch/etc/vstte2025/preprints/Tunable%2520Automation%2520in%2520Automated%2520Program%2520Verification.pdf&hl=en&sa=X&d=17965129023412328217&ei=m9vuaNiyN52k6rQP0P3a8Ao&scisig=AAZF9b_e-SoQG66vroZ02uumCCSH&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Integrating Large Language Models in Automated Program Verification", "first_label": ["Verification", "LLM"], "second_label": [], "data": "N Narodytska- # PLACEHOLDER_PARENT_METADATA_VALUE#, 2025\nThe demonstrated code-understanding capabilities of large language models (LLMs) \nraise the question of whether they can be used for automated program verification\na task that typically demands high-level, abstract reasoning about program\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://repositum.tuwien.at/bitstream/20.500.12708/219532/1/Narodytska-2025-Integrating%2520Large%2520Language%2520Models%2520in%2520Automated%2520Program%2520Ve...-vor.pdf&hl=en&sa=X&d=7972569135923682675&ei=m9vuaNiyN52k6rQP0P3a8Ao&scisig=AAZF9b-NppojD7cBzbVaV891ND28&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=3&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "R1-Fuzz: Specializing Language Models for Textual Fuzzing via Reinforcement Learning", "first_label": ["LLM", "Fuzzing"], "second_label": [], "data": "J Lin, L Su, J Li, C Qian- arXiv preprint arXiv:2509.20384, 2025\nFuzzing is effective for vulnerability discovery but struggles with complex targets such \nas compilers, interpreters, and database engines, which accept textual input that \nmust satisfy intricate syntactic and semantic constraints. Although language models", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.20384&hl=en&sa=X&d=1649136629077213896&ei=ndvuaKP4Ad_N6rQPhvXciAU&scisig=AAZF9b9A_fC3MFUyhQ5sK9VXroDy&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Fuzzing JavaScript JIT compilers with a high-quality differential test oracle", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "J Li, H Xu, Y Wang, Z Jiang, H Chun, P Xie, Y Chen- Computers & Security, 2025\nAbstract Modern JavaScript engines use Just-In-Time (JIT) compilers to convert \nfrequently executed code into machine instructions, boosting performance for web \napplications and cross-platform systems. However, the optimizations in JIT compilers", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825003499&hl=en&sa=X&d=7438620869129233397&ei=ndvuaKP4Ad_N6rQPhvXciAU&scisig=AAZF9b8tN2mMloCI7htWicorKtpq&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Evaluating Large Language Models for Functional and Maintainable Code in Industrial Settings: A Case Study at ASML", "first_label": ["LLM", "Code"], "second_label": [], "data": "Y Mundhra, M Valk, M Izadi- arXiv preprint arXiv:2509.12395, 2025\nLarge language models have shown impressive performance in various domains, \nincluding code generation across diverse open-source domains. However, their \napplicability in proprietary industrial settings, where domain-specific constraints and", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.12395%3F&hl=en&sa=X&d=13033881335704468477&ei=ndvuaKP4Ad_N6rQPhvXciAU&scisig=AAZF9b-JuDWgVwSA_z97rNvMJxOT&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
