{"title": "Gradient Surgery for Safe LLM Fine-Tuning", "first_label": ["LLM"], "second_label": [], "data": "B Yi, J Li, B Zhang, L Nie, T Li, T Huang, Z Liu- arXiv preprint arXiv:2508.07172, 2025\nFine-tuning-as-a-Service introduces a critical vulnerability where a few malicious \nexamples mixed into the user's fine-tuning dataset can compromise the safety \nalignment of Large Language Models (LLMs). While a recognized paradigm frames", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.07172&hl=en&sa=X&d=10352052812613128560&ei=y226aNvDIZTTieoP39ngwAI&scisig=AAZF9b_-UmhxxnT9CjoTuoEHfdfM&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Rethinking Safety in LLM Fine-tuning: An Optimization Perspective", "first_label": ["LLM"], "second_label": [], "data": "M Kim, JM Kwak, L Alssum, B Ghanem, P Torr- arXiv preprint arXiv, 2025\nFine-tuning language models is commonly believed to inevitably harm their safety, \nie, refusing to respond to harmful user requests, even when using harmless datasets, \nthus requiring additional safety measures. We challenge this belief through", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.12531&hl=en&sa=X&d=5765344796588629336&ei=y226aNvDIZTTieoP39ngwAI&scisig=AAZF9b824RRmgPcbwax6O3_MzYe2&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SafeConstellations: Steering LLM Safety to Reduce Over-Refusals Through Task-Specific Trajectory", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, S Yadav, M Dras, U Naseem- arXiv preprint arXiv:2508.11290, 2025\nLLMs increasingly exhibit over-refusal behavior, where safety mechanisms cause \nmodels to reject benign instructions that superficially resemble harmful content. This \nphenomena diminishes utility in production applications that repeatedly rely on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.11290&hl=en&sa=X&d=4418065858919549735&ei=y226aNvDIZTTieoP39ngwAI&scisig=AAZF9b_590TBu9nutdVdOeEXPNS5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "M Phute, R Balakrishnan- arXiv preprint arXiv:2508.08521, 2025\nVision Language Models (VLMs) are increasingly being used in a broad range of \napplications, bringing their security and behavioral control to the forefront. While \nexisting approaches for behavioral control or output redirection, like system", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.08521%3F&hl=en&sa=X&d=3389705349380814363&ei=y226aNvDIZTTieoP39ngwAI&scisig=AAZF9b_q3Y2_Sm63cdpM1VXa1B78&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A Survey on the Feedback Mechanism of LLM-based AI Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Z Liu, X Bai, K Chen, X Chen, X Li, Y Xiang, J Liu\nLarge language models (LLMs) are increasingly being adopted to develop general-\npurpose AI agents. However, it remains challenging for these LLM-based AI agents \nto efficiently learn from feedback and iteratively optimize their strategies. To address", "link": "https://scholar.google.com/scholar_url?url=https://ijcai-preprints.s3.us-west-1.amazonaws.com/2025/8835.pdf&hl=en&sa=X&d=14511738061688557547&ei=y226aNvDIZTTieoP39ngwAI&scisig=AAZF9b-4ZyHqXzP38qhsex58ULA6&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "GeoShield: Safeguarding Geolocation Privacy from Vision-Language Models via Adversarial Perturbations", "first_label": ["LLM"], "second_label": [], "data": "X Liu, X Jia, Y Xun, S Qin, X Cao- arXiv preprint arXiv:2508.03209, 2025\nVision-Language Models (VLMs) such as GPT-4o now demonstrate a remarkable \nability to infer users' locations from public shared images, posing a substantial risk to \ngeoprivacy. Although adversarial perturbations offer a potential defense, current", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.03209%3F&hl=en&sa=X&d=13915240034089835371&ei=y226aNvDIZTTieoP39ngwAI&scisig=AAZF9b-R0Q7j1ojvvDmMFEqYjWc6&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Smart Contract Vulnerability Detection using Prompt Engineering with Reasoning Models", "first_label": ["Vulnerabilities", "Smart Contracts"], "second_label": ["Detection", "Reasoning"], "data": "HG Le, HP Chu-Nguyen, VH Pham, PT Duy- 2025 International Conference on, 2025\nThe increasing deployment of smart contracts has drawn significant attention to the \nurgent need for robust and scalable vulnerability detection techniques to mitigate \nsubstantial financial risks associated with their immutable nature on blockchain", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11133797/&hl=en&sa=X&d=6034816921677024870&ei=y226aNvDIZTTieoP39ngwAI&scisig=AAZF9b8xnNfhA4cg4BKae47PHz-d&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research", "1 new citation to articles by Xin ZHOU"]}
{"title": "Membership and Memorization in LLM Knowledge Distillation", "first_label": ["LLM"], "second_label": [], "data": "Z Zhang, AS Shamsabadi, H Lu, Y Cai, H Haddadi- arXiv preprint arXiv:2508.07054, 2025\nRecent advances in Knowledge Distillation (KD) aim to mitigate the high \ncomputational demands of Large Language Models (LLMs) by transferring \nknowledge from a large''teacher''to a smaller''student''model. However, students may", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.07054%3F&hl=en&sa=X&d=15568245874926800615&ei=y226aNvDIZTTieoP39ngwAI&scisig=AAZF9b9B1fRaZ0fcyasatykoQEOB&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A Real-Time, Self-Tuning Moderator Framework for Adversarial Prompt Detection", "first_label": [], "second_label": ["Detection"], "data": "I Zhang- arXiv preprint arXiv:2508.07139, 2025\nEnsuring LLM alignment is critical to information security as AI models become \nincreasingly widespread and integrated in society. Unfortunately, many defenses \nagainst adversarial attacks and jailbreaking on LLMs cannot adapt quickly to new", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.07139%3F&hl=en&sa=X&d=16044253908885372456&ei=y226aNvDIZTTieoP39ngwAI&scisig=AAZF9b93YxGfEQp3lERsZvriTNh4&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Test-Time Prompt Tuning for Vision-Language Models", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "M Shu, W Nie, DA Huang, Z Yu, T Goldstein- Large Vision-Language, 2025\nPretrained contrastive vision-language models (VLMs)(eg, CLIP) have shown \npromising zero-shot generalization in many downstream tasks (eg, image \nclassification) with properly designed text prompts. Instead of relying on\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DEnqCEQAAQBAJ%26oi%3Dfnd%26pg%3DPA134%26ots%3Dgd6NsLnunh%26sig%3DrCyA8ik_28ZVSp0ee86L9GwjSaU&hl=en&sa=X&d=11380046470632555453&ei=y226aNvDIZTTieoP39ngwAI&scisig=AAZF9b-mhMkoGrWSLinQXP61bwNV&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Complementing Confidential Computing Environment for Applications on Arm CCA", "first_label": [], "second_label": [], "data": "Y Zhang, Y Hu, Z Ning, F Zhang, X Luo, H Huang- IEEE Transactions on, 2025\nTrustZone is a promising security technology for the use of partitioning sensitive data \ninto a trusted execution environment (TEE). Unfortunately, third-party developers \nhave limited access to TrustZone. Advanced virtualization-based TEE introduced in \nthe recent Arm Confidential Compute Architecture (CCA) creates a new physical \naddress space called Realm world for confidential computing to protect data \nconfidentiality and integrity of third-party. However, the current CCA primarily targets\nCites: BesFS: A POSIX Filesystem for Enclaves with a Mechanized Safety", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11143955/&hl=en&sa=X&d=4665874492156902712&ei=ym26aOLRDOKIieoP0JiMmQc&scisig=AAZF9b9s9wMMJHAwFGQYk05J36Gs&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": ".", "first_label": [], "second_label": [], "data": "- Journal Of Sichuan University (Natural, 2025\n, PoC , , \n. , . \n, .(1) \n, .(2) \n, \n. , \nCites: Directed greybox fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://search.ebscohost.com/login.aspx%3Fdirect%3Dtrue%26profile%3Dehost%26scope%3Dsite%26authtype%3Dcrawler%26jrnl%3D04906756%26AN%3D187494649%26h%3DROYPT9ZB8BJE6AnIS0nfBiD5TEh8%252BUwPVT6%252BNsjKRSk0Zze0Ue%252BiPXXJx3RiUL8g9T1LDZf2U6Bu3c8hURo%252BxQ%253D%253D%26crl%3Dc&hl=en&sa=X&d=15020256556068788576&ei=ym26aOLRDOKIieoP0JiMmQc&scisig=AAZF9b95_41WQNbhc_XkgNbDpCSC&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": "LCFuzzer:  .", "first_label": ["Fuzzing"], "second_label": [], "data": "- Journal Of Sichuan University (Natural Sciences, 2025\n, , \n. , , \n. , \nLCFuzzer , (LLM) \n, , 3 . \n, , . \nCites: Coverage-based greybox fuzzing as markov chain\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://search.ebscohost.com/login.aspx%3Fdirect%3Dtrue%26profile%3Dehost%26scope%3Dsite%26authtype%3Dcrawler%26jrnl%3D04906756%26AN%3D187494650%26h%3DO7mX6eNsS%252BT9dkE0nFFNP84%252FdHCFH53obkBJdcci9JlsipDZXsNlggYn1JohPmpIcO1nKffyRsISmED2h%252FO8Wg%253D%253D%26crl%3Dc&hl=en&sa=X&d=5669176434572964932&ei=ym26aOLRDOKIieoP0JiMmQc&scisig=AAZF9b-GAFy2uSRwwRYlOmkQyuvV&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["3 new citations to articles by Abhik Roychoudhury"]}
{"title": "A Cascaded Pipeline for Self-Directed, Model-Agnostic Unit Test Generation via LLMs", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "C Ni, X Wang, X Yin, L Chen, G Ma\nWhile existing ML-based unit test generation methods show promising results, they \nface three key limitations:(1) incomplete test case generation with excessive focus on \ntest oracles,(2) semantic inconsistencies between test components, and (3)\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://vinci-grape.github.io/papers/A_Cascaded_Pipeline_for_Self_Directed__Model_Agnostic_Unit_Test_Generation_via_LLMs.pdf&hl=en&sa=X&d=4873176567549061654&ei=y226aICvOZ6s6rQPxqLhuQI&scisig=AAZF9b_azI7z_JaYBXmFn6485aAs&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "SNFM: Scalable Node Feature Modeling in Smart Contracts for Vulnerability Detection through Graph-based Approaches", "first_label": ["Vulnerabilities", "Smart Contracts"], "second_label": ["Detection", "Graph"], "data": "Y Hong, X Liu, J Huang, T Chen, T Huang, Y Pang- 2025 IEEE Global Blockchain, 2025\nThe burgeoning security concerns of smart contracts, propelled by the significant \nassets they govern and the immutable nature of blockchain technology, have \ncatalyzed the need for robust vulnerability detection methods. Traditional \napproaches, predominantly rule-based, are beleaguered by high false-positive rates \nand protracted detection times. Contemporary scholarship has ventured into deep \nlearning techniques, yet these often neglect the nuanced semantic information\nCites: Smart contract development: Challenges and opportunities", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11134470/&hl=en&sa=X&d=6104574986728069554&ei=yW26aJf5BaPWieoPhpqLqAo&scisig=AAZF9b_pai6F4CXW80pqtj-hzI2J&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le"]}
{"title": "on Blockchain with Identity Retention", "first_label": ["Blockchain"], "second_label": [], "data": "HN Dinh, BL Do- Innovations in Knowledge Mining: Sustainability for, 2025\nAbstract Public Key Infrastructure (PKI) plays an essential role in securing \ncommunication and data exchange over the Internet. PKIs typically utilize two trust \nmodels: the CA-based model, which relies on a central authority for certificate \nissuance but creates a single point of failure, and the Web of Trust model, which \ndistributes trust among users but lacks scalability. In this paper, we introduce the \nMulti-CA trust model, which employs signatures from multiple Certificate Authorities\nCites: Smart contract development: Challenges and opportunities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DinqCEQAAQBAJ%26oi%3Dfnd%26pg%3DPA194%26ots%3D5WMkUjEsjB%26sig%3DhN9VfewR08h43ecAAaGJI8iathI&hl=en&sa=X&d=3106780753151245892&ei=yW26aJf5BaPWieoPhpqLqAo&scisig=AAZF9b_YJPe9fuPLpyQOmXfyISOB&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["2 new citations to articles by Bach Le"]}
{"title": "Generative Interfaces for Language Models", "first_label": ["LLM"], "second_label": [], "data": "J Chen, Y Zhang, Y Zhang, Y Shao, D Yang- arXiv preprint arXiv:2508.19227, 2025\nLarge language models (LLMs) are increasingly seen as assistants, copilots, and \nconsultants, capable of supporting a wide range of tasks through natural \nconversation. However, most systems remain constrained by a linear request\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.19227&hl=en&sa=X&d=16741735202537041853&ei=yW26aMqSKfrUieoPmfaJ2Q4&scisig=AAZF9b_WOVSvgnsSNkTkYD0YU0HR&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Bridging Language Models and Symbolic Solvers via the Model Context Protocol", "first_label": ["LLM"], "second_label": [], "data": "S Szeider- 28th International Conference on Theory and, 2025\nThis paper presents the MCP Solver, a system that bridges large language models \nwith symbolic solvers through the Model Context Protocol (MCP). The system \nincludes a server and a client component. The server provides an interface to\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.SAT.2025.30&hl=en&sa=X&d=4324969172721468247&ei=zG26aLHmErWR6rQPnoqX0Ak&scisig=AAZF9b-J0l5_VwCUAZr8vM3h6s5z&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
