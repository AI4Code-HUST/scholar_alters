{"title": "Characterizing Multi-Hunk Patches: Divergence, Proximity, and LLM Repair Challenges", "first_label": ["LLM"], "second_label": ["Repair"], "data": "N Nashid, D Ding, K Gallaba, AE Hassan, A Mesbah\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nMulti-hunk bugs, where fixes span disjoint regions of code, are common in practice, \nyet remain underrepresented in automated repair. Existing techniques and \nbenchmarks pre-dominantly target single-hunk scenarios, overlooking the added\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04418&hl=en&sa=X&d=15657538929124675032&ei=BMpIaOHrH-Ws6rQPpf7X-Aw&scisig=AAZF9b_-gIMENh8EU3j9mHDoC8N1&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=0&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "4 new citations to articles by Abhik Roychoudhury", "3 new citations to articles by Hong Jin Kang", "David Lo - new related research", "Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research", "2 new citations to articles by Xin ZHOU", "Hong Jin Kang - new related research"]}
{"title": "Enhancing Graph Based Models for Automatic Program Repair", "first_label": ["APR"], "second_label": ["Repair", "Graph"], "data": "V Singh, J Srivastava\\xc2\\xa0- International Conference on Soft Computing and its\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSoftware development teams are confronted with substantial problems when it \ncomes to software flaws, which can result in reduced user experience, compromised \nsecurity, and lower reliability. For software systems to be robust and mitigated\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-88039-1_20&hl=en&sa=X&d=4498114304407797139&ei=BMpIaOHrH-Ws6rQPpf7X-Aw&scisig=AAZF9b9LrBdztlF3BnOO33ftE2p4&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "A Multi-Dataset Evaluation of Models for Automated Vulnerability Repair", "first_label": ["Vulnerabilities"], "second_label": ["Repair"], "data": "ZA Khan, A Garg, Q Tang\\xc2\\xa0- arXiv preprint arXiv:2506.04987, 2025\nSoftware vulnerabilities pose significant security threats, requiring effective \nmitigation. While Automated Program Repair (APR) has advanced in fixing general \nbugs, vulnerability patching, a security-critical aspect of APR remains underexplored\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04987&hl=en&sa=X&d=8355847986163965479&ei=BMpIaOHrH-Ws6rQPpf7X-Aw&scisig=AAZF9b9iPSTGWnyCaOCv5RKilXRE&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=2&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research", "4 new citations to articles by Abhik Roychoudhury", "Xin ZHOU - new related research", "David Lo - new related research", "1 new citation to articles by Quang-Cuong Bui", "Thanh Le-Cong - new related research"]}
{"title": "CAPRA: Context-Aware patch risk assessment for detecting immature vulnerability in open-source software", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "B Tang, S Zhang, F Zhu, A Ye\\xc2\\xa0- Computers & Security, 2025\nSoftware development increasingly relies on open-source contributions, yet these \nprojects face significant security challenges. Large collaborative codebases \nfrequently encounter vulnerabilities due to varying developer skill levels and \nreviewers' incomplete understanding of code changes' contextual implications. \nTraditional detection measures typically activate only after code merging, missing \nopportunities for detecting potential risks (eg immature vulnerability). This paper\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaVulCurator: A Vulnerability-Fixing Commit Detector\\xe2\\x80\\xac\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404825002299&hl=en&sa=X&d=2397939480780174997&ei=BMpIaJHHHviJ6rQPkqSymQY&scisig=AAZF9b_Z4ubFE1jy83pk5L9P_Nc4&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=0&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["1 new citation to articles by Thanh Le-Cong", "3 new citations to articles by Hong Jin Kang", "2 new citations to articles by Bach Le"]}
{"title": "PoCGen: Generating Proof-of-Concept Exploits for Vulnerabilities in Npm Packages", "first_label": ["Vulnerabilities"], "second_label": ["Exploit"], "data": "D Simsek, A Eghbali, M Pradel\\xc2\\xa0- arXiv preprint arXiv:2506.04962, 2025\nSecurity vulnerabilities in software packages are a significant concern for developers \nand users alike. Patching these vulnerabilities in a timely manner is crucial to \nrestoring the integrity and security of software systems. However, previous work has \nshown that vulnerability reports often lack proof-of-concept (PoC) exploits, which are \nessential for fixing the vulnerability, testing patches, and avoiding regressions. \nCreating a PoC exploit is challenging because vulnerability reports are informal and\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaFixing Security Vulnerabilities with AI in OSS-Fuzz\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04962&hl=en&sa=X&d=16849568050797702158&ei=BMpIaJKvKKy16rQPz_Hl2Qs&scisig=AAZF9b9dyqmqECmRV8sk3WOgXrPu&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury", "Quang-Cuong Bui - new related research"]}
{"title": "Comprehensive Review of Smart Contract and DeFi Security: Attack, Vulnerability Detection, and Automated Repair", "first_label": ["Vulnerabilities", "Smart Contracts", "APR"], "second_label": ["Detection", "Repair"], "data": "P Qian, R Cao, Z Liu, W Li, M Li, L Zhang, Y Xu, J Chen\\xe2\\x80\\xa6\\xc2\\xa0- Expert Systems with\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAbstract Decentralized Finance (DeFi) is emerging as a peer-to-peer financial \necosystem. Currently, the substantial value locked in DeFi protocols makes them \nattractive targets for malicious attacks, which have resulted in huge losses and pose \na severe threat to the overall security of the DeFi ecosystem. While researchers have \nproposed a variety of strategies to safeguard DeFi and smart contracts, a \ncomprehensive study of these efforts remains elusive, leaving a critical gap in\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaSmart Contract Repair\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0957417425020500&hl=en&sa=X&d=3041825149613066311&ei=BMpIaJKvKKy16rQPz_Hl2Qs&scisig=AAZF9b_mkxrIj-DJUV62I0a6UyFS&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury", "Quang-Cuong Bui - new related research", "2 new citations to articles by Bach Le"]}
{"title": "LLM-Guided Scenario-based GUI Testing", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "S Yu, Y Ling, C Fang, Q Zhou, C Chen, S Zhu, Z Chen\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nThe assurance of mobile app GUI is more and more significant. Automated GUI \ntesting approaches of different strategies have been developed, while there are still \nhuge gaps between the approaches and the app business logic, not taking the\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.05079&hl=en&sa=X&d=10587655884573272012&ei=BMpIaK3_MKKr6rQPlpCs6Q0&scisig=AAZF9b_9oZAteogzTFVCpm4ZVNB0&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "BINGO! Simple Optimizers Win Big if Problems Collapse to a Few Buckets", "first_label": [], "second_label": [], "data": "KK Ganguly, T Menzies\\xc2\\xa0- arXiv preprint arXiv:2506.04509, 2025\nTraditional multi-objective optimization in software engineering (SE) can be slow and \ncomplex. This paper introduces the BINGO effect: a novel phenomenon where SE \ndata surprisingly collapses into a tiny fraction of possible solution\" buckets\"(eg, only \n100 used from 4,096 expected). We show the BINGO effect's prevalence across 39 \noptimization in SE problems. Exploiting this, we optimize 10,000 times faster than \nstate-of-the-art methods, with comparable effectiveness. Our new algorithms (LITE\\xc2\\xa0\\xe2\\x80\\xa6\n\\xe2\\x80\\xa2\nCites: \\xe2\\x80\\xaaHow to find actionable static analysis warnings: A case study with\\xc2\\xa0\\xe2\\x80\\xa6\\xe2\\x80\\xac", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04509&hl=en&sa=X&d=16875079174012414179&ei=BMpIaKXHIoqIieoPrumR8AU&scisig=AAZF9b-zlHmZv1ODu9DFndhj-ZTY&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=1&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang"]}
{"title": "Systematic exploration of fuzzing in IoT: techniques, vulnerabilities, and open challenges", "first_label": ["Vulnerabilities", "Fuzzing"], "second_label": [], "data": "A Touqir, F Iradat, W Iqbal, A Rakib, N Taskin\\xe2\\x80\\xa6\\xc2\\xa0- The Journal of\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nAs our dependence on the internet and digital platforms grows, the risk of cyber \nthreats rises, making it essential to implement effective measures to safeguard \nsensitive information through cybersecurity, ensure system integrity, and prevent\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/article/10.1007/s11227-025-07371-y&hl=en&sa=X&d=6083537071761720509&ei=BMpIaNDGK5LXieoP7MLq8Ak&scisig=AAZF9b9_2tGbhprfWVgY0gWilcYB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "Z Yuan, Y Xu, J Shi, P Zhou, L Sun\\xc2\\xa0- arXiv preprint arXiv:2505.23561, 2025\nModel merging for Large Language Models (LLMs) directly fuses the parameters of \ndifferent models finetuned on various tasks, creating a unified model for multi-domain \ntasks. However, due to potential vulnerabilities in models available on open-source\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.23561&hl=en&sa=X&d=6617189016454156514&ei=BMpIaPu-L86r6rQP3rzY-QM&scisig=AAZF9b-hKaNf3ql6GqPXtJeaxsCC&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "PandaGuard: Systematic Evaluation of LLM Safety in the Era of Jailbreaking Attacks", "first_label": ["LLM"], "second_label": [], "data": "G Shen, D Zhao, L Feng, X He, J Wang, S Shen\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) have achieved remarkable capabilities but remain \nvulnerable to adversarial prompts known as jailbreaks, which can bypass safety \nalignment and elicit harmful outputs. Despite growing efforts in LLM safety research\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.13862&hl=en&sa=X&d=7957433049052051517&ei=BMpIaPu-L86r6rQP3rzY-QM&scisig=AAZF9b8uuohndjng7lcz2CFokw4p&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based Backdoor Attacks for Jailbreaking Large Language Models", "first_label": ["LLM"], "second_label": [], "data": "J Kong, H Fang, X Yang, K Gao, B Chen, ST Xia\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSupervised fine-tuning (SFT) aligns large language models (LLMs) with human \nintent by training them on labeled task-specific data. Recent studies have shown that \nmalicious attackers can inject backdoors into these models by embedding triggers\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.17601%3F&hl=en&sa=X&d=14932585774719166007&ei=BMpIaPu-L86r6rQP3rzY-QM&scisig=AAZF9b-bRcbQ7r2VSTXuEVUTZE69&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Concept-Level Explainability for Auditing & Steering LLM Responses", "first_label": ["LLM"], "second_label": [], "data": "K Amara, R Sevastjanova, M El-Assady\\xc2\\xa0- arXiv preprint arXiv:2505.07610, 2025\nAs large language models (LLMs) become widely deployed, concerns about their \nsafety and alignment grow. An approach to steer LLM behavior, such as mitigating \nbiases or defending against jailbreaks, is to identify which parts of a prompt influence\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.07610&hl=en&sa=X&d=2487114209165587400&ei=BMpIaPu-L86r6rQP3rzY-QM&scisig=AAZF9b_MdyjKZG1aOlo4TZWZliFE&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack", "first_label": ["LLM"], "second_label": [], "data": "S Cappelletti, T Poppi, S Poppi, ZX Yong\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge Language Models (LLMs) are increasingly evaluated on multiple-choice \nquestion answering (MCQA) tasks using* first-token probability*(FTP), which selects \nthe answer option whose initial token has the highest likelihood. While efficient, FTP\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15323%3F&hl=en&sa=X&d=5513891085179250670&ei=BMpIaPu-L86r6rQP3rzY-QM&scisig=AAZF9b8ts6vJnVnPKgZRZk2J59vT&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Lifelong Safety Alignment for Language Models", "first_label": ["LLM"], "second_label": [], "data": "H Wang, Z Qin, Y Zhao, C Du, M Lin, X Wang, T Pang\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLLMs have made impressive progress, but their growing capabilities also expose \nthem to highly flexible jailbreaking attacks designed to bypass safety alignment. \nWhile many existing defenses focus on known types of attacks, it is more critical to\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.20259%3F&hl=en&sa=X&d=16834372085988299596&ei=BMpIaPu-L86r6rQP3rzY-QM&scisig=AAZF9b9d_59vHSVRWjToyCIlG2f5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "PS Pandey, S Simko, K Pelrine, Z Jin\\xc2\\xa0- arXiv preprint arXiv:2505.16789, 2025\nAs large language models gain popularity, their vulnerability to adversarial attacks \nremains a primary concern. While fine-tuning models on domain-specific datasets is \noften employed to improve model performance, it can introduce vulnerabilities within\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.16789%3F&hl=en&sa=X&d=9827187220639785834&ei=BMpIaPu-L86r6rQP3rzY-QM&scisig=AAZF9b-hRa3CIybDfceUhaRlecWD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Through the Stealth Lens: Rethinking Attacks and Defenses in RAG", "first_label": [], "second_label": [], "data": "S Choudhary, N Palumbo, A Hooda, KD Dvijotham\\xe2\\x80\\xa6\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nRetrieval-augmented generation (RAG) systems are vulnerable to attacks that inject \npoisoned passages into the retrieved set, even at low corruption rates. We show that \nexisting attacks are not designed to be stealthy, allowing reliable detection and\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04390&hl=en&sa=X&d=15468735482968103516&ei=BMpIaPu-L86r6rQP3rzY-QM&scisig=AAZF9b8u2OUJdUy7skXRySPRbZz3&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution", "first_label": [], "second_label": [], "data": "J Guo, X Wen, W Jiang, C Huang, J Li, H Li\\xc2\\xa0- arXiv preprint arXiv:2505.15308, 2025\nWith the widespread application of super-resolution (SR) in various fields, \nresearchers have begun to investigate its security. Previous studies have \ndemonstrated that SR models can also be subjected to backdoor attacks through\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.15308&hl=en&sa=X&d=13335437674086498390&ei=BMpIaPu-L86r6rQP3rzY-QM&scisig=AAZF9b8WmdvUXiuzvPutlRNCBmNP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "An Embarrassingly Simple Defense Against LLM Abliteration Attacks", "first_label": ["LLM"], "second_label": [], "data": "HA Shairah, HAAK Hammoud, B Ghanem, G Turkiyyah\\xc2\\xa0- arXiv preprint arXiv\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nLarge language models (LLMs) are typically aligned to comply with safety guidelines \nby refusing harmful instructions. A recent attack, termed abliteration, isolates and \nsuppresses the single latent direction most responsible for refusal behavior, enabling\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2505.19056&hl=en&sa=X&d=3737202939224050048&ei=BMpIaPu-L86r6rQP3rzY-QM&scisig=AAZF9b8QKV5yRTnfm0WbZVG9RAGO&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Leveraging Reward Models for Guiding Code Review Comment Generation", "first_label": ["Code Review", "Code"], "second_label": ["Generation"], "data": "OB Sghaier, R Tufano, G Bavota, H Sahraoui\\xc2\\xa0- arXiv preprint arXiv:2506.04464, 2025\nCode review is a crucial component of modern software development, involving the \nevaluation of code quality, providing feedback on potential issues, and refining the \ncode to address identified problems. Despite these benefits, code review can be\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2506.04464&hl=en&sa=X&d=7473922244289456987&ei=BMpIaJL4JsOr6rQP277P8QY&scisig=AAZF9b89dkAJjF38tpK6zQ6PDx7o&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "2 new citations to articles by Xin ZHOU", "Hong Jin Kang - new related research"]}
{"title": "Feature Disentanglement Based Heterogeneous Defect Prediction", "first_label": ["Software Defect"], "second_label": [], "data": "X Yu, J Yan, Q Gao, Q Peng, B Yu, J Du, Y Xing\\xe2\\x80\\xa6\\xc2\\xa0- ACM Transactions on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nCross-project defect prediction (CPDP) utilizes the existing labeled data in the \nsource project to assist with the prediction of unlabeled projects in the target dataset, \nwhich effectively improves the prediction performance and has become a research\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3742474&hl=en&sa=X&d=10323352525046689857&ei=BMpIaJL4JsOr6rQP277P8QY&scisig=AAZF9b_neYRu3xe_yc1Ee0VXlE3C&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Enhancing the Sustainability of Machine Learning-Based Malware Detection Techniques for Android Applications", "first_label": [], "second_label": ["Detection"], "data": "S Park, H Lee, D Kim, HJ Moon, S Cho, Y Hwang\\xe2\\x80\\xa6\\xc2\\xa0- IEEE Access, 2025\nThe rapid increase in smartphone usage has led to a corresponding rise in malicious \nAndroid applications, making it important to develop efficient and sustainable \nmalware detection methods with high accuracy. This paper presents a two-stage\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/6514899/11023590.pdf&hl=en&sa=X&d=4906749178551814268&ei=BMpIaJL4JsOr6rQP277P8QY&scisig=AAZF9b_Fb87xAAtTwapNGWYSF52X&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "AI-Enhanced Static Analysis: Reducing False Alarms Using Large Language Models", "first_label": ["LLM", "Static Analysis"], "second_label": [], "data": "GD Apostolidis, I Kalouptsoglou, M Siavvas\\xe2\\x80\\xa6\nIn modern software systems, the early and accurate detection of vulnerabilities is \ncritical from a security viewpoint. Traditional Static Analysis Tools (SATs) highlight \npotential security issues, providing fine-grained information including specific lines of\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/George-Apostolidis/publication/392424588_AI-Enhanced_Static_Analysis_Reducing_False_Alarms_Using_Large_Language_Models/links/68415b128a76251f22ebacdb/AI-Enhanced-Static-Analysis-Reducing-False-Alarms-Using-Large-Language-Models.pdf&hl=en&sa=X&d=2853376939638096529&ei=BMpIaJL4JsOr6rQP277P8QY&scisig=AAZF9b_6Tc1rXYm7WUXzpijlYeBM&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Efficient Adaptation of Large Language Models for Smart Contract Vulnerability Detection", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection"], "data": "F Sikder, Y Lei, Y Ji\\xc2\\xa0- Proceedings of the 21st International Conference on\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nSmart contracts underpin decentralized applications but face significant security risks \nfrom vulnerabilities, while traditional analysis methods have limitations. Large \nLanguage Models (LLMs) offer promise for vulnerability detection, yet adapting these\\xc2\\xa0\\xe2\\x80\\xa6\n\u00a0\nThis message was sent by Google Scholar because you\\'re following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert\n\\r\\n'", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3727582.3728688&hl=en&sa=X&d=12782146568247701389&ei=BMpIaKCIKviJ6rQPkqSymQY&scisig=AAZF9b_8PLkYyQ0Bl0nM0bnVJm19&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=3&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Trust Domain Extensions Guest Fuzzing Framework for Security Vulnerability Detection", "first_label": ["Vulnerabilities", "Fuzzing"], "second_label": ["Detection"], "data": "E Dahan, I Aviv, M Kiperberg\\xc2\\xa0- Mathematics, 2025\nThe Intel\\xc2\\xae Trust Domain Extensions (TDX) encrypt guest memory and minimize host \ninteractions to provide hardware-enforced isolation for sensitive virtual machines \n(VMs). Software vulnerabilities in the guest OS continue to pose a serious risk even\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2227-7390/13/11/1879&hl=en&sa=X&d=5761031908609107568&ei=BMpIaITGMr_N6rQPzuHnkAg&scisig=AAZF9b_G8kuPGvufOqoe5m3XBYu6&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=0&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Leveraging LLM Enhanced Commit Messages to Improve Machine Learning Based Test Case Prioritization", "first_label": ["LLM", "Commit Message", "Software Testing"], "second_label": [], "data": "Y Mahmoud, A Azim, R Liscano, K Smith, YK Chang\\xe2\\x80\\xa6\\xc2\\xa0- Proceedings of the 21st\\xc2\\xa0\\xe2\\x80\\xa6, 2025\nIn the rapidly evolving landscape of software development, software testing is critical \nfor maintaining code quality and reducing defects. Effective test case prioritization \nemploys techniques to identify defects early and ensure software quality. New\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3727582.3728681&hl=en&sa=X&d=2338002588478877175&ei=BMpIaITGMr_N6rQPzuHnkAg&scisig=AAZF9b9ZZdQSJWoVODzmMybSzj_D&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "An Empirical Study of Multi-Language Security Patches in Open Source Software", "first_label": [], "second_label": [], "data": "S Sun, Y Xing, G Zou, X Wang, K Sun\nVulnerabilities in software repositories written in multiple programming languages \npresent a major challenge to modern software quality assurance, especially those \nresulting from interactions between different languages. Existing static and dynamic\\xc2\\xa0\\xe2\\x80\\xa6", "link": "https://scholar.google.com/scholar_url?url=https://yunlongxing.github.io/publications/dimva25_Empirical.pdf&hl=en&sa=X&d=10326866748066170289&ei=BMpIaITGMr_N6rQPzuHnkAg&scisig=AAZF9b-FrAQMzcNeCYBMoioph8Ze&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
