{"title": "Aligning Requirement for Large Language Model's Code Generation", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "Z Tian, J Chen- arXiv preprint arXiv:2509.01313, 2025\nCode generation refers to the automatic generation of source code based on a given \nprogramming specification, which has garnered significant attention particularly with \nthe advancement of large language models (LLMs). However, due to the inherent", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01313&hl=en&sa=X&d=13370697676538068499&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b9B7L937IdcMo1J6Zsy7VAv&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Automated Repair of C Programs Using Large Language Models", "first_label": ["APR", "LLM"], "second_label": ["Repair"], "data": "M Farzandway, F Ghassemi- arXiv preprint arXiv:2509.01947, 2025\nThis study explores the potential of Large Language Models (LLMs) in automating \nthe repair of C programs. We present a framework that integrates spectrum-based \nfault localization (SBFL), runtime feedback, and Chain-of-Thought-structured", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01947&hl=en&sa=X&d=1317846922093490120&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b9xJ1n4DpSkY2MDDEUWo_Wk&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "10 new citations to articles by Abhik Roychoudhury", "Bach Le - new related research"]}
{"title": "ChopChop: a Programmable Framework for Semantically Constraining the Output of Language Models", "first_label": ["LLM"], "second_label": [], "data": "S Nagy, T Zhou, N Polikarpova, L D'Antoni- arXiv preprint arXiv:2509.00360, 2025\nLanguage models (LMs) can generate code, but cannot guarantee its correctness--\nproducing outputs that often violate type safety, program invariants, or semantic \nequivalence. Constrained decoding offers a solution by restricting generation to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.00360&hl=en&sa=X&d=15761961036894749958&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b9gFg_U0FktMXuQ5DX2sTxT&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=2&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Xin ZHOU - new related research", "Bach Le - new related research"]}
{"title": "Detecting Stealthy Data Poisoning Attacks in AI Code Generators", "first_label": ["Code"], "second_label": ["Detection"], "data": "C Improta- arXiv preprint arXiv:2508.21636, 2025\nDeep learning (DL) models for natural language-to-code generation have become \nintegral to modern software development pipelines. However, their heavy reliance on \nlarge amounts of data, often collected from unsanitized online sources, exposes", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21636&hl=en&sa=X&d=1475469146271069602&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b__JixuCYDK6mHiazPm85iV&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "4 new citations to articles by Hong Jin Kang"]}
{"title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "first_label": ["LLM"], "second_label": ["Agent"], "data": "T Lindenbauer, I Slinko, L Felder, E Bogomolov- arXiv preprint arXiv, 2025\nLarge Language Model (LLM)-based agents solve complex tasks through iterative \nreasoning, exploration, and tool-use, a process that can result in long, expensive \ncontext histories. While state-of-the-art Software Engineering (SE) agents like", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21433&hl=en&sa=X&d=3778813371369713554&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b8vjKgLLO8JtQg2HjxwaIIj&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Richard Fang - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Exploiting Contexts of LLM-based Code-Completion", "first_label": ["LLM", "Code"], "second_label": ["Generation", "Exploit"], "data": "M Noppel, K Rubel, C Wressnegger- German Conference on Artificial Intelligence, 2025\nCode assistants based on Large language models (LLMs) are built on massive \ndatasets, often sourced from untrusted GitHub repositories. Adversaries can poison \nthese sources so that the resulting models suggest insecure code. The", "link": "https://scholar.google.com/scholar_url?url=https://intellisec.org/pubs/2025a-ki.pdf&hl=en&sa=X&d=11435910170571140017&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b9NKcJ1sJL5SUxGI6_c6C_d&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=5&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Defect Prediction Guided Greybox Fuzz Testing", "first_label": ["Fuzzing", "Software Testing", "Software Defect"], "second_label": [], "data": "H Jin, Z Cui, R Zhang, X Chen, R Wang, X Liu- Journal of Systems and Software, 2025\nFuzz testing is an established automated technique for detecting defects in software \nby generating test cases randomly or semi-randomly. The escalating complexity of \nsoftware functionalities makes comprehensive testing more arduous. Research", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S016412122500278X&hl=en&sa=X&d=5767936158160667382&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b8Dto_RV5XzXWrnnCmGynLS&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=6&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "PATTERNS AND BEST PRACTICES OF KNOWLEDGE SHARING AMONG PROGRAMMERS ON STACK OVERFLOW: A QUALITATIVE STUDY", "first_label": [], "second_label": [], "data": "C WIRABUANA, MM RIDHO, DI SENSUSE, I EITIVENI- : Faculty of, 2025\nThis research explores knowledge-sharing patterns and best practices among \nprogrammers on the Stack Overflow platform. Using a qualitative approach, the study \nanalyzes interviews with seven programmers to identify user behavior and", "link": "https://scholar.google.com/scholar_url?url=https://elibrary.ru/item.asp%3Fid%3D82030709&hl=en&sa=X&d=15767019009267805002&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b85rkfchdG0s1hOqrm8mFGA&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=7&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution (arXiv version)", "first_label": ["LLM"], "second_label": [], "data": "K Even-Mendoza, A Brownlee, A Geiger, C Hanna - 2025\nGenetic Improvement (GI) of software automatically creates alternative software \nversions that are improved according to certain properties of interests (eg, running-\ntime). Search-based GI excels at navigating large program spaces, but operates\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://kclpure.kcl.ac.uk/portal/en/publications/llm-guided-genetic-improvement-envisioning-semantic-aware-automat&hl=en&sa=X&d=17522263310458421835&ei=x_68aKf5Bp-R6rQP28moiQw&scisig=AAZF9b9Mrgn6Wd2hitLrRWwo4Pj-&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=8&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "An Empirical Study of Vulnerable Package Dependencies in LLM Repositories", "first_label": ["LLM"], "second_label": [], "data": "S Liu, X Hu, X Xia, D Lo, X Yang- arXiv preprint arXiv:2508.21417, 2025\nLarge language models (LLMs) have developed rapidly in recent years, \nrevolutionizing various fields. Despite their widespread success, LLMs heavily rely \non external code dependencies from package management systems, creating a", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21417&hl=en&sa=X&d=14553577615445056080&ei=xv68aNvfF_fP6rQP2-GA-Qo&scisig=AAZF9b9j862ZVwGt7jgVb2PyU_Ih&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=1&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Benchmarking and Studying the LLM-based Code Review", "first_label": ["LLM", "Code Review", "Code"], "second_label": [], "data": "Z Zeng, R Shi, K Han, Y Li, K Sun, Y Wang, Z Yu, R Xie- arXiv preprint arXiv, 2025\nAutomated Code Review (ACR) is crucial for software quality, yet existing \nbenchmarks often fail to reflect real-world complexities, hindering the evaluation of \nmodern Large Language Models (LLMs). Current benchmarks frequently focus on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01494&hl=en&sa=X&d=9924101107475937857&ei=xv68aNvfF_fP6rQP2-GA-Qo&scisig=AAZF9b9CW-Ez1-ukRHGu-p7F6_IT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "LLM-Based Program Generation for Triggering Numerical Inconsistencies Across Compilers", "first_label": ["LLM"], "second_label": ["Generation"], "data": "Y Wang, C Rubio-Gonzlez- arXiv preprint arXiv:2509.00256, 2025\nFloating-point inconsistencies across compilers can undermine the reliability of \nnumerical software. We present LLM4FP, the first framework that uses Large \nLanguage Models (LLMs) to generate floating-point programs specifically designed", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.00256&hl=en&sa=X&d=6362971429469914313&ei=xv68aNvfF_fP6rQP2-GA-Qo&scisig=AAZF9b_4FT9ZnZeCMwHPUqYhSw9g&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=4&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "Token Sugar: Making Source Code Sweeter for LLMs through Token-Efficient Shorthand", "first_label": ["LLM", "Code"], "second_label": [], "data": "Z Sun, C Yang, X Du, Z Yang, L Li, D Lo\nLarge language models (LLMs) have shown exceptional performance in code \ngeneration and understanding tasks, yet their high computational costs hinder \nbroader adoption. One important factor is the inherent verbosity of programming\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://v587su.github.io/papers/SugarPaper.pdf&hl=en&sa=X&d=10071555566761971863&ei=xv68aNvfF_fP6rQP2-GA-Qo&scisig=AAZF9b_FQtP2qw0czwy-pXoKQTUa&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=5&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Human-Written vs. AI-Generated Code: A Large-Scale Study of Defects, Vulnerabilities, and Complexity", "first_label": ["Vulnerabilities", "Code", "Software Defect"], "second_label": [], "data": "D Cotroneo, C Improta, P Liguori- arXiv preprint arXiv:2508.21634, 2025\nAs AI code assistants become increasingly integrated into software development \nworkflows, understanding how their code compares to human-written programs is \ncritical for ensuring reliability, maintainability, and security. In this paper, we present \na large-scale comparison of code authored by human developers and three state-of-\nthe-art LLMs, ie, ChatGPT, DeepSeek-Coder, and Qwen-Coder, on multiple \ndimensions of software quality: code defects, security vulnerabilities, and structural\nCites: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21634&hl=en&sa=X&d=8477581447837533475&ei=xv68aNvhNfvoieoPtJ70sAg&scisig=AAZF9b-M9zrl_2Ouj3ipW3Ds0IQb&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le", "2 new citations to articles by Thanh Le-Cong", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Avaliao comparativa do desempenho de inteligncias artificiais generativas e ferramentas tradicionais na anlise de cdigo-fonte JavaScript", "first_label": [], "second_label": [], "data": "R Pimentel, CB Progetti- Simpsio Brasileiro de Segurana da Informao e de, 2025\nEstudo comparativo entre ferramentas SAST (Semgrep/SonarQube) e modelos LLM \n(DeepSeek/CodeLlama) na deteco de vulnerabilidades em JavaScript (OWASP \nJuice Shop). Resultados revelam complementaridade: SASTs alcanam 100% de \npreciso para vulnerabilidades padro (XSS/SQLi), enquanto LLMs oferecem maior \nrecall (70% no DeepSeek) para ameaas contextuais (NoSQLi/Broken Access \nControl). A taxa de 22-45% de falsos positivos em LLMs demanda estratgias de\nCites: Comparison of static application security testing tools and large", "link": "https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/sbseg_estendido/article/download/36756/36542/&hl=en&sa=X&d=11971438696651862258&ei=xv68aNvhNfvoieoPtJ70sAg&scisig=AAZF9b8NSgOQNe0ibg7Gi2jABLp4&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le", "2 new citations to articles by Thanh Le-Cong", "4 new citations to articles by Xin ZHOU"]}
{"title": "AI-Driven Smart Contract Vulnerability Detection: A Systematic Review of Methods, Challenges, and Future Prospects", "first_label": ["Vulnerabilities", "Smart Contracts"], "second_label": ["Detection"], "data": "SAL Azzam, RAL Kolandaisamy, GAL Dharhani- Mesopotamian Journal of Big Data, 2025\nSmart contracts (SCs) have become an essential component in the world of \ndecentralized applications, automating transactions across blockchain networks \nwithout the need for intermediaries, and with this rise in adoption, the technology has \nalso brought forth growing concern due to security vulnerabilities, which have led to \nserious financial damage, and the problem is far from being solved. Traditional \nauditing methods often struggle to capture the more intricate vulnerabilities hidden\nCites: Smart contract development: Challenges and opportunities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://mesopotamian.press/journals/index.php/bigdata/article/download/893/851&hl=en&sa=X&d=12330023021292636129&ei=xv68aNvhNfvoieoPtJ70sAg&scisig=AAZF9b_7P-iu93c_o28izZTxCF_Y&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["3 new citations to articles by Bach Le"]}
{"title": "Strata-Sword: A Hierarchical Safety Evaluation towards LLMs based on Reasoning Complexity of Jailbreak Instructions", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "S Zhao, R Duan, J Liu, X Jia, F Wang, C Wei, R Cheng- arXiv preprint arXiv, 2025\nLarge language models (LLMs) have gained widespread recognition for their \nsuperior comprehension and have been deployed across numerous domains. \nBuilding on Chain-of-Thought (CoT) ideology, Large Reasoning models (LRMs)", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01444&hl=en&sa=X&d=896578385661372830&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b8I5vGKeuVxp-aOZiMcDRaL&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "CCFC: Core & Core-Full-Core Dual-Track Defense for LLM Jailbreak Protection", "first_label": ["LLM"], "second_label": [], "data": "J Hu, H Wang, D Mukherjee, IC Paschalidis- arXiv preprint arXiv:2508.14128, 2025\nJailbreak attacks pose a serious challenge to the safe deployment of large language \nmodels (LLMs). We introduce CCFC (Core & Core-Full-Core), a dual-track, prompt-\nlevel defense framework designed to mitigate LLMs' vulnerabilities from prompt", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.14128%3F&hl=en&sa=X&d=11599114206454984055&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b9Gdzj9YdOMEQ2S0fYXS8oj&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks", "first_label": ["LLM"], "second_label": [], "data": "B Han, F Zhao, D Zhao, G Shen, P Wu, Y Shi, Y Zeng- arXiv preprint arXiv, 2025\nFine-tuning as service injects domain-specific knowledge into large language \nmodels (LLMs), while challenging the original alignment mechanisms and \nintroducing safety risks. A series of defense strategies have been proposed for the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.09190%3F&hl=en&sa=X&d=4598373852349660026&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b-FE-O4pS9mJhwptehdW8I-&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Automatic LLM Red Teaming", "first_label": ["LLM"], "second_label": [], "data": "R Belaire, A Sinha, P Varakantham- arXiv preprint arXiv:2508.04451, 2025\nRed teaming is critical for identifying vulnerabilities and building trust in current \nLLMs. However, current automated methods for Large Language Models (LLMs) rely \non brittle prompt templates or single-turn attacks, failing to capture the complex", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.04451%3F&hl=en&sa=X&d=2257827261327917536&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b_g0uCpzSGEd0WDaskjDUbX&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "When AIOps Become\" AI Oops\": Subverting LLM-driven IT Operations via Telemetry Manipulation", "first_label": ["LLM"], "second_label": [], "data": "D Pasquini, EM Kornaropoulos, G Ateniese, O Akgul- arXiv preprint arXiv, 2025\nAI for IT Operations (AIOps) is transforming how organizations manage complex \nsoftware systems by automating anomaly detection, incident diagnosis, and \nremediation. Modern AIOps solutions increasingly rely on autonomous LLM-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.06394&hl=en&sa=X&d=3305610682736444973&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b9VIvh1YIWaVZu12q2YDMRD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "In-Training Defenses against Emergent Misalignment in Language Models", "first_label": ["LLM"], "second_label": [], "data": "D Kaczr, M Jrgenvg, C Vetter, L Flek, F Mai- arXiv preprint arXiv:2508.06249, 2025\nFine-tuning lets practitioners repurpose aligned large language models (LLMs) for \nnew domains, yet recent work reveals emergent misalignment (EMA): Even a small, \ndomain-specific fine-tune can induce harmful behaviors far outside the target", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.06249%3F&hl=en&sa=X&d=2848574234538730362&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b_Lcm2qHmGdjcK978cplr7k&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Oyster-I: Beyond Refusal--Constructive Safety Alignment for Responsible Language Models", "first_label": ["LLM"], "second_label": [], "data": "R Duan, J Liu, X Jia, S Zhao, R Cheng, F Wang, C Wei- arXiv preprint arXiv, 2025\nLarge language models (LLMs) typically deploy safety mechanisms to prevent \nharmful content generation. Most current approaches focus narrowly on risks posed \nby malicious actors, often framing risks as adversarial events and relying on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01909&hl=en&sa=X&d=6590160868100905669&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b_ezPamqt6bxzEfPBipWSm1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards", "first_label": ["LLM"], "second_label": ["Agent"], "data": "X Wei, B Lu, X Zhang, Z Zhao, D Shen, L Xia, D Yin- arXiv preprint arXiv:2508.21476, 2025\nLarge Language Models (LLMs) have demonstrated remarkable creative writing \ncapabilities, yet their substantial computational demands hinder widespread use. \nEnhancing Small Language Models (SLMs) offers a promising alternative, but", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21476&hl=en&sa=X&d=16045680670429217257&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b8TCftu59j3-3zvJyKGC7dF&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Attacks and Defenses Against LLM Fingerprinting", "first_label": ["LLM"], "second_label": [], "data": "K Kurian, E Holland, S Oesch- arXiv preprint arXiv:2508.09021, 2025\nAs large language models are increasingly deployed in sensitive environments, \nfingerprinting attacks pose significant privacy and security risks. We present a study \nof LLM fingerprinting from both offensive and defensive perspectives. Our attack\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.09021%3F&hl=en&sa=X&d=11346875403769852401&ei=yP68aIGgGPrUieoP9Ofu-QY&scisig=AAZF9b80TL_tYih6TYkyzlWZHNot&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "WFC/WFD: Web Fuzzing Commons, Dataset and Guidelines to Support Experimentation in REST API Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "O Sahin, M Zhang, A Arcuri- arXiv preprint arXiv:2509.01612, 2025\nFuzzing REST APIs is an important research problem, with practical applications and \nimpact in industry. As such, a lot of research work has been carried out on this topic \nin the last few years. However, there are three major issues that hinder further", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01612&hl=en&sa=X&d=15816350851778106621&ei=yP68aLnjL-KIieoPnLqQyAQ&scisig=AAZF9b-S2JCSg3XJhjkuUNrlz4x7&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "10 new citations to articles by Abhik Roychoudhury", "Abhik Roychoudhury - new related research"]}
{"title": "Automated Bug Triaging using Instruction-Tuned Large Language Models", "first_label": ["LLM", "Bug"], "second_label": [], "data": "K Kiashemshaki, A Khosravani, A Hosseinpour- arXiv preprint arXiv, 2025\nBug triaging, the task of assigning new issues to developers, is often slow and \ninconsistent in large projects. We present a lightweight framework that instruction-\ntuned large language model (LLM) with LoRA adapters and uses candidate", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21156&hl=en&sa=X&d=2172606231080988528&ei=yP68aLnjL-KIieoPnLqQyAQ&scisig=AAZF9b_ky7wXlxHsyUsXzgeZukqK&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=3&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "Xin ZHOU - new related research"]}
{"title": "Wit-HW: Bug Localization in Hardware Design Code via Witness Test Case Generation", "first_label": ["Code", "Bug", "Software Testing"], "second_label": ["Generation", "Localization"], "data": "R Ma, D Kuang, Z Liu, J Zhang, P Fan, G Luo- arXiv preprint arXiv:2508.14414, 2025\nDebugging hardware designs requires significant manual effort during hardware \ndevelopment. After engineers identify a bug-triggering test case in simulation-based \nhardware verification, they usually spend considerable time analyzing the execution", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.14414&hl=en&sa=X&d=16419987568237253552&ei=yP68aLnjL-KIieoPnLqQyAQ&scisig=AAZF9b9FQ07vmTOCd9OcmFcv6_Gi&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Locus: Agentic Predicate Synthesis for Directed Fuzzing", "first_label": ["Fuzzing"], "second_label": ["Agent"], "data": "J Zhu, C Shen, Z Li, J Yu, Y Chen, K Pei- arXiv preprint arXiv:2508.21302, 2025\nDirected fuzzing aims to find program inputs that lead to specified target program \nstates. It has broad applications, such as debugging system crashes, confirming \nreported bugs, and generating exploits for potential vulnerabilities. This task is", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.21302&hl=en&sa=X&d=2138932734315377454&ei=yP68aLnjL-KIieoPnLqQyAQ&scisig=AAZF9b9iXz21pxlN8QAQ_QbeooKc&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=6&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Shaking Up Quantum Simulators with Fuzzing and Rigour", "first_label": ["Fuzzing"], "second_label": [], "data": "V Klimis- Proceedings of the Conference on Object-Oriented, 2025\nQuantum computing platforms rely on simulators for modelling circuit behaviour prior \nto hardware execution, where inconsistencies can lead to costly errors. While \nexisting formal validation methods typically target specific compiler components to\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/110396/Klimis%2520Shaking%2520Up%2520Quantum%2520Simulators%2520with%2520Fuzzing%2520and%2520Rigour%25202025%2520Accepted.pdf%3Fsequence%3D2&hl=en&sa=X&d=5527035386124790821&ei=yP68aLnjL-KIieoPnLqQyAQ&scisig=AAZF9b80cRKCwibL_hONzlSQKdaw&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=9&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Advanced Smart Contract Vulnerability Detection via LLM-Powered Multi-Agent Systems", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection", "Agent"], "data": "Z Wei, J Sun, Y Sun, Y Liu, D Wu, Z Zhang, X Zhang- IEEE Transactions on, 2025\nBlockchain's inherent immutability, while transformative, creates critical security risks \nin smart contracts, where undetected vulnerabilities can result in irreversible financial \nlosses. Current auditing tools and approaches often address specific vulnerability", "link": "https://scholar.google.com/scholar_url?url=http://daoyuan14.github.io/papers/TSE25_LLM-SmartAudit.pdf&hl=en&sa=X&d=8638183047541502664&ei=yP68aOGTJPfP6rQP2-GA-Qo&scisig=AAZF9b8v_J-cP7-n2rnam8LynLRR&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=6&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "CoreThink: A Symbolic Reasoning Layer to reason over Long Horizon Tasks with LLMs", "first_label": ["LLM"], "second_label": ["Reasoning"], "data": "J Vaghasiya, O Ghugarkar, V Bhat, V Dholaria- arXiv preprint arXiv, 2025\nWe introduce CoreThink, a state-of-the-art Reasoning Layer built upon a novel \nreasoning method called General Symbolics. This approach diverges from reasoning \nparadigms such as test-time scaling, Supervised Fine-Tuning (SFT), and \nReinforcement Learning with Verifiable Rewards (RLVR). CoreThink General \nSymbolic Reasoner (GSR) is specifically structured around three key use cases: tool-\ncalling, code generation, and planning, demonstrating exemplary performance\nCites: Surveying neuro-symbolic approaches for reliable artificial", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.00971&hl=en&sa=X&d=253240008306322840&ei=xv68aPv7Jp6s6rQP_Izu4Q0&scisig=AAZF9b8YC0I5jUP3UwA8gr77yxL0&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["4 new citations to articles by Hong Jin Kang"]}
{"title": "Neuro-Symbolic Methods for Times Series Analysis for Edge Computing", "first_label": [], "second_label": [], "data": "A Pacheco, M Rivera, E Flores, R Torres, R Chacon - 2025\nThis chapter explores methodologies for time series analysis based on the Neuro-\nsymbolic Artificial Intelligence paradigm, combining pattern recognition, knowledge \nrepresentation, and logical reasoning abilities to improve the effectiveness and \nverification of AI applications. Despite its promise, Neuro-symbolic AI is still in its \nearly stages and lacks widespread adoption. Taxonomies play a critical role in \norganizing this field, providing conceptual frameworks that help researchers\nCites: Surveying neuro-symbolic approaches for reliable artificial", "link": "https://scholar.google.com/scholar_url?url=https://www.intechopen.com/online-first/1225695&hl=en&sa=X&d=10619964232039270385&ei=xv68aPv7Jp6s6rQP_Izu4Q0&scisig=AAZF9b-GKpDssgkNyEC-AU5I18xM&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["4 new citations to articles by Hong Jin Kang"]}
{"title": "Towards Responsible AI through NeuroSymbolic Integration: A Survey", "first_label": [], "second_label": [], "data": "AI Weinberg, K Cohen - 2025\nThis paper explores how NeuroSymbolic (NeSy) approacheshybrid systems that \ncombine neural networks with symbolic reasoningcan enhance key dimensions of \nResponsible Artificial Intelligence (RAI), including transparency, fairness, robustness, \nand human-centered design. While deep learning models often lack interpretability \nand ethical alignment, NeSy systems offer structured reasoning, explainable \ndecision-making, and verifiable constraint enforcement. Uniquely, this paper\nCites: Surveying neuro-symbolic approaches for reliable artificial\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Abraham-Weinberg/publication/395129655_Towards_Responsible_AI_through_NeuroSymbolic_Integration_A_Survey/links/68b55e69360112563e0f9fdd/Towards-Responsible-AI-through-NeuroSymbolic-Integration-A-Survey.pdf&hl=en&sa=X&d=875708866933953987&ei=xv68aPv7Jp6s6rQP_Izu4Q0&scisig=AAZF9b8u9toDKn-oCJJlGpzea4iw&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=3&folt=cit", "author": ["Hong Jin Kang"], "ref": ["4 new citations to articles by Hong Jin Kang"]}
{"title": "Scalable Thread-Safety Analysis of Java Classes with CodeQL", "first_label": ["Code"], "second_label": [], "data": "BH Jtten, SB Jrgensen, R Petersen, R Pardo- arXiv preprint arXiv:2509.02022, 2025\nIn object-oriented languages software developers rely on thread-safe classes to \nimplement concurrent applications. However, determining whether a class is thread-\nsafe is a challenging task. This paper presents a highly scalable method to analyze \nthread-safety in Java classes. We provide a definition of thread-safety for Java \nclasses founded on the correctness principle of the Java memory model, data race \nfreedom. We devise a set of properties for Java classes that are proven to ensure\nCites: Selectively Uniform Concurrency Testing", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.02022&hl=en&sa=X&d=13350781536613733323&ei=x_68aPztFLWR6rQPyczN4AQ&scisig=AAZF9b99OYKD6ckdbzQbLp49qaI_&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Automated Generation of Issue-Reproducing Tests by Combining LLMs and Search-Based Testing", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation", "Search"], "data": "K Kitsios, M Castelluccio, A Bacchelli- arXiv preprint arXiv:2509.01616, 2025\nIssue-reproducing tests fail on buggy code and pass once a patch is applied, thus \nincreasing developers' confidence that the issue has been resolved and will not be \nre-introduced. However, past research has shown that developers often commit \npatches without such tests, making the automated generation of issue-reproducing \ntests an area of interest. We propose BLAST, a tool for automatically generating \nissue-reproducing tests from issue-patch pairs by combining LLMs and search\nCites: AutoCodeRover: Autonomous program improvement", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01616&hl=en&sa=X&d=7662112283941476702&ei=x_68aPztFLWR6rQPyczN4AQ&scisig=AAZF9b-fTfxp7oa_qkRHNK5lFZpA&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=5&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury", "Quang-Cuong Bui - new related research"]}
{"title": "A Contemporary Survey of Large Language Model Assisted Program Analysis", "first_label": ["LLM"], "second_label": [], "data": "J Wang, T Ni, WB Lee, Q Zhao- Transactions on Artificial Intelligence, 2025\nThe increasing complexity of software systems has driven significant advancements \nin program analysis, as traditional methods are unable to meet the demands of \nmodern software development. To address these limitations, deep learning \ntechniques, particularly Large Language Models (LLMs), have gained attention due \nto their context-aware capabilities in code comprehension. Recognizing the potential \nof LLMs, researchers have extensively explored their application in program analysis\nCites: Large language model guided protocol fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://www.sciltp.com/journals/tai/articles/2505000685&hl=en&sa=X&d=9976958458677084056&ei=x_68aPztFLWR6rQPyczN4AQ&scisig=AAZF9b-2X6b0-ttOl4JtqeNz6pii&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=6&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Automobile Intelligent Controls: A Comprehensive Review", "first_label": [], "second_label": [], "data": "Z Weiya, GZ Kai- 2025 IEEE Symposium on Industrial Electronics &, 2025\nThe rapid development of embedded systems has significantly transformed the \nautomotive industry. With the rise of wireless communication, smart sensors, and AI, \nembedded systems are crucial for enhancing vehicle performance and safety. This \npaper provides a thorough investigation into the current advancements in automobile-\nembedded controls and identifies challenges faced in the field. Some of the most \nsignificant advancements are ARM7-based airbag systems for low-cost accident\nCites: On testing embedded software", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11138426/&hl=en&sa=X&d=1672811103612883876&ei=x_68aPztFLWR6rQPyczN4AQ&scisig=AAZF9b_VvOVF0VaLCMY-4YBO0ASt&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=8&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "Advancement of HTTP and Security Issues Over It", "first_label": [], "second_label": [], "data": "NN Dwivedi, D Singh\nNow days so many organizations are focusing that how to improve http and security \nrelated problem over it. The new protocol, HTTP/2, has most popular in the web \nindustry as its typical information was confirmed and accepted earlier few years. \nMany of its technical structures are derived from the Google application-based \nprotocol, HTTP/2 solves many bugs and variations of HTTP/1.1, improving web \nperformance during page loading times. Expected. HTTP/2 introduces topic\nCites: Detecting energy bugs and hotspots in mobile apps\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.tejasjournals.com/Papers/2025/03/TJTHS-0403-002.pdf&hl=en&sa=X&d=9002435591097519327&ei=x_68aPztFLWR6rQPyczN4AQ&scisig=AAZF9b9b4jVN_5sHbG-qTMv90w1s&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=9&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["10 new citations to articles by Abhik Roychoudhury"]}
{"title": "GRAM-R $^ 2$: Self-Training Generative Foundation Reward Models for Reward Reasoning", "first_label": [], "second_label": ["Reasoning"], "data": "C Wang, Y Mu, H Zhou, Y Huo, Z Zhu, J Zeng, M Yang- arXiv preprint arXiv, 2025\nSignificant progress in reward modeling over recent years has been driven by a \nparadigm shift from task-specific designs towards generalist reward models. Despite \nthis trend, developing effective reward models remains a fundamental challenge: the \nheavy reliance on large-scale labeled preference data. Pre-training on abundant \nunlabeled data offers a promising direction, but existing approaches fall short of \ninstilling explicit reasoning into reward models. To bridge this gap, we propose a self\nCites: Codeultrafeedback: An llm-as-a-judge dataset for aligning large", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.02492&hl=en&sa=X&d=2685845414329502017&ei=yP68aLD5C4XR6rQPlLfCsQ8&scisig=AAZF9b-mrIGUqIlnQaB3qv3qMf3_&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks", "first_label": ["LLM"], "second_label": ["Search"], "data": "H Wan, C Yang, J Yu, M Tu, J Lu, D Yu, J Cao, B Gao- arXiv preprint arXiv, 2025\nDeep research agents have attracted growing attention for their potential to \norchestrate multi-stage research workflows, spanning literature synthesis, \nmethodological design, and empirical verification. Despite these strides, evaluating \ntheir research capability faithfully is rather challenging due to the difficulty of \ncollecting frontier research questions that genuinely capture researchers' attention \nand intellectual curiosity. To address this gap, we introduce DeepResearch Arena, a\nCites: LessLeak-Bench: A First Investigation of Data Leakage in LLMs", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01396&hl=en&sa=X&d=15455967310149889969&ei=yP68aLD5C4XR6rQPlLfCsQ8&scisig=AAZF9b9Cen7EYpR12FOXThd6aoud&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "MDPMORPH: An MDP-Based Metamorphic Testing Framework for Deep Reinforcement Learning Agents", "first_label": ["Software Testing"], "second_label": ["Agent"], "data": "J Li, Z Zheng, Y Xing, D Ren, S Cho, V Terragni\nDeep Reinforcement Learning (DRL) systems are widely used across various \ndomains. However, testing these systems presents significant challenges. The DRL \nagent, which serves as the core decision-maker, generates continuous value \nestimates rather than discrete labels and operates under nonstationary policies \nwithin complex and stochastic environments. Consequently, there is no definitive \ncorrect answer for each state-action pair, complicating automated test generation\nCites: Curiosity-driven testing for sequential decision-making process", "link": "https://scholar.google.com/scholar_url?url=https://valerio-terragni.github.io/assets/pdf/li-issre-2025.pdf&hl=en&sa=X&d=11908862816750347491&ei=yP68aLD5C4XR6rQPlLfCsQ8&scisig=AAZF9b8FHOsMn8c4xLUnrQKTZ7Mx&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["4 new citations to articles by Xin ZHOU"]}
{"title": "Private, Verifiable, and Auditable AI Systems", "first_label": [], "second_label": [], "data": "T South- arXiv preprint arXiv:2509.00085, 2025\nThe growing societal reliance on artificial intelligence necessitates robust \nframeworks for ensuring its security, accountability, and trustworthiness. This thesis \naddresses the complex interplay between privacy, verifiability, and auditability in \nmodern AI, particularly in foundation models. It argues that technical solutions that \nintegrate these elements are critical for responsible AI innovation. Drawing from \ninternational policy contributions and technical research to identify key risks in the AI\nCites: Llm agents can autonomously hack websites, 2024", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.00085&hl=en&sa=X&d=14343213836759072369&ei=xv68aJGHCPmI6rQP1e7wmQQ&scisig=AAZF9b-JMx3l6Rx1JgATaoEwRCOG&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "A Whole New World: Creating a Parallel-Poisoned Web Only AI-Agents Can See", "first_label": [], "second_label": ["Agent"], "data": "S Zychlinski- arXiv preprint arXiv:2509.00124, 2025\nThis paper introduces a novel attack vector that leverages website cloaking \ntechniques to compromise autonomous web-browsing agents powered by Large \nLanguage Models (LLMs). As these agents become more prevalent, their unique and \noften homogenous digital fingerprints-comprising browser attributes, automation \nframework signatures, and network characteristics-create a new, distinguishable \nclass of web traffic. The attack exploits this fingerprintability. A malicious website can\nCites: Llm agents can autonomously hack websites, 2024\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.00124&hl=en&sa=X&d=12002829683849877755&ei=xv68aJGHCPmI6rQP1e7wmQQ&scisig=AAZF9b9fZTLcHqX5d7AaOCr2Ebbp&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Software Engineering in the Era of Intelligence, Security, and Automation", "first_label": [], "second_label": [], "data": "S Aftab - 2025\nSoftware Engineering (JSE) as an academic platform dedicated to advancing \nresearch and innovation across the full spectrum of software engineering. The \njournal aims to create an inclusive and high-quality space for contributions that span", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Shabib-Aftab-2/publication/395107678_Software_Engineering_in_the_Era_of_Intelligence_Security_and_Automation/links/68b37e563391fb1a7a4c6087/Software-Engineering-in-the-Era-of-Intelligence-Security-and-Automation.pdf&hl=en&sa=X&d=5156508072237023278&ei=x_68aPa7L4zSieoP3YSb4Q4&scisig=AAZF9b_snamPPxcBt904-5TN2Pcl&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Leveraging SystemC-TLM-based Virtual Prototypes for Embedded Software Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "C Ghinami, J Winzer, N Bosbach, LM Reimann- arXiv preprint arXiv, 2025\nSystemC-based virtual prototypes have emerged as widely adopted tools to test \nsoftware ahead of hardware availability, reducing the time-to-market and improving \nsoftware reliability. Recently, fuzzing has become a popular method for automated", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2509.01318&hl=en&sa=X&d=1341175212014518141&ei=x_68aPa7L4zSieoP3YSb4Q4&scisig=AAZF9b9xqbJnzFJ8oCl2uemQ46wF&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
