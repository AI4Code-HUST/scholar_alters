{"title": "Multi-Agent Penetration Testing AI for the Web", "first_label": ["Software Testing"], "second_label": ["Agent"], "data": "I David, A Gervais- arXiv preprint arXiv:2508.20816, 2025\nAI-powered development platforms are making software creation accessible to a \nbroader audience, but this democratization has triggered a scalability crisis in \nsecurity auditing. With studies showing that up to 40% of AI-generated code contains", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.20816&hl=en&sa=X&d=4844919501821999836&ei=yc21aJngLKHN6rQPma25gQI&scisig=AAZF9b_I_7Wp_hGE7c4tW6dSSGgR&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Combining Code Generating Large Language Models and Self-Play to Iteratively Refine Strategies in Games", "first_label": ["LLM", "Code"], "second_label": [], "data": "Y Bachrach, E Toledo, K Hambardzumyan, D Magka\nWe propose a self-play approach to generating strategies for playing in multi-player \ngames, where strategies are represented as computer code. We use large language \nmodels (LLMs) to generate pieces of code to play in the game, which we refer to as", "link": "https://scholar.google.com/scholar_url?url=https://ijcai-preprints.s3.us-west-1.amazonaws.com/2025/DM24.pdf&hl=en&sa=X&d=11145484786866310576&ei=yc21aJngLKHN6rQPma25gQI&scisig=AAZF9b9UJ3FFk636jgXvcvyaqXUq&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Boosting Skeleton-Driven SMT Solver Fuzzing by Leveraging LLM to Produce Formula Generators", "first_label": ["LLM", "Fuzzing"], "second_label": [], "data": "M Sun, Y Yang, Y Zhou- arXiv preprint arXiv:2508.20340, 2025\nSatisfiability Modulo Theory (SMT) solvers are foundational to modern systems and \nprogramming languages research, providing the foundation for tasks like symbolic \nexecution and automated verification. Because these solvers sit on the critical path\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.20340&hl=en&sa=X&d=1695679758284148071&ei=yc21aJngLKHN6rQPma25gQI&scisig=AAZF9b-bzdShNjYbG_DukyZB6diB&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=2&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Patch Generation in APR: A Survey from the Perspectives of Utilizing LLMs and Using APR-Specific Information", "first_label": ["LLM"], "second_label": ["Generation"], "data": "Y Yang, C Li, Z Han, R Li, K Xu, Q Li, W Zhong, Z Shen- ACM Transactions on Software\nAutomated Program Repair (APR) is a crucial task in software development and \nmaintenance, aiming to patch software bugs automatically without human \nintervention. The rise of Large Language Models (LLMs) has significantly advanced", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3764584&hl=en&sa=X&d=12095139928200092084&ei=yc21aPLRHYvWieoPpLaliQQ&scisig=AAZF9b9FdXwyjqtbiPQo7S-egQ-4&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=0&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "3 new citations to articles by Hong Jin Kang", "2 new citations to articles by Thanh Le-Cong", "5 new citations to articles by Abhik Roychoudhury", "3 new citations to articles by Bach Le", "3 new citations to articles by Xin ZHOU"]}
{"title": "Effect of Deep Recurrent Architectures on Code Vulnerability Detection: Performance Evaluation for SQL Injection in Python", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "A Slotkien, A Poka, P Stefanovi, S Ramanauskait- Electronics, 2025\nSecurity defects in software code can lead to situations that compromise web-based \nsystems, data security, service availability, and the reliability of functionality. \nTherefore, it is crucial to detect code vulnerabilities as early as possible. During the", "link": "https://scholar.google.com/scholar_url?url=https://www.mdpi.com/2079-9292/14/17/3436&hl=en&sa=X&d=17611221135334497072&ei=yc21aPLRHYvWieoPpLaliQQ&scisig=AAZF9b8E-DzHzklagNrUxwZtKN6z&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=1&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "AI Agentic Vulnerability Injection And Transformation with Optimized Reasoning", "first_label": ["Vulnerabilities"], "second_label": ["Agent", "Reasoning"], "data": "A Lbath, MR Amini, A Delaitre, V Okun- arXiv preprint arXiv:2508.20866, 2025\nThe increasing complexity of software systems and the sophistication of cyber-\nattacks have underscored the critical need for effective automated vulnerability \ndetection and repair systems. Traditional methods, such as static program analysis", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.20866&hl=en&sa=X&d=3544592540780461734&ei=yc21aPLRHYvWieoPpLaliQQ&scisig=AAZF9b8p3vPmDSTC1680AMCVumV8&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=2&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "Xin ZHOU - new related research", "David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "Machine Learning Techniques for Automatic Program Repair: A Systematic Literature Mapping", "first_label": ["APR"], "second_label": ["Repair"], "data": "S Domnguez-Isidro, J Snchez-Garca- New Challenges in Software, 2025\nProgram repair involves identifying and fixing issues in a program's source code, \nencompassing error correction, performance improvement, code optimization, and \neven addressing security problems. However, this process can address issues\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-031-90310-6_32&hl=en&sa=X&d=2492969672266113366&ei=yc21aPLRHYvWieoPpLaliQQ&scisig=AAZF9b-JH-gkbMbo94UsYfG8n1JR&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=3&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research", "5 new citations to articles by Abhik Roychoudhury", "3 new citations to articles by Bach Le"]}
{"title": "Functional Consistency of LLM Code Embeddings: A Self-Evolving Data Synthesis Framework for Benchmarking", "first_label": ["LLM", "Code"], "second_label": [], "data": "Z Li, W Chen, J Yu, Z Lu- Expert Systems with Applications, 2025\nEmbedding models have demonstrated strong performance in tasks like clustering, \nretrieval, and feature extraction while offering computational advantages over \ngenerative models and cross-encoders. Benchmarks such as MTEB have shown that", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.19558&hl=en&sa=X&d=15100132484853175061&ei=ys21aN7DJ_voieoP_t6J0Qg&scisig=AAZF9b-2AWIbN3jfOfpV42M5folV&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=0&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "Towards Better Correctness and Efficiency in Code Generation", "first_label": ["Code"], "second_label": ["Generation"], "data": "Y Feng, Y Xu, X Xu, B Hui, J Lin- arXiv preprint arXiv:2508.20124, 2025\nWhile code large language models have demonstrated remarkable progress in code \ngeneration, the generated code often exhibits poor runtime efficiency, limiting its \npractical application in performance-sensitive scenarios. To address this limitation", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.20124&hl=en&sa=X&d=3240288768383467512&ei=ys21aN7DJ_voieoP_t6J0Qg&scisig=AAZF9b_SzzdGQdI-yKlU8IydAnQ7&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=2&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "3 new citations to articles by Hong Jin Kang", "David Lo - new related research"]}
{"title": "Improving Source Code Security: A Novel Approach Using Spectrum of Prompts and Automated State Machine", "first_label": ["Code"], "second_label": [], "data": "CAS Lelis, CAC Marcondes, K Fealey- Brasileiro de Segurana da Informao e de, 2025\nAs software security becomes increasingly vital, automating source code \nvulnerability remediation is essential for enhancing system reliability. This research \npresents an integrated framework that combines large language models (LLMs) with\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://sol.sbc.org.br/index.php/sbseg/article/download/36641/36428/&hl=en&sa=X&d=17468143338563062292&ei=ys21aN7DJ_voieoP_t6J0Qg&scisig=AAZF9b-OBcGLjdqgkLuluUieJGA8&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=3&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research", "1 new citation to articles by Quang-Cuong Bui", "5 new citations to articles by Abhik Roychoudhury"]}
{"title": "-", "first_label": [], "second_label": [], "data": ",  ,  -   , 2025\n      \n         \n.          \n     \n     \n.       \nCites: Semantic patches for java program transformation\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ispranproceedings.elpub.ru/jour/article/view/1824&hl=en&sa=X&d=8625546604190736434&ei=yM21aPTBB4fC6rQPgLuo8Qc&scisig=AAZF9b81YrFyoX04UmWZbhGcTdAm&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=2&folt=cit", "author": ["Hong Jin Kang"], "ref": ["3 new citations to articles by Hong Jin Kang"]}
{"title": "Athena: Intermediate Representations for Iterative Scaffolded App Generation with an LLM", "first_label": ["LLM"], "second_label": ["Generation"], "data": "J Beason, R Cheng, E Schoop, J Nichols- arXiv preprint arXiv:2508.20263, 2025\nIt is challenging to generate the code for a complete user interface using a Large \nLanguage Model (LLM). User interfaces are complex and their implementations often \nconsist of multiple, inter-related files that together specify the contents of each\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.20263&hl=en&sa=X&d=16100333742832142127&ei=yM21aOWeO6HN6rQPma25gQI&scisig=AAZF9b-L7XT2cvqAW9ETfxogVnSD&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Interleaving Large Language Models for Compiler Testing", "first_label": ["LLM", "Software Testing"], "second_label": [], "data": "Y Ni, S Li- arXiv preprint arXiv:2508.18955, 2025\nTesting compilers with AI models, especially large language models (LLMs), has \nshown great promise. However, current approaches struggle with two key problems: \nThe generated programs for testing compilers are often too simple, and extensive", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.18955&hl=en&sa=X&d=487666916091373873&ei=ys21aNTINIDXieoPk73huQQ&scisig=AAZF9b-AIHxzif6Q1-QX1fiyTuBb&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research", "David Lo - new related research"]}
{"title": "CODE COVERAGE", "first_label": ["Code"], "second_label": [], "data": "-  , 2025\n   ,    \n,  :  ,   .  \n   ,      ,  \n,    .     \n ,     ,    \n.      \nCites: Refining chatgpt-generated code: Characterizing and mitigating\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://cyberleninka.ru/article/n/code-coverage-i-stabilnost-klyuchevye-metriki-uspeha-tehnologicheskoy-komandy&hl=en&sa=X&d=10133539486544816960&ei=x821aIq7HvrUieoPmfaJ2Q4&scisig=AAZF9b__oOw2ALmBoOkA-WmZeuhF&oi=scholaralrt&hist=ylyK0_8AAAAJ:1164437029242115036:AAZF9b9cZXgBuh9nrxFB6U5Br4kf&html=&pos=1&folt=cit", "author": ["Thanh Le-Cong"], "ref": ["2 new citations to articles by Thanh Le-Cong", "3 new citations to articles by Bach Le"]}
{"title": "JADES: A Universal Framework for Jailbreak Assessment via Decompositional Scoring", "first_label": [], "second_label": [], "data": "J Chu, M Li, Z Yang, Y Leng, C Lin, C Shen, M Backes- arXiv preprint arXiv, 2025\nAccurately determining whether a jailbreak attempt has succeeded is a fundamental \nyet unresolved challenge. Existing evaluation methods rely on misaligned proxy \nindicators or naive holistic judgments. They frequently misinterpret model responses", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.20848&hl=en&sa=X&d=3354477192234789053&ei=ys21aPbJHbOk6rQPk-uVkAE&scisig=AAZF9b_OUtU5TwY5gFe7t_EPP97t&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks", "first_label": ["LLM"], "second_label": [], "data": "B Han, F Zhao, D Zhao, G Shen, P Wu, Y Shi, Y Zeng- arXiv preprint arXiv, 2025\nFine-tuning as service injects domain-specific knowledge into large language \nmodels (LLMs), while challenging the original alignment mechanisms and \nintroducing safety risks. A series of defense strategies have been proposed for the", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.09190%3F&hl=en&sa=X&d=4598373852349660026&ei=ys21aPbJHbOk6rQPk-uVkAE&scisig=AAZF9b-FE-O4pS9mJhwptehdW8I-&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Automatic LLM Red Teaming", "first_label": ["LLM"], "second_label": [], "data": "R Belaire, A Sinha, P Varakantham- arXiv preprint arXiv:2508.04451, 2025\nRed teaming is critical for identifying vulnerabilities and building trust in current \nLLMs. However, current automated methods for Large Language Models (LLMs) rely \non brittle prompt templates or single-turn attacks, failing to capture the complex", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.04451%3F&hl=en&sa=X&d=2257827261327917536&ei=ys21aPbJHbOk6rQPk-uVkAE&scisig=AAZF9b_g0uCpzSGEd0WDaskjDUbX&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "When AIOps Become\" AI Oops\": Subverting LLM-driven IT Operations via Telemetry Manipulation", "first_label": ["LLM"], "second_label": [], "data": "D Pasquini, EM Kornaropoulos, G Ateniese, O Akgul- arXiv preprint arXiv, 2025\nAI for IT Operations (AIOps) is transforming how organizations manage complex \nsoftware systems by automating anomaly detection, incident diagnosis, and \nremediation. Modern AIOps solutions increasingly rely on autonomous LLM-based", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.06394&hl=en&sa=X&d=3305610682736444973&ei=ys21aPbJHbOk6rQPk-uVkAE&scisig=AAZF9b9VIvh1YIWaVZu12q2YDMRD&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "In-Training Defenses against Emergent Misalignment in Language Models", "first_label": ["LLM"], "second_label": [], "data": "D Kaczr, M Jrgenvg, C Vetter, L Flek, F Mai- arXiv preprint arXiv:2508.06249, 2025\nFine-tuning lets practitioners repurpose aligned large language models (LLMs) for \nnew domains, yet recent work reveals emergent misalignment (EMA): Even a small, \ndomain-specific fine-tune can induce harmful behaviors far outside the target", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.06249%3F&hl=en&sa=X&d=2848574234538730362&ei=ys21aPbJHbOk6rQPk-uVkAE&scisig=AAZF9b_Lcm2qHmGdjcK978cplr7k&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Simulated Ensemble Attack: Transferring Jailbreaks Across Fine-tuned Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "R Wang, X Wang, Y Yao, X Tong, X Ma- arXiv preprint arXiv:2508.01741, 2025\nFine-tuning open-source Vision-Language Models (VLMs) creates a critical yet \nunderexplored attack surface: vulnerabilities in the base VLM could be retained in \nfine-tuned variants, rendering them susceptible to transferable jailbreak attacks. To", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.01741%3F&hl=en&sa=X&d=13634573132391004205&ei=ys21aPbJHbOk6rQPk-uVkAE&scisig=AAZF9b-WD8yrAEjxqk5AYRgNWSj1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs", "first_label": ["LLM"], "second_label": [], "data": "W Xing, M Li, C Hu, HXN Zhang, B Lin, M Han- arXiv preprint arXiv:2508.10029, 2025\nLarge language models (LLMs) demonstrate impressive capabilities in various \nlanguage tasks but are susceptible to jailbreak attacks that circumvent their safety \nalignments. This paper introduces Latent Fusion Jailbreak (LFJ), a representation", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.10029&hl=en&sa=X&d=15395219468843460694&ei=ys21aPbJHbOk6rQPk-uVkAE&scisig=AAZF9b8rU6ujBAfNkA_M5tKiNjJ6&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Dynamic Collaboration of Multi-Language Models based on Minimal Complete Semantic Units", "first_label": ["LLM"], "second_label": [], "data": "C Hao, Z Wang, Y Huang, R Xu, W Niu, X Liu, Z Yu- arXiv preprint arXiv:2508.18763, 2025\nThis paper investigates the enhancement of reasoning capabilities in language \nmodels through token-level multi-model collaboration. Our approach selects the \noptimal tokens from the next token distributions provided by multiple models to", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.18763&hl=en&sa=X&d=7978340676637382802&ei=ys21aPbJHbOk6rQPk-uVkAE&scisig=AAZF9b8qsff6JIq9FXQxpoyH5zNr&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models: A Unified and Accurate Approach", "first_label": ["LLM"], "second_label": [], "data": "S Liang, Z Xu, J Tao, H Xue, X Wang- arXiv preprint arXiv:2508.09201, 2025\nDespite extensive alignment efforts, Large Vision-Language Models (LVLMs) remain \nvulnerable to jailbreak attacks, posing serious safety risks. Although recent detection \nworks have shifted to internal representations due to their rich cross-modal", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.09201%3F&hl=en&sa=X&d=18315359548988601437&ei=ys21aPbJHbOk6rQPk-uVkAE&scisig=AAZF9b-JER6kReVLcbFPLmFoxVC_&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Towards Evaluation for Real-World LLM Unlearning", "first_label": ["LLM"], "second_label": [], "data": "K Miao, Y Hu, X Li, W Bao, Z Liu, Z Qin, K Ren- arXiv preprint arXiv:2508.01324, 2025\nThis paper analyzes the limitations of existing unlearning evaluation metrics in terms \nof practicality, exactness, and robustness in real-world LLM unlearning scenarios. To \novercome these limitations, we propose a new metric called Distribution Correction\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.01324%3F&hl=en&sa=X&d=3951001180431648386&ei=ys21aPbJHbOk6rQPk-uVkAE&scisig=AAZF9b_75D0a0mqlX1m7HkWmVpF1&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Understanding the potentially confounding effect of test suite size in test effectiveness evaluation", "first_label": ["Software Testing"], "second_label": [], "data": "Z Lu, Y Wang, Y Rong, Y Huang, X Wang, P Zhang- ACM Transactions on, 2025\nBackground: Code coverage and mutation score serve as pivotal test effectiveness \nmetrics used to assess a test suite's ability to uncover actual defects. However, prior \nresearch has produced inconsistent or even conflicting findings regarding their \ncorrelation with defect detection capability, particularly concerning the impact of test \nsuite size. Problem: The extent of the potentially confounding effect of test suite size \nin test effectiveness evaluation context is not clear, nor is the method to remove the\nCites: Smart greybox fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3748504&hl=en&sa=X&d=17755438009705655820&ei=yc21aJCQDqPWieoPhpqLqAo&scisig=AAZF9b-uFChQan2FjV7k8DKKYbE5&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=3&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "PANGOLIN: a Comprehensive Testing Framework for Configuration-Rich Key-Value Stores", "first_label": ["Software Testing"], "second_label": [], "data": "S Duan, S Kannan, AC Arpaci-Dusseau- Proceedings of the 18th, 2025\nIn this paper, we present Pangolin, a comprehensive testing framework for \nconfiguration-rich key-value stores. To better understand bugs in modern key-value \nstores and explore domain knowledge for efficiently identifying new ones, we first \ncomprehensively study historical bugs in five mature key-value stores during the last \neight years. Then, we design and implement Pangolin, which is motivated by insights \nfrom our bug study, which indicated most bugs could be identified by systematically\nCites: Directed greybox fuzzing\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3757347.3759132&hl=en&sa=X&d=15440488289208500222&ei=yc21aJCQDqPWieoPhpqLqAo&scisig=AAZF9b8qr39eiGYwEq4-hXUPlShh&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=4&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["5 new citations to articles by Abhik Roychoudhury"]}
{"title": "CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics", "first_label": ["LLM"], "second_label": ["Agent"], "data": "S Fumero, K Huang, M Boffa, D Giordano, M Mellia- arXiv preprint arXiv, 2025\nLarge Language Model (LLM) agents are powerful tools for automating complex \ntasks. In cybersecurity, researchers have primarily explored their use in red-team \noperations such as vulnerability discovery and penetration tests. Defensive uses for \nincident response and forensics have received comparatively less attention and \nremain at an early stage. This work presents a systematic study of LLM-agent design \nfor the forensic investigation of realistic web application attacks. We propose\nCites: CVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.20643&hl=en&sa=X&d=4157175005797422882&ei=x821aJrwMeDM6rQPycS0-AI&scisig=AAZF9b-EyN-S69V8M8QzOl1x6TfM&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning", "first_label": ["LLM"], "second_label": [], "data": "W Feng, L Wang, T Wei, J Zhang, C Gao, S Zhan, P Lv- arXiv preprint arXiv, 2025\nAs large language models (LLMs) continue to grow in capability, so do the risks of \nharmful misuse through fine-tuning. While most prior studies assume that attackers \nrely on supervised fine-tuning (SFT) for such misuse, we systematically demonstrate \nthat reinforcement learning (RL) enables adversaries to more effectively break safety \nalignment and facilitate advanced harmful task assistance, under matched \ncomputational budgets. To counter this emerging threat, we propose TokenBuncher\nCites: Removing rlhf protections in gpt-4 via fine-tuning", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.20697&hl=en&sa=X&d=13446977088965088347&ei=x821aJrwMeDM6rQPycS0-AI&scisig=AAZF9b-dJ0ZBodvXmZXfW2lgSXa0&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection", "first_label": [], "second_label": [], "data": "HA Shairah, HAAK Hammoud, G Turkiyyah, B Ghanem- arXiv preprint arXiv, 2025\nSafety alignment in Large Language Models (LLMs) often involves mediating \ninternal representations to refuse harmful requests. Recent research has \ndemonstrated that these safety mechanisms can be bypassed by ablating or \nremoving specific representational directions within the model. In this paper, we \npropose the opposite approach: Rank-One Safety Injection (ROSI), a white-box \nmethod that amplifies a model's safety alignment by permanently steering its\nCites: Removing rlhf protections in gpt-4 via fine-tuning", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.20766&hl=en&sa=X&d=14789718056790263300&ei=x821aJrwMeDM6rQPycS0-AI&scisig=AAZF9b_KNkaHt4hXMV-7TFQBdUZm&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=2&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "Rethinking the Safety Landscape for Foundation Models: A Multi-Modal Perspective", "first_label": [], "second_label": [], "data": "X Li, S Zhao, F Zhao, R Yu\nWith the rise of multi-modal foundation models in domains such as autonomous \ndriving, healthcare, and virtual assistants, safety concerns have become increasingly \nimportant. Unlike uni-modal learning, these models rely on modality alignment and \nfusion to integrate cross-modal informationintroducing novel threats that existing \nsafety frameworks fail to address. Current safety solutions often assume prior \nknowledge of compromised modalities and overlook complex cross-modal\nCites: Removing rlhf protections in gpt-4 via fine-tuning\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://lixi1994.github.io/assets/publications/2025_ICCV_T2FM/paper.pdf&hl=en&sa=X&d=14370337437498939819&ei=x821aJrwMeDM6rQPycS0-AI&scisig=AAZF9b_lE_G7h2U1Gzm2mJozkDiP&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=3&folt=cit", "author": ["Richard Fang"], "ref": ["4 new citations to articles by Richard Fang"]}
{"title": "BePilot: An AI Programming Assistant for Compiler Backend Development", "first_label": [], "second_label": [], "data": "M Zhong, X Sun, F Lv, L Wang, H Geng, L Qiu, H Cui- ACM Transactions on, 2025\nCompiler backends are tasked with generating executable machine code for various \nprocessors. As the diversity of processors continues to grow, it is imperative for \nprogrammers to tailor specific compiler backends to accommodate each one. \nHowever, compiler backend development remains a labor-intensive and time-\nconsuming process, with limited automation tools available. Although large language \nmodels (LLMs) have demonstrated strong abilities in code completion and\nCites: An LLM-as-Judge Metric for Bridging the Gap with Human", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3764585&hl=en&sa=X&d=57737463069935228&ei=ys21aMy4DIfC6rQPgLuo8Qc&scisig=AAZF9b874V1LRkqdD8Xy7ICAnnvp&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["3 new citations to articles by Xin ZHOU"]}
{"title": "The Impact of Class Noise-handling on the Effectiveness of Machine Learning-based Methods for Build Outcome and Code Change Request Predictions", "first_label": ["Code", "Code Change"], "second_label": [], "data": "K Al-Sabbagh, M Staron, R Hebig- ACM Transactions on Software Engineering and\nMachine learning-based methods for optimizing build processes and code review \nprocesses are commonly used to accelerate feature delivery to end-users in modern \nsoftware engineering. These methods leverage large volumes of historical code \nchanges to train models on predicting and preventing issues in the code-base that \ncould delay code integrations. The objective of this paper is to improve these \nmethods by reducing the impact of noise on their predictive performance. In this\nCites: Assessing generalizability of codebert\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3764864&hl=en&sa=X&d=6929809996551122379&ei=ys21aMy4DIfC6rQPgLuo8Qc&scisig=AAZF9b-BYbCkanzPUyztydvBsSVR&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=2&folt=cit", "author": ["Xin ZHOU"], "ref": ["3 new citations to articles by Xin ZHOU"]}
{"title": "LLM-based Generation of Formal Specification for Run-time Security Monitoring of ICS", "first_label": ["LLM"], "second_label": ["Generation"], "data": "GE Raptis, MT Khan, C Koulamas, D Serpanos- 2025 IEEE International Conference, 2025\nIndustrial Control Systems (ICS) are vulnerable to cybersecurity threats due to their \ndistributed architecture and critical role in infrastructure sectors. Ensuring their \nsecure operation requires deploying runtime monitoring mechanisms to detect \nbehavioral deviations, with inline security monitoring arising as a practical solution. \nHowever, writing these specifications manually is time-consuming, error-prone, and \nrequires deep domain expertise. In this paper, we explore the feasibility of using\nCites: Can LLMs Reason About Program Semantics? A Comprehensive", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11130130/&hl=en&sa=X&d=1833485915756417544&ei=6N2zaPqNL4XR6rQP27rbgAs&scisig=AAZF9b8rc8dksCWHyDLd6ykXBOlH&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=0&folt=cit", "author": ["Bach Le"], "ref": ["7 new citations to articles by Bach Le", "5 new citations to articles by Thanh Le-Cong"]}
{"title": "An AI-powered pipeline for enabling Self-Healing in Software Systems", "first_label": [], "second_label": [], "data": "G Siachamis, G Papadopoulos, AL Symeonidis- 2025 IEEE International Conference, 2025\nThe continuous digitisation of all types of data and business information, although \nundoubtedly beneficial, has triggered an exponential rise to security risks, as more \nattack vectors are introduced at a high frequency. To facilitate the process of \nsuppressing security threats to software, we present an AI-powered pipeline that \nenables developers to mitigate security alerts identified by security assessment \nreports generated by popular open source security tools. The proposed pipeline\nCites: Comparison of static application security testing tools and large", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11130137/&hl=en&sa=X&d=9966959413278561935&ei=6N2zaPqNL4XR6rQP27rbgAs&scisig=AAZF9b_iZKpa5ZeT4pmQniUd477v&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=1&folt=cit", "author": ["Bach Le"], "ref": ["7 new citations to articles by Bach Le", "1 new citation to articles by Quang-Cuong Bui", "5 new citations to articles by Thanh Le-Cong", "6 new citations to articles by Xin ZHOU", "4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Evaluation of the Code Generated By Large Language Models: The State of the Art", "first_label": ["LLM", "Code"], "second_label": [], "data": "Z Ying, D Towey, Y Zhang- 2025 IEEE 49th Annual Computers, Software, and, 2025\nThe rapid development of Large Language Models (LLMs), such as ChatGPT and \nDeepSeek, has revolutionized software development, particularly in the domain of \nautomated code generation. These models, built on architectures like the \nTransformer, have demonstrated remarkable capabilities in generating human-like \ntext and source code, significantly enhancing developer productivity and reducing \ndevelopment time. However, the widespread adoption of LLMs for code generation\nCites: Refining chatgpt-generated code: Characterizing and mitigating", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11126696/&hl=en&sa=X&d=12484343861239898882&ei=6N2zaPqNL4XR6rQP27rbgAs&scisig=AAZF9b_7wjcMe67kD6SY7gom0tNW&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=2&folt=cit", "author": ["Bach Le"], "ref": ["7 new citations to articles by Bach Le", "5 new citations to articles by Thanh Le-Cong"]}
{"title": "VFProber: A Vulnerability-Fixing Identification Framework Based on Code Changes and Semantic Adjustment", "first_label": ["Vulnerabilities", "Code", "Code Change"], "second_label": [], "data": "J Dong, G Fan, Y Yu, Y Liang, Y Ye, H Yu, W Chen- 2025 IEEE 49th Annual, 2025\nWith the accelerated development of software, developers face the continuous \nchallenge of fixing vulnerabilities but vulnerability-fixing commits often disassociated \nfrom the vulnerabilities, and the structural and semantic differences between code \nchanges and natural language present significant challenges in identifying these \ncommits. Existing approaches utilize machine learning and deep learning \ntechniques to address this problem, but they often do not fully leverage the\nCites: Multi-granularity detector for vulnerability fixes", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11126599/&hl=en&sa=X&d=10091484810073408440&ei=6N2zaPqNL4XR6rQP27rbgAs&scisig=AAZF9b_ERuwIhuYdUW8lIULXjpL1&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=3&folt=cit", "author": ["Bach Le"], "ref": ["7 new citations to articles by Bach Le", "5 new citations to articles by Thanh Le-Cong", "7 new citations to articles by Hong Jin Kang"]}
{"title": "Research Directions in Software Supply Chain Security", "first_label": [], "second_label": ["Search"], "data": "I RAHMAN, M TAMANNA, G TYSTAHL, N ZAHAN - 2025\nThe modern world relies on digital innovation in almost every human endeavor, \nincluding critical infrastructure. Digital innovation has accelerated substantially as \nsoftware is increasingly built with layers of reusable abstractions, including libraries, \nframeworks, cloud infrastructure, and AI modules. This style of software development \nis considered a software supply chain where software projects depend on and build \nupon other software projects. Based upon its analysis of 1,067 commercial code\nCites: Vulcurator: a vulnerability-fixing commit detector", "link": "https://scholar.google.com/scholar_url?url=https://www.kapravelos.com/publications/tosem-directions.pdf&hl=en&sa=X&d=15468523295392098242&ei=6N2zaPqNL4XR6rQP27rbgAs&scisig=AAZF9b9TufW503PQh-LPbCpZV45e&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=4&folt=cit", "author": ["Bach Le"], "ref": ["7 new citations to articles by Bach Le", "5 new citations to articles by Thanh Le-Cong", "7 new citations to articles by Hong Jin Kang"]}
{"title": "A Blockchain-based cross-platform authentication scheme for EV aggregate charging platform", "first_label": ["Blockchain"], "second_label": [], "data": "T Yuan, Y He, P Xiao, K Xiao, B Wu- Cybersecurity, 2025\nWith the development of electric vehicles, charging stations have garnered \nsignificant attention and progress. As a result, various charging platforms have \nemerged. However, due to the lack of shared charging information, issues such as \nlow utilization of charging stations during peak hours and insufficient station \navailability have negatively impacted user experience. Inspired by the concept of an \naggregation platform, we propose an aggregated charging platform for electric\nCites: Smart contract development: Challenges and opportunities", "link": "https://scholar.google.com/scholar_url?url=https://cybersecurity.springeropen.com/articles/10.1186/s42400-025-00355-8&hl=en&sa=X&d=16508338657620145573&ei=6N2zaPqNL4XR6rQP27rbgAs&scisig=AAZF9b9wKQDI2Xevd1Xvau3wiDxd&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=5&folt=cit", "author": ["Bach Le"], "ref": ["7 new citations to articles by Bach Le"]}
{"title": "Immutable Digital Recognition via Blockchain", "first_label": ["Blockchain"], "second_label": [], "data": "Z Zhang, X Li- arXiv preprint arXiv:2508.18750, 2025\nThe process integrates the decentralised management and centralised operation \nmodels, aligning them with the national policy directives. The developed solution \nenables the full utilisation of blockchain technology's advantages while also fostering \ncommunity participation. Consequently, it establishes a secure, legal, reliable, and \ndynamic electronic certification system.\nCites: Smart contract development: Challenges and opportunities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.18750&hl=en&sa=X&d=6837037584227388350&ei=6N2zaPqNL4XR6rQP27rbgAs&scisig=AAZF9b9j_XLtwkXrbWfVeVQU-hyT&oi=scholaralrt&hist=ylyK0_8AAAAJ:4974034551180671527:AAZF9b-CBry8NrRagz6L4gSOAv5X&html=&pos=6&folt=cit", "author": ["Bach Le"], "ref": ["7 new citations to articles by Bach Le"]}
{"title": "Automated Bug Frame Retrieval from Gameplay Videos Using Vision-Language Models", "first_label": ["LLM", "Bug"], "second_label": [], "data": "W Lu, A Senchenko, A Hindle, CP Bezemer- arXiv preprint arXiv:2508.04895, 2025\nModern game studios deliver new builds and patches at a rapid pace, generating \nthousands of bug reports, many of which embed gameplay videos. To verify and \ntriage these bug reports, developers must watch the submitted videos. This manual", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.04895&hl=en&sa=X&d=11413311830969918411&ei=6d2zaNvcDIvWieoPpLaliQQ&scisig=AAZF9b-NCiqpLdz5tIxck1-Y0eW_&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=0&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "Bach Le - new related research", "Xin ZHOU - new related research", "Abhik Roychoudhury - new related research"]}
{"title": "Does AI Code Review Lead to Code Changes? A Case Study of GitHub Actions", "first_label": ["Code Review", "Code", "Code Change"], "second_label": [], "data": "K Sun, H Kuang, S Baltes, X Zhou, H Zhang, X Ma- arXiv preprint arXiv, 2025\nAI-based code review tools automatically review and comment on pull requests to \nimprove code quality. Despite their growing presence, little is known about their \nactual impact. We present a large-scale empirical study of 16 popular AI-based code", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.18771&hl=en&sa=X&d=1087042547895093020&ei=6d2zaNvcDIvWieoPpLaliQQ&scisig=AAZF9b8tPdgA8_g47l6rpQckHRi_&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=1&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Thanh Le-Cong - new related research", "Hong Jin Kang - new related research", "6 new citations to articles by Xin ZHOU"]}
{"title": "The Influence of Code Comments on the Perceived Helpfulness of Stack Overflow Posts", "first_label": ["Code"], "second_label": [], "data": "K Figl, M Kirchner, S Baltes, M Felderer- arXiv preprint arXiv:2508.19610, 2025\nQuestion-and-answer platforms such as Stack Overflow have become an important \nway for software developers to share and retrieve knowledge. However, reusing \npoorly understood code can lead to serious problems, such as bugs or security", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.19610&hl=en&sa=X&d=18228892591081713851&ei=6d2zaNvcDIvWieoPpLaliQQ&scisig=AAZF9b95EV84xcxfab741iP0LzEY&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=3&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research"]}
{"title": "Together We Are Better: LLM, IDE and Semantic Embedding to Assist Move Method Refactoring", "first_label": ["LLM"], "second_label": [], "data": "A Bellur, F Batole, MR Ullah, M Dilhara, Y Zharov\nMOVEMETHOD is a hallmark refactoring. Despite a plethora of research tools that \nrecommend which methods to move and where, these recommendations do not \nalign with how expert developers perform MOVEMETHOD. Given the extensive\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nDavid Lo\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://danny.cs.colorado.edu/papers/ICSME25_MM-Assist.pdf&hl=en&sa=X&d=17436443422942948018&ei=6d2zaNvcDIvWieoPpLaliQQ&scisig=AAZF9b9g2uoTGnzhsnQCpHyGa4Ms&oi=scholaralrt&hist=ylyK0_8AAAAJ:5865787842749446205:AAZF9b9CiGf-firBvlixUlAEJTz9&html=&pos=4&folt=rel", "author": ["David Lo"], "ref": ["David Lo - new related research", "Hong Jin Kang - new related research"]}
{"title": "SIExVulTS: Sensitive Information Exposure Vulnerability Detection System using Transformer Models and Static Analysis", "first_label": ["Vulnerabilities", "Static Analysis"], "second_label": ["Detection"], "data": "K Katz, S Moshtari, I Mujhid, M Mirakhorli, D Garcia- arXiv preprint arXiv:2508.19472, 2025\nSensitive Information Exposure (SIEx) vulnerabilities (CWE-200) remain a persistent \nand under-addressed threat across software systems, often leading to serious \nsecurity breaches. Existing detection tools rarely target the diverse subcategories of", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.19472&hl=en&sa=X&d=7796505405812517065&ei=6N2zaIXvEvmi6rQPgs_o-AI&scisig=AAZF9b_N_o9MHRnErNEAJe_2k9p9&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=2&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research", "Quang-Cuong Bui - new related research"]}
{"title": "Prompting Matters: Assessing the Effect of Prompting Techniques on LLM-Generated Class Code", "first_label": ["LLM", "Code"], "second_label": [], "data": "A Yuen, J Pangas, MMH Polash, A Abdellatif\nThe field of software engineering and coding has undergone a significant \ntransformation. The integration of large language models (LLMs), such as ChatGPT, \ninto software development workflows is changing how developers at all skill levels\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nThanh Le-Cong\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Ahmad-Abdellatif-2/publication/394255549_Prompting_Matters_Assessing_the_Effect_of_Prompting_Techniques_on_LLM-Generated_Class_Code/links/688f775d86911c11bfed27c8/Prompting-Matters-Assessing-the-Effect-of-Prompting-Techniques-on-LLM-Generated-Class-Code.pdf&hl=en&sa=X&d=1370100941342347490&ei=6N2zaIXvEvmi6rQPgs_o-AI&scisig=AAZF9b8Vnec2OY49V3WcHZYAdXYP&oi=scholaralrt&hist=ylyK0_8AAAAJ:4812769200119993430:AAZF9b_1MT--9phVV-34dqGZeQFI&html=&pos=3&folt=rel", "author": ["Thanh Le-Cong"], "ref": ["Thanh Le-Cong - new related research"]}
{"title": "i7Fuzzer: Neural-Guided Fuzzing for Enhancing Security Testing of Stateful Protocols", "first_label": ["Fuzzing", "Software Testing"], "second_label": [], "data": "L Al Sardy, AR Prasad, R German- Conference on Computer Safety, Reliability, and, 2025\nThis article proposes i7Fuzzer, a hybrid fuzzing framework designed to enhance the \nsecurity testing of stateful communication protocols such as Real-Time Streaming \nProtocol (RTSP) and Message Queuing Telemetry Transport (MQTT). These", "link": "https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-3-032-02018-5_9&hl=en&sa=X&d=15492249647143212662&ei=6t2zaLTxLp6s6rQPxqLhuQI&scisig=AAZF9b8QYUyDOPDhvzOStj7tO8qZ&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=1&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Three Large Language Models for Solidity Smart Contract Vulnerability Detection", "first_label": ["Vulnerabilities", "Smart Contracts", "LLM"], "second_label": ["Detection"], "data": "A Almaghthawi, WMS Yafooz, NS Albalawi- Journal of Artificial Intelligence and, 2025\nIn decentralized apps, smart contracts are used to conduct trusted transactions on \nthe Blockchain (BC). While smart contracts are highly effective, they are also highly \nsusceptible to security flaws, leading to serious financial consequences. However", "link": "https://scholar.google.com/scholar_url?url=https://ojs.istp-press.com/jait/article/download/811/633&hl=en&sa=X&d=2293700346610362010&ei=6t2zaLTxLp6s6rQPxqLhuQI&scisig=AAZF9b8rRBtNxFhvv4fjpSNhPebz&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=2&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "LLM as an Execution Estimator: Recovering Missing Dependency for Practical Time-travelling Debugging", "first_label": ["LLM", "Bug"], "second_label": [], "data": "Y Pei, H Wang, W Zhang, Y Lin, W Kong- arXiv preprint arXiv:2508.18721, 2025\nDynamic data dependency, answering\" why a variable has this value?\", is critical for \ndebugging. Given a program stepsreading a variablev, finding the dynamic definition \nofvis challenging. Traditional methods require either (1) exhaustive instrumentation", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.18721&hl=en&sa=X&d=9469297087740937979&ei=6t2zaLTxLp6s6rQPxqLhuQI&scisig=AAZF9b99kfXihCB2m5Hyo4na6QuH&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=4&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "FragmentFool: Fragment-based Adversarial Perturbation for Graph Neural Network-based Vulnerability Detection", "first_label": ["Vulnerabilities"], "second_label": ["Detection", "Graph"], "data": "MF Rozi, T Ban, S Ozawa, H Inoue, T Takahashi\nSoftware vulnerability detection has achieved promising performance using graph \nneural networks (GNNs) to capture structural information in source code graph \nrepresentations. However, these methods are vulnerable to various attacks", "link": "https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Muhammad-Rozi-5/publication/394295349_FragmentFool_Fragment-based_Adversarial_Perturbation_for_Graph_Neural_Network-based_Vulnerability_Detection/links/6891926f6e1ad24f59edab84/FragmentFool-Fragment-based-Adversarial-Perturbation-for-Graph-Neural-Network-based-Vulnerability-Detection.pdf&hl=en&sa=X&d=6441262819501010184&ei=6t2zaLTxLp6s6rQPxqLhuQI&scisig=AAZF9b_MGW925MPYxH1t2vaBnR_K&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=5&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Mining GitHub Software Repositories to Look for Programming Language Cocktails", "first_label": [], "second_label": [], "data": "J Loureiro, A Costa Neto, MJV Pereira, PR Henriques- 14th Symposium on, 2025\nIn light of specific development needs, it is common to concurrently apply different \ntechnologies to build complex applications. Given that lowering risks, costs, and \nother negative factors, while improving their positive counterparts is paramount to a", "link": "https://scholar.google.com/scholar_url?url=https://drops.dagstuhl.de/storage/01oasics/oasics-vol135-slate2025/OASIcs.SLATE.2025.13/OASIcs.SLATE.2025.13.pdf&hl=en&sa=X&d=10789262385929385618&ei=6t2zaLTxLp6s6rQPxqLhuQI&scisig=AAZF9b8UxM7ZN3xvEAjAVGy4C18R&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=7&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "A transformer-based framework for software vulnerability detection using attention-driven convolutional neural networks", "first_label": ["Vulnerabilities"], "second_label": ["Detection"], "data": "A Smaili, Y Zhang, DE Mekkaoui, MA Midoun- Engineering Applications of, 2025\nIn the realm of software systems and quality assurance, vulnerability identification \nhas become a critical concern in today's connected world. Vulnerabilities not only \nmake systems less effective, but they also pose significant risks to user privacy and\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nHong Jin Kang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0952197625018615&hl=en&sa=X&d=12459478534958660377&ei=6t2zaLTxLp6s6rQPxqLhuQI&scisig=AAZF9b8TIWSrstdPEDjHTDy_b6tt&oi=scholaralrt&hist=ylyK0_8AAAAJ:17903213248891513419:AAZF9b_VfgOz15WyMBkfhPNIM3wy&html=&pos=8&folt=rel", "author": ["Hong Jin Kang"], "ref": ["Hong Jin Kang - new related research"]}
{"title": "Generative Interfaces for Language Models", "first_label": ["LLM"], "second_label": [], "data": "J Chen, Y Zhang, Y Zhang, Y Shao, D Yang- arXiv preprint arXiv:2508.19227, 2025\nLarge language models (LLMs) are increasingly seen as assistants, copilots, and \nconsultants, capable of supporting a wide range of tasks through natural \nconversation. However, most systems remain constrained by a linear request\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nBach Le\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.19227&hl=en&sa=X&d=16741735202537041853&ei=592zaIr0MeDM6rQPycS0-AI&scisig=AAZF9b_WOVSvgnsSNkTkYD0YU0HR&oi=scholaralrt&hist=ylyK0_8AAAAJ:4328508672846969495:AAZF9b9vPVpCbQIEUDOQKatBd4_T&html=&pos=1&folt=rel", "author": ["Bach Le"], "ref": ["Bach Le - new related research"]}
{"title": "Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks", "first_label": ["LLM"], "second_label": [], "data": "S Liu, Q Sheng, D Wang, Y Li, G Yang, J Cao- arXiv preprint arXiv:2508.20038, 2025\nDespite advances in improving large language model (LLM) to refuse to answer \nmalicious instructions, widely used LLMs remain vulnerable to jailbreak attacks \nwhere attackers generate instructions with distributions differing from safety", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.20038&hl=en&sa=X&d=11499997617504089069&ei=6t2zaOzXGKbT6rQPheXy8Aw&scisig=AAZF9b_-SljSalMA3Nr3eqFvnpKe&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=0&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Gradient Surgery for Safe LLM Fine-Tuning", "first_label": ["LLM"], "second_label": [], "data": "B Yi, J Li, B Zhang, L Nie, T Li, T Huang, Z Liu- arXiv preprint arXiv:2508.07172, 2025\nFine-tuning-as-a-Service introduces a critical vulnerability where a few malicious \nexamples mixed into the user's fine-tuning dataset can compromise the safety \nalignment of Large Language Models (LLMs). While a recognized paradigm frames", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.07172&hl=en&sa=X&d=10352052812613128560&ei=6t2zaOzXGKbT6rQPheXy8Aw&scisig=AAZF9b_-UmhxxnT9CjoTuoEHfdfM&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=1&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Prompt-in-Content Attacks: Exploiting Uploaded Inputs to Hijack LLM Behavior", "first_label": ["LLM"], "second_label": ["Exploit"], "data": "Z Lian, W Wang, Q Zeng, T Nakanishi, T Kitasuka, C Su- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) are widely deployed in applications that accept user-\nsubmitted content, such as uploaded documents or pasted text, for tasks like \nsummarization and question answering. In this paper, we identify a new class of", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.19287&hl=en&sa=X&d=15365588001769154326&ei=6t2zaOzXGKbT6rQPheXy8Aw&scisig=AAZF9b9zRkfat5KvxBryPsOOoLQF&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=2&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "SafeConstellations: Steering LLM Safety to Reduce Over-Refusals Through Task-Specific Trajectory", "first_label": ["LLM"], "second_label": [], "data": "U Maskey, S Yadav, M Dras, U Naseem- arXiv preprint arXiv:2508.11290, 2025\nLLMs increasingly exhibit over-refusal behavior, where safety mechanisms cause \nmodels to reject benign instructions that superficially resemble harmful content. This \nphenomena diminishes utility in production applications that repeatedly rely on", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.11290&hl=en&sa=X&d=4418065858919549735&ei=6t2zaOzXGKbT6rQPheXy8Aw&scisig=AAZF9b_590TBu9nutdVdOeEXPNS5&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=3&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "M Phute, R Balakrishnan- arXiv preprint arXiv:2508.08521, 2025\nVision Language Models (VLMs) are increasingly being used in a broad range of \napplications, bringing their security and behavioral control to the forefront. While \nexisting approaches for behavioral control or output redirection, like system", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.08521%3F&hl=en&sa=X&d=3389705349380814363&ei=6t2zaOzXGKbT6rQPheXy8Aw&scisig=AAZF9b_q3Y2_Sm63cdpM1VXa1B78&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=4&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "A Survey on the Feedback Mechanism of LLM-based AI Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Z Liu, X Bai, K Chen, X Chen, X Li, Y Xiang, J Liu\nLarge language models (LLMs) are increasingly being adopted to develop general-\npurpose AI agents. However, it remains challenging for these LLM-based AI agents \nto efficiently learn from feedback and iteratively optimize their strategies. To address", "link": "https://scholar.google.com/scholar_url?url=https://ijcai-preprints.s3.us-west-1.amazonaws.com/2025/8835.pdf&hl=en&sa=X&d=14511738061688557547&ei=6t2zaOzXGKbT6rQPheXy8Aw&scisig=AAZF9b-4ZyHqXzP38qhsex58ULA6&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=5&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "GeoShield: Safeguarding Geolocation Privacy from Vision-Language Models via Adversarial Perturbations", "first_label": ["LLM"], "second_label": [], "data": "X Liu, X Jia, Y Xun, S Qin, X Cao- arXiv preprint arXiv:2508.03209, 2025\nVision-Language Models (VLMs) such as GPT-4o now demonstrate a remarkable \nability to infer users' locations from public shared images, posing a substantial risk to \ngeoprivacy. Although adversarial perturbations offer a potential defense, current", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.03209%3F&hl=en&sa=X&d=13915240034089835371&ei=6t2zaOzXGKbT6rQPheXy8Aw&scisig=AAZF9b-R0Q7j1ojvvDmMFEqYjWc6&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=6&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Language-Specific Layer Matters: Efficient Multilingual Enhancement for Large Vision-Language Models", "first_label": ["LLM"], "second_label": [], "data": "Y Fan, Y Wang, Y Mu, L Huang, B Li, X Feng, T Xiao- arXiv preprint arXiv, 2025\nLarge vision-language models (LVLMs) have demonstrated exceptional capabilities \nin understanding visual information with human languages but also exhibit an \nimbalance in multilingual capabilities. In this work, we delve into the multilingual", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.18381&hl=en&sa=X&d=13986681064510856087&ei=6t2zaOzXGKbT6rQPheXy8Aw&scisig=AAZF9b9LPWyWhGGZG8bklMuBcWrV&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=7&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "CCoRe: Cooperative-Competitive Reasoning LLM-based Multi-Agent Framework", "first_label": ["LLM"], "second_label": ["Agent", "Reasoning"], "data": "H Bouchtib, K Karboub, M Tabaa, M Hamlich - 2025\nAbstract Large Language Model-based Multi-Agent systems (LLM-MAS) emerged as \na promising approach for solving complex tasks and queries that go beyond Single-\nAgent systems' abilities. Cooperative-Competitive Reasoning LLM-based Multi", "link": "https://scholar.google.com/scholar_url?url=https://www.researchsquare.com/article/rs-7255220/latest&hl=en&sa=X&d=1667845995030354299&ei=6t2zaOzXGKbT6rQPheXy8Aw&scisig=AAZF9b-kUL7BEosn-k-Ec9m7xf-S&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=8&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Fine-tuning Vision-Language Models for Animal Behavior Analysis", "first_label": ["LLM"], "second_label": [], "data": "S Mamooler, H Qi, V Gabeff, S Montariol, A Bosselut- LLM for Scientific Discovery\nAnimal behavior analysis is fundamental to ethology, behavioral ecology, and \nneuroscience. Current methods typically use vision-only classifiers, which are task-\nspecific and limited to closed-vocabulary classification paradigms. Vision-language\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://openreview.net/pdf%3Fid%3DHVQ9MA5f7j&hl=en&sa=X&d=12438006064255978058&ei=6t2zaOzXGKbT6rQPheXy8Aw&scisig=AAZF9b-jW--lVUBzUfGFBuqpaHOP&oi=scholaralrt&hist=ylyK0_8AAAAJ:15287030194885030172:AAZF9b9ZGN1vUuxfG1GbOlvhloTS&html=&pos=9&folt=rel", "author": ["Richard Fang"], "ref": ["Richard Fang - new related research"]}
{"title": "Benchmarking LLMs for Unit Test Generation from Real-World Functions", "first_label": ["LLM", "Software Testing"], "second_label": ["Generation"], "data": "D Huang, JM Zhang, M Harman, Q Zhang, M Du- arXiv preprint arXiv, 2025\nRecently, large language models (LLMs) have shown great promise in automating \nunit test generation, significantly reducing the manual effort required by developers. \nTo effectively evaluate the capabilities of LLMs in this domain, it is crucial to have a\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.00408%3F&hl=en&sa=X&d=7634539076722696920&ei=6t2zaJDnI-fYieoPkKvSuAw&scisig=AAZF9b-FrmdI0-q-Mp5l8hREvGGF&oi=scholaralrt&hist=ylyK0_8AAAAJ:16898579961534012346:AAZF9b8mlk_JgC2UbDdCdga5r9UH&html=&pos=1&folt=rel", "author": ["Xin ZHOU"], "ref": ["Xin ZHOU - new related research"]}
{"title": "AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical Reasoning in Real-World Scenarios", "first_label": [], "second_label": ["Agent", "Reasoning"], "data": "L Alazraki, L Chen, A Brassard, J Stacey, HA Rahmani- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) have achieved high accuracy on complex \ncommonsense and mathematical problems that involve the composition of multiple \nreasoning steps. However, current compositional benchmarks testing these skills \ntend to focus on either commonsense or math reasoning, whereas LLM agents \nsolving real-world tasks would require a combination of both. In this work, we \nintroduce an Agentic Commonsense and Math benchmark (AgentCoMa), where\nCites: An LLM-as-Judge Metric for Bridging the Gap with Human", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.19988&hl=en&sa=X&d=6212777414657996216&ei=6t2zaK-KDfnSieoPxKLpgQ0&scisig=AAZF9b-xXGMLWblpHMygABJQlcMb&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=0&folt=cit", "author": ["Xin ZHOU"], "ref": ["6 new citations to articles by Xin ZHOU"]}
{"title": "VISION: Robust and Interpretable Code Vulnerability Detection Leveraging Counterfactual Augmentation", "first_label": ["Vulnerabilities", "Code"], "second_label": ["Detection"], "data": "D Egea, B Halder, S Dutta- arXiv preprint arXiv:2508.18933, 2025\nAutomated detection of vulnerabilities in source code is an essential cybersecurity \nchallenge, underpinning trust in digital systems and services. Graph Neural \nNetworks (GNNs) have emerged as a promising approach as they can learn \nstructural and logical code relationships in a data-driven manner. However, their \nperformance is severely constrained by training data imbalances and label noise. \nGNNs often learn'spurious' correlations from superficial code similarities, producing\nCites: Large language model for vulnerability detection: Emerging results", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.18933&hl=en&sa=X&d=8884776096476507213&ei=6t2zaK-KDfnSieoPxKLpgQ0&scisig=AAZF9b-nqxohJ1vj2A4dT-NyroLe&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=1&folt=cit", "author": ["Xin ZHOU"], "ref": ["6 new citations to articles by Xin ZHOU"]}
{"title": "FRCS-LLM: A Framework for Refining Code Summarization in Large Language Models via Pre-trained Models", "first_label": ["LLM", "Code"], "second_label": [], "data": "Y Wang, C Xie, W Zhang, X Qiu- 2025 IEEE 49th Annual Computers, Software, and, 2025\nTo enhance software development and maintenance efficiency, code summarization \nhas become a research hotspot. In recent years, due to the generation capabilities of \nLarge Language Models (LLMs), researchers have begun to propose LLMs into \ncode-related tasks. Existing code summarization techniques are insufficient due to \ntheir limited ability to deeply comprehend code structure and semantics, frequently \nyielding verbose or imprecise summaries. To address these challenges, we present\nCites: Large language model for vulnerability detection: Emerging results", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11126841/&hl=en&sa=X&d=2591652282520708493&ei=6t2zaK-KDfnSieoPxKLpgQ0&scisig=AAZF9b_L_Kmt0pGA-8RylLqEpUWx&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=4&folt=cit", "author": ["Xin ZHOU"], "ref": ["6 new citations to articles by Xin ZHOU"]}
{"title": "JIT-Align: A Semantic Alignment-Based Ranking Framework for Just-In-Time Defect Prediction", "first_label": ["Software Defect"], "second_label": [], "data": "Y Ye, H Yu, G Fan, Y Liang, J Dong, W Chen- 2025 IEEE 49th Annual Computers, 2025\nTo promptly identify software defects and prevent defective code changes from being \nintegrated into the repository, Just-In-Time Software Defect Prediction (JIT-SDP) has \ndemonstrated promising research findings. Recent studies have begun to utilize Pre-\ntrained Models (PTMs) for training and prediction, yet these models inherently \nimpose input length limitations, leading to forced truncation of inputs. However, \nprevious work has largely overlooked the impact of forced truncation, even though it\nCites: Simple or complex? together for a more accurate just-in-time defect\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nXin ZHOU\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11126559/&hl=en&sa=X&d=15464838415295184187&ei=6t2zaK-KDfnSieoPxKLpgQ0&scisig=AAZF9b9zrdROWxMS29rOjuY4yVKB&oi=scholaralrt&hist=ylyK0_8AAAAJ:15035864585353249078:AAZF9b__fNdZeFj1p33oPi7SBv6G&html=&pos=5&folt=cit", "author": ["Xin ZHOU"], "ref": ["6 new citations to articles by Xin ZHOU", "7 new citations to articles by Hong Jin Kang"]}
{"title": "Security Vulnerabilities in AI-Generated JavaScript: A Comparative Study of Large Language Models", "first_label": ["Vulnerabilities", "LLM"], "second_label": [], "data": "D Aydn,  Bahtiyar- 2025 IEEE International Conference on Cyber Security, 2025\nLarge Language Models (LLMs) have been widely used in software development, \nyet the security of AI-generated code remains a critical concern. This research \nexamines security vulnerabilities in JavaScript code generated by six LLMs, which\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nQuang-Cuong Bui\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11130176/&hl=en&sa=X&d=7884646507479183550&ei=6d2zaJWcJofC6rQPgLuo8Qc&scisig=AAZF9b82MUEj-il4alC_eykb4zP9&oi=scholaralrt&hist=ylyK0_8AAAAJ:11088443020050739259:AAZF9b_dlaF_l6JD6R93aQP1v_a_&html=&pos=1&folt=rel", "author": ["Quang-Cuong Bui"], "ref": ["Quang-Cuong Bui - new related research"]}
{"title": "Reliable Weak-to-Strong Monitoring of LLM Agents", "first_label": ["LLM"], "second_label": ["Agent"], "data": "N Kale, CBC Zhang, K Zhu, A Aich, P Rodriguez- arXiv preprint arXiv, 2025\nWe stress test monitoring systems for detecting covert misbehavior in autonomous \nLLM agents (eg, secretly sharing private information). To this end, we systematize a \nmonitor red teaming (MRT) workflow that incorporates:(1) varying levels of agent and \nmonitor situational awareness;(2) distinct adversarial strategies to evade the monitor, \nsuch as prompt injection; and (3) two datasets and environments--SHADE-Arena for \ntool-calling agents and our new CUA-SHADE-Arena, which extends\nCites: CVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.19461&hl=en&sa=X&d=7947164652712524894&ei=6N2zaOX9A4vWieoPpLaliQQ&scisig=AAZF9b80wbgHAOHa58QwfcvpGojg&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=0&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Y Liu, R Zhang, H Luo, Y Lin, G Sun, D Niyato, H Du- arXiv preprint arXiv, 2025\nAgentification serves as a critical enabler of Edge General Intelligence (EGI), \ntransforming massive edge devices into cognitive agents through integrating Large \nLanguage Models (LLMs) and perception, reasoning, and acting modules. These \nagents collaborate across heterogeneous edge infrastructures, forming multi-LLM \nagentic AI systems that leverage collective intelligence and specialized capabilities \nto tackle complex, multi-step tasks. However, the collaborative nature of multi-LLM\nCites: Llm agents can autonomously exploit one-day vulnerabilities\u00a0\u00a0\n\u00a0\nThis message was sent by Google Scholar because you're following new citations to articles written by \nRichard Fang\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.19870&hl=en&sa=X&d=5781896119950920734&ei=6N2zaOX9A4vWieoPpLaliQQ&scisig=AAZF9b9LbpscIm54FUTJigihgS-T&oi=scholaralrt&hist=ylyK0_8AAAAJ:4436498698466669065:AAZF9b-6dRec6PGUxNGKd2t3_e20&html=&pos=1&folt=cit", "author": ["Richard Fang"], "ref": ["2 new citations to articles by Richard Fang"]}
{"title": "Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards", "first_label": [], "second_label": [], "data": "Z Sun, D Li, Z Chen, Y Qin, B Hu- arXiv preprint arXiv:2508.10548, 2025\nReward sparsity in long-horizon reinforcement learning (RL) tasks remains a \nsignificant challenge, while existing outcome-based reward shaping struggles to \ndefine meaningful immediate rewards without introducing bias or requiring explicit", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.10548&hl=en&sa=X&d=7288484897495657661&ei=6d2zaNK_MprH6rQPsqDZkA8&scisig=AAZF9b_i0hCe3Vfb7_dMU2SQy8-a&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=0&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "RepoForge: Training a SOTA Fast-thinking SWE Agent with an End-to-End Data Curation Pipeline Synergizing SFT and RL at Scale", "first_label": [], "second_label": ["Agent"], "data": "Z Chen, C Zhao, B Chen, D Lin, Y Chen, A Leung- arXiv preprint arXiv, 2025\nTraining software engineering (SWE) LLMs is bottlenecked by expensive \ninfrastructure, inefficient evaluation pipelines, scarce training data, and costly quality \ncontrol. We present RepoForge, an autonomous, end-to-end pipeline that generates", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.01550&hl=en&sa=X&d=12917750125985049268&ei=6d2zaNK_MprH6rQPsqDZkA8&scisig=AAZF9b8q_RRH3F9AZVIud9uUY_eV&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=1&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "Unveiling the Potential of Massive Language Models in Software Engineering: Exploring Opportunities, Addressing Risks, and Comprehending Implications", "first_label": ["LLM"], "second_label": [], "data": "M Chugh- Textual Intelligence: Large Language Models and, 2025\nLarge language models, like GPT3.5, have brought about a fully innovative phase \nin software engineering with various potential challenges and transformative \nimplications. This book chapter evaluates the intricate scenario of using these", "link": "https://scholar.google.com/scholar_url?url=https://onlinelibrary.wiley.com/doi/abs/10.1002/9781394287499.ch15&hl=en&sa=X&d=3389390255331029623&ei=6d2zaNK_MprH6rQPsqDZkA8&scisig=AAZF9b9EJx6kpi2BoqL-moAIN7b-&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=3&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "You Don't Know Until You Click: Automated GUI Testing for Production-Ready Software Evaluation", "first_label": ["Software Testing"], "second_label": [], "data": "Y Bian, X Lin, Y Xie, T Liu, M Zhuge, S Lu, H Tang- arXiv preprint arXiv, 2025\nLarge Language Models (LLMs) and code agents in software development are \nrapidly evolving from generating isolated code snippets to producing full-fledged \nsoftware applications with graphical interfaces, interactive logic, and dynamic\n\u00a0\nThis message was sent by Google Scholar because you're following new articles related to research by \nAbhik Roychoudhury\n.\nList alerts\nCancel alert", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.14104%3F&hl=en&sa=X&d=6564100077162278532&ei=6d2zaNK_MprH6rQPsqDZkA8&scisig=AAZF9b-NKgaR19BxNPxl7Gh2cqVU&oi=scholaralrt&hist=ylyK0_8AAAAJ:12723761785867032729:AAZF9b9l_z1CTdTcNTkZbRX9RLem&html=&pos=4&folt=rel", "author": ["Abhik Roychoudhury"], "ref": ["Abhik Roychoudhury - new related research"]}
{"title": "VERIRL: Boosting the LLM-based Verilog Code Generation via Reinforcement Learning", "first_label": ["LLM", "Code"], "second_label": ["Generation"], "data": "F Teng, M Pan, X Zhang, Z He, Y Yang, X Chai, M Qi- arXiv preprint arXiv, 2025\nRecent advancements in code generation have shown remarkable success across \nsoftware domains, yet hardware description languages (HDLs) such as Verilog \nremain underexplored due to their concurrency semantics, syntactic rigidity, and \nsimulation complexity. In this work, we address these challenges by introducing a \nreinforcement learning (RL) framework tailored for Verilog code generation. We first \nconstruct Veribench-53K, a high-quality dataset curated from over 700K Verilog\nCites: ACECode: A Reinforcement Learning Framework for Aligning", "link": "https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2508.18462&hl=en&sa=X&d=7942433950117660905&ei=6N2zaJGSIYfC6rQPgLuo8Qc&scisig=AAZF9b8ZEH2YnCI74ZBIwCPsPnKd&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=0&folt=cit", "author": ["Hong Jin Kang"], "ref": ["7 new citations to articles by Hong Jin Kang"]}
{"title": "Nested Human-in-the-Loop AI: A Chain of Code Prompting Framework for Research Tool Development with GenAI", "first_label": ["Code"], "second_label": ["Search"], "data": "CF Atkinson - 2025\nThis article presents a novel, nested approach to Human-in-the-Loop (HITL) Artificial \nIntelligence (AI), utilising Chain of Code (CoC) prompting to iteratively develop AI-\nassisted research tools. Focusing on Generative AI (GenAI) systems such as \nChatGPT-4o, this article explores how nested HITL structureswhere expert \nfeedback is integrated at each developmental layercan drive AI outputs to meet \ndomain-specific needs. Through a case study involving a grey literature retrieval tool\nCites: Surveying neuro-symbolic approaches for reliable artificial", "link": "https://scholar.google.com/scholar_url?url=https://www.researchsquare.com/article/rs-5702366/latest&hl=en&sa=X&d=756580507982064017&ei=6N2zaJGSIYfC6rQPgLuo8Qc&scisig=AAZF9b9M_6_LQQWWG4x8jHD4TdFY&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=3&folt=cit", "author": ["Hong Jin Kang"], "ref": ["7 new citations to articles by Hong Jin Kang"]}
{"title": "MiniLib: A flow analysisbased approach for attack surface reduction through software debloating", "first_label": [], "second_label": [], "data": "L Kopanias, P Sotiropoulos, N Kolokotronis- 2025 IEEE International, 2025\nSoftware applications typically use libraries for the implementation of commonly used \ntasks. Each library encompasses an extensive collection of functionalities that cover \na specific task area, such as interfacing with a database. However, while applications \ntypically use a small subset of these functionalities, the unused ones are also \nbundled into the final distribution, due to the fact that the libraries are loaded and \nlinked as indivisible objects. The presence of unused functionalities in the\nCites: Automated identification of libraries from vulnerability data: Can we", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11129981/&hl=en&sa=X&d=15014830420250427126&ei=6N2zaJGSIYfC6rQPgLuo8Qc&scisig=AAZF9b_rYfOxJwwjCi_-qTrxXFrc&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=4&folt=cit", "author": ["Hong Jin Kang"], "ref": ["7 new citations to articles by Hong Jin Kang"]}
{"title": "oHIT-A framework for openHAB Interaction Threats Identification in IoT Systems", "first_label": [], "second_label": [], "data": "J Quantrill, N Khajehnouri, MH Alalfi- 2025 IEEE 49th Annual Computers, Software, 2025\nAs we increase our reliance upon Internet of Things (IoT) systems, we increase our \nconvenience and efficiency, but we also expose ourselves to significant safety \nchallenges, particularly in home automation platforms like openHAB. openHAB's rule-\nbased trigger-condition-action (TCA) paradigm allows for extensive flexibility in \ndesigning one's home system, but increases the risk of unintended rule interactions, \nleading to unpredictable or unsafe behaviors. This paper presents oHIT, a novel\nCites: Iotbox: Sandbox mining to prevent interaction threats in iot systems", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11126761/&hl=en&sa=X&d=6823629516333731157&ei=6N2zaJGSIYfC6rQPgLuo8Qc&scisig=AAZF9b9K43ptKp-GpINcCPVXQPdO&oi=scholaralrt&hist=ylyK0_8AAAAJ:4851239734318863641:AAZF9b8LH3KLAxOt2g9Q0Um21N4o&html=&pos=5&folt=cit", "author": ["Hong Jin Kang"], "ref": ["7 new citations to articles by Hong Jin Kang"]}
{"title": ":", "first_label": [], "second_label": [], "data": "- , 2025\n, (NPF) , NPF \n. , , \n, , . NPF \n, NPF , , , \nNPF , NPF . \nNPF , \nCites: Program Environment Fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://jeit.ac.cn/cn/article/pdf/preview/10.11999/JEIT250188.pdf&hl=en&sa=X&d=1608377314531828959&ei=6d2zaIHZGYXR6rQP27rbgAs&scisig=AAZF9b_fAXI3gIlnNkev4YyNjvxX&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=0&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "Intent-Driven Network Management with Multi-Agent LLMs: The Confucius Framework", "first_label": ["LLM"], "second_label": ["Agent"], "data": "Z Wang, S Lin, G Yan, S Ghorbani, M Yu, J Zhou, N Hu- Proceedings of the ACM, 2025\nAdvancements in Large Language Models (LLMs) are significantly transforming \nnetwork management practices. In this paper, we present our experience developing \nConfucius, a multi-agent framework for network management at Meta. We model \nnetwork management workflows as directed acyclic graphs (DAGs) to aid planning. \nOur framework integrates LLMs with existing management tools to achieve seamless \noperational integration, employs retrieval-augmented generation (RAG) to improve\nCites: Large language model guided protocol fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3718958.3750537&hl=en&sa=X&d=8322668407235313321&ei=6d2zaIHZGYXR6rQP27rbgAs&scisig=AAZF9b-SYFDA9bCWmVTRxVyuea3U&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=1&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
{"title": "AceCov: Auxiliary Composite Edge Coverage for Fuzzing", "first_label": ["Fuzzing"], "second_label": [], "data": "H Yoshida, Y Sugiyama, R Shioya- 2025 IEEE 10th European Symposium on, 2025\nSecurity flaws in software, including bugs and vulnerabilities, can cause serious \nissues, and fuzzing has been extensively studied and employed to identify them. A \ntypical fuzzer automatically generates test inputs and feeds back information \nobtained from executed programs for efficient software verification. As the feedback \ninformation, edge coverage, which is based on edge traversals in a control flow \ngraph, is widely used. We focus on branches whose results change depending on\nCites: Smart greybox fuzzing", "link": "https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11129392/&hl=en&sa=X&d=15601497705967739826&ei=6d2zaIHZGYXR6rQP27rbgAs&scisig=AAZF9b_uyyQv1Kqy3RF5Qnm4bary&oi=scholaralrt&hist=ylyK0_8AAAAJ:10071049626428824134:AAZF9b8j6D2HAFt59uW8wFlKdfsL&html=&pos=2&folt=cit", "author": ["Abhik Roychoudhury"], "ref": ["4 new citations to articles by Abhik Roychoudhury"]}
